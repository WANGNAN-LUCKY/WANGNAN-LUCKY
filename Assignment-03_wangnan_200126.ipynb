{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-03 First Step of Machine Learning: Model and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同学们，今天我们的学习了基本的机器学习概念，相比你已经对机器学习的这些方法有一个基本的认识了。值得说明的是，机器学习不仅仅是一系列方法，更重要的是一种思维体系，即：依据以往的、现有的数据，构建某种方法来解决未见过的问题。而且决策树，贝叶斯只是实现这个目标的一个方法，包括之后的神经网络。很有可能有一天，神经网络也会被淘汰，但是重要的是我们要理解机器学习的目标，就是尽可能的自动化解决未知的问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1571556399207&di=4a97dc15ad08dd49d3748d1edf6109b3&imgtype=0&src=http%3A%2F%2Fc.hiphotos.baidu.com%2Fzhidao%2Fwh%3D450%2C600%2Fsign%3Dae742c6aedcd7b89e93932873a146e91%2F5d6034a85edf8db1b16050c40223dd54574e74c7.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-1 Programming Review 编程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Re-code the Linear-Regression Model using scikit-learning(10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>： \n",
    "> + 是否完成线性回归模型 (4')\n",
    "+ 能够进行预测新数据(3')\n",
    "+ 能够进行可视化操作(3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.构建线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13892787, 0.72372588],\n",
       "       [0.81783187, 0.23424954],\n",
       "       [0.8776829 , 0.99889731],\n",
       "       [0.59450736, 0.39961234],\n",
       "       [0.4827306 , 0.38048092],\n",
       "       [0.78843334, 0.95963533],\n",
       "       [0.91371469, 0.03207241],\n",
       "       [0.7348447 , 0.08688479],\n",
       "       [0.81015842, 0.27565234],\n",
       "       [0.32406415, 0.48941717],\n",
       "       [0.30276748, 0.2145607 ],\n",
       "       [0.99632248, 0.10161956],\n",
       "       [0.99186243, 0.50662539],\n",
       "       [0.12523288, 0.47045069],\n",
       "       [0.72013539, 0.33778805],\n",
       "       [0.33424986, 0.04179337],\n",
       "       [0.37084433, 0.69255705],\n",
       "       [0.4576026 , 0.38218447],\n",
       "       [0.11729869, 0.7246643 ],\n",
       "       [0.95727604, 0.1223775 ],\n",
       "       [0.98749586, 0.13548684],\n",
       "       [0.99521049, 0.71439779],\n",
       "       [0.40953861, 0.97448446],\n",
       "       [0.91763579, 0.68515644],\n",
       "       [0.5854996 , 0.2825013 ],\n",
       "       [0.76499049, 0.30286989],\n",
       "       [0.9764078 , 0.290337  ],\n",
       "       [0.98938731, 0.94216691],\n",
       "       [0.85430473, 0.1906085 ],\n",
       "       [0.96324007, 0.65881584]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.random.random((30,2))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13892787 0.81783187 0.8776829  0.59450736 0.4827306  0.78843334\n",
      " 0.91371469 0.7348447  0.81015842 0.32406415 0.30276748 0.99632248\n",
      " 0.99186243 0.12523288 0.72013539 0.33424986 0.37084433 0.4576026\n",
      " 0.11729869 0.95727604 0.98749586 0.99521049 0.40953861 0.91763579\n",
      " 0.5854996  0.76499049 0.9764078  0.98938731 0.85430473 0.96324007] [0.72372588 0.23424954 0.99889731 0.39961234 0.38048092 0.95963533\n",
      " 0.03207241 0.08688479 0.27565234 0.48941717 0.2145607  0.10161956\n",
      " 0.50662539 0.47045069 0.33778805 0.04179337 0.69255705 0.38218447\n",
      " 0.7246643  0.1223775  0.13548684 0.71439779 0.97448446 0.68515644\n",
      " 0.2825013  0.30286989 0.290337   0.94216691 0.1906085  0.65881584]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = dataset[:, 0]\n",
    "Y = dataset[:, 1]\n",
    "print(X,Y)\n",
    "print(type(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assmuing_function(x):\n",
    "    # 在我们的日常生活中是常见的\n",
    "    # 体重 -> 高血压的概率\n",
    "    # 收入 -> 买阿玛尼的概率\n",
    "    # 其实都是一种潜在的函数关系 + 一个随机变化\n",
    "    return 13.4 * x + 5 + random.randint(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [assmuing_function(x) for x in X]\n",
    "# 每个y值都是一个医院线性函数的结果；每个一元线性模型的结构是一样的，参数不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x9eb6978>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)      # X是dataset随机生成的第一列; x是X中的元素； y是x function函数的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LinearRegression(fit_intercept=True, normalize=False, copy_X=True, n_jobs=None)\n",
    "fit_intercept:是否有截据，如果没有则直线过原点;\n",
    "normalize:是否将数据归一化;\n",
    "copy_X:默认为True，当为True时，X会被copied,否则X将会被覆写;\n",
    "n_jobs:默认值为1。计算时使用的核数\n",
    "'''\n",
    "reg = LinearRegression().fit(X.reshape(-1, 1), y)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993156161336413"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "【例子：reshape用法】指定 新数组X的列为“1”  reshape用法 （-1,2）列为2  （1，-1）行为1\n",
    "【例子：lineregression.score用法】： 返回：决定系数 R2\n",
    " R² =（1-u/v）。\n",
    " u=((y_true - y_pred) ** 2).sum()     v=((y_true - y_true.mean()) ** 2).sum()\n",
    " 决定系数用来评估线性模型预测精度： 最优值 = 1 ， 糟糕的结果可能为 负数  \n",
    "\"\"\"\n",
    "reg.score(X.reshape(-1, 1), y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.19169721])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "LinearRegression有两个属性intercept_和coef_，分别对应θ数组中的θ0(截距)  和θ1-θn（系数）， \n",
    "\"\"\"\n",
    "\n",
    "reg.coef_     #斜率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.217626231286404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_  #截距"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用训练数据 X ，y； 训练的 线性模型res中的（斜率 和 截距）构建一个新的模型 f（x）\n",
    "def f(x): \n",
    "    return reg.coef_ * x + reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa125a58>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.plot(X, f(X), color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.新数据集的预测与可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成新的数据集\n",
    "dataset_new_x = np.random.random((30,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.69650616]\n",
      " [0.70119823]\n",
      " [0.88251029]\n",
      " [0.01153717]\n",
      " [0.51836195]\n",
      " [0.07955428]\n",
      " [0.51931346]\n",
      " [0.28542102]\n",
      " [0.64634189]\n",
      " [0.01138326]\n",
      " [0.72081468]\n",
      " [0.74034409]\n",
      " [0.81848164]\n",
      " [0.12610291]\n",
      " [0.50566233]\n",
      " [0.15883807]\n",
      " [0.93478615]\n",
      " [0.31950411]\n",
      " [0.54439809]\n",
      " [0.04192424]\n",
      " [0.54129775]\n",
      " [0.98330508]\n",
      " [0.25969203]\n",
      " [0.89898148]\n",
      " [0.93154437]\n",
      " [0.1689254 ]\n",
      " [0.25156809]\n",
      " [0.31224241]\n",
      " [0.71813498]\n",
      " [0.16476235]] [[14.70921839]\n",
      " [14.76642274]\n",
      " [16.97692445]\n",
      " [ 6.35828396]\n",
      " [12.53733818]\n",
      " [ 7.18752792]\n",
      " [12.54893871]\n",
      " [ 9.69739284]\n",
      " [14.09763085]\n",
      " [ 6.35640748]\n",
      " [15.00558053]\n",
      " [15.2436772 ]\n",
      " [16.19630656]\n",
      " [ 7.75503467]\n",
      " [12.3825083 ]\n",
      " [ 8.15413193]\n",
      " [17.61425589]\n",
      " [10.11292356]\n",
      " [12.85476294]\n",
      " [ 6.72875383]\n",
      " [12.81696455]\n",
      " [18.20578403]\n",
      " [ 9.38371282]\n",
      " [17.17773617]\n",
      " [17.57473307]\n",
      " [ 8.2771136 ]\n",
      " [ 9.28466826]\n",
      " [10.02439119]\n",
      " [14.9729104 ]\n",
      " [ 8.22635896]]\n"
     ]
    }
   ],
   "source": [
    "#预测新数据 dataset_pre_y\n",
    "dataset_pre_y = f(dataset_new_x)\n",
    "print(dataset_new_x,dataset_pre_y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb193fd0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#新数据可视化  ---> 随机生成的data_new_x 通过f（x）线性函数，预测得到 dataset_pre_y\n",
    "plt.scatter(dataset_new_x, dataset_pre_y,color='green')\n",
    "plt.scatter(X,y)\n",
    "plt.plot(dataset_new_x,f(dataset_new_x), color='orange')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Complete the unfinished KNN Model using pure python to solve the previous Line-Regression problem. (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>:\n",
    "> + 是否完成了KNN模型 (4')\n",
    "+ 是否能够预测新的数据 (4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 完成KNN模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 4), (2, 5), (3, 6)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "zip() 用法\n",
    "用来 对 x ，y 配对成一个新的元组 ；\n",
    "\"\"\"\n",
    "a= [1,2,3] \n",
    "b=[4,5,6,]\n",
    "z= zip(a,b)\n",
    "print(list(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将 X，y 存储为：包含元组对列表【（x，y）】\n",
    "def model(X, y): \n",
    "    # 直接存储 X,y 即可\n",
    "    return [(Xi, yi) for Xi, yi in zip(X, y)]   #输出 x 与 y的元组对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "用于计算两个数组之间的余弦距离\n",
    "u和v之间的余弦距离定义为：                        \n",
    "输出：1- cos（u，v）\n",
    "\"\"\"\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(x1, x2):\n",
    "    return cosine(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sorted( key=)  基于 key的规则进行排序\n",
    "lambda 函数返回的是 distance return的 两个点的余弦距离 数据集 [xi 与 所有的x点] .升序排列\n",
    "[:k]代表 输出前 k个，距离最短的\n",
    "\"\"\"\n",
    "def predict(x, k=3):\n",
    "    # 在predicate的时候，需要做大量的计算\n",
    "    most_similars = sorted(model(X, y), key=lambda xi: distance(xi[0], x))[:k]    \n",
    "    y_hats = [_y for x, _y in most_similars]    \n",
    "    print(most_similars)    \n",
    "    return np.mean(y_hats)\n",
    "    # -> regression: numerical -> most_similars (y)\n",
    "    # -> classification: categorical -> most_similar (y)\n",
    "    \n",
    "    # 已经获得了最相似的数据集\n",
    "    # 然后呢，Counter() -> most_common() -> 就可以获得出现最多的这个y了   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 用KNN模型预测新数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成新的数据集\n",
    "dataset_new = np.random.random((30,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12286892 0.81661317 0.13659262 0.35782867 0.55449681 0.40804146\n",
      " 0.38584991 0.53677208 0.32271566 0.11042861 0.19089746 0.561252\n",
      " 0.3339653  0.88538827 0.47982296 0.32392076 0.23449038 0.37086121\n",
      " 0.09870263 0.71926404 0.35330543 0.02808929 0.95701958 0.7914537\n",
      " 0.68474231 0.93313995 0.7130431  0.41093073 0.78960249 0.06489259] [0.15566322 0.10535749 0.52921819 0.13622354 0.78730066 0.71192843\n",
      " 0.93928869 0.12075367 0.51419399 0.11765467 0.9496528  0.44551755\n",
      " 0.34262313 0.19553889 0.5933543  0.83929625 0.07240124 0.42920773\n",
      " 0.18222984 0.74011507 0.89792261 0.25842508 0.64209696 0.50014977\n",
      " 0.4353832  0.78972089 0.93634719 0.56734558 0.67446442 0.73547519]\n"
     ]
    }
   ],
   "source": [
    "X = dataset_new[:, 0]\n",
    "Y = dataset_new[:, 1]\n",
    "print(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y): \n",
    "    # 直接存储 X,y 即可\n",
    "    return [(Xi, yi) for Xi, yi in zip(X, y)]   #输出 x 与 y的元组对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.8166131749788934, 19.95894705859559), (0.13659261576979442, 16.76095091986808), (0.408041458170081, 14.565006787823581)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.094968255429084"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测 x=0.8 对应的 y值 （y值等于 与 x 余弦距离最近的3个点的y值的平均值）\n",
    "predict(0.8, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Re-code the Decision Tree, which could sort the features by salience. (12 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否实现了信息熵 (1' )\n",
    "+ 是否实现了最优先特征点的选择(5')\n",
    "+ 是否实现了持续的特征选则(6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 实现信息熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Counter({4: 3, 5: 3, 1: 1, 2: 1, 3: 1, 9: 1, 8: 1}) 计数次数\n",
    "for c in set(test): 依次输出 列表中的元素 \n",
    "\"\"\"\n",
    "\n",
    "def entropy(elements):\n",
    "    '''群体的混乱程度'''\n",
    "    counter = Counter(elements)\n",
    "    probs = [counter[c] / len(elements) for c in set(elements)]\n",
    "    ic(probs)\n",
    "    return - sum(p * np.log(p) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=[1,2,3,4,4,5,5,5,9,4,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.09090909090909091,\n",
      "            0.09090909090909091,\n",
      "            0.09090909090909091,\n",
      "            0.2727272727272727,\n",
      "            0.2727272727272727,\n",
      "            0.09090909090909091,\n",
      "            0.09090909090909091]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7986522062521288"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 实现最优特征值选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建数据集 \n",
    "事件 ： 判断一个人是不是产妇（有过，或正在有生产行为的人） ；  \n",
    "标签：  是 ，否\n",
    "特征：  性别，年龄，城市级别，收入,婚否\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = {\n",
    "    'gender':['F', 'F', 'F', 'F', 'M', 'M', 'M', 'F','M'],\n",
    "    'income': ['+10', '-10', '-10', '+10', '+10', '+10', '-10','+10','-10'],\n",
    "    'age': [\"30-39\", \"20-29\",\"30-39\" ,\"10-19\" ,\"20-29\" ,\"40-49\" ,\"50-59\" ,\"60-69\" ,\"30-39\"],\n",
    "    'city': [2, 4, 1, 2, 2, 3, 4,3,1],\n",
    "    'married':[1,1,1,1,0,1,0,1,1],\n",
    "    'born_baby':[1, 1, 1, 0, 0, 0, 0, 1, 0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>married</th>\n",
       "      <th>born_baby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>10-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>40-49</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>60-69</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  gender income    age  city  married  born_baby\n",
       "0      F    +10  30-39     2        1          1\n",
       "1      F    -10  20-29     4        1          1\n",
       "2      F    -10  30-39     1        1          1\n",
       "3      F    +10  10-19     2        1          0\n",
       "4      M    +10  20-29     2        0          0\n",
       "5      M    +10  40-49     3        1          0\n",
       "6      M    -10  50-59     4        0          0\n",
       "7      F    +10  60-69     3        1          1\n",
       "8      M    -10  30-39     1        1          0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分别计算“性别”，“年龄”，“收入”，“城市级别”，“婚否” 对于 有无生娃行为的熵；\n",
    "# 熵值最小的那个特征就是 最优的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6365141682948128\n",
      "1.3862943611198906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.42857142857142855, 0.5714285714285714]\n",
      "ic| probs"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3296613488547582\n",
      "2.715955709974649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": [1.0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6829081047004717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6365141682948128,\n",
       " 0.6829081047004717,\n",
       " 1.3296613488547582,\n",
       " 1.3862943611198906,\n",
       " 2.715955709974649]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split_by_gender: \n",
    "s_gender = entropy([1,1,1,0,1,0]) + entropy([0,0,0])\n",
    "print(s_gender)\n",
    "# split_by_income:\n",
    "s_income = entropy([1,0,0,1]) + entropy([1,1,0,0])\n",
    "print(s_income)\n",
    "# split_by_age:\n",
    "s_age = entropy([0]) + entropy([1,0]) + entropy([1,1,0]) + entropy([0]) + entropy([0])+ entropy([1])\n",
    "print(s_age)\n",
    "# split_by_city:\n",
    "s_city = entropy([1,0]) + entropy([1,0,0]) + entropy([0,1]) + entropy([1,0])\n",
    "print(s_city)\n",
    "# split_by_married:\n",
    "s_married = entropy([1,1,1,0,0,1,0]) + entropy([0,0])\n",
    "print(s_married)\n",
    "sorted([s_age,s_city,s_gender,s_income,s_married])\n",
    "# 排序结果： 性别<婚否<年龄<收入<城市"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_optimal_spilter(training_data: pd.DataFrame, target: str) -> str:  # 输入 训练数据（pd） ； 标签名（str）\n",
    "    x_fields = set(training_data.columns.tolist()) - {target}    # 训练集 -标签 ；分离出特征列    \n",
    "    spliter = None                                               # 初始化   \n",
    "    min_entropy = float('inf')                                   # 最小熵 默认为 “无穷大”    \n",
    "    for f in x_fields:                                           # f（str） 遍历 特征列\n",
    "        ic(f)                                                    \n",
    "        values = set(training_data[f])                           # 提取 特征f 对应的 values （set格式） \n",
    "        ic(values)     \n",
    "        for v in values:                                         # 提取 values 中的 value（str）\n",
    "            sub_spliter_1 = training_data[training_data[f] == v][target].tolist() # 切分矩阵： 提取f列，v行对应的标签值，存成list\n",
    "            #ic(sub_split_1)\n",
    "            # split by the current feature and one value\n",
    "            entropy_1 = entropy(sub_spliter_1)                  #  求出 sub_spliter_1 对应的熵1\n",
    "            ic(entropy_1)   \n",
    "            sub_spliter_2 = training_data[training_data[f] != v][target].tolist() # 切分矩阵：提取f列，非v行对应的标签值，存成list\n",
    "            #ic(sub_split_2)            \n",
    "            entropy_2 = entropy(sub_spliter_2)                  #  求出 sub_spliter_1 对应的熵2\n",
    "            ic(entropy_2)\n",
    "            entropy_v = entropy_1 + entropy_2                   #  求出 f列，v行 值 对应的熵\n",
    "            ic(entropy_v)\n",
    "            \n",
    "            if entropy_v < min_entropy:                        #  如果这个值小于 min ；它就是min\n",
    "                min_entropy = entropy_v\n",
    "                spliter = (f, v)                                #  输出 f 和 v 组成的元组 spliter\n",
    "    \n",
    "    print('spliter is: {}'.format(spliter))\n",
    "    print('the min entropy is: {}'.format(min_entropy))\n",
    "    \n",
    "    return spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_data = {\n",
    "    'gender':['F', 'F', 'F', 'M', 'M', 'M', 'M', 'F','F','M','M'],\n",
    "    'income': ['+10', '-10', '-10', '+10', '+10', '+10', '-10','+10','-10','+10','+10'],\n",
    "    'age': [\"30-39\", \"20-29\",\"30-39\" ,\"10-19\" ,\"20-29\" ,\"40-49\" ,\"50-59\" ,\"60-69\" ,\"30-39\",'20-29','20-29'],\n",
    "    'city': [2, 4, 1, 2, 2, 3, 4,3,1,4,4],\n",
    "    'married':[1,1,0,1,0,1,0,0,1,0,0],\n",
    "    'born_baby':[1, 1, 1, 0, 0, 0, 0, 1, 0,0,0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame.from_dict(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.2, 0.8]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.2, 0.8]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.625, 0.375]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [0.5714285714285714, 0.42857142857142855]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.7142857142857143, 0.2857142857142857]\n",
      "ic| probs: [0.7142857142857143, 0.2857142857142857]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [0.5714285714285714, 0.42857142857142855]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.7, 0.3]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.6, 0.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('gender', 'M')\n",
      "the min entropy is: 0.5004024235381879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('gender', 'M')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_the_optimal_spilter(dataset,\"born_baby\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 实现持续的特征选则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思路： \n",
    "【Step1】\n",
    "input ： 训练集1\n",
    "output：find_the_optimal_spilter   =》 熵最小的特征1 下面的v值 （f1，v1）  输出：（f1，v1） 对应的 事件概率  \n",
    "【Step2】 \n",
    "第1次 切分：      训练集2 = 训练集1【特征1【v！】】 \n",
    "     删除特征1：  训练集2 = del【特征1】\n",
    "input ： 训练集2 \n",
    "output ：find_the_optimal_spilter   =》 熵最小的特征2 下面的v值 （f2，v1）  输出：（f2，v1） 对应的 事件概率 \n",
    "【Step3】 \n",
    "第2次 切分： 训练集3 = 训练集2【特征2【v1！】】\n",
    "     删除特征2：  训练集3 = del【特征1】\n",
    "input ： 训练集3 \n",
    "output ：find_the_optimal_spilter   =》 熵最小的特征3 下面的v值 （f3，v1）  输出：（f3，v1） 对应的 事件概率 \n",
    "\n",
    "。。。。。。\n",
    "【Stepn】 \n",
    "第n-1次 切分： 训练集n = 训练集n-1【特征n-1【v1！】】\n",
    "input ： 训练集n \n",
    "output ：find_the_optimal_spilter   =》 熵最小的特征n 下面的v值 （fn，v1）  输出：（fn，v1） 对应的 事件概率\n",
    "\n",
    "n切分次数为 特征值的个数，因为每次切分，下次的输入会删减上一层的列； 列数-1 \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>married</th>\n",
       "      <th>born_baby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>10-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>40-49</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>60-69</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender income    age  city  married  born_baby\n",
       "0       F    +10  30-39     2        1          1\n",
       "1       F    -10  20-29     4        1          1\n",
       "2       F    -10  30-39     1        0          1\n",
       "3       M    +10  10-19     2        1          0\n",
       "4       M    +10  20-29     2        0          0\n",
       "5       M    +10  40-49     3        1          0\n",
       "6       M    -10  50-59     4        0          0\n",
       "7       F    +10  60-69     3        0          1\n",
       "8       F    -10  30-39     1        1          0\n",
       "9       M    +10  20-29     4        0          0\n",
       "10      M    +10  20-29     4        0          0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_optimal_spilter(training_data: pd.DataFrame, target: str) -> str:  # 输入 训练数据（pd） ； 标签名（str）\n",
    "    x_fields = set(training_data.columns.tolist()) - {target}    # 训练集 -标签 ；分离出特征列    \n",
    "    spliter = None                                               # 初始化   \n",
    "    min_entropy = float('inf')                                   # 最小熵 默认为 “无穷大”    \n",
    "    for f in x_fields:                                           # f（str） 遍历 特征列\n",
    "        #ic(f)                                                    \n",
    "        values = set(training_data[f])                           # 提取 特征f 对应的 values （set格式） \n",
    "        #ic(values)     \n",
    "        for v in values:                                         # 提取 values 中的 value（str）\n",
    "            sub_spliter_1 = training_data[training_data[f] == v][target].tolist() # 切分矩阵： 提取f列，v行对应的标签值，存成list\n",
    "            #ic(sub_split_1)\n",
    "            # split by the current feature and one value\n",
    "            entropy_1 = entropy(sub_spliter_1)                  #  求出 sub_spliter_1 对应的熵1\n",
    "            #ic(entropy_1)   \n",
    "            sub_spliter_2 = training_data[training_data[f] != v][target].tolist() # 切分矩阵：提取f列，非v行对应的标签值，存成list\n",
    "            #ic(sub_split_2)            \n",
    "            entropy_2 = entropy(sub_spliter_2)                  #  求出 sub_spliter_1 对应的熵2\n",
    "            #ic(entropy_2)\n",
    "            entropy_v = entropy_1 + entropy_2                   #  求出 f列，v行 值 对应的熵\n",
    "            #ic(entropy_v)\n",
    "            \n",
    "            if entropy_v <= min_entropy:                        #  如果这个值小于 min ；它就是min\n",
    "                min_entropy = entropy_v\n",
    "                spliter = (f, v)                                #  输出 f 和 v 组成的元组 spliter\n",
    "    \n",
    "    print('spliter is: {}'.format(spliter))\n",
    "    print('the min entropy is: {}'.format(min_entropy))\n",
    "    \n",
    "    return spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sustain_spilter (training_data: pd.DataFrame, target: str, n):\n",
    "    data = training_data \n",
    "    print('初始训练集')\n",
    "    print(data)\n",
    "    for i in range(n):\n",
    "   \n",
    "        spilter = find_the_optimal_spilter(data, target)  \n",
    "    #第一次切分\n",
    "        data = data[data[spilter[0]] != spilter[1]]\n",
    "        del data[spilter[0]]        \n",
    "        print(\"第{}次切分\".format(i+1))\n",
    "        print(data)        \n",
    "        i +=1\n",
    "        if i == n:\n",
    "            print('finish')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.2, 0.8]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.2, 0.8]\n",
      "ic| probs: [0.5, 0.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始训练集\n",
      "   gender income    age  city  married  born_baby\n",
      "0       F    +10  30-39     2        1          1\n",
      "1       F    -10  20-29     4        1          1\n",
      "2       F    -10  30-39     1        0          1\n",
      "3       M    +10  10-19     2        1          0\n",
      "4       M    +10  20-29     2        0          0\n",
      "5       M    +10  40-49     3        1          0\n",
      "6       M    -10  50-59     4        0          0\n",
      "7       F    +10  60-69     3        0          1\n",
      "8       F    -10  30-39     1        1          0\n",
      "9       M    +10  20-29     4        0          0\n",
      "10      M    +10  20-29     4        0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.625, 0.375]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [0.5714285714285714, 0.42857142857142855]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.7142857142857143, 0.2857142857142857]\n",
      "ic| probs: [0.7142857142857143, 0.2857142857142857]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.6666666666666666, 0.3333333333333333]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [0.75, 0.25]\n",
      "ic| probs: [0.5714285714285714, 0.42857142857142855]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.7, 0.3]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.6, 0.4]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('gender', 'M')\n",
      "the min entropy is: 0.5004024235381879\n",
      "第1次切分\n",
      "  income    age  city  married  born_baby\n",
      "0    +10  30-39     2        1          1\n",
      "1    -10  20-29     4        1          1\n",
      "2    -10  30-39     1        0          1\n",
      "7    +10  60-69     3        0          1\n",
      "8    -10  30-39     1        1          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.25, 0.75]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic|"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('age', '60-69')\n",
      "the min entropy is: 0.5623351446188083\n",
      "第2次切分\n",
      "  income  city  married  born_baby\n",
      "0    +10     2        1          1\n",
      "1    -10     4        1          1\n",
      "2    -10     1        0          1\n",
      "8    -10     1        1          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " probs: [1.0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.3333333333333333, 0.6666666666666666]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('city', 4)\n",
      "the min entropy is: 0.6365141682948128\n",
      "第3次切分\n",
      "  income  married  born_baby\n",
      "0    +10        1          1\n",
      "2    -10        0          1\n",
      "8    -10        1          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| probs: [1.0]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [0.5, 0.5]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: [1.0]\n",
      "ic| probs: []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('married', 1)\n",
      "the min entropy is: 0.6931471805599453\n",
      "第4次切分\n",
      "  income  born_baby\n",
      "2    -10          1\n",
      "spliter is: ('income', '-10')\n",
      "the min entropy is: 0.0\n",
      "第5次切分\n",
      "Empty DataFrame\n",
      "Columns: [born_baby]\n",
      "Index: []\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "Sustain_spilter (dataset, 'born_baby',n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Finish the K-Means using 2-D matplotlib (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否完成了KMeans模型，基于scikit-learning (3')\n",
    "+ 是否完成了可视化任务（5'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-2 Question and Answer 问答"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What's the *model*? why  all the models are wrong, but some are useful? (5 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "什么是“模型”？\n",
    "\n",
    "从数学的维度类比，模型相当于数学的函数；而函数的定义是定义域（input） 与 值域（output）的映射关系。迁移到“模型”的概念，我理解模型就是可以客观反映数据或事物之间规律的映射关系。\n",
    "\n",
    "人们如果掌握了某个“模型”，知道了定义域； 就可以预测模型输出的结果, 来做到提前的预测；评估，调优\n",
    "\n",
    "应用场景： 比如：工程上产量的预测 ； 经济上的财务预测； 医学传染病人的传播趋势.....等等\n",
    "\n",
    "\n",
    "对于“why all the models are wrong, but some are useful?”的理解\n",
    "\n",
    "人们对“客观世界”的认识是基于主观世界，人们所描述的“客观世界”其实是经过了人类认知加工后的“客观世界”的一种主观映射。\n",
    "比如： “地心说”，之所以认为地球是中心，因为观察者的“客观世界”就是这样子，太阳和星星围绕地球转。\n",
    "      而“日心说”，是站在另一个视角看同样的客体；得出了不同的结论； \n",
    "\n",
    "这里的例子有些“偏题”，我的意图是想说明，人类的对世界的认知是狭隘且片面的；因此当前构建出的所有“模型”都是具有一定的狭隘性，特殊性；而且会随着人类对客体事物认知的升级不断地自我优化，甚至被“颠覆”。 因此回答第一个问题： 所有的模型都是错误的， 原因在于人类固有认知的局限性，不可能找出“完美”的模型。\n",
    "\n",
    "后半句“模型是有用的” ，虽然我们无法找到“完美的模型”，但是生活，日常应用中，人类只要抓住一个或几个“主要矛盾”就可以解决大部分的问题；应用模型的预测来发现客观规律，指导生活和生产实践。因此很多专业领域都是基于模型来解决实际问题；\n",
    "\n",
    "比如： 经济学，医学，社会学，工业生产....。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对模型的理解是否正确,对模型的抽象性是否正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the underfitting and overfitting? List the reasons that could make model overfitting or underfitting. (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "欠拟合： 模型对训练集的训练效果不足，没有完全学习到数据应该辨识的特征；导致应用真实数据预测，效果不佳。\n",
    "过拟合： 模型对训练集过度学习，学习了训练集中的一些数据“噪音”（不具备普适性的特征）；导致模型在训练集表现超常，真实情况表现不佳。\n",
    "\n",
    "过拟合 和 欠拟合 原因？\n",
    "\n",
    "过拟合的根本原因：特征维度过多，模型假设过于复杂，参数过多，训练数据过少，噪声过多，导致拟合的函数完美的预测训练集，但对新数据的测试集预测结果差。 过度的拟合了训练数据，而没有考虑到泛化能力。因此需要减少特征维度，或者正则化降低参数值。\n",
    "\n",
    "欠拟合的根本原因：特征维度过少，模型过于简单，导致拟合的函数无法满足训练集，误差较大； 因此需要增加特征维度，增加训练数据。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对过拟合和欠拟合的理解是否正确 (3')\n",
    "+ 对欠拟合产生的原因是否理解正确(2')\n",
    "+ 对过拟合产生的原因是否理解正确(5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What's the precision, recall, AUC, F1, F2score. What are they mainly target on? (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "\n",
    "【1】Precision（精度） = 预测正确的正例数 / 所有预测的正例数 \n",
    "   精度用来表征 ： 预测结果为正的例子中，真正正确的正例数量 ； 反应的是模型输出结果的可靠度 \n",
    "   \n",
    "【2】Recall（召回率） = 预测正确的正例数 /所有真实的正例数\n",
    "   召回率用来表征： 所有的真实正例中，有多少结果被模型准确的识别预测出来，反应的是模型的对全部案例的覆盖度\n",
    "\n",
    "【3】F-score = （1+β**2）× PR / (β**2P + R ) \n",
    "当 β =1 时 是 F1-score 代表；P 与 R同样重要\n",
    "F1 = 2PR / （P+R） ；因为 精度和召回在真实场景中往往存在取舍矛盾；因此F1表征的是考虑P，R的综合效果 \n",
    "当 β>1 时 ，Recall 的权重变大； Precision权重变小； 比如 F2-score\n",
    "当 β＜1 时 ，Recall 的权重变小； Precision权重变大； \n",
    "\n",
    "   F1 或 F2 是用来调和 精度和召回率的综合评估指标 ；\n",
    "\n",
    "\n",
    "【4】AUC(Area under Curve)：Roc曲线下的面积，介于0.1和1之间。Auc作为数值可以直观的评价分类器的好坏，值越大越好。\n",
    "    首先AUC值是一个概率值，当你随机挑选一个正样本以及负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值，AUC值越\n",
    "\n",
    "ROC曲线是由负正类率和真正类率坐标系下，构成的曲线\n",
    "1、roc曲线：接收者操作特征(receiveroperating characteristic),roc曲线上每个点反映着对同一信号刺激的感受性。\n",
    "横轴：负正类率(false postive rate FPR)特异度，划分实例中所有负例占所有负例的比例；(1-Specificity)\n",
    "纵轴：真正类率(true postive rate TPR)灵敏度，Sensitivity(正类覆盖率)\n",
    "2针对一个二分类问题，将实例分成正类(postive)或者负类(negative)。但是实际中分类时，会出现四种情况.\n",
    "(1)若一个实例是正类并且被预测为正类，即为真正类(True Postive TP)\n",
    "(2)若一个实例是正类，但是被预测成为负类，即为假负类(False Negative FN)\n",
    "(3)若一个实例是负类，但是被预测成为正类，即为假正类(False Postive FP)\n",
    "(4)若一个实例是负类，但是被预测成为负类，即为真负类(True Negative TN)\n",
    "\n",
    "(1)真正类率(True Postive Rate)TPR: TP/(TP+FN),代表分类器预测的正类中实际正实例占所有正实例的比例。Sensitivity\n",
    "\n",
    "(2)负正类率(False Postive Rate)FPR: FP/(FP+TN)，代表分类器预测的正类中实际负实例占所有负实例的比例。1-Specificity\n",
    "\n",
    "(3)真负类率(True Negative Rate)TNR: TN/(FP+TN),代表分类器预测的负类中实际负实例占所有负实例的比例，TNR=1-FPR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 对precision, recall, AUC, F1, F2 理解是否正确(6‘)\n",
    "+ 对precision, recall, AUC, F1, F2的使用侧重点是否理解正确 (6’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Based on our course and yourself mind, what's the machine learning?  (8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "我理解的“机器学习”，概念上是用程序从“数据”中得到规律，再通过规律来服务现实的工作场景；\n",
    "\n",
    "更深层次意义的探讨；举一个真人学习的例子来类比：\n",
    "\n",
    "【方式一】： 老师教授了一个学生，某一个科目的某一类题目是怎么做的； 第一步审题，第二步分析问题和条件； 三步....最后写答之类的；\n",
    "\n",
    "应试教育的环境下，有些学生在这种模式下学习，可以快速掌握某一个类型的题目的解法；但是换了一个新的科目和题型，学生又要重新学习新的知识体系和解题步骤；\n",
    "\n",
    "\n",
    "【方式二】： 一个学生自己拿了一个练习册去刷题，刷题后查阅“答案”（监督学习），更正；若不查阅答案（无监督学习）；这个过程没有老师指导，学生自己从海量的练习题目中摸索规律，吸收了大量错误的经验，来提升最终的应试成绩。  \n",
    "\n",
    "\n",
    "方式一的方式是“专家系统” ；方式二的学习方式是“机器学习” ；  \n",
    "\n",
    "对于人类学习来说，普遍采用方式一；因为人类更容易做“知识的迁移”学习，举一反三 ； 当然也有不少“不聪明”的 学生在刷题海战术；从教学来说显然是低效的，不被提倡的。\n",
    "\n",
    "但是对于“机器”来说，机器属性上超越人的是“计算力”和“记忆”能力 ； 可以理解为，如果一个老师面对的是一个“不懂得举一反三，但是记忆力和计算力超过正常人数百倍”的问题学生？ 该选用什么方式让这个学生在考试中能做对更多的题目呢？ 显然方式二，对于“机器”这个学生来说更有效。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，是否能说出来机器学习这种思维方式和传统的分析式编程的区别（8'）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. \"正确定义了机器学习模型的评价标准(evaluation)， 问题基本上就已经解决一半\". 这句话是否正确？你是怎么看待的？ (8‘)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我认为这句话非常正确！ 解释如下：\n",
    "\n",
    "从项目的范畴来说； 机器学习只是解决业务问题的方法或工具； 最终对于项目是否成功，评价标准还是“是否解决了业务问题”，“解决的好不好？”，“ML项目上线前是什么状态，上线后是什么状态？” ，“是否产生了商业价值？”，这些问题才是一级问题。\n",
    "\n",
    "而题目中的评价标准“evaluation”，我理解应该是机器学习的输出结果的评价指标(比如：精度，召回率，F1，F2 ....)，这些评价指标属于二级问题；\n",
    "\n",
    "但是这些“二级指标” 恰恰是 “连接” 业务问题 与 技术工程，最关键的“桥梁” ； \n",
    "、\n",
    "这个桥梁的端是“业务侧”和“工程侧”\n",
    "（1）业务侧，评估指标的制定一定是基于真实的用户，最终交付的产品才具有可用性\n",
    "（2）工程侧，评估标准的制定，决定了“算法工程师”的技术选型，需要多少数据？训练周期等，才能达到业务要求。 \n",
    "\n",
    "举例说明： 比如 医疗上用CV技术识别 肺炎和健康人的X光片\n",
    "         假设： 肺炎的x光片是 “正例” ；那么我们是保“精度”还是“召回率”呢？ \n",
    "         在这个场景下，很显然是要保证“召回率” ； 精度低，只是会把大量的健康的人误诊为病人； 但是如果召回低，出现了漏判的情况，就会耽误肺炎患者病情，所以在这个场景下，评价指标【召回率】优先级要高于【精度】。\n",
    "         \n",
    "可见：后续70-80%的工作量，都是围绕着如何达成“evaluation”的评估指标；工程上达成了这个指标，代表了业务上该产品可以解决用户的问题；如果评估指标定义的不合理，或者方向不正确；很可能交付一款不可用的产品，浪费人力财力。         \n",
    "         \n",
    "         \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点> 开放式问题，主要看能理解评价指标对机器学习模型的重要性."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part-03 Programming Practice 编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In our course and previous practice, we complete some importance components of Decision Tree. In this problem, you need to build a **completed** Decision Tree Model. You show finish a `predicate()` function, which accepts three parameters **<gender, income, family_number>**, and outputs the predicated 'bought': 1 or 0.  (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码思路\n",
    "\n",
    "1. 训练集 ： 采用代码复现决策树的 dataset\n",
    "2. 模型函数 ：  函数Sustain_spilter 的输出做一些修改： 输出每一层的“特征名”，每一层最纯的特征结果的概率\n",
    "3. 训练模型 ： 利用数据集 输入构建的模型 输出： 决策树的层级和树杈关系\n",
    "4. 随机输入一组没有特征的数据;与生成的 决策树关系进行匹配 ； 找到最终“树杈”上的对应的结果； "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树结构\n",
    "\n",
    "第一层 ：（特征1） --- 结果1.1 对应的概率 \n",
    "                --- 非结果1.1 ==> 第二层 ：（特征2） --- 结果2.1 对应的概率\n",
    "                                                 --- 非结果2.1 ===> 第三层 （特征3）--- 结果3.1 对应的概率 \n",
    "                                                                                 --- 非结果3.1 ==> 特征4 .....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练集\n",
    "mock_data = {\n",
    "    'gender':['F', 'F', 'F', 'M', 'M', 'M', 'M', 'F','F','M','M','M','F','M','F'],\n",
    "    'income': ['+10', '-10', '-10', '+10', '+10', '+10', '-10','+10','-10','+10','+10','+10',\"-10\",'+10',\"-10\"],\n",
    "    'age': [\"30-39\", \"20-29\",\"30-39\" ,\"10-19\" ,\"20-29\" ,\"40-49\" ,\"50-59\" ,\"50-59\" ,\"30-39\",'30-39','20-29',\"50-59\" ,\"30-39\",'30-39','20-29'],\n",
    "    'city': [2, 4, 1, 2, 2, 3, 4,3,1,4,4,2,3,1,4],\n",
    "    'married':[1,1,1,1,0,1,0,1,1,0,1,1,1,0,1],\n",
    "    'born_baby':[1, 0, 1, 0, 0, 0, 0, 1, 0,0,0,0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.DataFrame.from_dict(mock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>married</th>\n",
       "      <th>born_baby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>10-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>40-49</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender income    age  city  married  born_baby\n",
       "0       F    +10  30-39     2        1          1\n",
       "1       F    -10  20-29     4        1          0\n",
       "2       F    -10  30-39     1        1          1\n",
       "3       M    +10  10-19     2        1          0\n",
       "4       M    +10  20-29     2        0          0\n",
       "5       M    +10  40-49     3        1          0\n",
       "6       M    -10  50-59     4        0          0\n",
       "7       F    +10  50-59     3        1          1\n",
       "8       F    -10  30-39     1        1          0\n",
       "9       M    +10  30-39     4        0          0\n",
       "10      M    +10  20-29     4        1          0\n",
       "11      M    +10  50-59     2        1          0\n",
       "12      F    -10  30-39     3        1          0\n",
       "13      M    +10  30-39     1        0          0\n",
       "14      F    -10  20-29     4        1          1"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#熵值计算函数 ；可以输出对应结果的概率值\n",
    "def entropy(elements):             \n",
    "    result_dict={}\n",
    "    counter = Counter(elements)\n",
    "    for c in set(elements):\n",
    "        probs = [counter[c] / len(elements)]\n",
    "        result_dict[c]= probs    \n",
    "        probs = [counter[c] / len(elements) for c in set(elements)]\n",
    "        #ic(probs)\n",
    "        entropy_value = -sum(p * np.log(p) for p in probs)    \n",
    "    return entropy_value ,result_dict  # # entropy函数 输出熵值，概率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6829081047004717, {0: [0.42857142857142855], 1: [0.5714285714285714]})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy([1,1,0,0,1,1,0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_the_optimal_spilter(training_data: pd.DataFrame, target: str) -> str:  # 输入 训练数据（pd） ； 标签名（str）\n",
    "    x_fields = set(training_data.columns.tolist()) - {target}    # 训练集 -标签 ；分离出特征列    \n",
    "    spliter = None                                               # 初始化   \n",
    "    min_entropy = float('inf')                                   # 最小熵 默认为 “无穷大”    \n",
    "    min_list=[]\n",
    "    for f in x_fields:                                           # f（str） 遍历 特征列\n",
    "        #ic(f)                                                    \n",
    "        values = set(training_data[f])                           # 提取 特征f 对应的 values （set格式） \n",
    "        #ic(values)     \n",
    "        for v in values:                                       # 提取 values 中的 value（str）\n",
    "            sub_spliter_1 = training_data[training_data[f] == v][target].tolist() # 切分矩阵：提取f列，v行对应的标签值，存成list\n",
    "            #ic(sub_split_1)\n",
    "            # split by the current feature and one value\n",
    "            entropy_1 = entropy(sub_spliter_1)[0]                  #  求出 sub_spliter_1 对应的熵1\n",
    "            result_1 = entropy(sub_spliter_1)[1]                   #  求出 sub_spliter_1 对应标签的概率分布(字典)\n",
    "            #ic(entropy_1)   \n",
    "            \n",
    "            if entropy_1 == 0 :\n",
    "                min_list.append(v)\n",
    "                        \n",
    "            sub_spliter_2 = training_data[training_data[f] != v][target].tolist() # 切分矩阵：提取f列，非v行对应的标签值，存成list\n",
    "            #ic(sub_split_2)            \n",
    "            \n",
    "            if sub_spliter_2 ==[]:\n",
    "                entropy_v = entropy_1\n",
    "            else: \n",
    "            #ic(sub_split_2)   \n",
    "                entropy_2 = entropy(sub_spliter_2)[0]                  #  求出 sub_spliter_1 对应的熵2\n",
    "            #ic(entropy_2)\n",
    "                result_2 = entropy(sub_spliter_2)[1]                #  求出 sub_spliter_2 对应标签的概率分布(字典)\n",
    "                entropy_v = entropy_1 + entropy_2                   #  求出 f列，v行 值 对应的熵\n",
    "            #ic(entropy_v)\n",
    "                        \n",
    "            \n",
    "            \n",
    "            if entropy_v < min_entropy:                        #  如果这个值小于 min ；它就是min\n",
    "                min_entropy = entropy_v\n",
    "                spliter = (f,v,result_1)\n",
    "                #if min_list == []:\n",
    "                #    pass\n",
    "                #else:\n",
    "                #    v = min_list[0]                                \n",
    "                #    spliter = (f,v)                                #  输出 f 和 v 组成的元组 spliter\n",
    "                                \n",
    "    \n",
    "    print('spliter is: {}'.format(spliter))\n",
    "    #print('结果是百分之{}的概率'.format(result_1)\n",
    "    print('the min entropy is: {}'.format(min_entropy))\n",
    "    \n",
    "    return spliter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliter is: ('age', '40-49', {0: [1.0]})\n",
      "the min entropy is: 0.5982695885852573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('age', '40-49', {0: [1.0]})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_the_optimal_spilter(data_train,target=\"born_baby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#切分并构建决策树\n",
    "\n",
    "def Sustain_spilter (training_data: pd.DataFrame, target: str, n):\n",
    "    Decision_Tree ={}\n",
    "    data = training_data \n",
    "    print('初始训练集')\n",
    "    #print(data)\n",
    "    for i in range(n):\n",
    "        #开始第1次 到 第n-1次切分\n",
    "        spilter = find_the_optimal_spilter(data, target) \n",
    "        Decision_Tree[spilter[0]] = [spilter[1],spilter[2]]        \n",
    "        print('第{}次spilter'.format(i+1),spilter)\n",
    "        data = data[data[spilter[0]] != spilter[1]]\n",
    "        del data[spilter[0]]  #data 更新为 删掉第一层，切分后的数据组\n",
    "        if data.empty :\n",
    "            print('finish')\n",
    "            break\n",
    "        print(\"第{}次切分\".format(i+1)) \n",
    "        if i == n-1:\n",
    "            print('finish')                    \n",
    "    return Decision_Tree     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始训练集\n",
      "spliter is: ('age', '40-49', {0: [1.0]})\n",
      "the min entropy is: 0.5982695885852573\n",
      "第1次spilter ('age', '40-49', {0: [1.0]})\n",
      "第1次切分\n",
      "spliter is: ('married', 0, {0: [1.0]})\n",
      "the min entropy is: 0.6730116670092565\n",
      "第2次spilter ('married', 0, {0: [1.0]})\n",
      "第2次切分\n",
      "spliter is: ('gender', 'F', {0: [0.42857142857142855], 1: [0.5714285714285714]})\n",
      "the min entropy is: 0.6829081047004717\n",
      "第3次spilter ('gender', 'F', {0: [0.42857142857142855], 1: [0.5714285714285714]})\n",
      "第3次切分\n",
      "spliter is: ('income', '+10', {0: [1.0]})\n",
      "the min entropy is: -0.0\n",
      "第4次spilter ('income', '+10', {0: [1.0]})\n",
      "finish\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'age': ['40-49', {0: [1.0]}],\n",
       " 'married': [0, {0: [1.0]}],\n",
       " 'gender': ['F', {0: [0.42857142857142855], 1: [0.5714285714285714]}],\n",
       " 'income': ['+10', {0: [1.0]}]}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sustain_spilter (data_train, 'born_baby',n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始训练集\n",
      "spliter is: ('age', '40-49', {0: [1.0]})\n",
      "the min entropy is: 0.5982695885852573\n",
      "第1次spilter ('age', '40-49', {0: [1.0]})\n",
      "第1次切分\n",
      "spliter is: ('married', 0, {0: [1.0]})\n",
      "the min entropy is: 0.6730116670092565\n",
      "第2次spilter ('married', 0, {0: [1.0]})\n",
      "第2次切分\n",
      "spliter is: ('gender', 'F', {0: [0.42857142857142855], 1: [0.5714285714285714]})\n",
      "the min entropy is: 0.6829081047004717\n",
      "第3次spilter ('gender', 'F', {0: [0.42857142857142855], 1: [0.5714285714285714]})\n",
      "第3次切分\n",
      "spliter is: ('income', '+10', {0: [1.0]})\n",
      "the min entropy is: -0.0\n",
      "第4次spilter ('income', '+10', {0: [1.0]})\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "dict_test = Sustain_spilter (data_train, 'born_baby',n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个是要预测是数据： 一个 收入+10 ，20-29岁，二线城市，结婚的女性 ； 预测其生育行为的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_input = {\n",
    "    'gender':['F'],\n",
    "    'income': [ '+10'],\n",
    "    'age': [\"20-29\"],\n",
    "    'city': [2],\n",
    "    'married':[1]\n",
    "       }   #该数据不在 data_train中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个是训练数据： 决策树模型基于这个数据产生"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>city</th>\n",
       "      <th>married</th>\n",
       "      <th>born_baby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>10-19</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>40-49</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>-10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F</td>\n",
       "      <td>+10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>50-59</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M</td>\n",
       "      <td>+10</td>\n",
       "      <td>30-39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>F</td>\n",
       "      <td>-10</td>\n",
       "      <td>20-29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender income    age  city  married  born_baby\n",
       "0       F    +10  30-39     2        1          1\n",
       "1       F    -10  20-29     4        1          0\n",
       "2       F    -10  30-39     1        1          1\n",
       "3       M    +10  10-19     2        1          0\n",
       "4       M    +10  20-29     2        0          0\n",
       "5       M    +10  40-49     3        1          0\n",
       "6       M    -10  50-59     4        0          0\n",
       "7       F    +10  50-59     3        1          1\n",
       "8       F    -10  30-39     1        1          0\n",
       "9       M    +10  30-39     4        0          0\n",
       "10      M    +10  20-29     4        1          0\n",
       "11      M    +10  50-59     2        1          0\n",
       "12      F    -10  30-39     3        1          0\n",
       "13      M    +10  30-39     1        0          0\n",
       "14      F    -10  20-29     4        1          1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建模型\n",
    "def Decision_Tree (training_data: pd.DataFrame, target: str, n,test_data):        \n",
    "    Decision_Tree = Sustain_spilter (data_train, target ,n)    \n",
    "    for dict_key ,dict_value in Decision_Tree.items():\n",
    "    #print( dict_input1[str(dict_key)][0])\n",
    "        if test_data[str(dict_key)][0] == dict_value[0]:\n",
    "            print('得到预测结果是{}'.format( dict_value[1]))        \n",
    "            break    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出的决策树判断逻辑\n",
    "\n",
    "第一层 ： 判断 年龄是否在 40-49岁 ；如果是： 100%没生过孩子 如果不是：进行第二层判断\n",
    "第二层 ： 判断 是否未婚结婚（married = 0）  如果是 ： 100%没生过孩子 如果不是： 进行第三层判断\n",
    "第三层 ： 判断 性别是否是 女性    如果是： 有57%的概率生过孩子  如果不是： 进行第四层判断 \n",
    "第四层 ： 判断 收入是否 +10 ； 如果是 ： 100%没生过孩子\n",
    "\n",
    "\n",
    "\n",
    "预测数据是： 一个 收入+10 ，20-29岁，二线城市，结婚的女性 ； 预测其生育行为的概率\n",
    "（1） 不是 40-49岁 ， 进入下一轮\n",
    "（2） 不是未婚 ， 进入下一轮\n",
    "（3） 是女性 ： 输出结果 ： 有57%的概率生过孩子，43%的概率没生过孩子；\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初始训练集\n",
      "spliter is: ('age', '40-49', {0: [1.0]})\n",
      "the min entropy is: 0.5982695885852573\n",
      "第1次spilter ('age', '40-49', {0: [1.0]})\n",
      "第1次切分\n",
      "spliter is: ('married', 0, {0: [1.0]})\n",
      "the min entropy is: 0.6730116670092565\n",
      "第2次spilter ('married', 0, {0: [1.0]})\n",
      "第2次切分\n",
      "spliter is: ('gender', 'F', {0: [0.42857142857142855], 1: [0.5714285714285714]})\n",
      "the min entropy is: 0.6829081047004717\n",
      "第3次spilter ('gender', 'F', {0: [0.42857142857142855], 1: [0.5714285714285714]})\n",
      "第3次切分\n",
      "spliter is: ('income', '+10', {0: [1.0]})\n",
      "the min entropy is: -0.0\n",
      "第4次spilter ('income', '+10', {0: [1.0]})\n",
      "finish\n",
      "得到预测结果是{0: [0.42857142857142855], 1: [0.5714285714285714]}\n"
     ]
    }
   ],
   "source": [
    "Decision_Tree(data_train,'born_baby',n=5, test_data=pre_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "思考：训练集数据的质量，对模型的影响权重巨大；\n",
    "\n",
    "比如：　为什么“４０－４９”岁反而成了第一区分特征；因为，不巧的是训练集里只有这一条数据，而且生育是０，显然这不太符合现实生活的认知常识，可以认为是一条“ｂａｄ　ｃａｓｅ”，但是它对决策树模型影响巨\n",
    "如何改善，才能提升训练集的质量？\n",
    "（１）　数据样本分布的均衡性，　比如不要出现　４０－４９岁的数据只有一条\n",
    "（２）　保持数据是真实的；来自实际场景，　本次数据除了　我主动控制了　Ｍ男性不可能生孩子，这一条，其他都是随机敲的属性。而坏的属性，显然把我特意想创造的： Gender M = 0  这个判断给淹没了\n",
    "（３）　条件允许尽可能的增大训练样本量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "> + 是否将之前的决策树模型的部分进行合并组装， predicate函数能够顺利运行(8')\n",
    "+ 是够能够输入未曾见过的X变量，例如gender, income, family_number 分别是： <M, -10, 1>, 模型能够预测出结果 (12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 将上一节课(第二节课)的线性回归问题中的Loss函数改成\"绝对值\"，并且改变其偏导的求值方式，观察其结果的变化。(19 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<评阅点>\n",
    "+ 是否将Loss改成了“绝对值”(3')\n",
    "+ 是否完成了偏导的重新定义(5')\n",
    "+ 新的模型Loss是否能够收敛 (11’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=dataset['data'],dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rm = x[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xe2e9e48>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the RM with respect to y\n",
    "plt.scatter(X_rm,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define target function\n",
    "def price(rm, k, b):\n",
    "    return k * rm + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ loss = \\frac{1}{n} \\sum{|(y_i - \\hat{y_i})|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function \n",
    "def loss(y,y_hat):\n",
    "    s2=0\n",
    "    s1=0\n",
    "    for y_i, y_hat_i in zip(list(y),list(y_hat)):\n",
    "        if y_i > y_hat_i :\n",
    "            s1= y_i - y_hat_i +s1\n",
    "        else:\n",
    "            s2= y_hat_i - y_i +s2\n",
    "    return (s1+s2)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = [1,2,3,4,5,6,7,8]\n",
    "test2 = [2,3,5,4,2,6,4,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.375"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(test1,test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$$ loss = \\frac{1}{n} \\sum{|(y_i - \\hat{y_i})|}$$\n",
    "\n",
    "当 y > y_hat , \n",
    "$$ loss = \\frac{1}{n} \\sum{(y_i - \\hat{y_i})}$$\n",
    "\n",
    "求 kb偏导\n",
    "\n",
    "$$ \\frac{\\partial{loss}}{\\partial{k}} = \\frac{1}{n}\\sum(- x_i)$$\n",
    "\n",
    "$$ \\frac{\\partial{loss}}{\\partial{b}} = \\frac{1}{n}\\sum(-1)=-1$$\n",
    "\n",
    "当 y < y_hat , \n",
    "$$ loss = \\frac{1}{n} \\sum{(\\hat{y_i}- y_i)}$$\n",
    "\n",
    "求 kb偏导\n",
    "\n",
    "$$ \\frac{\\partial{loss}}{\\partial{k}} = \\frac{1}{n}\\sum(x_i)$$\n",
    "\n",
    "$$ \\frac{\\partial{loss}}{\\partial{b}} = \\frac{1}{n}\\sum(1)=1$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define partial derivative \n",
    "def partial_derivative_k(x, y, y_hat): \n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        if y_i > y_hat_i:\n",
    "            gradient += x_i*(-1) \n",
    "        else:\n",
    "            gradient += x_i\n",
    "    return 1/n * gradient \n",
    "\n",
    "def partial_derivative_b(y, y_hat):\n",
    "    n = len(y)\n",
    "    gradient = 0\n",
    "    for x_i, y_i, y_hat_i in zip(list(x),list(y),list(y_hat)):\n",
    "        if y_i> y_hat_i:\n",
    "            gradient += -1 \n",
    "        else:\n",
    "            gradient += 1\n",
    "    return 1/n * gradient \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, the loss is 75.41782645577753, parameters k is 21.9934908987359 and b is -40.2704164202158\n",
      "Iteration 1, the loss is 75.3773298263948, parameters k is 21.987206264348547 and b is -40.2714164202158\n",
      "Iteration 2, the loss is 75.33683319701218, parameters k is 21.980921629961195 and b is -40.2724164202158\n",
      "Iteration 3, the loss is 75.29633656762944, parameters k is 21.974636995573842 and b is -40.273416420215796\n",
      "Iteration 4, the loss is 75.2558399382468, parameters k is 21.96835236118649 and b is -40.27441642021579\n",
      "Iteration 5, the loss is 75.21534330886408, parameters k is 21.962067726799138 and b is -40.27541642021579\n",
      "Iteration 6, the loss is 75.17484667948139, parameters k is 21.955783092411785 and b is -40.27641642021579\n",
      "Iteration 7, the loss is 75.13435005009877, parameters k is 21.949498458024433 and b is -40.277416420215786\n",
      "Iteration 8, the loss is 75.09385342071609, parameters k is 21.94321382363708 and b is -40.278416420215784\n",
      "Iteration 9, the loss is 75.05335679133339, parameters k is 21.936929189249728 and b is -40.27941642021578\n",
      "Iteration 10, the loss is 75.01286016195071, parameters k is 21.930644554862376 and b is -40.28041642021578\n",
      "Iteration 11, the loss is 74.97236353256798, parameters k is 21.924359920475023 and b is -40.28141642021578\n",
      "Iteration 12, the loss is 74.9318669031853, parameters k is 21.91807528608767 and b is -40.282416420215775\n",
      "Iteration 13, the loss is 74.89137027380264, parameters k is 21.91179065170032 and b is -40.28341642021577\n",
      "Iteration 14, the loss is 74.85087364441988, parameters k is 21.905506017312966 and b is -40.28441642021577\n",
      "Iteration 15, the loss is 74.8103770150372, parameters k is 21.899221382925614 and b is -40.28541642021577\n",
      "Iteration 16, the loss is 74.76988038565455, parameters k is 21.89293674853826 and b is -40.286416420215765\n",
      "Iteration 17, the loss is 74.72938375627186, parameters k is 21.88665211415091 and b is -40.28741642021576\n",
      "Iteration 18, the loss is 74.6888871268892, parameters k is 21.880367479763557 and b is -40.28841642021576\n",
      "Iteration 19, the loss is 74.64839049750655, parameters k is 21.874082845376204 and b is -40.28941642021576\n",
      "Iteration 20, the loss is 74.60789386812385, parameters k is 21.867798210988852 and b is -40.290416420215756\n",
      "Iteration 21, the loss is 74.5673972387412, parameters k is 21.8615135766015 and b is -40.291416420215754\n",
      "Iteration 22, the loss is 74.52690060935839, parameters k is 21.855228942214147 and b is -40.29241642021575\n",
      "Iteration 23, the loss is 74.48640397997568, parameters k is 21.848944307826795 and b is -40.29341642021575\n",
      "Iteration 24, the loss is 74.44590735059307, parameters k is 21.842659673439442 and b is -40.29441642021575\n",
      "Iteration 25, the loss is 74.40541072121036, parameters k is 21.83637503905209 and b is -40.295416420215744\n",
      "Iteration 26, the loss is 74.36491409182776, parameters k is 21.830090404664737 and b is -40.29641642021574\n",
      "Iteration 27, the loss is 74.32441746244504, parameters k is 21.823805770277385 and b is -40.29741642021574\n",
      "Iteration 28, the loss is 74.2839208330624, parameters k is 21.817521135890033 and b is -40.29841642021574\n",
      "Iteration 29, the loss is 74.24342420367968, parameters k is 21.81123650150268 and b is -40.299416420215735\n",
      "Iteration 30, the loss is 74.20292757429696, parameters k is 21.804951867115328 and b is -40.30041642021573\n",
      "Iteration 31, the loss is 74.16243094491423, parameters k is 21.798667232727976 and b is -40.30141642021573\n",
      "Iteration 32, the loss is 74.12193431553156, parameters k is 21.792382598340623 and b is -40.30241642021573\n",
      "Iteration 33, the loss is 74.08143768614889, parameters k is 21.78609796395327 and b is -40.303416420215726\n",
      "Iteration 34, the loss is 74.04094105676627, parameters k is 21.77981332956592 and b is -40.30441642021572\n",
      "Iteration 35, the loss is 74.00044442738356, parameters k is 21.773528695178566 and b is -40.30541642021572\n",
      "Iteration 36, the loss is 73.95994779800081, parameters k is 21.767244060791214 and b is -40.30641642021572\n",
      "Iteration 37, the loss is 73.91945116861818, parameters k is 21.76095942640386 and b is -40.307416420215716\n",
      "Iteration 38, the loss is 73.87895453923541, parameters k is 21.75467479201651 and b is -40.308416420215714\n",
      "Iteration 39, the loss is 73.8384579098528, parameters k is 21.748390157629157 and b is -40.30941642021571\n",
      "Iteration 40, the loss is 73.7979612804701, parameters k is 21.742105523241804 and b is -40.31041642021571\n",
      "Iteration 41, the loss is 73.7574646510874, parameters k is 21.73582088885445 and b is -40.31141642021571\n",
      "Iteration 42, the loss is 73.71696802170473, parameters k is 21.7295362544671 and b is -40.312416420215705\n",
      "Iteration 43, the loss is 73.67647139232207, parameters k is 21.723251620079747 and b is -40.3134164202157\n",
      "Iteration 44, the loss is 73.63597476293933, parameters k is 21.716966985692395 and b is -40.3144164202157\n",
      "Iteration 45, the loss is 73.59547813355665, parameters k is 21.710682351305042 and b is -40.3154164202157\n",
      "Iteration 46, the loss is 73.55498150417412, parameters k is 21.70439771691769 and b is -40.316416420215695\n",
      "Iteration 47, the loss is 73.5144848747913, parameters k is 21.698113082530337 and b is -40.31741642021569\n",
      "Iteration 48, the loss is 73.47398824540855, parameters k is 21.691828448142985 and b is -40.31841642021569\n",
      "Iteration 49, the loss is 73.43349161602586, parameters k is 21.685543813755633 and b is -40.31941642021569\n",
      "Iteration 50, the loss is 73.39299498664323, parameters k is 21.67925917936828 and b is -40.320416420215686\n",
      "Iteration 51, the loss is 73.3524983572605, parameters k is 21.672974544980928 and b is -40.321416420215684\n",
      "Iteration 52, the loss is 73.31200172787791, parameters k is 21.666689910593576 and b is -40.32241642021568\n",
      "Iteration 53, the loss is 73.2715050984951, parameters k is 21.660405276206223 and b is -40.32341642021568\n",
      "Iteration 54, the loss is 73.2310084691125, parameters k is 21.65412064181887 and b is -40.32441642021568\n",
      "Iteration 55, the loss is 73.19051183972981, parameters k is 21.64783600743152 and b is -40.325416420215674\n",
      "Iteration 56, the loss is 73.1500152103471, parameters k is 21.641551373044166 and b is -40.32641642021567\n",
      "Iteration 57, the loss is 73.10951858096439, parameters k is 21.635266738656814 and b is -40.32741642021567\n",
      "Iteration 58, the loss is 73.06902195158173, parameters k is 21.62898210426946 and b is -40.32841642021567\n",
      "Iteration 59, the loss is 73.02852532219907, parameters k is 21.62269746988211 and b is -40.329416420215665\n",
      "Iteration 60, the loss is 72.98802869281637, parameters k is 21.616412835494756 and b is -40.33041642021566\n",
      "Iteration 61, the loss is 72.9475320634337, parameters k is 21.610128201107404 and b is -40.33141642021566\n",
      "Iteration 62, the loss is 72.90703543405105, parameters k is 21.60384356672005 and b is -40.33241642021566\n",
      "Iteration 63, the loss is 72.86653880466832, parameters k is 21.5975589323327 and b is -40.333416420215656\n",
      "Iteration 64, the loss is 72.82604217528566, parameters k is 21.591274297945347 and b is -40.33441642021565\n",
      "Iteration 65, the loss is 72.78554554590293, parameters k is 21.584989663557995 and b is -40.33541642021565\n",
      "Iteration 66, the loss is 72.74504891652033, parameters k is 21.578705029170642 and b is -40.33641642021565\n",
      "Iteration 67, the loss is 72.70455228713759, parameters k is 21.57242039478329 and b is -40.337416420215646\n",
      "Iteration 68, the loss is 72.66405565775491, parameters k is 21.566135760395937 and b is -40.338416420215644\n",
      "Iteration 69, the loss is 72.62355902837213, parameters k is 21.559851126008585 and b is -40.33941642021564\n",
      "Iteration 70, the loss is 72.58306239898953, parameters k is 21.553566491621233 and b is -40.34041642021564\n",
      "Iteration 71, the loss is 72.54256576960688, parameters k is 21.54728185723388 and b is -40.34141642021564\n",
      "Iteration 72, the loss is 72.50206914022414, parameters k is 21.540997222846528 and b is -40.342416420215635\n",
      "Iteration 73, the loss is 72.46157251084145, parameters k is 21.534712588459175 and b is -40.34341642021563\n",
      "Iteration 74, the loss is 72.42107588145875, parameters k is 21.528427954071823 and b is -40.34441642021563\n",
      "Iteration 75, the loss is 72.38057925207609, parameters k is 21.52214331968447 and b is -40.34541642021563\n",
      "Iteration 76, the loss is 72.34008262269346, parameters k is 21.51585868529712 and b is -40.346416420215625\n",
      "Iteration 77, the loss is 72.29958599331071, parameters k is 21.509574050909766 and b is -40.34741642021562\n",
      "Iteration 78, the loss is 72.25908936392804, parameters k is 21.503289416522414 and b is -40.34841642021562\n",
      "Iteration 79, the loss is 72.21859273454535, parameters k is 21.49700478213506 and b is -40.34941642021562\n",
      "Iteration 80, the loss is 72.1780961051627, parameters k is 21.49072014774771 and b is -40.350416420215616\n",
      "Iteration 81, the loss is 72.13759947577998, parameters k is 21.484435513360356 and b is -40.351416420215614\n",
      "Iteration 82, the loss is 72.09710284639725, parameters k is 21.478150878973004 and b is -40.35241642021561\n",
      "Iteration 83, the loss is 72.05660621701465, parameters k is 21.47186624458565 and b is -40.35341642021561\n",
      "Iteration 84, the loss is 72.01610958763192, parameters k is 21.4655816101983 and b is -40.35441642021561\n",
      "Iteration 85, the loss is 71.9756129582492, parameters k is 21.459296975810947 and b is -40.355416420215604\n",
      "Iteration 86, the loss is 71.93511632886648, parameters k is 21.453012341423594 and b is -40.3564164202156\n",
      "Iteration 87, the loss is 71.89461969948384, parameters k is 21.446727707036242 and b is -40.3574164202156\n",
      "Iteration 88, the loss is 71.85412307010118, parameters k is 21.44044307264889 and b is -40.3584164202156\n",
      "Iteration 89, the loss is 71.81362644071855, parameters k is 21.434158438261537 and b is -40.359416420215595\n",
      "Iteration 90, the loss is 71.77312981133579, parameters k is 21.427873803874185 and b is -40.36041642021559\n",
      "Iteration 91, the loss is 71.73263318195315, parameters k is 21.421589169486833 and b is -40.36141642021559\n",
      "Iteration 92, the loss is 71.69213655257037, parameters k is 21.41530453509948 and b is -40.36241642021559\n",
      "Iteration 93, the loss is 71.65163992318773, parameters k is 21.409019900712128 and b is -40.363416420215586\n",
      "Iteration 94, the loss is 71.61114329380504, parameters k is 21.402735266324775 and b is -40.36441642021558\n",
      "Iteration 95, the loss is 71.57064666442237, parameters k is 21.396450631937423 and b is -40.36541642021558\n",
      "Iteration 96, the loss is 71.53015003503968, parameters k is 21.39016599755007 and b is -40.36641642021558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 97, the loss is 71.48965340565697, parameters k is 21.38388136316272 and b is -40.36741642021558\n",
      "Iteration 98, the loss is 71.44915677627432, parameters k is 21.377596728775366 and b is -40.368416420215574\n",
      "Iteration 99, the loss is 71.40866014689165, parameters k is 21.371312094388013 and b is -40.36941642021557\n",
      "Iteration 100, the loss is 71.36816351750892, parameters k is 21.36502746000066 and b is -40.37041642021557\n",
      "Iteration 101, the loss is 71.32766688812632, parameters k is 21.35874282561331 and b is -40.37141642021557\n",
      "Iteration 102, the loss is 71.28717025874357, parameters k is 21.352458191225956 and b is -40.372416420215565\n",
      "Iteration 103, the loss is 71.24667362936097, parameters k is 21.346173556838604 and b is -40.37341642021556\n",
      "Iteration 104, the loss is 71.20617699997817, parameters k is 21.33988892245125 and b is -40.37441642021556\n",
      "Iteration 105, the loss is 71.16568037059548, parameters k is 21.3336042880639 and b is -40.37541642021556\n",
      "Iteration 106, the loss is 71.12518374121288, parameters k is 21.327319653676547 and b is -40.376416420215556\n",
      "Iteration 107, the loss is 71.08468711183016, parameters k is 21.321035019289194 and b is -40.37741642021555\n",
      "Iteration 108, the loss is 71.04419048244756, parameters k is 21.314750384901842 and b is -40.37841642021555\n",
      "Iteration 109, the loss is 71.00369385306486, parameters k is 21.30846575051449 and b is -40.37941642021555\n",
      "Iteration 110, the loss is 70.96319722368206, parameters k is 21.302181116127137 and b is -40.380416420215546\n",
      "Iteration 111, the loss is 70.9227005942994, parameters k is 21.295896481739785 and b is -40.381416420215544\n",
      "Iteration 112, the loss is 70.8822039649167, parameters k is 21.289611847352433 and b is -40.38241642021554\n",
      "Iteration 113, the loss is 70.84170733553405, parameters k is 21.28332721296508 and b is -40.38341642021554\n",
      "Iteration 114, the loss is 70.8012107061514, parameters k is 21.277042578577728 and b is -40.38441642021554\n",
      "Iteration 115, the loss is 70.76071407676858, parameters k is 21.270757944190375 and b is -40.385416420215535\n",
      "Iteration 116, the loss is 70.72021744738598, parameters k is 21.264473309803023 and b is -40.38641642021553\n",
      "Iteration 117, the loss is 70.67972081800333, parameters k is 21.25818867541567 and b is -40.38741642021553\n",
      "Iteration 118, the loss is 70.63922418862057, parameters k is 21.251904041028318 and b is -40.38841642021553\n",
      "Iteration 119, the loss is 70.59872755923787, parameters k is 21.245619406640966 and b is -40.389416420215525\n",
      "Iteration 120, the loss is 70.5582309298552, parameters k is 21.239334772253613 and b is -40.39041642021552\n",
      "Iteration 121, the loss is 70.51773430047248, parameters k is 21.23305013786626 and b is -40.39141642021552\n",
      "Iteration 122, the loss is 70.47723767108988, parameters k is 21.22676550347891 and b is -40.39241642021552\n",
      "Iteration 123, the loss is 70.43674104170711, parameters k is 21.220480869091556 and b is -40.393416420215516\n",
      "Iteration 124, the loss is 70.39624441232449, parameters k is 21.214196234704204 and b is -40.394416420215514\n",
      "Iteration 125, the loss is 70.3557477829418, parameters k is 21.20791160031685 and b is -40.39541642021551\n",
      "Iteration 126, the loss is 70.31525115355907, parameters k is 21.2016269659295 and b is -40.39641642021551\n",
      "Iteration 127, the loss is 70.27475452417643, parameters k is 21.195342331542147 and b is -40.39741642021551\n",
      "Iteration 128, the loss is 70.23425789479374, parameters k is 21.189057697154794 and b is -40.398416420215504\n",
      "Iteration 129, the loss is 70.19376126541103, parameters k is 21.182773062767442 and b is -40.3994164202155\n",
      "Iteration 130, the loss is 70.15326463602834, parameters k is 21.17648842838009 and b is -40.4004164202155\n",
      "Iteration 131, the loss is 70.11276800664567, parameters k is 21.170203793992737 and b is -40.4014164202155\n",
      "Iteration 132, the loss is 70.07227137726298, parameters k is 21.163919159605385 and b is -40.402416420215495\n",
      "Iteration 133, the loss is 70.03177474788038, parameters k is 21.157634525218032 and b is -40.40341642021549\n",
      "Iteration 134, the loss is 69.99127811849766, parameters k is 21.15134989083068 and b is -40.40441642021549\n",
      "Iteration 135, the loss is 69.95078148911495, parameters k is 21.145065256443328 and b is -40.40541642021549\n",
      "Iteration 136, the loss is 69.91028485973229, parameters k is 21.138780622055975 and b is -40.406416420215486\n",
      "Iteration 137, the loss is 69.86978823034958, parameters k is 21.132495987668623 and b is -40.40741642021548\n",
      "Iteration 138, the loss is 69.82929160096681, parameters k is 21.12621135328127 and b is -40.40841642021548\n",
      "Iteration 139, the loss is 69.78879497158418, parameters k is 21.119926718893918 and b is -40.40941642021548\n",
      "Iteration 140, the loss is 69.74829834220144, parameters k is 21.113642084506566 and b is -40.410416420215476\n",
      "Iteration 141, the loss is 69.7078017128188, parameters k is 21.107357450119213 and b is -40.411416420215474\n",
      "Iteration 142, the loss is 69.66730508343616, parameters k is 21.10107281573186 and b is -40.41241642021547\n",
      "Iteration 143, the loss is 69.62680845405347, parameters k is 21.09478818134451 and b is -40.41341642021547\n",
      "Iteration 144, the loss is 69.5863118246708, parameters k is 21.088503546957156 and b is -40.41441642021547\n",
      "Iteration 145, the loss is 69.5458151952881, parameters k is 21.082218912569804 and b is -40.415416420215465\n",
      "Iteration 146, the loss is 69.50531856590536, parameters k is 21.07593427818245 and b is -40.41641642021546\n",
      "Iteration 147, the loss is 69.46482193652275, parameters k is 21.0696496437951 and b is -40.41741642021546\n",
      "Iteration 148, the loss is 69.42432530713998, parameters k is 21.063365009407747 and b is -40.41841642021546\n",
      "Iteration 149, the loss is 69.38382867775726, parameters k is 21.057080375020394 and b is -40.419416420215455\n",
      "Iteration 150, the loss is 69.34333204837472, parameters k is 21.050795740633042 and b is -40.42041642021545\n",
      "Iteration 151, the loss is 69.30283541899196, parameters k is 21.04451110624569 and b is -40.42141642021545\n",
      "Iteration 152, the loss is 69.26233878960926, parameters k is 21.038226471858337 and b is -40.42241642021545\n",
      "Iteration 153, the loss is 69.22184216022659, parameters k is 21.031941837470985 and b is -40.423416420215446\n",
      "Iteration 154, the loss is 69.18134553084381, parameters k is 21.025657203083632 and b is -40.424416420215444\n",
      "Iteration 155, the loss is 69.14084890146123, parameters k is 21.01937256869628 and b is -40.42541642021544\n",
      "Iteration 156, the loss is 69.10035227207844, parameters k is 21.013087934308928 and b is -40.42641642021544\n",
      "Iteration 157, the loss is 69.05985564269584, parameters k is 21.006803299921575 and b is -40.42741642021544\n",
      "Iteration 158, the loss is 69.01935901331318, parameters k is 21.000518665534223 and b is -40.428416420215434\n",
      "Iteration 159, the loss is 68.97886238393046, parameters k is 20.99423403114687 and b is -40.42941642021543\n",
      "Iteration 160, the loss is 68.93836575454776, parameters k is 20.987949396759518 and b is -40.43041642021543\n",
      "Iteration 161, the loss is 68.89786912516514, parameters k is 20.981664762372166 and b is -40.43141642021543\n",
      "Iteration 162, the loss is 68.85737249578237, parameters k is 20.975380127984813 and b is -40.432416420215425\n",
      "Iteration 163, the loss is 68.8168758663997, parameters k is 20.96909549359746 and b is -40.43341642021542\n",
      "Iteration 164, the loss is 68.7763792370171, parameters k is 20.96281085921011 and b is -40.43441642021542\n",
      "Iteration 165, the loss is 68.73588260763432, parameters k is 20.956526224822756 and b is -40.43541642021542\n",
      "Iteration 166, the loss is 68.69538597825171, parameters k is 20.950241590435404 and b is -40.436416420215416\n",
      "Iteration 167, the loss is 68.65488934886902, parameters k is 20.94395695604805 and b is -40.43741642021541\n",
      "Iteration 168, the loss is 68.61439271948635, parameters k is 20.9376723216607 and b is -40.43841642021541\n",
      "Iteration 169, the loss is 68.57389609010362, parameters k is 20.931387687273347 and b is -40.43941642021541\n",
      "Iteration 170, the loss is 68.53339946072097, parameters k is 20.925103052885994 and b is -40.440416420215406\n",
      "Iteration 171, the loss is 68.49290283133818, parameters k is 20.918818418498642 and b is -40.441416420215404\n",
      "Iteration 172, the loss is 68.45240620195553, parameters k is 20.91253378411129 and b is -40.4424164202154\n",
      "Iteration 173, the loss is 68.41190957257291, parameters k is 20.906249149723937 and b is -40.4434164202154\n",
      "Iteration 174, the loss is 68.37141294319015, parameters k is 20.899964515336585 and b is -40.4444164202154\n",
      "Iteration 175, the loss is 68.3309163138075, parameters k is 20.893679880949232 and b is -40.445416420215395\n",
      "Iteration 176, the loss is 68.29041968442478, parameters k is 20.88739524656188 and b is -40.44641642021539\n",
      "Iteration 177, the loss is 68.24992305504217, parameters k is 20.881110612174528 and b is -40.44741642021539\n",
      "Iteration 178, the loss is 68.20942642565944, parameters k is 20.874825977787175 and b is -40.44841642021539\n",
      "Iteration 179, the loss is 68.16892979627674, parameters k is 20.868541343399823 and b is -40.449416420215385\n",
      "Iteration 180, the loss is 68.12843316689413, parameters k is 20.86225670901247 and b is -40.45041642021538\n",
      "Iteration 181, the loss is 68.08793653751135, parameters k is 20.855972074625118 and b is -40.45141642021538\n",
      "Iteration 182, the loss is 68.04743990812868, parameters k is 20.849687440237766 and b is -40.45241642021538\n",
      "Iteration 183, the loss is 68.00694327874598, parameters k is 20.843402805850413 and b is -40.453416420215376\n",
      "Iteration 184, the loss is 67.9664466493633, parameters k is 20.83711817146306 and b is -40.454416420215374\n",
      "Iteration 185, the loss is 67.92595001998058, parameters k is 20.83083353707571 and b is -40.45541642021537\n",
      "Iteration 186, the loss is 67.88545339059795, parameters k is 20.824548902688356 and b is -40.45641642021537\n",
      "Iteration 187, the loss is 67.84495676121527, parameters k is 20.818264268301004 and b is -40.45741642021537\n",
      "Iteration 188, the loss is 67.80446013183254, parameters k is 20.81197963391365 and b is -40.458416420215364\n",
      "Iteration 189, the loss is 67.76396350244997, parameters k is 20.8056949995263 and b is -40.45941642021536\n",
      "Iteration 190, the loss is 67.72346687306724, parameters k is 20.799410365138947 and b is -40.46041642021536\n",
      "Iteration 191, the loss is 67.68297024368461, parameters k is 20.793125730751594 and b is -40.46141642021536\n",
      "Iteration 192, the loss is 67.6424736143018, parameters k is 20.786841096364242 and b is -40.462416420215355\n",
      "Iteration 193, the loss is 67.60197698491922, parameters k is 20.78055646197689 and b is -40.46341642021535\n",
      "Iteration 194, the loss is 67.56148035553646, parameters k is 20.774271827589537 and b is -40.46441642021535\n",
      "Iteration 195, the loss is 67.52098372615382, parameters k is 20.767987193202185 and b is -40.46541642021535\n",
      "Iteration 196, the loss is 67.48048709677111, parameters k is 20.761702558814832 and b is -40.466416420215346\n",
      "Iteration 197, the loss is 67.43999046738843, parameters k is 20.75541792442748 and b is -40.46741642021534\n",
      "Iteration 198, the loss is 67.39949383800572, parameters k is 20.749133290040128 and b is -40.46841642021534\n",
      "Iteration 199, the loss is 67.35899720862305, parameters k is 20.742848655652775 and b is -40.46941642021534\n",
      "Iteration 200, the loss is 67.31850057924032, parameters k is 20.736564021265423 and b is -40.47041642021534\n",
      "Iteration 201, the loss is 67.27800394985762, parameters k is 20.73027938687807 and b is -40.471416420215334\n",
      "Iteration 202, the loss is 67.23750732047499, parameters k is 20.723994752490718 and b is -40.47241642021533\n",
      "Iteration 203, the loss is 67.19701069109232, parameters k is 20.717710118103366 and b is -40.47341642021533\n",
      "Iteration 204, the loss is 67.15651406170961, parameters k is 20.711425483716013 and b is -40.47441642021533\n",
      "Iteration 205, the loss is 67.11601743232687, parameters k is 20.70514084932866 and b is -40.475416420215325\n",
      "Iteration 206, the loss is 67.07552080294421, parameters k is 20.69885621494131 and b is -40.47641642021532\n",
      "Iteration 207, the loss is 67.03502417356161, parameters k is 20.692571580553956 and b is -40.47741642021532\n",
      "Iteration 208, the loss is 66.99452754417887, parameters k is 20.686286946166604 and b is -40.47841642021532\n",
      "Iteration 209, the loss is 66.95403091479623, parameters k is 20.68000231177925 and b is -40.479416420215315\n",
      "Iteration 210, the loss is 66.91353428541342, parameters k is 20.6737176773919 and b is -40.48041642021531\n",
      "Iteration 211, the loss is 66.87303765603086, parameters k is 20.667433043004547 and b is -40.48141642021531\n",
      "Iteration 212, the loss is 66.83254102664812, parameters k is 20.661148408617194 and b is -40.48241642021531\n",
      "Iteration 213, the loss is 66.79204439726547, parameters k is 20.65486377422984 and b is -40.483416420215306\n",
      "Iteration 214, the loss is 66.75154776788268, parameters k is 20.64857913984249 and b is -40.484416420215304\n",
      "Iteration 215, the loss is 66.71105113850014, parameters k is 20.642294505455137 and b is -40.4854164202153\n",
      "Iteration 216, the loss is 66.67055450911741, parameters k is 20.636009871067785 and b is -40.4864164202153\n",
      "Iteration 217, the loss is 66.63005787973462, parameters k is 20.629725236680432 and b is -40.4874164202153\n",
      "Iteration 218, the loss is 66.58956125035198, parameters k is 20.62344060229308 and b is -40.488416420215295\n",
      "Iteration 219, the loss is 66.54906462096938, parameters k is 20.617155967905727 and b is -40.48941642021529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 220, the loss is 66.50856799158659, parameters k is 20.610871333518375 and b is -40.49041642021529\n",
      "Iteration 221, the loss is 66.46807136220394, parameters k is 20.604586699131023 and b is -40.49141642021529\n",
      "Iteration 222, the loss is 66.42757473282128, parameters k is 20.59830206474367 and b is -40.492416420215285\n",
      "Iteration 223, the loss is 66.38707810343855, parameters k is 20.592017430356318 and b is -40.49341642021528\n",
      "Iteration 224, the loss is 66.34658147405587, parameters k is 20.585732795968966 and b is -40.49441642021528\n",
      "Iteration 225, the loss is 66.30608484467318, parameters k is 20.579448161581613 and b is -40.49541642021528\n",
      "Iteration 226, the loss is 66.26558821529056, parameters k is 20.57316352719426 and b is -40.496416420215276\n",
      "Iteration 227, the loss is 66.22509158590785, parameters k is 20.56687889280691 and b is -40.49741642021527\n",
      "Iteration 228, the loss is 66.18459495652517, parameters k is 20.560594258419556 and b is -40.49841642021527\n",
      "Iteration 229, the loss is 66.14409832714242, parameters k is 20.554309624032204 and b is -40.49941642021527\n",
      "Iteration 230, the loss is 66.10360169775981, parameters k is 20.54802498964485 and b is -40.50041642021527\n",
      "Iteration 231, the loss is 66.06310506837703, parameters k is 20.5417403552575 and b is -40.501416420215264\n",
      "Iteration 232, the loss is 66.02260843899431, parameters k is 20.535455720870146 and b is -40.50241642021526\n",
      "Iteration 233, the loss is 65.98211180961172, parameters k is 20.529171086482794 and b is -40.50341642021526\n",
      "Iteration 234, the loss is 65.94161518022905, parameters k is 20.52288645209544 and b is -40.50441642021526\n",
      "Iteration 235, the loss is 65.90111855084636, parameters k is 20.51660181770809 and b is -40.505416420215255\n",
      "Iteration 236, the loss is 65.86062192146363, parameters k is 20.510317183320737 and b is -40.50641642021525\n",
      "Iteration 237, the loss is 65.82012529208093, parameters k is 20.504032548933385 and b is -40.50741642021525\n",
      "Iteration 238, the loss is 65.77962866269831, parameters k is 20.497747914546032 and b is -40.50841642021525\n",
      "Iteration 239, the loss is 65.7391320333156, parameters k is 20.49146328015868 and b is -40.509416420215246\n",
      "Iteration 240, the loss is 65.69863540393287, parameters k is 20.485178645771327 and b is -40.51041642021524\n",
      "Iteration 241, the loss is 65.65813877455021, parameters k is 20.478894011383975 and b is -40.51141642021524\n",
      "Iteration 242, the loss is 65.61764214516755, parameters k is 20.472609376996623 and b is -40.51241642021524\n",
      "Iteration 243, the loss is 65.57714551578488, parameters k is 20.46632474260927 and b is -40.513416420215236\n",
      "Iteration 244, the loss is 65.53664888640216, parameters k is 20.460040108221918 and b is -40.514416420215234\n",
      "Iteration 245, the loss is 65.49615225701952, parameters k is 20.453755473834565 and b is -40.51541642021523\n",
      "Iteration 246, the loss is 65.45565562763683, parameters k is 20.447470839447213 and b is -40.51641642021523\n",
      "Iteration 247, the loss is 65.41515899825404, parameters k is 20.44118620505986 and b is -40.51741642021523\n",
      "Iteration 248, the loss is 65.3746623688714, parameters k is 20.43490157067251 and b is -40.518416420215225\n",
      "Iteration 249, the loss is 65.33416573948875, parameters k is 20.428616936285156 and b is -40.51941642021522\n",
      "Iteration 250, the loss is 65.29366911010611, parameters k is 20.422332301897804 and b is -40.52041642021522\n",
      "Iteration 251, the loss is 65.25317248072334, parameters k is 20.41604766751045 and b is -40.52141642021522\n",
      "Iteration 252, the loss is 65.21267585134062, parameters k is 20.4097630331231 and b is -40.522416420215215\n",
      "Iteration 253, the loss is 65.17217922195802, parameters k is 20.403478398735746 and b is -40.52341642021521\n",
      "Iteration 254, the loss is 65.13168259257527, parameters k is 20.397193764348394 and b is -40.52441642021521\n",
      "Iteration 255, the loss is 65.09118596319259, parameters k is 20.39090912996104 and b is -40.52541642021521\n",
      "Iteration 256, the loss is 65.05068933380996, parameters k is 20.38462449557369 and b is -40.526416420215206\n",
      "Iteration 257, the loss is 65.0101927044273, parameters k is 20.378339861186337 and b is -40.527416420215204\n",
      "Iteration 258, the loss is 64.96969607504454, parameters k is 20.372055226798985 and b is -40.5284164202152\n",
      "Iteration 259, the loss is 64.9291994456618, parameters k is 20.365770592411632 and b is -40.5294164202152\n",
      "Iteration 260, the loss is 64.88870281627916, parameters k is 20.35948595802428 and b is -40.5304164202152\n",
      "Iteration 261, the loss is 64.84820618689653, parameters k is 20.353201323636927 and b is -40.531416420215194\n",
      "Iteration 262, the loss is 64.80770955751379, parameters k is 20.346916689249575 and b is -40.53241642021519\n",
      "Iteration 263, the loss is 64.76721292813107, parameters k is 20.340632054862223 and b is -40.53341642021519\n",
      "Iteration 264, the loss is 64.72671629874849, parameters k is 20.33434742047487 and b is -40.53441642021519\n",
      "Iteration 265, the loss is 64.68621966936577, parameters k is 20.328062786087518 and b is -40.535416420215185\n",
      "Iteration 266, the loss is 64.6457230399831, parameters k is 20.321778151700165 and b is -40.53641642021518\n",
      "Iteration 267, the loss is 64.60522641060041, parameters k is 20.315493517312813 and b is -40.53741642021518\n",
      "Iteration 268, the loss is 64.56472978121772, parameters k is 20.30920888292546 and b is -40.53841642021518\n",
      "Iteration 269, the loss is 64.52423315183493, parameters k is 20.30292424853811 and b is -40.539416420215176\n",
      "Iteration 270, the loss is 64.48373652245232, parameters k is 20.296639614150756 and b is -40.54041642021517\n",
      "Iteration 271, the loss is 64.44323989306959, parameters k is 20.290354979763404 and b is -40.54141642021517\n",
      "Iteration 272, the loss is 64.40274326368689, parameters k is 20.28407034537605 and b is -40.54241642021517\n",
      "Iteration 273, the loss is 64.3622466343042, parameters k is 20.2777857109887 and b is -40.543416420215166\n",
      "Iteration 274, the loss is 64.32175000492168, parameters k is 20.271501076601346 and b is -40.544416420215164\n",
      "Iteration 275, the loss is 64.28125337553892, parameters k is 20.265216442213994 and b is -40.54541642021516\n",
      "Iteration 276, the loss is 64.2407567461562, parameters k is 20.25893180782664 and b is -40.54641642021516\n",
      "Iteration 277, the loss is 64.20026011677349, parameters k is 20.25264717343929 and b is -40.54741642021516\n",
      "Iteration 278, the loss is 64.15976348739085, parameters k is 20.246362539051937 and b is -40.548416420215155\n",
      "Iteration 279, the loss is 64.11926685800817, parameters k is 20.240077904664584 and b is -40.54941642021515\n",
      "Iteration 280, the loss is 64.07877022862547, parameters k is 20.233793270277232 and b is -40.55041642021515\n",
      "Iteration 281, the loss is 64.03827359924276, parameters k is 20.22750863588988 and b is -40.55141642021515\n",
      "Iteration 282, the loss is 63.99777696986013, parameters k is 20.221224001502527 and b is -40.552416420215145\n",
      "Iteration 283, the loss is 63.95728034047738, parameters k is 20.214939367115175 and b is -40.55341642021514\n",
      "Iteration 284, the loss is 63.91678371109467, parameters k is 20.208654732727823 and b is -40.55441642021514\n",
      "Iteration 285, the loss is 63.87628708171199, parameters k is 20.20237009834047 and b is -40.55541642021514\n",
      "Iteration 286, the loss is 63.835790452329384, parameters k is 20.196085463953118 and b is -40.556416420215136\n",
      "Iteration 287, the loss is 63.79529382294665, parameters k is 20.189800829565765 and b is -40.557416420215134\n",
      "Iteration 288, the loss is 63.754797193563974, parameters k is 20.183516195178413 and b is -40.55841642021513\n",
      "Iteration 289, the loss is 63.7143005641813, parameters k is 20.17723156079106 and b is -40.55941642021513\n",
      "Iteration 290, the loss is 63.6738039347986, parameters k is 20.17094692640371 and b is -40.56041642021513\n",
      "Iteration 291, the loss is 63.63330730541592, parameters k is 20.164662292016356 and b is -40.561416420215124\n",
      "Iteration 292, the loss is 63.59281067603318, parameters k is 20.158377657629003 and b is -40.56241642021512\n",
      "Iteration 293, the loss is 63.552314046650565, parameters k is 20.15209302324165 and b is -40.56341642021512\n",
      "Iteration 294, the loss is 63.51181741726784, parameters k is 20.1458083888543 and b is -40.56441642021512\n",
      "Iteration 295, the loss is 63.47132078788515, parameters k is 20.139523754466946 and b is -40.565416420215115\n",
      "Iteration 296, the loss is 63.430824158502496, parameters k is 20.133239120079594 and b is -40.56641642021511\n",
      "Iteration 297, the loss is 63.39032752911983, parameters k is 20.12695448569224 and b is -40.56741642021511\n",
      "Iteration 298, the loss is 63.34983089973705, parameters k is 20.12066985130489 and b is -40.56841642021511\n",
      "Iteration 299, the loss is 63.309334270354434, parameters k is 20.114385216917537 and b is -40.569416420215106\n",
      "Iteration 300, the loss is 63.26883764097179, parameters k is 20.108100582530184 and b is -40.5704164202151\n",
      "Iteration 301, the loss is 63.22834101158904, parameters k is 20.101815948142832 and b is -40.5714164202151\n",
      "Iteration 302, the loss is 63.18784438220638, parameters k is 20.09553131375548 and b is -40.5724164202151\n",
      "Iteration 303, the loss is 63.147347752823684, parameters k is 20.089246679368127 and b is -40.573416420215096\n",
      "Iteration 304, the loss is 63.10685112344102, parameters k is 20.082962044980775 and b is -40.574416420215094\n",
      "Iteration 305, the loss is 63.066354494058345, parameters k is 20.076677410593422 and b is -40.57541642021509\n",
      "Iteration 306, the loss is 63.02585786467556, parameters k is 20.07039277620607 and b is -40.57641642021509\n",
      "Iteration 307, the loss is 62.98536123529297, parameters k is 20.064108141818718 and b is -40.57741642021509\n",
      "Iteration 308, the loss is 62.944864605910254, parameters k is 20.057823507431365 and b is -40.578416420215085\n",
      "Iteration 309, the loss is 62.90436797652762, parameters k is 20.051538873044013 and b is -40.57941642021508\n",
      "Iteration 310, the loss is 62.86387134714494, parameters k is 20.04525423865666 and b is -40.58041642021508\n",
      "Iteration 311, the loss is 62.823374717762164, parameters k is 20.038969604269308 and b is -40.58141642021508\n",
      "Iteration 312, the loss is 62.78287808837949, parameters k is 20.032684969881956 and b is -40.582416420215075\n",
      "Iteration 313, the loss is 62.74238145899681, parameters k is 20.026400335494603 and b is -40.58341642021507\n",
      "Iteration 314, the loss is 62.701884829614166, parameters k is 20.02011570110725 and b is -40.58441642021507\n",
      "Iteration 315, the loss is 62.6613882002315, parameters k is 20.0138310667199 and b is -40.58541642021507\n",
      "Iteration 316, the loss is 62.62089157084871, parameters k is 20.007546432332546 and b is -40.586416420215066\n",
      "Iteration 317, the loss is 62.58039494146605, parameters k is 20.001261797945194 and b is -40.587416420215064\n",
      "Iteration 318, the loss is 62.53989831208336, parameters k is 19.99497716355784 and b is -40.58841642021506\n",
      "Iteration 319, the loss is 62.49940168270075, parameters k is 19.98869252917049 and b is -40.58941642021506\n",
      "Iteration 320, the loss is 62.45890505331798, parameters k is 19.982407894783137 and b is -40.59041642021506\n",
      "Iteration 321, the loss is 62.4184084239353, parameters k is 19.976123260395784 and b is -40.591416420215054\n",
      "Iteration 322, the loss is 62.37791179455268, parameters k is 19.969838626008432 and b is -40.59241642021505\n",
      "Iteration 323, the loss is 62.33741516517003, parameters k is 19.96355399162108 and b is -40.59341642021505\n",
      "Iteration 324, the loss is 62.29691853578731, parameters k is 19.957269357233727 and b is -40.59441642021505\n",
      "Iteration 325, the loss is 62.256421906404604, parameters k is 19.950984722846375 and b is -40.595416420215045\n",
      "Iteration 326, the loss is 62.21592527702196, parameters k is 19.944700088459022 and b is -40.59641642021504\n",
      "Iteration 327, the loss is 62.175428647639194, parameters k is 19.93841545407167 and b is -40.59741642021504\n",
      "Iteration 328, the loss is 62.134932018256606, parameters k is 19.932130819684318 and b is -40.59841642021504\n",
      "Iteration 329, the loss is 62.094435388873826, parameters k is 19.925846185296965 and b is -40.599416420215036\n",
      "Iteration 330, the loss is 62.05393875949121, parameters k is 19.919561550909613 and b is -40.60041642021503\n",
      "Iteration 331, the loss is 62.01344213010848, parameters k is 19.91327691652226 and b is -40.60141642021503\n",
      "Iteration 332, the loss is 61.97294550072582, parameters k is 19.906992282134908 and b is -40.60241642021503\n",
      "Iteration 333, the loss is 61.93244887134314, parameters k is 19.900707647747556 and b is -40.60341642021503\n",
      "Iteration 334, the loss is 61.891952241960446, parameters k is 19.894423013360203 and b is -40.604416420215024\n",
      "Iteration 335, the loss is 61.85145561257776, parameters k is 19.88813837897285 and b is -40.60541642021502\n",
      "Iteration 336, the loss is 61.81095898319501, parameters k is 19.8818537445855 and b is -40.60641642021502\n",
      "Iteration 337, the loss is 61.77046235381239, parameters k is 19.875569110198146 and b is -40.60741642021502\n",
      "Iteration 338, the loss is 61.72996572442969, parameters k is 19.869284475810794 and b is -40.608416420215015\n",
      "Iteration 339, the loss is 61.68946909504701, parameters k is 19.86299984142344 and b is -40.60941642021501\n",
      "Iteration 340, the loss is 61.6489724656643, parameters k is 19.85671520703609 and b is -40.61041642021501\n",
      "Iteration 341, the loss is 61.608475836281684, parameters k is 19.850430572648737 and b is -40.61141642021501\n",
      "Iteration 342, the loss is 61.567979206898976, parameters k is 19.844145938261384 and b is -40.612416420215006\n",
      "Iteration 343, the loss is 61.527482577516274, parameters k is 19.837861303874032 and b is -40.613416420215\n",
      "Iteration 344, the loss is 61.48698594813355, parameters k is 19.83157666948668 and b is -40.614416420215\n",
      "Iteration 345, the loss is 61.44648931875093, parameters k is 19.825292035099327 and b is -40.615416420215\n",
      "Iteration 346, the loss is 61.405992689368304, parameters k is 19.819007400711975 and b is -40.616416420214996\n",
      "Iteration 347, the loss is 61.365496059985475, parameters k is 19.812722766324622 and b is -40.617416420214994\n",
      "Iteration 348, the loss is 61.324999430602844, parameters k is 19.80643813193727 and b is -40.61841642021499\n",
      "Iteration 349, the loss is 61.28450280122016, parameters k is 19.800153497549918 and b is -40.61941642021499\n",
      "Iteration 350, the loss is 61.24400617183749, parameters k is 19.793868863162565 and b is -40.62041642021499\n",
      "Iteration 351, the loss is 61.20350954245483, parameters k is 19.787584228775213 and b is -40.621416420214985\n",
      "Iteration 352, the loss is 61.16301291307209, parameters k is 19.78129959438786 and b is -40.62241642021498\n",
      "Iteration 353, the loss is 61.12251628368943, parameters k is 19.775014960000508 and b is -40.62341642021498\n",
      "Iteration 354, the loss is 61.08201965430673, parameters k is 19.768730325613156 and b is -40.62441642021498\n",
      "Iteration 355, the loss is 61.04152302492403, parameters k is 19.762445691225803 and b is -40.625416420214975\n",
      "Iteration 356, the loss is 61.001026395541345, parameters k is 19.75616105683845 and b is -40.62641642021497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 357, the loss is 60.96052976615868, parameters k is 19.7498764224511 and b is -40.62741642021497\n",
      "Iteration 358, the loss is 60.920033136776006, parameters k is 19.743591788063746 and b is -40.62841642021497\n",
      "Iteration 359, the loss is 60.87953650739331, parameters k is 19.737307153676394 and b is -40.629416420214966\n",
      "Iteration 360, the loss is 60.83903987801054, parameters k is 19.73102251928904 and b is -40.630416420214964\n",
      "Iteration 361, the loss is 60.79854324862789, parameters k is 19.72473788490169 and b is -40.63141642021496\n",
      "Iteration 362, the loss is 60.75804661924522, parameters k is 19.718453250514337 and b is -40.63241642021496\n",
      "Iteration 363, the loss is 60.71754998986259, parameters k is 19.712168616126984 and b is -40.63341642021496\n",
      "Iteration 364, the loss is 60.677053360479825, parameters k is 19.705883981739632 and b is -40.634416420214954\n",
      "Iteration 365, the loss is 60.63655673109715, parameters k is 19.69959934735228 and b is -40.63541642021495\n",
      "Iteration 366, the loss is 60.596060101714436, parameters k is 19.693314712964927 and b is -40.63641642021495\n",
      "Iteration 367, the loss is 60.555563472331855, parameters k is 19.687030078577575 and b is -40.63741642021495\n",
      "Iteration 368, the loss is 60.51506684294916, parameters k is 19.680745444190222 and b is -40.638416420214945\n",
      "Iteration 369, the loss is 60.474570213566444, parameters k is 19.67446080980287 and b is -40.63941642021494\n",
      "Iteration 370, the loss is 60.4340735841837, parameters k is 19.668176175415518 and b is -40.64041642021494\n",
      "Iteration 371, the loss is 60.39357695480104, parameters k is 19.661891541028165 and b is -40.64141642021494\n",
      "Iteration 372, the loss is 60.35308032541837, parameters k is 19.655606906640813 and b is -40.642416420214936\n",
      "Iteration 373, the loss is 60.31258369603566, parameters k is 19.64932227225346 and b is -40.64341642021493\n",
      "Iteration 374, the loss is 60.27208706665305, parameters k is 19.643037637866108 and b is -40.64441642021493\n",
      "Iteration 375, the loss is 60.23159043727032, parameters k is 19.636753003478756 and b is -40.64541642021493\n",
      "Iteration 376, the loss is 60.19109380788758, parameters k is 19.630468369091403 and b is -40.646416420214926\n",
      "Iteration 377, the loss is 60.150597178504995, parameters k is 19.62418373470405 and b is -40.647416420214924\n",
      "Iteration 378, the loss is 60.110100549122244, parameters k is 19.6178991003167 and b is -40.64841642021492\n",
      "Iteration 379, the loss is 60.069603919739535, parameters k is 19.611614465929346 and b is -40.64941642021492\n",
      "Iteration 380, the loss is 60.02910729035689, parameters k is 19.605329831541994 and b is -40.65041642021492\n",
      "Iteration 381, the loss is 59.988610660974196, parameters k is 19.59904519715464 and b is -40.651416420214915\n",
      "Iteration 382, the loss is 59.94811403159153, parameters k is 19.59276056276729 and b is -40.65241642021491\n",
      "Iteration 383, the loss is 59.90761740220882, parameters k is 19.586475928379937 and b is -40.65341642021491\n",
      "Iteration 384, the loss is 59.86712077282613, parameters k is 19.580191293992584 and b is -40.65441642021491\n",
      "Iteration 385, the loss is 59.82662414344346, parameters k is 19.573906659605232 and b is -40.655416420214905\n",
      "Iteration 386, the loss is 59.78612751406077, parameters k is 19.56762202521788 and b is -40.6564164202149\n",
      "Iteration 387, the loss is 59.74563088467807, parameters k is 19.561337390830527 and b is -40.6574164202149\n",
      "Iteration 388, the loss is 59.705134255295334, parameters k is 19.555052756443175 and b is -40.6584164202149\n",
      "Iteration 389, the loss is 59.66463762591267, parameters k is 19.548768122055822 and b is -40.659416420214896\n",
      "Iteration 390, the loss is 59.62414099653006, parameters k is 19.54248348766847 and b is -40.660416420214894\n",
      "Iteration 391, the loss is 59.58364436714738, parameters k is 19.536198853281117 and b is -40.66141642021489\n",
      "Iteration 392, the loss is 59.54314773776464, parameters k is 19.529914218893765 and b is -40.66241642021489\n",
      "Iteration 393, the loss is 59.502651108381976, parameters k is 19.523629584506413 and b is -40.66341642021489\n",
      "Iteration 394, the loss is 59.462154478999224, parameters k is 19.51734495011906 and b is -40.664416420214884\n",
      "Iteration 395, the loss is 59.421657849616565, parameters k is 19.511060315731708 and b is -40.66541642021488\n",
      "Iteration 396, the loss is 59.3811612202339, parameters k is 19.504775681344356 and b is -40.66641642021488\n",
      "Iteration 397, the loss is 59.34066459085122, parameters k is 19.498491046957003 and b is -40.66741642021488\n",
      "Iteration 398, the loss is 59.30016796146859, parameters k is 19.49220641256965 and b is -40.668416420214875\n",
      "Iteration 399, the loss is 59.25967133208581, parameters k is 19.4859217781823 and b is -40.66941642021487\n",
      "Iteration 400, the loss is 59.219174702703214, parameters k is 19.479637143794946 and b is -40.67041642021487\n",
      "Iteration 401, the loss is 59.17867807332046, parameters k is 19.473352509407594 and b is -40.67141642021487\n",
      "Iteration 402, the loss is 59.13818144393784, parameters k is 19.46706787502024 and b is -40.672416420214866\n",
      "Iteration 403, the loss is 59.09768481455511, parameters k is 19.46078324063289 and b is -40.67341642021486\n",
      "Iteration 404, the loss is 59.05718818517242, parameters k is 19.454498606245537 and b is -40.67441642021486\n",
      "Iteration 405, the loss is 59.01669155578972, parameters k is 19.448213971858184 and b is -40.67541642021486\n",
      "Iteration 406, the loss is 58.97619492640706, parameters k is 19.44192933747083 and b is -40.676416420214856\n",
      "Iteration 407, the loss is 58.935698297024324, parameters k is 19.43564470308348 and b is -40.677416420214854\n",
      "Iteration 408, the loss is 58.89520166764171, parameters k is 19.429360068696127 and b is -40.67841642021485\n",
      "Iteration 409, the loss is 58.854705038258935, parameters k is 19.423075434308775 and b is -40.67941642021485\n",
      "Iteration 410, the loss is 58.81420840887628, parameters k is 19.416790799921422 and b is -40.68041642021485\n",
      "Iteration 411, the loss is 58.773711779493645, parameters k is 19.41050616553407 and b is -40.681416420214845\n",
      "Iteration 412, the loss is 58.73321515011097, parameters k is 19.404221531146717 and b is -40.68241642021484\n",
      "Iteration 413, the loss is 58.69271852072827, parameters k is 19.397936896759365 and b is -40.68341642021484\n",
      "Iteration 414, the loss is 58.652221891345555, parameters k is 19.391652262372013 and b is -40.68441642021484\n",
      "Iteration 415, the loss is 58.61172526196282, parameters k is 19.38536762798466 and b is -40.685416420214835\n",
      "Iteration 416, the loss is 58.57122863258016, parameters k is 19.379082993597308 and b is -40.68641642021483\n",
      "Iteration 417, the loss is 58.53073200319747, parameters k is 19.372798359209956 and b is -40.68741642021483\n",
      "Iteration 418, the loss is 58.490235373814784, parameters k is 19.366513724822603 and b is -40.68841642021483\n",
      "Iteration 419, the loss is 58.449738744432075, parameters k is 19.36022909043525 and b is -40.689416420214826\n",
      "Iteration 420, the loss is 58.40924211504946, parameters k is 19.3539444560479 and b is -40.690416420214824\n",
      "Iteration 421, the loss is 58.368745485666715, parameters k is 19.347659821660546 and b is -40.69141642021482\n",
      "Iteration 422, the loss is 58.328248856284056, parameters k is 19.341375187273194 and b is -40.69241642021482\n",
      "Iteration 423, the loss is 58.2877522269014, parameters k is 19.33509055288584 and b is -40.69341642021482\n",
      "Iteration 424, the loss is 58.24725559751874, parameters k is 19.32880591849849 and b is -40.694416420214814\n",
      "Iteration 425, the loss is 58.206758968136036, parameters k is 19.322521284111136 and b is -40.69541642021481\n",
      "Iteration 426, the loss is 58.16626233875335, parameters k is 19.316236649723784 and b is -40.69641642021481\n",
      "Iteration 427, the loss is 58.12576570937063, parameters k is 19.30995201533643 and b is -40.69741642021481\n",
      "Iteration 428, the loss is 58.085269079987945, parameters k is 19.30366738094908 and b is -40.698416420214805\n",
      "Iteration 429, the loss is 58.04477245060526, parameters k is 19.297382746561727 and b is -40.6994164202148\n",
      "Iteration 430, the loss is 58.00427582122253, parameters k is 19.291098112174375 and b is -40.7004164202148\n",
      "Iteration 431, the loss is 57.96377919183989, parameters k is 19.284813477787022 and b is -40.7014164202148\n",
      "Iteration 432, the loss is 57.923282562457196, parameters k is 19.27852884339967 and b is -40.702416420214796\n",
      "Iteration 433, the loss is 57.882785933074516, parameters k is 19.272244209012317 and b is -40.70341642021479\n",
      "Iteration 434, the loss is 57.84228930369178, parameters k is 19.265959574624965 and b is -40.70441642021479\n",
      "Iteration 435, the loss is 57.801792674309205, parameters k is 19.259674940237613 and b is -40.70541642021479\n",
      "Iteration 436, the loss is 57.76129604492648, parameters k is 19.25339030585026 and b is -40.70641642021479\n",
      "Iteration 437, the loss is 57.72079941554381, parameters k is 19.247105671462908 and b is -40.707416420214784\n",
      "Iteration 438, the loss is 57.68030278616109, parameters k is 19.240821037075555 and b is -40.70841642021478\n",
      "Iteration 439, the loss is 57.63980615677843, parameters k is 19.234536402688203 and b is -40.70941642021478\n",
      "Iteration 440, the loss is 57.5993095273957, parameters k is 19.22825176830085 and b is -40.71041642021478\n",
      "Iteration 441, the loss is 57.55881289801306, parameters k is 19.2219671339135 and b is -40.711416420214775\n",
      "Iteration 442, the loss is 57.51831626863039, parameters k is 19.215682499526146 and b is -40.71241642021477\n",
      "Iteration 443, the loss is 57.47781963924765, parameters k is 19.209397865138794 and b is -40.71341642021477\n",
      "Iteration 444, the loss is 57.437323009864976, parameters k is 19.20311323075144 and b is -40.71441642021477\n",
      "Iteration 445, the loss is 57.39682638048226, parameters k is 19.19682859636409 and b is -40.715416420214765\n",
      "Iteration 446, the loss is 57.356329751099615, parameters k is 19.190543961976736 and b is -40.71641642021476\n",
      "Iteration 447, the loss is 57.31583312171697, parameters k is 19.184259327589384 and b is -40.71741642021476\n",
      "Iteration 448, the loss is 57.275336492334276, parameters k is 19.17797469320203 and b is -40.71841642021476\n",
      "Iteration 449, the loss is 57.234839862951546, parameters k is 19.17169005881468 and b is -40.719416420214756\n",
      "Iteration 450, the loss is 57.19434323356883, parameters k is 19.165405424427327 and b is -40.720416420214754\n",
      "Iteration 451, the loss is 57.15384660418617, parameters k is 19.159120790039974 and b is -40.72141642021475\n",
      "Iteration 452, the loss is 57.11342573318276, parameters k is 19.152836155652622 and b is -40.72241642021475\n",
      "Iteration 453, the loss is 57.073113708907236, parameters k is 19.146565596364084 and b is -40.72341246764558\n",
      "Iteration 454, the loss is 57.03280168463162, parameters k is 19.140295037075546 and b is -40.72440851507641\n",
      "Iteration 455, the loss is 56.99248966035609, parameters k is 19.13402447778701 and b is -40.725404562507244\n",
      "Iteration 456, the loss is 56.952177636080506, parameters k is 19.12775391849847 and b is -40.726400609938075\n",
      "Iteration 457, the loss is 56.911865611805005, parameters k is 19.121483359209932 and b is -40.72739665736891\n",
      "Iteration 458, the loss is 56.87155358752949, parameters k is 19.115212799921395 and b is -40.72839270479974\n",
      "Iteration 459, the loss is 56.831241563253954, parameters k is 19.108942240632857 and b is -40.72938875223057\n",
      "Iteration 460, the loss is 56.79092953897842, parameters k is 19.10267168134432 and b is -40.7303847996614\n",
      "Iteration 461, the loss is 56.75061751470287, parameters k is 19.09640112205578 and b is -40.73138084709223\n",
      "Iteration 462, the loss is 56.71030549042735, parameters k is 19.090130562767243 and b is -40.732376894523064\n",
      "Iteration 463, the loss is 56.66999346615182, parameters k is 19.083860003478705 and b is -40.733372941953895\n",
      "Iteration 464, the loss is 56.62968144187631, parameters k is 19.077589444190167 and b is -40.73436898938473\n",
      "Iteration 465, the loss is 56.589369417600736, parameters k is 19.07131888490163 and b is -40.73536503681556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 466, the loss is 56.54905739332523, parameters k is 19.06504832561309 and b is -40.73636108424639\n",
      "Iteration 467, the loss is 56.50874536904971, parameters k is 19.058777766324553 and b is -40.73735713167722\n",
      "Iteration 468, the loss is 56.468433344774134, parameters k is 19.052507207036015 and b is -40.73835317910805\n",
      "Iteration 469, the loss is 56.42812132049858, parameters k is 19.046236647747477 and b is -40.739349226538884\n",
      "Iteration 470, the loss is 56.38780929622309, parameters k is 19.03996608845894 and b is -40.740345273969716\n",
      "Iteration 471, the loss is 56.34749727194761, parameters k is 19.0336955291704 and b is -40.74134132140055\n",
      "Iteration 472, the loss is 56.30718524767203, parameters k is 19.027424969881864 and b is -40.74233736883138\n",
      "Iteration 473, the loss is 56.26687322339654, parameters k is 19.021154410593326 and b is -40.74333341626221\n",
      "Iteration 474, the loss is 56.226561199121, parameters k is 19.014883851304788 and b is -40.74432946369304\n",
      "Iteration 475, the loss is 56.18624917484543, parameters k is 19.00861329201625 and b is -40.74532551112387\n",
      "Iteration 476, the loss is 56.14593715056989, parameters k is 19.002342732727712 and b is -40.746321558554705\n",
      "Iteration 477, the loss is 56.10562512629435, parameters k is 18.996072173439174 and b is -40.747317605985536\n",
      "Iteration 478, the loss is 56.06531310201889, parameters k is 18.989801614150636 and b is -40.74831365341637\n",
      "Iteration 479, the loss is 56.02500107774334, parameters k is 18.983531054862098 and b is -40.7493097008472\n",
      "Iteration 480, the loss is 55.984689053467775, parameters k is 18.97726049557356 and b is -40.75030574827803\n",
      "Iteration 481, the loss is 55.94437702919228, parameters k is 18.970989936285022 and b is -40.75130179570886\n",
      "Iteration 482, the loss is 55.904065004916724, parameters k is 18.964719376996484 and b is -40.752297843139694\n",
      "Iteration 483, the loss is 55.86375298064116, parameters k is 18.958448817707946 and b is -40.753293890570525\n",
      "Iteration 484, the loss is 55.823440956365715, parameters k is 18.95217825841941 and b is -40.75428993800136\n",
      "Iteration 485, the loss is 55.78312893209013, parameters k is 18.94590769913087 and b is -40.75528598543219\n",
      "Iteration 486, the loss is 55.74281690781459, parameters k is 18.939637139842333 and b is -40.75628203286302\n",
      "Iteration 487, the loss is 55.70250488353914, parameters k is 18.933366580553795 and b is -40.75727808029385\n",
      "Iteration 488, the loss is 55.662192859263556, parameters k is 18.927096021265257 and b is -40.75827412772468\n",
      "Iteration 489, the loss is 55.62188083498805, parameters k is 18.92082546197672 and b is -40.759270175155514\n",
      "Iteration 490, the loss is 55.5815688107125, parameters k is 18.91455490268818 and b is -40.760266222586345\n",
      "Iteration 491, the loss is 55.541256786436946, parameters k is 18.908284343399643 and b is -40.76126227001718\n",
      "Iteration 492, the loss is 55.500944762161396, parameters k is 18.902013784111105 and b is -40.76225831744801\n",
      "Iteration 493, the loss is 55.46063273788593, parameters k is 18.895743224822567 and b is -40.76325436487884\n",
      "Iteration 494, the loss is 55.42032071361036, parameters k is 18.88947266553403 and b is -40.76425041230967\n",
      "Iteration 495, the loss is 55.38000868933478, parameters k is 18.88320210624549 and b is -40.7652464597405\n",
      "Iteration 496, the loss is 55.33969666505927, parameters k is 18.876931546956953 and b is -40.766242507171334\n",
      "Iteration 497, the loss is 55.29938464078375, parameters k is 18.870660987668415 and b is -40.767238554602166\n",
      "Iteration 498, the loss is 55.259072616508234, parameters k is 18.864390428379878 and b is -40.768234602033\n",
      "Iteration 499, the loss is 55.2187605922327, parameters k is 18.85811986909134 and b is -40.76923064946383\n",
      "Iteration 500, the loss is 55.178448567957155, parameters k is 18.8518493098028 and b is -40.77022669689466\n",
      "Iteration 501, the loss is 55.13813654368165, parameters k is 18.845578750514264 and b is -40.77122274432549\n",
      "Iteration 502, the loss is 55.09782451940615, parameters k is 18.839308191225726 and b is -40.77221879175632\n",
      "Iteration 503, the loss is 55.05751249513058, parameters k is 18.833037631937188 and b is -40.773214839187155\n",
      "Iteration 504, the loss is 55.01720047085501, parameters k is 18.82676707264865 and b is -40.774210886617986\n",
      "Iteration 505, the loss is 54.97688844657951, parameters k is 18.820496513360112 and b is -40.77520693404882\n",
      "Iteration 506, the loss is 54.93657642230401, parameters k is 18.814225954071574 and b is -40.77620298147965\n",
      "Iteration 507, the loss is 54.89626439802849, parameters k is 18.807955394783036 and b is -40.77719902891048\n",
      "Iteration 508, the loss is 54.85595237375291, parameters k is 18.8016848354945 and b is -40.77819507634131\n",
      "Iteration 509, the loss is 54.81564034947734, parameters k is 18.79541427620596 and b is -40.779191123772144\n",
      "Iteration 510, the loss is 54.77532832520185, parameters k is 18.789143716917422 and b is -40.780187171202975\n",
      "Iteration 511, the loss is 54.73501630092631, parameters k is 18.782873157628885 and b is -40.78118321863381\n",
      "Iteration 512, the loss is 54.69470427665078, parameters k is 18.776602598340347 and b is -40.78217926606464\n",
      "Iteration 513, the loss is 54.654392252375246, parameters k is 18.77033203905181 and b is -40.78317531349547\n",
      "Iteration 514, the loss is 54.614080228099716, parameters k is 18.76406147976327 and b is -40.7841713609263\n",
      "Iteration 515, the loss is 54.5737682038243, parameters k is 18.757790920474733 and b is -40.78516740835713\n",
      "Iteration 516, the loss is 54.533456179548665, parameters k is 18.751520361186195 and b is -40.786163455787964\n",
      "Iteration 517, the loss is 54.49314415527313, parameters k is 18.745249801897657 and b is -40.787159503218795\n",
      "Iteration 518, the loss is 54.45283213099757, parameters k is 18.73897924260912 and b is -40.78815555064963\n",
      "Iteration 519, the loss is 54.412520106722084, parameters k is 18.73270868332058 and b is -40.78915159808046\n",
      "Iteration 520, the loss is 54.372208082446605, parameters k is 18.726438124032043 and b is -40.79014764551129\n",
      "Iteration 521, the loss is 54.331896058171004, parameters k is 18.720167564743505 and b is -40.79114369294212\n",
      "Iteration 522, the loss is 54.29158403389545, parameters k is 18.713897005454967 and b is -40.79213974037295\n",
      "Iteration 523, the loss is 54.25127200961994, parameters k is 18.70762644616643 and b is -40.793135787803784\n",
      "Iteration 524, the loss is 54.210959985344395, parameters k is 18.70135588687789 and b is -40.794131835234616\n",
      "Iteration 525, the loss is 54.1706479610689, parameters k is 18.695085327589354 and b is -40.79512788266545\n",
      "Iteration 526, the loss is 54.1303359367934, parameters k is 18.688814768300816 and b is -40.79612393009628\n",
      "Iteration 527, the loss is 54.09002391251783, parameters k is 18.682544209012278 and b is -40.79711997752711\n",
      "Iteration 528, the loss is 54.04971188824232, parameters k is 18.67627364972374 and b is -40.79811602495794\n",
      "Iteration 529, the loss is 54.0093998639668, parameters k is 18.670003090435202 and b is -40.79911207238877\n",
      "Iteration 530, the loss is 53.96908783969121, parameters k is 18.663732531146664 and b is -40.800108119819605\n",
      "Iteration 531, the loss is 53.9287758154157, parameters k is 18.657461971858126 and b is -40.801104167250436\n",
      "Iteration 532, the loss is 53.88846379114013, parameters k is 18.651191412569588 and b is -40.80210021468127\n",
      "Iteration 533, the loss is 53.84815176686465, parameters k is 18.64492085328105 and b is -40.8030962621121\n",
      "Iteration 534, the loss is 53.8078397425891, parameters k is 18.638650293992512 and b is -40.80409230954293\n",
      "Iteration 535, the loss is 53.767527718313616, parameters k is 18.632379734703974 and b is -40.80508835697376\n",
      "Iteration 536, the loss is 53.72721569403798, parameters k is 18.626109175415436 and b is -40.806084404404594\n",
      "Iteration 537, the loss is 53.68690366976248, parameters k is 18.6198386161269 and b is -40.807080451835425\n",
      "Iteration 538, the loss is 53.64659164548697, parameters k is 18.61356805683836 and b is -40.80807649926626\n",
      "Iteration 539, the loss is 53.606279621211435, parameters k is 18.607297497549823 and b is -40.80907254669709\n",
      "Iteration 540, the loss is 53.5659675969359, parameters k is 18.601026938261285 and b is -40.81006859412792\n",
      "Iteration 541, the loss is 53.525655572660376, parameters k is 18.594756378972747 and b is -40.81106464155875\n",
      "Iteration 542, the loss is 53.485343548384876, parameters k is 18.58848581968421 and b is -40.81206068898958\n",
      "Iteration 543, the loss is 53.44503152410935, parameters k is 18.58221526039567 and b is -40.813056736420414\n",
      "Iteration 544, the loss is 53.404719499833774, parameters k is 18.575944701107133 and b is -40.814052783851245\n",
      "Iteration 545, the loss is 53.364407475558224, parameters k is 18.569674141818595 and b is -40.81504883128208\n",
      "Iteration 546, the loss is 53.32409545128274, parameters k is 18.563403582530057 and b is -40.81604487871291\n",
      "Iteration 547, the loss is 53.28378342700718, parameters k is 18.55713302324152 and b is -40.81704092614374\n",
      "Iteration 548, the loss is 53.24347140273165, parameters k is 18.55086246395298 and b is -40.81803697357457\n",
      "Iteration 549, the loss is 53.203159378456185, parameters k is 18.544591904664443 and b is -40.8190330210054\n",
      "Iteration 550, the loss is 53.16284735418056, parameters k is 18.538321345375905 and b is -40.820029068436234\n",
      "Iteration 551, the loss is 53.12253532990505, parameters k is 18.532050786087368 and b is -40.821025115867066\n",
      "Iteration 552, the loss is 53.08222330562952, parameters k is 18.52578022679883 and b is -40.8220211632979\n",
      "Iteration 553, the loss is 53.04191128135401, parameters k is 18.51950966751029 and b is -40.82301721072873\n",
      "Iteration 554, the loss is 53.00159925707848, parameters k is 18.513239108221754 and b is -40.82401325815956\n",
      "Iteration 555, the loss is 52.961287232802974, parameters k is 18.506968548933216 and b is -40.82500930559039\n",
      "Iteration 556, the loss is 52.92097520852739, parameters k is 18.500697989644678 and b is -40.82600535302122\n",
      "Iteration 557, the loss is 52.88066318425186, parameters k is 18.49442743035614 and b is -40.827001400452055\n",
      "Iteration 558, the loss is 52.840351159976315, parameters k is 18.488156871067602 and b is -40.827997447882886\n",
      "Iteration 559, the loss is 52.80003913570078, parameters k is 18.481886311779064 and b is -40.82899349531372\n",
      "Iteration 560, the loss is 52.759727111425285, parameters k is 18.475615752490526 and b is -40.82998954274455\n",
      "Iteration 561, the loss is 52.71941508714972, parameters k is 18.46934519320199 and b is -40.83098559017538\n",
      "Iteration 562, the loss is 52.67910306287424, parameters k is 18.46307463391345 and b is -40.83198163760621\n",
      "Iteration 563, the loss is 52.638791038598704, parameters k is 18.456804074624912 and b is -40.832977685037044\n",
      "Iteration 564, the loss is 52.59847901432321, parameters k is 18.450533515336375 and b is -40.833973732467875\n",
      "Iteration 565, the loss is 52.558166990047596, parameters k is 18.444262956047837 and b is -40.83496977989871\n",
      "Iteration 566, the loss is 52.5178549657721, parameters k is 18.4379923967593 and b is -40.83596582732954\n",
      "Iteration 567, the loss is 52.47754294149661, parameters k is 18.43172183747076 and b is -40.83696187476037\n",
      "Iteration 568, the loss is 52.43723091722104, parameters k is 18.425451278182223 and b is -40.8379579221912\n",
      "Iteration 569, the loss is 52.39691889294553, parameters k is 18.419180718893685 and b is -40.83895396962203\n",
      "Iteration 570, the loss is 52.35660686866999, parameters k is 18.412910159605147 and b is -40.839950017052864\n",
      "Iteration 571, the loss is 52.31629484439441, parameters k is 18.40663960031661 and b is -40.840946064483695\n",
      "Iteration 572, the loss is 52.275982820118905, parameters k is 18.40036904102807 and b is -40.84194211191453\n",
      "Iteration 573, the loss is 52.235670795843376, parameters k is 18.394098481739533 and b is -40.84293815934536\n",
      "Iteration 574, the loss is 52.19535877156785, parameters k is 18.387827922450995 and b is -40.84393420677619\n",
      "Iteration 575, the loss is 52.15504674729232, parameters k is 18.381557363162457 and b is -40.84493025420702\n",
      "Iteration 576, the loss is 52.114734723016774, parameters k is 18.37528680387392 and b is -40.84592630163785\n",
      "Iteration 577, the loss is 52.07442269874125, parameters k is 18.36901624458538 and b is -40.846922349068684\n",
      "Iteration 578, the loss is 52.03411067446569, parameters k is 18.362745685296844 and b is -40.847918396499516\n",
      "Iteration 579, the loss is 51.99379865019021, parameters k is 18.356475126008306 and b is -40.84891444393035\n",
      "Iteration 580, the loss is 51.953486625914664, parameters k is 18.350204566719768 and b is -40.84991049136118\n",
      "Iteration 581, the loss is 51.91317460163911, parameters k is 18.34393400743123 and b is -40.85090653879201\n",
      "Iteration 582, the loss is 51.87286257736361, parameters k is 18.337663448142692 and b is -40.85190258622284\n",
      "Iteration 583, the loss is 51.83255055308807, parameters k is 18.331392888854154 and b is -40.85289863365367\n",
      "Iteration 584, the loss is 51.79223852881254, parameters k is 18.325122329565616 and b is -40.853894681084505\n",
      "Iteration 585, the loss is 51.75192650453695, parameters k is 18.318851770277078 and b is -40.854890728515336\n",
      "Iteration 586, the loss is 51.71161448026143, parameters k is 18.31258121098854 and b is -40.85588677594617\n",
      "Iteration 587, the loss is 51.67130245598598, parameters k is 18.306310651700002 and b is -40.856882823377\n",
      "Iteration 588, the loss is 51.63099043171034, parameters k is 18.300040092411464 and b is -40.85787887080783\n",
      "Iteration 589, the loss is 51.590678407434844, parameters k is 18.293769533122926 and b is -40.85887491823866\n",
      "Iteration 590, the loss is 51.55036638315935, parameters k is 18.28749897383439 and b is -40.859870965669494\n",
      "Iteration 591, the loss is 51.51006685608857, parameters k is 18.28122841454585 and b is -40.860867013100325\n",
      "Iteration 592, the loss is 51.47000866528972, parameters k is 18.274977499526088 and b is -40.86185910796198\n",
      "Iteration 593, the loss is 51.42995047449092, parameters k is 18.268726584506325 and b is -40.86285120282364\n",
      "Iteration 594, the loss is 51.389892283692085, parameters k is 18.262475669486562 and b is -40.8638432976853\n",
      "Iteration 595, the loss is 51.349834092893275, parameters k is 18.2562247544668 and b is -40.86483539254696\n",
      "Iteration 596, the loss is 51.30977590209442, parameters k is 18.249973839447037 and b is -40.865827487408616\n",
      "Iteration 597, the loss is 51.2697177112956, parameters k is 18.243722924427274 and b is -40.866819582270274\n",
      "Iteration 598, the loss is 51.22965952049672, parameters k is 18.23747200940751 and b is -40.86781167713193\n",
      "Iteration 599, the loss is 51.189601329697986, parameters k is 18.23122109438775 and b is -40.86880377199359\n",
      "Iteration 600, the loss is 51.149543138899126, parameters k is 18.224970179367986 and b is -40.86979586685525\n",
      "Iteration 601, the loss is 51.109484948100274, parameters k is 18.218719264348223 and b is -40.87078796171691\n",
      "Iteration 602, the loss is 51.069426757301464, parameters k is 18.21246834932846 and b is -40.871780056578565\n",
      "Iteration 603, the loss is 51.02936856650264, parameters k is 18.206217434308698 and b is -40.87277215144022\n",
      "Iteration 604, the loss is 50.98931037570392, parameters k is 18.199966519288935 and b is -40.87376424630188\n",
      "Iteration 605, the loss is 50.94925218490501, parameters k is 18.193715604269173 and b is -40.87475634116354\n",
      "Iteration 606, the loss is 50.90919399410616, parameters k is 18.18746468924941 and b is -40.8757484360252\n",
      "Iteration 607, the loss is 50.869135803307366, parameters k is 18.181213774229647 and b is -40.876740530886856\n",
      "Iteration 608, the loss is 50.82907761250852, parameters k is 18.174962859209884 and b is -40.877732625748514\n",
      "Iteration 609, the loss is 50.78901942170971, parameters k is 18.16871194419012 and b is -40.87872472061017\n",
      "Iteration 610, the loss is 50.748961230910886, parameters k is 18.16246102917036 and b is -40.87971681547183\n",
      "Iteration 611, the loss is 50.7089030401121, parameters k is 18.156210114150596 and b is -40.88070891033349\n",
      "Iteration 612, the loss is 50.66884484931324, parameters k is 18.149959199130834 and b is -40.88170100519515\n",
      "Iteration 613, the loss is 50.628786658514464, parameters k is 18.14370828411107 and b is -40.882693100056805\n",
      "Iteration 614, the loss is 50.58872846771555, parameters k is 18.137457369091308 and b is -40.88368519491846\n",
      "Iteration 615, the loss is 50.548670276916724, parameters k is 18.131206454071545 and b is -40.88467728978012\n",
      "Iteration 616, the loss is 50.50861208611794, parameters k is 18.124955539051783 and b is -40.88566938464178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 617, the loss is 50.4685538953191, parameters k is 18.11870462403202 and b is -40.88666147950344\n",
      "Iteration 618, the loss is 50.428495704520266, parameters k is 18.112453709012257 and b is -40.887653574365096\n",
      "Iteration 619, the loss is 50.38843751372148, parameters k is 18.106202793992495 and b is -40.888645669226754\n",
      "Iteration 620, the loss is 50.34837932292262, parameters k is 18.099951878972732 and b is -40.88963776408841\n",
      "Iteration 621, the loss is 50.30832113212379, parameters k is 18.09370096395297 and b is -40.89062985895007\n",
      "Iteration 622, the loss is 50.26826294132496, parameters k is 18.087450048933206 and b is -40.89162195381173\n",
      "Iteration 623, the loss is 50.22820475052616, parameters k is 18.081199133913444 and b is -40.89261404867339\n",
      "Iteration 624, the loss is 50.18814655972729, parameters k is 18.07494821889368 and b is -40.893606143535045\n",
      "Iteration 625, the loss is 50.14808836892847, parameters k is 18.06869730387392 and b is -40.8945982383967\n",
      "Iteration 626, the loss is 50.108030178129646, parameters k is 18.062446388854156 and b is -40.89559033325836\n",
      "Iteration 627, the loss is 50.067971987330836, parameters k is 18.056195473834393 and b is -40.89658242812002\n",
      "Iteration 628, the loss is 50.02791379653202, parameters k is 18.04994455881463 and b is -40.89757452298168\n",
      "Iteration 629, the loss is 49.987855605733216, parameters k is 18.043693643794867 and b is -40.898566617843336\n",
      "Iteration 630, the loss is 49.94779741493442, parameters k is 18.037442728775105 and b is -40.899558712704994\n",
      "Iteration 631, the loss is 49.90773922413555, parameters k is 18.031191813755342 and b is -40.90055080756665\n",
      "Iteration 632, the loss is 49.867681033336716, parameters k is 18.02494089873558 and b is -40.90154290242831\n",
      "Iteration 633, the loss is 49.827622842537906, parameters k is 18.018689983715817 and b is -40.90253499728997\n",
      "Iteration 634, the loss is 49.787564651739075, parameters k is 18.012439068696054 and b is -40.90352709215163\n",
      "Iteration 635, the loss is 49.747506460940244, parameters k is 18.00618815367629 and b is -40.904519187013285\n",
      "Iteration 636, the loss is 49.70744827014142, parameters k is 17.99993723865653 and b is -40.905511281874944\n",
      "Iteration 637, the loss is 49.66739007934259, parameters k is 17.993686323636766 and b is -40.9065033767366\n",
      "Iteration 638, the loss is 49.627331888543765, parameters k is 17.987435408617003 and b is -40.90749547159826\n",
      "Iteration 639, the loss is 49.58727369774488, parameters k is 17.98118449359724 and b is -40.90848756645992\n",
      "Iteration 640, the loss is 49.54721550694606, parameters k is 17.974933578577478 and b is -40.909479661321576\n",
      "Iteration 641, the loss is 49.507157316147264, parameters k is 17.968682663557715 and b is -40.910471756183235\n",
      "Iteration 642, the loss is 49.46709912534842, parameters k is 17.962431748537952 and b is -40.91146385104489\n",
      "Iteration 643, the loss is 49.42704093454957, parameters k is 17.95618083351819 and b is -40.91245594590655\n",
      "Iteration 644, the loss is 49.38698274375082, parameters k is 17.949929918498427 and b is -40.91344804076821\n",
      "Iteration 645, the loss is 49.34692455295199, parameters k is 17.943679003478664 and b is -40.91444013562987\n",
      "Iteration 646, the loss is 49.30686636215312, parameters k is 17.9374280884589 and b is -40.915432230491525\n",
      "Iteration 647, the loss is 49.26680817135429, parameters k is 17.93117717343914 and b is -40.916424325353184\n",
      "Iteration 648, the loss is 49.22674998055549, parameters k is 17.924926258419376 and b is -40.91741642021484\n",
      "Iteration 649, the loss is 49.18669178975666, parameters k is 17.918675343399613 and b is -40.9184085150765\n",
      "Iteration 650, the loss is 49.14663359895783, parameters k is 17.91242442837985 and b is -40.91940060993816\n",
      "Iteration 651, the loss is 49.106575408159074, parameters k is 17.906173513360088 and b is -40.920392704799816\n",
      "Iteration 652, the loss is 49.06651721736022, parameters k is 17.899922598340325 and b is -40.921384799661475\n",
      "Iteration 653, the loss is 49.026459026561334, parameters k is 17.893671683320562 and b is -40.92237689452313\n",
      "Iteration 654, the loss is 48.98640083576256, parameters k is 17.8874207683008 and b is -40.92336898938479\n",
      "Iteration 655, the loss is 48.94634264496367, parameters k is 17.881169853281037 and b is -40.92436108424645\n",
      "Iteration 656, the loss is 48.90628445416484, parameters k is 17.874918938261274 and b is -40.92535317910811\n",
      "Iteration 657, the loss is 48.86622626336603, parameters k is 17.86866802324151 and b is -40.926345273969766\n",
      "Iteration 658, the loss is 48.82616807256725, parameters k is 17.86241710822175 and b is -40.927337368831424\n",
      "Iteration 659, the loss is 48.78610988176839, parameters k is 17.856166193201986 and b is -40.92832946369308\n",
      "Iteration 660, the loss is 48.74605169096961, parameters k is 17.849915278182223 and b is -40.92932155855474\n",
      "Iteration 661, the loss is 48.70599350017076, parameters k is 17.84366436316246 and b is -40.9303136534164\n",
      "Iteration 662, the loss is 48.665935309371854, parameters k is 17.837413448142698 and b is -40.93130574827806\n",
      "Iteration 663, the loss is 48.6258771185731, parameters k is 17.831162533122935 and b is -40.932297843139715\n",
      "Iteration 664, the loss is 48.58581892777424, parameters k is 17.824911618103172 and b is -40.93328993800137\n",
      "Iteration 665, the loss is 48.54576073697541, parameters k is 17.81866070308341 and b is -40.93428203286303\n",
      "Iteration 666, the loss is 48.50570254617656, parameters k is 17.812409788063647 and b is -40.93527412772469\n",
      "Iteration 667, the loss is 48.46564435537777, parameters k is 17.806158873043884 and b is -40.93626622258635\n",
      "Iteration 668, the loss is 48.42558616457897, parameters k is 17.79990795802412 and b is -40.937258317448006\n",
      "Iteration 669, the loss is 48.385527973780114, parameters k is 17.79365704300436 and b is -40.938250412309664\n",
      "Iteration 670, the loss is 48.34546978298134, parameters k is 17.787406127984596 and b is -40.93924250717132\n",
      "Iteration 671, the loss is 48.305411592182445, parameters k is 17.781155212964833 and b is -40.94023460203298\n",
      "Iteration 672, the loss is 48.26535340138365, parameters k is 17.77490429794507 and b is -40.94122669689464\n",
      "Iteration 673, the loss is 48.225295210584804, parameters k is 17.768653382925308 and b is -40.9422187917563\n",
      "Iteration 674, the loss is 48.18523701978595, parameters k is 17.762402467905545 and b is -40.943210886617955\n",
      "Iteration 675, the loss is 48.14517882898712, parameters k is 17.756151552885783 and b is -40.94420298147961\n",
      "Iteration 676, the loss is 48.105120638188325, parameters k is 17.74990063786602 and b is -40.94519507634127\n",
      "Iteration 677, the loss is 48.06506244738945, parameters k is 17.743649722846257 and b is -40.94618717120293\n",
      "Iteration 678, the loss is 48.02500425659067, parameters k is 17.737398807826494 and b is -40.94717926606459\n",
      "Iteration 679, the loss is 47.9849460657919, parameters k is 17.73114789280673 and b is -40.948171360926246\n",
      "Iteration 680, the loss is 47.944887874993, parameters k is 17.72489697778697 and b is -40.949163455787904\n",
      "Iteration 681, the loss is 47.90482968419423, parameters k is 17.718646062767206 and b is -40.95015555064956\n",
      "Iteration 682, the loss is 47.864771493395416, parameters k is 17.712395147747444 and b is -40.95114764551122\n",
      "Iteration 683, the loss is 47.824713302596514, parameters k is 17.70614423272768 and b is -40.95213974037288\n",
      "Iteration 684, the loss is 47.784655111797754, parameters k is 17.699893317707918 and b is -40.95313183523454\n",
      "Iteration 685, the loss is 47.7445969209989, parameters k is 17.693642402688155 and b is -40.954123930096195\n",
      "Iteration 686, the loss is 47.70453873020004, parameters k is 17.687391487668393 and b is -40.95511602495785\n",
      "Iteration 687, the loss is 47.66448053940125, parameters k is 17.68114057264863 and b is -40.95610811981951\n",
      "Iteration 688, the loss is 47.62442234860243, parameters k is 17.674889657628867 and b is -40.95710021468117\n",
      "Iteration 689, the loss is 47.58436415780362, parameters k is 17.668638742609104 and b is -40.95809230954283\n",
      "Iteration 690, the loss is 47.54430596700474, parameters k is 17.662387827589342 and b is -40.959084404404486\n",
      "Iteration 691, the loss is 47.504247776205894, parameters k is 17.65613691256958 and b is -40.960076499266144\n",
      "Iteration 692, the loss is 47.46418958540708, parameters k is 17.649885997549816 and b is -40.9610685941278\n",
      "Iteration 693, the loss is 47.42413139460831, parameters k is 17.643635082530054 and b is -40.96206068898946\n",
      "Iteration 694, the loss is 47.384073203809464, parameters k is 17.63738416751029 and b is -40.96305278385112\n",
      "Iteration 695, the loss is 47.34401501301071, parameters k is 17.631133252490528 and b is -40.96404487871278\n",
      "Iteration 696, the loss is 47.30395682221187, parameters k is 17.624882337470765 and b is -40.965036973574435\n",
      "Iteration 697, the loss is 47.26389863141298, parameters k is 17.618631422451003 and b is -40.96602906843609\n",
      "Iteration 698, the loss is 47.22384044061415, parameters k is 17.61238050743124 and b is -40.96702116329775\n",
      "Iteration 699, the loss is 47.18378224981535, parameters k is 17.606129592411477 and b is -40.96801325815941\n",
      "Iteration 700, the loss is 47.14372405901646, parameters k is 17.599878677391715 and b is -40.96900535302107\n",
      "Iteration 701, the loss is 47.103665868217746, parameters k is 17.593627762371952 and b is -40.969997447882726\n",
      "Iteration 702, the loss is 47.06360767741889, parameters k is 17.58737684735219 and b is -40.970989542744384\n",
      "Iteration 703, the loss is 47.02354948661999, parameters k is 17.581125932332426 and b is -40.97198163760604\n",
      "Iteration 704, the loss is 46.98349129582123, parameters k is 17.574875017312664 and b is -40.9729737324677\n",
      "Iteration 705, the loss is 46.94343310502235, parameters k is 17.5686241022929 and b is -40.97396582732936\n",
      "Iteration 706, the loss is 46.90337491422358, parameters k is 17.56237318727314 and b is -40.97495792219102\n",
      "Iteration 707, the loss is 46.863316723424724, parameters k is 17.556122272253376 and b is -40.975950017052675\n",
      "Iteration 708, the loss is 46.82325853262587, parameters k is 17.549871357233613 and b is -40.97694211191433\n",
      "Iteration 709, the loss is 46.78320034182705, parameters k is 17.54362044221385 and b is -40.97793420677599\n",
      "Iteration 710, the loss is 46.74314215102826, parameters k is 17.537369527194087 and b is -40.97892630163765\n",
      "Iteration 711, the loss is 46.70308396022943, parameters k is 17.531118612174325 and b is -40.97991839649931\n",
      "Iteration 712, the loss is 46.66302576943059, parameters k is 17.524867697154562 and b is -40.980910491360966\n",
      "Iteration 713, the loss is 46.62296757863181, parameters k is 17.5186167821348 and b is -40.981902586222624\n",
      "Iteration 714, the loss is 46.58290938783296, parameters k is 17.512365867115037 and b is -40.98289468108428\n",
      "Iteration 715, the loss is 46.54285119703414, parameters k is 17.506114952095274 and b is -40.98388677594594\n",
      "Iteration 716, the loss is 46.5027930062353, parameters k is 17.49986403707551 and b is -40.9848788708076\n",
      "Iteration 717, the loss is 46.462734815436455, parameters k is 17.49361312205575 and b is -40.98587096566926\n",
      "Iteration 718, the loss is 46.42267662463765, parameters k is 17.487362207035986 and b is -40.986863060530915\n",
      "Iteration 719, the loss is 46.382618433838836, parameters k is 17.481111292016223 and b is -40.98785515539257\n",
      "Iteration 720, the loss is 46.34256024303997, parameters k is 17.47486037699646 and b is -40.98884725025423\n",
      "Iteration 721, the loss is 46.30250205224119, parameters k is 17.468609461976698 and b is -40.98983934511589\n",
      "Iteration 722, the loss is 46.26244386144232, parameters k is 17.462358546956935 and b is -40.99083143997755\n",
      "Iteration 723, the loss is 46.22238567064344, parameters k is 17.456107631937172 and b is -40.991823534839206\n",
      "Iteration 724, the loss is 46.18232747984462, parameters k is 17.44985671691741 and b is -40.992815629700864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 725, the loss is 46.14226928904589, parameters k is 17.443605801897647 and b is -40.99380772456252\n",
      "Iteration 726, the loss is 46.10221109824701, parameters k is 17.437354886877884 and b is -40.99479981942418\n",
      "Iteration 727, the loss is 46.062152907448215, parameters k is 17.43110397185812 and b is -40.99579191428584\n",
      "Iteration 728, the loss is 46.022094716649356, parameters k is 17.42485305683836 and b is -40.9967840091475\n",
      "Iteration 729, the loss is 45.98203652585054, parameters k is 17.418602141818596 and b is -40.997776104009155\n",
      "Iteration 730, the loss is 45.94197833505176, parameters k is 17.412351226798833 and b is -40.99876819887081\n",
      "Iteration 731, the loss is 45.901920144252884, parameters k is 17.40610031177907 and b is -40.99976029373247\n",
      "Iteration 732, the loss is 45.8618619534541, parameters k is 17.399849396759308 and b is -41.00075238859413\n",
      "Iteration 733, the loss is 45.82180376265528, parameters k is 17.393598481739545 and b is -41.00174448345579\n",
      "Iteration 734, the loss is 45.78174557185645, parameters k is 17.387347566719782 and b is -41.002736578317446\n",
      "Iteration 735, the loss is 45.74168738105756, parameters k is 17.38109665170002 and b is -41.003728673179104\n",
      "Iteration 736, the loss is 45.70162919025875, parameters k is 17.374845736680257 and b is -41.00472076804076\n",
      "Iteration 737, the loss is 45.66157099945993, parameters k is 17.368594821660494 and b is -41.00571286290242\n",
      "Iteration 738, the loss is 45.62151280866114, parameters k is 17.36234390664073 and b is -41.00670495776408\n",
      "Iteration 739, the loss is 45.58145461786228, parameters k is 17.35609299162097 and b is -41.00769705262574\n",
      "Iteration 740, the loss is 45.541396427063425, parameters k is 17.349842076601206 and b is -41.008689147487395\n",
      "Iteration 741, the loss is 45.50133823626463, parameters k is 17.343591161581443 and b is -41.00968124234905\n",
      "Iteration 742, the loss is 45.46128004546577, parameters k is 17.33734024656168 and b is -41.01067333721071\n",
      "Iteration 743, the loss is 45.421221854667024, parameters k is 17.331089331541918 and b is -41.01166543207237\n",
      "Iteration 744, the loss is 45.381163663868165, parameters k is 17.324838416522155 and b is -41.01265752693403\n",
      "Iteration 745, the loss is 45.34110547306933, parameters k is 17.318587501502392 and b is -41.013649621795686\n",
      "Iteration 746, the loss is 45.30104728227046, parameters k is 17.31233658648263 and b is -41.014641716657344\n",
      "Iteration 747, the loss is 45.26098909147166, parameters k is 17.306085671462867 and b is -41.015633811519\n",
      "Iteration 748, the loss is 45.22093090067285, parameters k is 17.299834756443104 and b is -41.01662590638066\n",
      "Iteration 749, the loss is 45.18087270987406, parameters k is 17.29358384142334 and b is -41.01761800124232\n",
      "Iteration 750, the loss is 45.14081451907518, parameters k is 17.28733292640358 and b is -41.01861009610398\n",
      "Iteration 751, the loss is 45.100756328276375, parameters k is 17.281082011383816 and b is -41.019602190965635\n",
      "Iteration 752, the loss is 45.06069813747756, parameters k is 17.274831096364053 and b is -41.02059428582729\n",
      "Iteration 753, the loss is 45.02063994667871, parameters k is 17.26858018134429 and b is -41.02158638068895\n",
      "Iteration 754, the loss is 44.980581755879825, parameters k is 17.262329266324528 and b is -41.02257847555061\n",
      "Iteration 755, the loss is 44.9405235650811, parameters k is 17.256078351304765 and b is -41.02357057041227\n",
      "Iteration 756, the loss is 44.90046537428224, parameters k is 17.249827436285003 and b is -41.024562665273926\n",
      "Iteration 757, the loss is 44.860407183483424, parameters k is 17.24357652126524 and b is -41.025554760135584\n",
      "Iteration 758, the loss is 44.820348992684586, parameters k is 17.237325606245477 and b is -41.02654685499724\n",
      "Iteration 759, the loss is 44.78029080188572, parameters k is 17.231074691225714 and b is -41.0275389498589\n",
      "Iteration 760, the loss is 44.74023261108689, parameters k is 17.22482377620595 and b is -41.02853104472056\n",
      "Iteration 761, the loss is 44.70017442028805, parameters k is 17.21857286118619 and b is -41.02952313958222\n",
      "Iteration 762, the loss is 44.66011622948922, parameters k is 17.212321946166426 and b is -41.030515234443875\n",
      "Iteration 763, the loss is 44.62005803869046, parameters k is 17.206071031146664 and b is -41.03150732930553\n",
      "Iteration 764, the loss is 44.57999984789161, parameters k is 17.1998201161269 and b is -41.03249942416719\n",
      "Iteration 765, the loss is 44.53994165709276, parameters k is 17.193569201107138 and b is -41.03349151902885\n",
      "Iteration 766, the loss is 44.49988346629391, parameters k is 17.187318286087375 and b is -41.03448361389051\n",
      "Iteration 767, the loss is 44.45982527549519, parameters k is 17.181067371067613 and b is -41.035475708752166\n",
      "Iteration 768, the loss is 44.419767084696296, parameters k is 17.17481645604785 and b is -41.036467803613824\n",
      "Iteration 769, the loss is 44.37970889389746, parameters k is 17.168565541028087 and b is -41.03745989847548\n",
      "Iteration 770, the loss is 44.33965070309865, parameters k is 17.162314626008325 and b is -41.03845199333714\n",
      "Iteration 771, the loss is 44.2995925122998, parameters k is 17.156063710988562 and b is -41.0394440881988\n",
      "Iteration 772, the loss is 44.259534321501064, parameters k is 17.1498127959688 and b is -41.04043618306046\n",
      "Iteration 773, the loss is 44.21947613070217, parameters k is 17.143561880949036 and b is -41.041428277922115\n",
      "Iteration 774, the loss is 44.179417939903395, parameters k is 17.137310965929274 and b is -41.04242037278377\n",
      "Iteration 775, the loss is 44.13935974910453, parameters k is 17.13106005090951 and b is -41.04341246764543\n",
      "Iteration 776, the loss is 44.099301558305676, parameters k is 17.12480913588975 and b is -41.04440456250709\n",
      "Iteration 777, the loss is 44.05924336750684, parameters k is 17.118558220869986 and b is -41.04539665736875\n",
      "Iteration 778, the loss is 44.01918517670806, parameters k is 17.112307305850223 and b is -41.046388752230406\n",
      "Iteration 779, the loss is 43.979126985909296, parameters k is 17.10605639083046 and b is -41.047380847092064\n",
      "Iteration 780, the loss is 43.939068795110394, parameters k is 17.099805475810697 and b is -41.04837294195372\n",
      "Iteration 781, the loss is 43.899010604311584, parameters k is 17.093554560790935 and b is -41.04936503681538\n",
      "Iteration 782, the loss is 43.85895241351277, parameters k is 17.087303645771172 and b is -41.05035713167704\n",
      "Iteration 783, the loss is 43.81889422271387, parameters k is 17.08105273075141 and b is -41.0513492265387\n",
      "Iteration 784, the loss is 43.7788360319151, parameters k is 17.074801815731647 and b is -41.052341321400355\n",
      "Iteration 785, the loss is 43.73877784111628, parameters k is 17.068550900711884 and b is -41.053333416262014\n",
      "Iteration 786, the loss is 43.6987196503174, parameters k is 17.06229998569212 and b is -41.05432551112367\n",
      "Iteration 787, the loss is 43.65866145951863, parameters k is 17.05604907067236 and b is -41.05531760598533\n",
      "Iteration 788, the loss is 43.618603268719816, parameters k is 17.049798155652596 and b is -41.05630970084699\n",
      "Iteration 789, the loss is 43.57854507792094, parameters k is 17.043547240632833 and b is -41.057301795708646\n",
      "Iteration 790, the loss is 43.53848688712215, parameters k is 17.03729632561307 and b is -41.058293890570305\n",
      "Iteration 791, the loss is 43.4984286963233, parameters k is 17.031045410593308 and b is -41.05928598543196\n",
      "Iteration 792, the loss is 43.4583705055245, parameters k is 17.024794495573545 and b is -41.06027808029362\n",
      "Iteration 793, the loss is 43.418312314725654, parameters k is 17.018543580553782 and b is -41.06127017515528\n",
      "Iteration 794, the loss is 43.378254123926844, parameters k is 17.01229266553402 and b is -41.06226227001694\n",
      "Iteration 795, the loss is 43.33819593312801, parameters k is 17.006041750514257 and b is -41.063254364878595\n",
      "Iteration 796, the loss is 43.298137742329146, parameters k is 16.999790835494494 and b is -41.064246459740254\n",
      "Iteration 797, the loss is 43.25807955153037, parameters k is 16.99353992047473 and b is -41.06523855460191\n",
      "Iteration 798, the loss is 43.218021360731484, parameters k is 16.98728900545497 and b is -41.06623064946357\n",
      "Iteration 799, the loss is 43.17796316993268, parameters k is 16.981038090435206 and b is -41.06722274432523\n",
      "Iteration 800, the loss is 43.13790497913388, parameters k is 16.974787175415443 and b is -41.068214839186886\n",
      "Iteration 801, the loss is 43.09784678833501, parameters k is 16.96853626039568 and b is -41.069206934048545\n",
      "Iteration 802, the loss is 43.05778859753625, parameters k is 16.962285345375918 and b is -41.0701990289102\n",
      "Iteration 803, the loss is 43.017730406737364, parameters k is 16.956034430356155 and b is -41.07119112377186\n",
      "Iteration 804, the loss is 42.977672215938554, parameters k is 16.949783515336392 and b is -41.07218321863352\n",
      "Iteration 805, the loss is 42.93761402513971, parameters k is 16.94353260031663 and b is -41.07317531349518\n",
      "Iteration 806, the loss is 42.89755583434089, parameters k is 16.937281685296867 and b is -41.074167408356836\n",
      "Iteration 807, the loss is 42.85749764354211, parameters k is 16.931030770277104 and b is -41.075159503218494\n",
      "Iteration 808, the loss is 42.817439452743265, parameters k is 16.92477985525734 and b is -41.07615159808015\n",
      "Iteration 809, the loss is 42.777381261944484, parameters k is 16.91852894023758 and b is -41.07714369294181\n",
      "Iteration 810, the loss is 42.7373230711456, parameters k is 16.912278025217816 and b is -41.07813578780347\n",
      "Iteration 811, the loss is 42.697264880346765, parameters k is 16.906027110198053 and b is -41.07912788266513\n",
      "Iteration 812, the loss is 42.65720668954797, parameters k is 16.89977619517829 and b is -41.080119977526785\n",
      "Iteration 813, the loss is 42.61714849874913, parameters k is 16.893525280158528 and b is -41.08111207238844\n",
      "Iteration 814, the loss is 42.57709030795029, parameters k is 16.887274365138765 and b is -41.0821041672501\n",
      "Iteration 815, the loss is 42.537032117151476, parameters k is 16.881023450119002 and b is -41.08309626211176\n",
      "Iteration 816, the loss is 42.49697392635264, parameters k is 16.87477253509924 and b is -41.08408835697342\n",
      "Iteration 817, the loss is 42.45691573555385, parameters k is 16.868521620079477 and b is -41.085080451835076\n",
      "Iteration 818, the loss is 42.41685754475498, parameters k is 16.862270705059714 and b is -41.086072546696734\n",
      "Iteration 819, the loss is 42.376799353956166, parameters k is 16.85601979003995 and b is -41.08706464155839\n",
      "Iteration 820, the loss is 42.33674116315739, parameters k is 16.84976887502019 and b is -41.08805673642005\n",
      "Iteration 821, the loss is 42.29668297235851, parameters k is 16.843517960000426 and b is -41.08904883128171\n",
      "Iteration 822, the loss is 42.2566247815597, parameters k is 16.837267044980663 and b is -41.09004092614337\n",
      "Iteration 823, the loss is 42.21656659076085, parameters k is 16.8310161299609 and b is -41.091033021005025\n",
      "Iteration 824, the loss is 42.176508399962046, parameters k is 16.824765214941138 and b is -41.09202511586668\n",
      "Iteration 825, the loss is 42.136450209163215, parameters k is 16.818514299921375 and b is -41.09301721072834\n",
      "Iteration 826, the loss is 42.096392018364384, parameters k is 16.812263384901613 and b is -41.09400930559\n",
      "Iteration 827, the loss is 42.05633382756555, parameters k is 16.80601246988185 and b is -41.09500140045166\n",
      "Iteration 828, the loss is 42.01627563676674, parameters k is 16.799761554862087 and b is -41.095993495313316\n",
      "Iteration 829, the loss is 41.97621744596794, parameters k is 16.793510639842324 and b is -41.096985590174974\n",
      "Iteration 830, the loss is 41.93615925516906, parameters k is 16.78725972482256 and b is -41.09797768503663\n",
      "Iteration 831, the loss is 41.89610106437024, parameters k is 16.7810088098028 and b is -41.09896977989829\n",
      "Iteration 832, the loss is 41.85604287357147, parameters k is 16.774757894783036 and b is -41.09996187475995\n",
      "Iteration 833, the loss is 41.815984682772545, parameters k is 16.768506979763274 and b is -41.10095396962161\n",
      "Iteration 834, the loss is 41.77592649197378, parameters k is 16.76225606474351 and b is -41.101946064483265\n",
      "Iteration 835, the loss is 41.73586830117494, parameters k is 16.756005149723748 and b is -41.10293815934492\n",
      "Iteration 836, the loss is 41.69581011037611, parameters k is 16.749754234703985 and b is -41.10393025420658\n",
      "Iteration 837, the loss is 41.655751919577305, parameters k is 16.743503319684223 and b is -41.10492234906824\n",
      "Iteration 838, the loss is 41.61569372877846, parameters k is 16.73725240466446 and b is -41.1059144439299\n",
      "Iteration 839, the loss is 41.575635537979686, parameters k is 16.731001489644697 and b is -41.106906538791556\n",
      "Iteration 840, the loss is 41.53557734718081, parameters k is 16.724750574624935 and b is -41.107898633653214\n",
      "Iteration 841, the loss is 41.495519156381945, parameters k is 16.718499659605172 and b is -41.10889072851487\n",
      "Iteration 842, the loss is 41.45546096558318, parameters k is 16.71224874458541 and b is -41.10988282337653\n",
      "Iteration 843, the loss is 41.415402774784326, parameters k is 16.705997829565646 and b is -41.11087491823819\n",
      "Iteration 844, the loss is 41.37534458398554, parameters k is 16.699746914545884 and b is -41.11186701309985\n",
      "Iteration 845, the loss is 41.33528639318667, parameters k is 16.69349599952612 and b is -41.112859107961505\n",
      "Iteration 846, the loss is 41.29522820238786, parameters k is 16.68724508450636 and b is -41.11385120282316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 847, the loss is 41.255170011589044, parameters k is 16.680994169486596 and b is -41.11484329768482\n",
      "Iteration 848, the loss is 41.215111820790206, parameters k is 16.674743254466833 and b is -41.11583539254648\n",
      "Iteration 849, the loss is 41.17505362999136, parameters k is 16.66849233944707 and b is -41.11682748740814\n",
      "Iteration 850, the loss is 41.134995439192515, parameters k is 16.662241424427307 and b is -41.117819582269796\n",
      "Iteration 851, the loss is 41.09493724839373, parameters k is 16.655990509407545 and b is -41.118811677131454\n",
      "Iteration 852, the loss is 41.054879057594945, parameters k is 16.649739594387782 and b is -41.11980377199311\n",
      "Iteration 853, the loss is 41.014820866796065, parameters k is 16.64348867936802 and b is -41.12079586685477\n",
      "Iteration 854, the loss is 40.97476267599723, parameters k is 16.637237764348257 and b is -41.12178796171643\n",
      "Iteration 855, the loss is 40.93470448519843, parameters k is 16.630986849328494 and b is -41.12278005657809\n",
      "Iteration 856, the loss is 40.894655848696864, parameters k is 16.62473593430873 and b is -41.123772151439745\n",
      "Iteration 857, the loss is 40.854796139413104, parameters k is 16.61850028806367 and b is -41.12476029373224\n",
      "Iteration 858, the loss is 40.81493643012943, parameters k is 16.612264641818612 and b is -41.12574843602473\n",
      "Iteration 859, the loss is 40.775076720845625, parameters k is 16.606028995573553 and b is -41.12673657831722\n",
      "Iteration 860, the loss is 40.73521701156198, parameters k is 16.599793349328493 and b is -41.12772472060971\n",
      "Iteration 861, the loss is 40.69535730227818, parameters k is 16.593557703083434 and b is -41.128712862902205\n",
      "Iteration 862, the loss is 40.65549759299443, parameters k is 16.587322056838374 and b is -41.1297010051947\n",
      "Iteration 863, the loss is 40.61563788371075, parameters k is 16.581086410593315 and b is -41.13068914748719\n",
      "Iteration 864, the loss is 40.57577817442703, parameters k is 16.574850764348255 and b is -41.13167728977968\n",
      "Iteration 865, the loss is 40.53591846514326, parameters k is 16.568615118103196 and b is -41.13266543207217\n",
      "Iteration 866, the loss is 40.496058755859515, parameters k is 16.562379471858137 and b is -41.133653574364665\n",
      "Iteration 867, the loss is 40.456199046575776, parameters k is 16.556143825613077 and b is -41.13464171665716\n",
      "Iteration 868, the loss is 40.41633933729202, parameters k is 16.549908179368018 and b is -41.13562985894965\n",
      "Iteration 869, the loss is 40.37647962800831, parameters k is 16.543672533122958 and b is -41.13661800124214\n",
      "Iteration 870, the loss is 40.3366199187246, parameters k is 16.5374368868779 and b is -41.13760614353463\n",
      "Iteration 871, the loss is 40.29676020944086, parameters k is 16.53120124063284 and b is -41.138594285827125\n",
      "Iteration 872, the loss is 40.256900500157116, parameters k is 16.52496559438778 and b is -41.13958242811962\n",
      "Iteration 873, the loss is 40.217040790873405, parameters k is 16.51872994814272 and b is -41.14057057041211\n",
      "Iteration 874, the loss is 40.177181081589666, parameters k is 16.51249430189766 and b is -41.1415587127046\n",
      "Iteration 875, the loss is 40.13732137230595, parameters k is 16.5062586556526 and b is -41.14254685499709\n",
      "Iteration 876, the loss is 40.09746166302218, parameters k is 16.500023009407542 and b is -41.143534997289585\n",
      "Iteration 877, the loss is 40.057601953738484, parameters k is 16.493787363162483 and b is -41.14452313958208\n",
      "Iteration 878, the loss is 40.01774224445476, parameters k is 16.487551716917423 and b is -41.14551128187457\n",
      "Iteration 879, the loss is 39.97788253517097, parameters k is 16.481316070672364 and b is -41.14649942416706\n",
      "Iteration 880, the loss is 39.938022825887266, parameters k is 16.475080424427304 and b is -41.14748756645955\n",
      "Iteration 881, the loss is 39.89816311660346, parameters k is 16.468844778182245 and b is -41.148475708752045\n",
      "Iteration 882, the loss is 39.85830340731978, parameters k is 16.462609131937185 and b is -41.14946385104454\n",
      "Iteration 883, the loss is 39.81844369803606, parameters k is 16.456373485692126 and b is -41.15045199333703\n",
      "Iteration 884, the loss is 39.77858398875238, parameters k is 16.450137839447066 and b is -41.15144013562952\n",
      "Iteration 885, the loss is 39.73872427946858, parameters k is 16.443902193202007 and b is -41.15242827792201\n",
      "Iteration 886, the loss is 39.69886457018483, parameters k is 16.437666546956947 and b is -41.153416420214505\n",
      "Iteration 887, the loss is 39.65900486090117, parameters k is 16.431430900711888 and b is -41.154404562507\n",
      "Iteration 888, the loss is 39.6191451516174, parameters k is 16.42519525446683 and b is -41.15539270479949\n",
      "Iteration 889, the loss is 39.57928544233363, parameters k is 16.41895960822177 and b is -41.15638084709198\n",
      "Iteration 890, the loss is 39.53942573304996, parameters k is 16.41272396197671 and b is -41.15736898938447\n",
      "Iteration 891, the loss is 39.499566023766256, parameters k is 16.40648831573165 and b is -41.158357131676965\n",
      "Iteration 892, the loss is 39.45970631448245, parameters k is 16.40025266948659 and b is -41.15934527396946\n",
      "Iteration 893, the loss is 39.41984660519872, parameters k is 16.39401702324153 and b is -41.16033341626195\n",
      "Iteration 894, the loss is 39.379986895914996, parameters k is 16.38778137699647 and b is -41.16132155855444\n",
      "Iteration 895, the loss is 39.34012718663126, parameters k is 16.381545730751412 and b is -41.16230970084693\n",
      "Iteration 896, the loss is 39.300267477347546, parameters k is 16.375310084506353 and b is -41.163297843139425\n",
      "Iteration 897, the loss is 39.26040776806382, parameters k is 16.369074438261293 and b is -41.16428598543192\n",
      "Iteration 898, the loss is 39.220548058780075, parameters k is 16.362838792016234 and b is -41.16527412772441\n",
      "Iteration 899, the loss is 39.18068834949636, parameters k is 16.356603145771174 and b is -41.1662622700169\n",
      "Iteration 900, the loss is 39.14082864021261, parameters k is 16.350367499526115 and b is -41.16725041230939\n",
      "Iteration 901, the loss is 39.10096893092884, parameters k is 16.344131853281056 and b is -41.168238554601885\n",
      "Iteration 902, the loss is 39.06110922164511, parameters k is 16.337896207035996 and b is -41.16922669689438\n",
      "Iteration 903, the loss is 39.021249512361415, parameters k is 16.331660560790937 and b is -41.17021483918687\n",
      "Iteration 904, the loss is 38.981389803077704, parameters k is 16.325424914545877 and b is -41.17120298147936\n",
      "Iteration 905, the loss is 38.94153009379393, parameters k is 16.319189268300818 and b is -41.17219112377185\n",
      "Iteration 906, the loss is 38.901670384510226, parameters k is 16.31295362205576 and b is -41.173179266064345\n",
      "Iteration 907, the loss is 38.861810675226444, parameters k is 16.3067179758107 and b is -41.17416740835684\n",
      "Iteration 908, the loss is 38.821950965942776, parameters k is 16.30048232956564 and b is -41.17515555064933\n",
      "Iteration 909, the loss is 38.78209125665895, parameters k is 16.29424668332058 and b is -41.17614369294182\n",
      "Iteration 910, the loss is 38.742231547375305, parameters k is 16.28801103707552 and b is -41.17713183523431\n",
      "Iteration 911, the loss is 38.70237183809152, parameters k is 16.28177539083046 and b is -41.178119977526805\n",
      "Iteration 912, the loss is 38.66251212880782, parameters k is 16.2755397445854 and b is -41.1791081198193\n",
      "Iteration 913, the loss is 38.622652419524094, parameters k is 16.269304098340342 and b is -41.18009626211179\n",
      "Iteration 914, the loss is 38.582792710240355, parameters k is 16.263068452095283 and b is -41.18108440440428\n",
      "Iteration 915, the loss is 38.542933000956644, parameters k is 16.256832805850223 and b is -41.18207254669677\n",
      "Iteration 916, the loss is 38.503073291672926, parameters k is 16.250597159605164 and b is -41.183060688989265\n",
      "Iteration 917, the loss is 38.463213582389194, parameters k is 16.244361513360104 and b is -41.18404883128176\n",
      "Iteration 918, the loss is 38.42335387310547, parameters k is 16.238125867115045 and b is -41.18503697357425\n",
      "Iteration 919, the loss is 38.383494163821666, parameters k is 16.231890220869985 and b is -41.18602511586674\n",
      "Iteration 920, the loss is 38.34363445453797, parameters k is 16.225654574624926 and b is -41.18701325815923\n",
      "Iteration 921, the loss is 38.30377474525424, parameters k is 16.219418928379866 and b is -41.188001400451725\n",
      "Iteration 922, the loss is 38.263915035970506, parameters k is 16.213183282134807 and b is -41.18898954274422\n",
      "Iteration 923, the loss is 38.22405532668677, parameters k is 16.206947635889748 and b is -41.18997768503671\n",
      "Iteration 924, the loss is 38.18419561740305, parameters k is 16.200711989644688 and b is -41.1909658273292\n",
      "Iteration 925, the loss is 38.1443359081193, parameters k is 16.19447634339963 and b is -41.19195396962169\n",
      "Iteration 926, the loss is 38.104476198835535, parameters k is 16.18824069715457 and b is -41.192942111914185\n",
      "Iteration 927, the loss is 38.06461648955182, parameters k is 16.18200505090951 and b is -41.19393025420668\n",
      "Iteration 928, the loss is 38.02475678026811, parameters k is 16.17576940466445 and b is -41.19491839649917\n",
      "Iteration 929, the loss is 37.98489707098436, parameters k is 16.16953375841939 and b is -41.19590653879166\n",
      "Iteration 930, the loss is 37.94503736170067, parameters k is 16.16329811217433 and b is -41.19689468108415\n",
      "Iteration 931, the loss is 37.90517765241692, parameters k is 16.157062465929272 and b is -41.197882823376645\n",
      "Iteration 932, the loss is 37.86531794313313, parameters k is 16.150826819684212 and b is -41.19887096566914\n",
      "Iteration 933, the loss is 37.825458233849425, parameters k is 16.144591173439153 and b is -41.19985910796163\n",
      "Iteration 934, the loss is 37.78559852456575, parameters k is 16.138355527194093 and b is -41.20084725025412\n",
      "Iteration 935, the loss is 37.745738815281975, parameters k is 16.132119880949034 and b is -41.20183539254661\n",
      "Iteration 936, the loss is 37.70587910599825, parameters k is 16.125884234703975 and b is -41.202823534839105\n",
      "Iteration 937, the loss is 37.666019396714496, parameters k is 16.119648588458915 and b is -41.2038116771316\n",
      "Iteration 938, the loss is 37.626159687430786, parameters k is 16.113412942213856 and b is -41.20479981942409\n",
      "Iteration 939, the loss is 37.586299978147025, parameters k is 16.107177295968796 and b is -41.20578796171658\n",
      "Iteration 940, the loss is 37.5464402688633, parameters k is 16.100941649723737 and b is -41.20677610400907\n",
      "Iteration 941, the loss is 37.50658055957958, parameters k is 16.094706003478677 and b is -41.207764246301565\n",
      "Iteration 942, the loss is 37.466720850295864, parameters k is 16.088470357233618 and b is -41.20875238859406\n",
      "Iteration 943, the loss is 37.42686114101218, parameters k is 16.08223471098856 and b is -41.20974053088655\n",
      "Iteration 944, the loss is 37.387001431728336, parameters k is 16.0759990647435 and b is -41.21072867317904\n",
      "Iteration 945, the loss is 37.3471417224447, parameters k is 16.06976341849844 and b is -41.21171681547153\n",
      "Iteration 946, the loss is 37.3072820131609, parameters k is 16.06352777225338 and b is -41.212704957764025\n",
      "Iteration 947, the loss is 37.267422303877176, parameters k is 16.05729212600832 and b is -41.21369310005652\n",
      "Iteration 948, the loss is 37.22756259459344, parameters k is 16.05105647976326 and b is -41.21468124234901\n",
      "Iteration 949, the loss is 37.18770288530973, parameters k is 16.0448208335182 and b is -41.2156693846415\n",
      "Iteration 950, the loss is 37.14784317602595, parameters k is 16.038585187273142 and b is -41.21665752693399\n",
      "Iteration 951, the loss is 37.10798346674229, parameters k is 16.032349541028083 and b is -41.217645669226485\n",
      "Iteration 952, the loss is 37.068123757458515, parameters k is 16.026113894783023 and b is -41.21863381151898\n",
      "Iteration 953, the loss is 37.02826404817479, parameters k is 16.019878248537964 and b is -41.21962195381147\n",
      "Iteration 954, the loss is 36.98840433889106, parameters k is 16.013642602292904 and b is -41.22061009610396\n",
      "Iteration 955, the loss is 36.9485446296074, parameters k is 16.007406956047845 and b is -41.22159823839645\n",
      "Iteration 956, the loss is 36.90868492032356, parameters k is 16.001171309802785 and b is -41.222586380688945\n",
      "Iteration 957, the loss is 36.86882521103981, parameters k is 15.994935663557726 and b is -41.22357452298144\n",
      "Iteration 958, the loss is 36.82896550175612, parameters k is 15.988700017312667 and b is -41.22456266527393\n",
      "Iteration 959, the loss is 36.789105792472434, parameters k is 15.982464371067607 and b is -41.22555080756642\n",
      "Iteration 960, the loss is 36.74924608318866, parameters k is 15.976228724822548 and b is -41.22653894985891\n",
      "Iteration 961, the loss is 36.709386373904884, parameters k is 15.969993078577488 and b is -41.227527092151405\n",
      "Iteration 962, the loss is 36.669526664621195, parameters k is 15.963757432332429 and b is -41.2285152344439\n",
      "Iteration 963, the loss is 36.629666955337484, parameters k is 15.95752178608737 and b is -41.22950337673639\n",
      "Iteration 964, the loss is 36.589807246053745, parameters k is 15.95128613984231 and b is -41.23049151902888\n",
      "Iteration 965, the loss is 36.54994753677002, parameters k is 15.94505049359725 and b is -41.23147966132137\n",
      "Iteration 966, the loss is 36.51008782748626, parameters k is 15.938814847352191 and b is -41.232467803613865\n",
      "Iteration 967, the loss is 36.470228118202535, parameters k is 15.932579201107131 and b is -41.23345594590636\n",
      "Iteration 968, the loss is 36.430368408918795, parameters k is 15.926343554862072 and b is -41.23444408819885\n",
      "Iteration 969, the loss is 36.39050869963508, parameters k is 15.920107908617013 and b is -41.23543223049134\n",
      "Iteration 970, the loss is 36.35064899035131, parameters k is 15.913872262371953 and b is -41.23642037278383\n",
      "Iteration 971, the loss is 36.3107892810676, parameters k is 15.907636616126894 and b is -41.237408515076325\n",
      "Iteration 972, the loss is 36.27092957178385, parameters k is 15.901400969881834 and b is -41.23839665736882\n",
      "Iteration 973, the loss is 36.231069862500135, parameters k is 15.895165323636775 and b is -41.23938479966131\n",
      "Iteration 974, the loss is 36.19121015321636, parameters k is 15.888929677391715 and b is -41.2403729419538\n",
      "Iteration 975, the loss is 36.15135044393269, parameters k is 15.882694031146656 and b is -41.24136108424629\n",
      "Iteration 976, the loss is 36.111490734648974, parameters k is 15.876458384901596 and b is -41.242349226538785\n",
      "Iteration 977, the loss is 36.07163102536522, parameters k is 15.870222738656537 and b is -41.24333736883128\n",
      "Iteration 978, the loss is 36.03177131608147, parameters k is 15.863987092411477 and b is -41.24432551112377\n",
      "Iteration 979, the loss is 35.991911606797764, parameters k is 15.857751446166418 and b is -41.24531365341626\n",
      "Iteration 980, the loss is 35.95205189751399, parameters k is 15.851515799921359 and b is -41.24630179570875\n",
      "Iteration 981, the loss is 35.91219218823029, parameters k is 15.845280153676299 and b is -41.247289938001245\n",
      "Iteration 982, the loss is 35.87233247894653, parameters k is 15.83904450743124 and b is -41.24827808029374\n",
      "Iteration 983, the loss is 35.83247276966281, parameters k is 15.83280886118618 and b is -41.24926622258623\n",
      "Iteration 984, the loss is 35.79261306037908, parameters k is 15.82657321494112 and b is -41.25025436487872\n",
      "Iteration 985, the loss is 35.75275335109532, parameters k is 15.820337568696061 and b is -41.25124250717121\n",
      "Iteration 986, the loss is 35.71289364181162, parameters k is 15.814101922451002 and b is -41.252230649463705\n",
      "Iteration 987, the loss is 35.67303393252785, parameters k is 15.807866276205942 and b is -41.2532187917562\n",
      "Iteration 988, the loss is 35.63317422324418, parameters k is 15.801630629960883 and b is -41.25420693404869\n",
      "Iteration 989, the loss is 35.59331451396042, parameters k is 15.795394983715823 and b is -41.25519507634118\n",
      "Iteration 990, the loss is 35.553454804676704, parameters k is 15.789159337470764 and b is -41.25618321863367\n",
      "Iteration 991, the loss is 35.51359509539294, parameters k is 15.782923691225704 and b is -41.257171360926165\n",
      "Iteration 992, the loss is 35.47373538610923, parameters k is 15.776688044980645 and b is -41.25815950321866\n",
      "Iteration 993, the loss is 35.43387567682552, parameters k is 15.770452398735586 and b is -41.25914764551115\n",
      "Iteration 994, the loss is 35.394015967541776, parameters k is 15.764216752490526 and b is -41.26013578780364\n",
      "Iteration 995, the loss is 35.35415625825803, parameters k is 15.757981106245467 and b is -41.26112393009613\n",
      "Iteration 996, the loss is 35.3142965489743, parameters k is 15.751745460000407 and b is -41.262112072388625\n",
      "Iteration 997, the loss is 35.27443683969056, parameters k is 15.745509813755348 and b is -41.26310021468112\n",
      "Iteration 998, the loss is 35.234577130406876, parameters k is 15.739274167510288 and b is -41.26408835697361\n",
      "Iteration 999, the loss is 35.19471742112305, parameters k is 15.733038521265229 and b is -41.2650764992661\n",
      "Iteration 1000, the loss is 35.15485771183932, parameters k is 15.72680287502017 and b is -41.26606464155859\n",
      "Iteration 1001, the loss is 35.11499800255559, parameters k is 15.72056722877511 and b is -41.267052783851085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1002, the loss is 35.0751382932719, parameters k is 15.71433158253005 and b is -41.26804092614358\n",
      "Iteration 1003, the loss is 35.0352785839882, parameters k is 15.708095936284991 and b is -41.26902906843607\n",
      "Iteration 1004, the loss is 34.9954188747044, parameters k is 15.701860290039932 and b is -41.27001721072856\n",
      "Iteration 1005, the loss is 34.955559165420695, parameters k is 15.695624643794872 and b is -41.27100535302105\n",
      "Iteration 1006, the loss is 34.91569945613697, parameters k is 15.689388997549813 and b is -41.271993495313545\n",
      "Iteration 1007, the loss is 34.875839746853245, parameters k is 15.683153351304753 and b is -41.27298163760604\n",
      "Iteration 1008, the loss is 34.835980037569506, parameters k is 15.676917705059694 and b is -41.27396977989853\n",
      "Iteration 1009, the loss is 34.796120328285774, parameters k is 15.670682058814634 and b is -41.27495792219102\n",
      "Iteration 1010, the loss is 34.756260619002035, parameters k is 15.664446412569575 and b is -41.27594606448351\n",
      "Iteration 1011, the loss is 34.716400909718296, parameters k is 15.658210766324515 and b is -41.276934206776005\n",
      "Iteration 1012, the loss is 34.67654120043456, parameters k is 15.651975120079456 and b is -41.2779223490685\n",
      "Iteration 1013, the loss is 34.63668149115081, parameters k is 15.645739473834396 and b is -41.27891049136099\n",
      "Iteration 1014, the loss is 34.596821781867106, parameters k is 15.639503827589337 and b is -41.27989863365348\n",
      "Iteration 1015, the loss is 34.5569620725834, parameters k is 15.633268181344278 and b is -41.28088677594597\n",
      "Iteration 1016, the loss is 34.51710236329961, parameters k is 15.627032535099218 and b is -41.281874918238465\n",
      "Iteration 1017, the loss is 34.4772426540159, parameters k is 15.620796888854159 and b is -41.28286306053096\n",
      "Iteration 1018, the loss is 34.43738294473217, parameters k is 15.6145612426091 and b is -41.28385120282345\n",
      "Iteration 1019, the loss is 34.39752323544846, parameters k is 15.60832559636404 and b is -41.28483934511594\n",
      "Iteration 1020, the loss is 34.35766352616471, parameters k is 15.60208995011898 and b is -41.28582748740843\n",
      "Iteration 1021, the loss is 34.31780381688101, parameters k is 15.59585430387392 and b is -41.286815629700925\n",
      "Iteration 1022, the loss is 34.27794410759726, parameters k is 15.589618657628861 and b is -41.28780377199342\n",
      "Iteration 1023, the loss is 34.23808439831354, parameters k is 15.583383011383802 and b is -41.28879191428591\n",
      "Iteration 1024, the loss is 34.198224689029814, parameters k is 15.577147365138742 and b is -41.2897800565784\n",
      "Iteration 1025, the loss is 34.15836497974605, parameters k is 15.570911718893683 and b is -41.29076819887089\n",
      "Iteration 1026, the loss is 34.1185052704623, parameters k is 15.564676072648624 and b is -41.291756341163385\n",
      "Iteration 1027, the loss is 34.078645561178575, parameters k is 15.558440426403564 and b is -41.29274448345588\n",
      "Iteration 1028, the loss is 34.03878585189485, parameters k is 15.552204780158505 and b is -41.29373262574837\n",
      "Iteration 1029, the loss is 33.99892614261108, parameters k is 15.545969133913445 and b is -41.29472076804086\n",
      "Iteration 1030, the loss is 33.95906643332738, parameters k is 15.539733487668386 and b is -41.29570891033335\n",
      "Iteration 1031, the loss is 33.91935453919886, parameters k is 15.533497841423326 and b is -41.296697052625845\n",
      "Iteration 1032, the loss is 33.879791686634476, parameters k is 15.52728541652214 and b is -41.297681242349164\n",
      "Iteration 1033, the loss is 33.84022883407014, parameters k is 15.521072991620954 and b is -41.29866543207248\n",
      "Iteration 1034, the loss is 33.80066598150577, parameters k is 15.514860566719769 and b is -41.2996496217958\n",
      "Iteration 1035, the loss is 33.76110312894141, parameters k is 15.508648141818583 and b is -41.30063381151912\n",
      "Iteration 1036, the loss is 33.72154027637705, parameters k is 15.502435716917397 and b is -41.30161800124244\n",
      "Iteration 1037, the loss is 33.68197742381268, parameters k is 15.49622329201621 and b is -41.30260219096576\n",
      "Iteration 1038, the loss is 33.64241457124832, parameters k is 15.490010867115025 and b is -41.303586380689076\n",
      "Iteration 1039, the loss is 33.60285171868396, parameters k is 15.483798442213839 and b is -41.304570570412395\n",
      "Iteration 1040, the loss is 33.56328886611959, parameters k is 15.477586017312653 and b is -41.30555476013571\n",
      "Iteration 1041, the loss is 33.52372601355524, parameters k is 15.471373592411467 and b is -41.30653894985903\n",
      "Iteration 1042, the loss is 33.48416316099089, parameters k is 15.465161167510281 and b is -41.30752313958235\n",
      "Iteration 1043, the loss is 33.44460030842652, parameters k is 15.458948742609095 and b is -41.30850732930567\n",
      "Iteration 1044, the loss is 33.405037455862164, parameters k is 15.45273631770791 and b is -41.30949151902899\n",
      "Iteration 1045, the loss is 33.36547460329777, parameters k is 15.446523892806724 and b is -41.31047570875231\n",
      "Iteration 1046, the loss is 33.32591175073341, parameters k is 15.440311467905538 and b is -41.311459898475626\n",
      "Iteration 1047, the loss is 33.2863488981691, parameters k is 15.434099043004352 and b is -41.312444088198944\n",
      "Iteration 1048, the loss is 33.246786045604736, parameters k is 15.427886618103166 and b is -41.31342827792226\n",
      "Iteration 1049, the loss is 33.20722319304036, parameters k is 15.42167419320198 and b is -41.31441246764558\n",
      "Iteration 1050, the loss is 33.16766034047598, parameters k is 15.415461768300794 and b is -41.3153966573689\n",
      "Iteration 1051, the loss is 33.12809748791161, parameters k is 15.409249343399608 and b is -41.31638084709222\n",
      "Iteration 1052, the loss is 33.08853463534727, parameters k is 15.403036918498422 and b is -41.31736503681554\n",
      "Iteration 1053, the loss is 33.04897178278287, parameters k is 15.396824493597236 and b is -41.31834922653886\n",
      "Iteration 1054, the loss is 33.0094089302185, parameters k is 15.39061206869605 and b is -41.319333416262175\n",
      "Iteration 1055, the loss is 32.96984607765417, parameters k is 15.384399643794865 and b is -41.320317605985494\n",
      "Iteration 1056, the loss is 32.93028322508983, parameters k is 15.378187218893679 and b is -41.32130179570881\n",
      "Iteration 1057, the loss is 32.89072037252543, parameters k is 15.371974793992493 and b is -41.32228598543213\n",
      "Iteration 1058, the loss is 32.85115751996107, parameters k is 15.365762369091307 and b is -41.32327017515545\n",
      "Iteration 1059, the loss is 32.81159466739674, parameters k is 15.359549944190121 and b is -41.32425436487877\n",
      "Iteration 1060, the loss is 32.77203181483236, parameters k is 15.353337519288935 and b is -41.32523855460209\n",
      "Iteration 1061, the loss is 32.73246896226801, parameters k is 15.34712509438775 and b is -41.326222744325406\n",
      "Iteration 1062, the loss is 32.69290610970363, parameters k is 15.340912669486563 and b is -41.327206934048725\n",
      "Iteration 1063, the loss is 32.65334325713924, parameters k is 15.334700244585378 and b is -41.328191123772044\n",
      "Iteration 1064, the loss is 32.61378040457487, parameters k is 15.328487819684192 and b is -41.32917531349536\n",
      "Iteration 1065, the loss is 32.57421755201056, parameters k is 15.322275394783006 and b is -41.33015950321868\n",
      "Iteration 1066, the loss is 32.53465469944623, parameters k is 15.31606296988182 and b is -41.331143692942\n",
      "Iteration 1067, the loss is 32.495091846881834, parameters k is 15.309850544980634 and b is -41.33212788266532\n",
      "Iteration 1068, the loss is 32.45552899431751, parameters k is 15.303638120079448 and b is -41.33311207238864\n",
      "Iteration 1069, the loss is 32.41596614175311, parameters k is 15.297425695178262 and b is -41.334096262111956\n",
      "Iteration 1070, the loss is 32.37640328918874, parameters k is 15.291213270277076 and b is -41.335080451835275\n",
      "Iteration 1071, the loss is 32.336840436624406, parameters k is 15.28500084537589 and b is -41.33606464155859\n",
      "Iteration 1072, the loss is 32.29727758406005, parameters k is 15.278788420474704 and b is -41.33704883128191\n",
      "Iteration 1073, the loss is 32.25771473149567, parameters k is 15.272575995573519 and b is -41.33803302100523\n",
      "Iteration 1074, the loss is 32.218151878931295, parameters k is 15.266363570672333 and b is -41.33901721072855\n",
      "Iteration 1075, the loss is 32.17858902636692, parameters k is 15.260151145771147 and b is -41.34000140045187\n",
      "Iteration 1076, the loss is 32.139026173802584, parameters k is 15.25393872086996 and b is -41.34098559017519\n",
      "Iteration 1077, the loss is 32.099463321238204, parameters k is 15.247726295968775 and b is -41.341969779898506\n",
      "Iteration 1078, the loss is 32.05990046867387, parameters k is 15.241513871067589 and b is -41.342953969621824\n",
      "Iteration 1079, the loss is 32.020337616109515, parameters k is 15.235301446166403 and b is -41.34393815934514\n",
      "Iteration 1080, the loss is 31.980774763545135, parameters k is 15.229089021265217 and b is -41.34492234906846\n",
      "Iteration 1081, the loss is 31.94121191098076, parameters k is 15.222876596364031 and b is -41.34590653879178\n",
      "Iteration 1082, the loss is 31.901649058416414, parameters k is 15.216664171462845 and b is -41.3468907285151\n",
      "Iteration 1083, the loss is 31.862086205852062, parameters k is 15.21045174656166 and b is -41.34787491823842\n",
      "Iteration 1084, the loss is 31.822523353287696, parameters k is 15.204239321660474 and b is -41.34885910796174\n",
      "Iteration 1085, the loss is 31.782960500723313, parameters k is 15.198026896759288 and b is -41.349843297685055\n",
      "Iteration 1086, the loss is 31.74339764815898, parameters k is 15.191814471858102 and b is -41.350827487408374\n",
      "Iteration 1087, the loss is 31.703834795594602, parameters k is 15.185602046956916 and b is -41.35181167713169\n",
      "Iteration 1088, the loss is 31.66427194303024, parameters k is 15.17938962205573 and b is -41.35279586685501\n",
      "Iteration 1089, the loss is 31.624709090465903, parameters k is 15.173177197154544 and b is -41.35378005657833\n",
      "Iteration 1090, the loss is 31.58514623790152, parameters k is 15.166964772253358 and b is -41.35476424630165\n",
      "Iteration 1091, the loss is 31.545583385337164, parameters k is 15.160752347352172 and b is -41.35574843602497\n",
      "Iteration 1092, the loss is 31.5060205327728, parameters k is 15.154539922450986 and b is -41.356732625748286\n",
      "Iteration 1093, the loss is 31.466457680208464, parameters k is 15.1483274975498 and b is -41.357716815471605\n",
      "Iteration 1094, the loss is 31.42689482764405, parameters k is 15.142115072648615 and b is -41.35870100519492\n",
      "Iteration 1095, the loss is 31.38733197507972, parameters k is 15.135902647747429 and b is -41.35968519491824\n",
      "Iteration 1096, the loss is 31.347769122515366, parameters k is 15.129690222846243 and b is -41.36066938464156\n",
      "Iteration 1097, the loss is 31.308206269950997, parameters k is 15.123477797945057 and b is -41.36165357436488\n",
      "Iteration 1098, the loss is 31.268643417386617, parameters k is 15.117265373043871 and b is -41.3626377640882\n",
      "Iteration 1099, the loss is 31.22908056482229, parameters k is 15.111052948142685 and b is -41.36362195381152\n",
      "Iteration 1100, the loss is 31.18951771225791, parameters k is 15.1048405232415 and b is -41.364606143534836\n",
      "Iteration 1101, the loss is 31.14995485969354, parameters k is 15.098628098340313 and b is -41.365590333258154\n",
      "Iteration 1102, the loss is 31.110392007129192, parameters k is 15.092415673439127 and b is -41.36657452298147\n",
      "Iteration 1103, the loss is 31.07082915456483, parameters k is 15.086203248537942 and b is -41.36755871270479\n",
      "Iteration 1104, the loss is 31.031266302000482, parameters k is 15.079990823636756 and b is -41.36854290242811\n",
      "Iteration 1105, the loss is 30.99170344943612, parameters k is 15.07377839873557 and b is -41.36952709215143\n",
      "Iteration 1106, the loss is 30.952140596871757, parameters k is 15.067565973834384 and b is -41.37051128187475\n",
      "Iteration 1107, the loss is 30.912577744307377, parameters k is 15.061353548933198 and b is -41.37149547159807\n",
      "Iteration 1108, the loss is 30.87301489174301, parameters k is 15.055141124032012 and b is -41.372479661321385\n",
      "Iteration 1109, the loss is 30.833452039178667, parameters k is 15.048928699130826 and b is -41.373463851044704\n",
      "Iteration 1110, the loss is 30.793889186614283, parameters k is 15.04271627422964 and b is -41.37444804076802\n",
      "Iteration 1111, the loss is 30.75432633404994, parameters k is 15.036503849328454 and b is -41.37543223049134\n",
      "Iteration 1112, the loss is 30.714763481485562, parameters k is 15.030291424427269 and b is -41.37641642021466\n",
      "Iteration 1113, the loss is 30.675200628921218, parameters k is 15.024078999526083 and b is -41.37740060993798\n",
      "Iteration 1114, the loss is 30.63563777635684, parameters k is 15.017866574624897 and b is -41.3783847996613\n",
      "Iteration 1115, the loss is 30.59607492379249, parameters k is 15.01165414972371 and b is -41.379368989384616\n",
      "Iteration 1116, the loss is 30.556512071228124, parameters k is 15.005441724822525 and b is -41.380353179107935\n",
      "Iteration 1117, the loss is 30.51694921866378, parameters k is 14.999229299921339 and b is -41.381337368831254\n",
      "Iteration 1118, the loss is 30.477386366099402, parameters k is 14.993016875020153 and b is -41.38232155855457\n",
      "Iteration 1119, the loss is 30.437823513535058, parameters k is 14.986804450118967 and b is -41.38330574827789\n",
      "Iteration 1120, the loss is 30.398260660970667, parameters k is 14.980592025217781 and b is -41.38428993800121\n",
      "Iteration 1121, the loss is 30.35869780840628, parameters k is 14.974379600316595 and b is -41.38527412772453\n",
      "Iteration 1122, the loss is 30.31913495584195, parameters k is 14.96816717541541 and b is -41.38625831744785\n",
      "Iteration 1123, the loss is 30.27957210327758, parameters k is 14.961954750514224 and b is -41.387242507171166\n",
      "Iteration 1124, the loss is 30.240009250713243, parameters k is 14.955742325613038 and b is -41.388226696894485\n",
      "Iteration 1125, the loss is 30.200446398148884, parameters k is 14.949529900711852 and b is -41.3892108866178\n",
      "Iteration 1126, the loss is 30.16088354558452, parameters k is 14.943317475810666 and b is -41.39019507634112\n",
      "Iteration 1127, the loss is 30.12132069302018, parameters k is 14.93710505090948 and b is -41.39117926606444\n",
      "Iteration 1128, the loss is 30.081757840455825, parameters k is 14.930892626008294 and b is -41.39216345578776\n",
      "Iteration 1129, the loss is 30.042194987891406, parameters k is 14.924680201107108 and b is -41.39314764551108\n",
      "Iteration 1130, the loss is 30.002632135327048, parameters k is 14.918467776205922 and b is -41.3941318352344\n",
      "Iteration 1131, the loss is 29.963069282762692, parameters k is 14.912255351304736 and b is -41.395116024957716\n",
      "Iteration 1132, the loss is 29.923506430198337, parameters k is 14.90604292640355 and b is -41.396100214681034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1133, the loss is 29.88394357763395, parameters k is 14.899830501502365 and b is -41.39708440440435\n",
      "Iteration 1134, the loss is 29.8443807250696, parameters k is 14.893618076601179 and b is -41.39806859412767\n",
      "Iteration 1135, the loss is 29.804817872505257, parameters k is 14.887405651699993 and b is -41.39905278385099\n",
      "Iteration 1136, the loss is 29.76525501994089, parameters k is 14.881193226798807 and b is -41.40003697357431\n",
      "Iteration 1137, the loss is 29.725692167376554, parameters k is 14.874980801897621 and b is -41.40102116329763\n",
      "Iteration 1138, the loss is 29.68612931481218, parameters k is 14.868768376996435 and b is -41.40200535302095\n",
      "Iteration 1139, the loss is 29.646566462247822, parameters k is 14.86255595209525 and b is -41.402989542744265\n",
      "Iteration 1140, the loss is 29.60700360968343, parameters k is 14.856343527194063 and b is -41.403973732467584\n",
      "Iteration 1141, the loss is 29.5674407571191, parameters k is 14.850131102292877 and b is -41.4049579221909\n",
      "Iteration 1142, the loss is 29.52787790455475, parameters k is 14.843918677391692 and b is -41.40594211191422\n",
      "Iteration 1143, the loss is 29.48831505199037, parameters k is 14.837706252490506 and b is -41.40692630163754\n",
      "Iteration 1144, the loss is 29.448752199425996, parameters k is 14.83149382758932 and b is -41.40791049136086\n",
      "Iteration 1145, the loss is 29.409189346861652, parameters k is 14.825281402688134 and b is -41.40889468108418\n",
      "Iteration 1146, the loss is 29.36962649429731, parameters k is 14.819068977786948 and b is -41.409878870807496\n",
      "Iteration 1147, the loss is 29.3300636417329, parameters k is 14.812856552885762 and b is -41.410863060530815\n",
      "Iteration 1148, the loss is 29.29050078916856, parameters k is 14.806644127984576 and b is -41.411847250254134\n",
      "Iteration 1149, the loss is 29.250937936604185, parameters k is 14.80043170308339 and b is -41.41283143997745\n",
      "Iteration 1150, the loss is 29.2113750840398, parameters k is 14.794219278182204 and b is -41.41381562970077\n",
      "Iteration 1151, the loss is 29.17181223147546, parameters k is 14.788006853281018 and b is -41.41479981942409\n",
      "Iteration 1152, the loss is 29.132249378911105, parameters k is 14.781794428379833 and b is -41.41578400914741\n",
      "Iteration 1153, the loss is 29.092686526346785, parameters k is 14.775582003478647 and b is -41.41676819887073\n",
      "Iteration 1154, the loss is 29.053123673782398, parameters k is 14.76936957857746 and b is -41.417752388594046\n",
      "Iteration 1155, the loss is 29.013560821218043, parameters k is 14.763157153676275 and b is -41.418736578317365\n",
      "Iteration 1156, the loss is 28.9739979686537, parameters k is 14.756944728775089 and b is -41.41972076804068\n",
      "Iteration 1157, the loss is 28.934435116089293, parameters k is 14.750732303873903 and b is -41.420704957764\n",
      "Iteration 1158, the loss is 28.894872263524977, parameters k is 14.744519878972717 and b is -41.42168914748732\n",
      "Iteration 1159, the loss is 28.855309410960576, parameters k is 14.738307454071531 and b is -41.42267333721064\n",
      "Iteration 1160, the loss is 28.815746558396228, parameters k is 14.732095029170345 and b is -41.42365752693396\n",
      "Iteration 1161, the loss is 28.776183705831848, parameters k is 14.72588260426916 and b is -41.42464171665728\n",
      "Iteration 1162, the loss is 28.736620853267485, parameters k is 14.719670179367974 and b is -41.425625906380596\n",
      "Iteration 1163, the loss is 28.697058000703127, parameters k is 14.713457754466788 and b is -41.426610096103914\n",
      "Iteration 1164, the loss is 28.65752422844407, parameters k is 14.707245329565602 and b is -41.42759428582723\n",
      "Iteration 1165, the loss is 28.618273805015264, parameters k is 14.701057473834377 and b is -41.428574522981386\n",
      "Iteration 1166, the loss is 28.579023381586445, parameters k is 14.694869618103152 and b is -41.42955476013554\n",
      "Iteration 1167, the loss is 28.539772958157602, parameters k is 14.688681762371926 and b is -41.43053499728969\n",
      "Iteration 1168, the loss is 28.500522534728802, parameters k is 14.682493906640701 and b is -41.43151523444384\n",
      "Iteration 1169, the loss is 28.461272111299934, parameters k is 14.676306050909476 and b is -41.432495471597996\n",
      "Iteration 1170, the loss is 28.42202168787112, parameters k is 14.67011819517825 and b is -41.43347570875215\n",
      "Iteration 1171, the loss is 28.382771264442248, parameters k is 14.663930339447026 and b is -41.4344559459063\n",
      "Iteration 1172, the loss is 28.34352084101342, parameters k is 14.6577424837158 and b is -41.43543618306045\n",
      "Iteration 1173, the loss is 28.30427041758459, parameters k is 14.651554627984575 and b is -41.436416420214606\n",
      "Iteration 1174, the loss is 28.26501999415575, parameters k is 14.64536677225335 and b is -41.43739665736876\n",
      "Iteration 1175, the loss is 28.225769570726882, parameters k is 14.639178916522125 and b is -41.43837689452291\n",
      "Iteration 1176, the loss is 28.186519147298085, parameters k is 14.6329910607909 and b is -41.43935713167706\n",
      "Iteration 1177, the loss is 28.14726872386922, parameters k is 14.626803205059675 and b is -41.440337368831216\n",
      "Iteration 1178, the loss is 28.108018300440385, parameters k is 14.62061534932845 and b is -41.44131760598537\n",
      "Iteration 1179, the loss is 28.068767877011567, parameters k is 14.614427493597224 and b is -41.44229784313952\n",
      "Iteration 1180, the loss is 28.029517453582713, parameters k is 14.608239637866 and b is -41.44327808029367\n",
      "Iteration 1181, the loss is 27.99026703015391, parameters k is 14.602051782134774 and b is -41.444258317447826\n",
      "Iteration 1182, the loss is 27.951016606725076, parameters k is 14.595863926403549 and b is -41.44523855460198\n",
      "Iteration 1183, the loss is 27.91176618329623, parameters k is 14.589676070672324 and b is -41.44621879175613\n",
      "Iteration 1184, the loss is 27.872515759867408, parameters k is 14.583488214941099 and b is -41.44719902891028\n",
      "Iteration 1185, the loss is 27.833265336438572, parameters k is 14.577300359209874 and b is -41.448179266064436\n",
      "Iteration 1186, the loss is 27.794014913009725, parameters k is 14.571112503478648 and b is -41.44915950321859\n",
      "Iteration 1187, the loss is 27.754764489580907, parameters k is 14.564924647747423 and b is -41.45013974037274\n",
      "Iteration 1188, the loss is 27.71551406615206, parameters k is 14.558736792016198 and b is -41.45111997752689\n",
      "Iteration 1189, the loss is 27.676263642723235, parameters k is 14.552548936284973 and b is -41.452100214681046\n",
      "Iteration 1190, the loss is 27.63701321929438, parameters k is 14.546361080553748 and b is -41.4530804518352\n",
      "Iteration 1191, the loss is 27.597762795865496, parameters k is 14.540173224822523 and b is -41.45406068898935\n",
      "Iteration 1192, the loss is 27.558512372436674, parameters k is 14.533985369091297 and b is -41.455040926143504\n",
      "Iteration 1193, the loss is 27.519261949007888, parameters k is 14.527797513360072 and b is -41.456021163297656\n",
      "Iteration 1194, the loss is 27.48001152557906, parameters k is 14.521609657628847 and b is -41.45700140045181\n",
      "Iteration 1195, the loss is 27.44076110215022, parameters k is 14.515421801897622 and b is -41.45798163760596\n",
      "Iteration 1196, the loss is 27.401510678721372, parameters k is 14.509233946166397 and b is -41.458961874760114\n",
      "Iteration 1197, the loss is 27.362260255292536, parameters k is 14.503046090435172 and b is -41.459942111914266\n",
      "Iteration 1198, the loss is 27.323009831863697, parameters k is 14.496858234703947 and b is -41.46092234906842\n",
      "Iteration 1199, the loss is 27.283759408434864, parameters k is 14.490670378972721 and b is -41.46190258622257\n",
      "Iteration 1200, the loss is 27.24450898500605, parameters k is 14.484482523241496 and b is -41.462882823376724\n",
      "Iteration 1201, the loss is 27.205258561577185, parameters k is 14.478294667510271 and b is -41.463863060530876\n",
      "Iteration 1202, the loss is 27.166008138148364, parameters k is 14.472106811779046 and b is -41.46484329768503\n",
      "Iteration 1203, the loss is 27.12675771471951, parameters k is 14.46591895604782 and b is -41.46582353483918\n",
      "Iteration 1204, the loss is 27.08750729129069, parameters k is 14.459731100316596 and b is -41.466803771993334\n",
      "Iteration 1205, the loss is 27.04825686786183, parameters k is 14.45354324458537 and b is -41.467784009147486\n",
      "Iteration 1206, the loss is 27.009006444433044, parameters k is 14.447355388854145 and b is -41.46876424630164\n",
      "Iteration 1207, the loss is 26.969756021004176, parameters k is 14.44116753312292 and b is -41.46974448345579\n",
      "Iteration 1208, the loss is 26.930505597575337, parameters k is 14.434979677391695 and b is -41.470724720609944\n",
      "Iteration 1209, the loss is 26.891255174146515, parameters k is 14.42879182166047 and b is -41.471704957764096\n",
      "Iteration 1210, the loss is 26.852004750717672, parameters k is 14.422603965929245 and b is -41.47268519491825\n",
      "Iteration 1211, the loss is 26.81275432728883, parameters k is 14.41641611019802 and b is -41.4736654320724\n",
      "Iteration 1212, the loss is 26.77350390385998, parameters k is 14.410228254466794 and b is -41.474645669226554\n",
      "Iteration 1213, the loss is 26.734253480431153, parameters k is 14.40404039873557 and b is -41.47562590638071\n",
      "Iteration 1214, the loss is 26.695003057002292, parameters k is 14.397852543004344 and b is -41.47660614353486\n",
      "Iteration 1215, the loss is 26.655752633573464, parameters k is 14.391664687273119 and b is -41.47758638068901\n",
      "Iteration 1216, the loss is 26.61650221014467, parameters k is 14.385476831541894 and b is -41.478566617843164\n",
      "Iteration 1217, the loss is 26.577251786715802, parameters k is 14.379288975810669 and b is -41.47954685499732\n",
      "Iteration 1218, the loss is 26.53800136328698, parameters k is 14.373101120079443 and b is -41.48052709215147\n",
      "Iteration 1219, the loss is 26.498750939858116, parameters k is 14.366913264348218 and b is -41.48150732930562\n",
      "Iteration 1220, the loss is 26.45950051642929, parameters k is 14.360725408616993 and b is -41.482487566459774\n",
      "Iteration 1221, the loss is 26.420250093000472, parameters k is 14.354537552885768 and b is -41.48346780361393\n",
      "Iteration 1222, the loss is 26.380999669571644, parameters k is 14.348349697154543 and b is -41.48444804076808\n",
      "Iteration 1223, the loss is 26.341749246142797, parameters k is 14.342161841423318 and b is -41.48542827792223\n",
      "Iteration 1224, the loss is 26.302498822713993, parameters k is 14.335973985692092 and b is -41.486408515076384\n",
      "Iteration 1225, the loss is 26.263248399285153, parameters k is 14.329786129960867 and b is -41.48738875223054\n",
      "Iteration 1226, the loss is 26.223997975856307, parameters k is 14.323598274229642 and b is -41.48836898938469\n",
      "Iteration 1227, the loss is 26.184747552427453, parameters k is 14.317410418498417 and b is -41.48934922653884\n",
      "Iteration 1228, the loss is 26.14549712899864, parameters k is 14.311222562767192 and b is -41.490329463692994\n",
      "Iteration 1229, the loss is 26.10624670556979, parameters k is 14.305034707035967 and b is -41.49130970084715\n",
      "Iteration 1230, the loss is 26.06699628214096, parameters k is 14.298846851304742 and b is -41.4922899380013\n",
      "Iteration 1231, the loss is 26.02774585871211, parameters k is 14.292658995573516 and b is -41.49327017515545\n",
      "Iteration 1232, the loss is 25.988495435283294, parameters k is 14.286471139842291 and b is -41.494250412309604\n",
      "Iteration 1233, the loss is 25.949245011854444, parameters k is 14.280283284111066 and b is -41.49523064946376\n",
      "Iteration 1234, the loss is 25.909994588425597, parameters k is 14.274095428379841 and b is -41.49621088661791\n",
      "Iteration 1235, the loss is 25.870744164996765, parameters k is 14.267907572648616 and b is -41.49719112377206\n",
      "Iteration 1236, the loss is 25.83149374156794, parameters k is 14.26171971691739 and b is -41.498171360926214\n",
      "Iteration 1237, the loss is 25.7922433181391, parameters k is 14.255531861186165 and b is -41.49915159808037\n",
      "Iteration 1238, the loss is 25.752992894710303, parameters k is 14.24934400545494 and b is -41.50013183523452\n",
      "Iteration 1239, the loss is 25.713742471281428, parameters k is 14.243156149723715 and b is -41.50111207238867\n",
      "Iteration 1240, the loss is 25.67449204785259, parameters k is 14.23696829399249 and b is -41.502092309542824\n",
      "Iteration 1241, the loss is 25.635241624423788, parameters k is 14.230780438261265 and b is -41.50307254669698\n",
      "Iteration 1242, the loss is 25.59599120099492, parameters k is 14.22459258253004 and b is -41.50405278385113\n",
      "Iteration 1243, the loss is 25.5567407775661, parameters k is 14.218404726798815 and b is -41.50503302100528\n",
      "Iteration 1244, the loss is 25.51749035413727, parameters k is 14.21221687106759 and b is -41.506013258159435\n",
      "Iteration 1245, the loss is 25.478239930708412, parameters k is 14.206029015336364 and b is -41.50699349531359\n",
      "Iteration 1246, the loss is 25.43898950727958, parameters k is 14.199841159605139 and b is -41.50797373246774\n",
      "Iteration 1247, the loss is 25.39973908385073, parameters k is 14.193653303873914 and b is -41.50895396962189\n",
      "Iteration 1248, the loss is 25.36048866042191, parameters k is 14.187465448142689 and b is -41.509934206776045\n",
      "Iteration 1249, the loss is 25.321238236993096, parameters k is 14.181277592411464 and b is -41.5109144439302\n",
      "Iteration 1250, the loss is 25.281987813564232, parameters k is 14.175089736680238 and b is -41.51189468108435\n",
      "Iteration 1251, the loss is 25.24273739013541, parameters k is 14.168901880949013 and b is -41.5128749182385\n",
      "Iteration 1252, the loss is 25.203486966706535, parameters k is 14.162714025217788 and b is -41.513855155392655\n",
      "Iteration 1253, the loss is 25.164236543277728, parameters k is 14.156526169486563 and b is -41.51483539254681\n",
      "Iteration 1254, the loss is 25.124986119848913, parameters k is 14.150338313755338 and b is -41.51581562970096\n",
      "Iteration 1255, the loss is 25.085735696420084, parameters k is 14.144150458024113 and b is -41.51679586685511\n",
      "Iteration 1256, the loss is 25.046485272991227, parameters k is 14.137962602292887 and b is -41.517776104009265\n",
      "Iteration 1257, the loss is 25.007234849562376, parameters k is 14.131774746561662 and b is -41.51875634116342\n",
      "Iteration 1258, the loss is 24.967984426133544, parameters k is 14.125586890830437 and b is -41.51973657831757\n",
      "Iteration 1259, the loss is 24.928734002704704, parameters k is 14.119399035099212 and b is -41.52071681547172\n",
      "Iteration 1260, the loss is 24.889483579275865, parameters k is 14.113211179367987 and b is -41.521697052625875\n",
      "Iteration 1261, the loss is 24.85023315584705, parameters k is 14.107023323636762 and b is -41.52267728978003\n",
      "Iteration 1262, the loss is 24.810982732418225, parameters k is 14.100835467905537 and b is -41.52365752693418\n",
      "Iteration 1263, the loss is 24.7717323089894, parameters k is 14.094647612174311 and b is -41.52463776408833\n",
      "Iteration 1264, the loss is 24.732481885560553, parameters k is 14.088459756443086 and b is -41.525618001242485\n",
      "Iteration 1265, the loss is 24.693231462131678, parameters k is 14.082271900711861 and b is -41.52659823839664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1266, the loss is 24.653981038702867, parameters k is 14.076084044980636 and b is -41.52757847555079\n",
      "Iteration 1267, the loss is 24.614730615274063, parameters k is 14.06989618924941 and b is -41.52855871270494\n",
      "Iteration 1268, the loss is 24.575480191845188, parameters k is 14.063708333518186 and b is -41.529538949859095\n",
      "Iteration 1269, the loss is 24.536229768416387, parameters k is 14.05752047778696 and b is -41.53051918701325\n",
      "Iteration 1270, the loss is 24.49697934498755, parameters k is 14.051332622055735 and b is -41.5314994241674\n",
      "Iteration 1271, the loss is 24.45772892155869, parameters k is 14.04514476632451 and b is -41.53247966132155\n",
      "Iteration 1272, the loss is 24.418478498129847, parameters k is 14.038956910593285 and b is -41.533459898475705\n",
      "Iteration 1273, the loss is 24.379228074701018, parameters k is 14.03276905486206 and b is -41.53444013562986\n",
      "Iteration 1274, the loss is 24.339977651272196, parameters k is 14.026581199130835 and b is -41.53542037278401\n",
      "Iteration 1275, the loss is 24.300727227843346, parameters k is 14.02039334339961 and b is -41.53640060993816\n",
      "Iteration 1276, the loss is 24.26147680441449, parameters k is 14.014205487668384 and b is -41.537380847092315\n",
      "Iteration 1277, the loss is 24.222226380985678, parameters k is 14.00801763193716 and b is -41.53836108424647\n",
      "Iteration 1278, the loss is 24.18297595755685, parameters k is 14.001829776205934 and b is -41.53934132140062\n",
      "Iteration 1279, the loss is 24.143725534128006, parameters k is 13.995641920474709 and b is -41.54032155855477\n",
      "Iteration 1280, the loss is 24.104475110699163, parameters k is 13.989454064743484 and b is -41.541301795708925\n",
      "Iteration 1281, the loss is 24.065224687270355, parameters k is 13.983266209012259 and b is -41.54228203286308\n",
      "Iteration 1282, the loss is 24.025974263841512, parameters k is 13.977078353281033 and b is -41.54326227001723\n",
      "Iteration 1283, the loss is 23.98672384041264, parameters k is 13.970890497549808 and b is -41.54424250717138\n",
      "Iteration 1284, the loss is 23.947473416983836, parameters k is 13.964702641818583 and b is -41.545222744325535\n",
      "Iteration 1285, the loss is 23.908222993554983, parameters k is 13.958514786087358 and b is -41.54620298147969\n",
      "Iteration 1286, the loss is 23.868972570126157, parameters k is 13.952326930356133 and b is -41.54718321863384\n",
      "Iteration 1287, the loss is 23.829722146697318, parameters k is 13.946139074624908 and b is -41.54816345578799\n",
      "Iteration 1288, the loss is 23.790471723268503, parameters k is 13.939951218893682 and b is -41.549143692942145\n",
      "Iteration 1289, the loss is 23.75122129983965, parameters k is 13.933763363162457 and b is -41.5501239300963\n",
      "Iteration 1290, the loss is 23.71197087641078, parameters k is 13.927575507431232 and b is -41.55110416725045\n",
      "Iteration 1291, the loss is 23.672720452982002, parameters k is 13.921387651700007 and b is -41.5520844044046\n",
      "Iteration 1292, the loss is 23.633470029553152, parameters k is 13.915199795968782 and b is -41.553064641558755\n",
      "Iteration 1293, the loss is 23.594219606124312, parameters k is 13.909011940237557 and b is -41.55404487871291\n",
      "Iteration 1294, the loss is 23.554969182695462, parameters k is 13.902824084506332 and b is -41.55502511586706\n",
      "Iteration 1295, the loss is 23.51571875926664, parameters k is 13.896636228775106 and b is -41.55600535302121\n",
      "Iteration 1296, the loss is 23.47646833583779, parameters k is 13.890448373043881 and b is -41.556985590175366\n",
      "Iteration 1297, the loss is 23.437217912408965, parameters k is 13.884260517312656 and b is -41.55796582732952\n",
      "Iteration 1298, the loss is 23.397967488980097, parameters k is 13.878072661581431 and b is -41.55894606448367\n",
      "Iteration 1299, the loss is 23.35871706555129, parameters k is 13.871884805850206 and b is -41.55992630163782\n",
      "Iteration 1300, the loss is 23.319466642122464, parameters k is 13.86569695011898 and b is -41.560906538791976\n",
      "Iteration 1301, the loss is 23.280216218693596, parameters k is 13.859509094387755 and b is -41.56188677594613\n",
      "Iteration 1302, the loss is 23.2409657952648, parameters k is 13.85332123865653 and b is -41.56286701310028\n",
      "Iteration 1303, the loss is 23.201715371835956, parameters k is 13.847133382925305 and b is -41.56384725025443\n",
      "Iteration 1304, the loss is 23.162464948407113, parameters k is 13.84094552719408 and b is -41.564827487408586\n",
      "Iteration 1305, the loss is 23.123214524978252, parameters k is 13.834757671462855 and b is -41.56580772456274\n",
      "Iteration 1306, the loss is 23.08396410154944, parameters k is 13.82856981573163 and b is -41.56678796171689\n",
      "Iteration 1307, the loss is 23.0447136781206, parameters k is 13.822381960000405 and b is -41.56776819887104\n",
      "Iteration 1308, the loss is 23.005463254691783, parameters k is 13.81619410426918 and b is -41.568748436025196\n",
      "Iteration 1309, the loss is 22.96621283126294, parameters k is 13.810006248537954 and b is -41.56972867317935\n",
      "Iteration 1310, the loss is 22.926962407834097, parameters k is 13.803818392806729 and b is -41.5707089103335\n",
      "Iteration 1311, the loss is 22.887711984405268, parameters k is 13.797630537075504 and b is -41.57168914748765\n",
      "Iteration 1312, the loss is 22.84846156097644, parameters k is 13.791442681344279 and b is -41.572669384641806\n",
      "Iteration 1313, the loss is 22.8092111375476, parameters k is 13.785254825613054 and b is -41.57364962179596\n",
      "Iteration 1314, the loss is 22.769960714118774, parameters k is 13.779066969881828 and b is -41.57462985895011\n",
      "Iteration 1315, the loss is 22.73071029068993, parameters k is 13.772879114150603 and b is -41.57561009610426\n",
      "Iteration 1316, the loss is 22.691459867261095, parameters k is 13.766691258419378 and b is -41.576590333258416\n",
      "Iteration 1317, the loss is 22.652209443832263, parameters k is 13.760503402688153 and b is -41.57757057041257\n",
      "Iteration 1318, the loss is 22.612959020403427, parameters k is 13.754315546956928 and b is -41.57855080756672\n",
      "Iteration 1319, the loss is 22.573708596974594, parameters k is 13.748127691225703 and b is -41.57953104472087\n",
      "Iteration 1320, the loss is 22.53445817354575, parameters k is 13.741939835494478 and b is -41.580511281875026\n",
      "Iteration 1321, the loss is 22.49520775011692, parameters k is 13.735751979763252 and b is -41.58149151902918\n",
      "Iteration 1322, the loss is 22.455957326688075, parameters k is 13.729564124032027 and b is -41.58247175618333\n",
      "Iteration 1323, the loss is 22.416706903259257, parameters k is 13.723376268300802 and b is -41.58345199333748\n",
      "Iteration 1324, the loss is 22.37745647983041, parameters k is 13.717188412569577 and b is -41.584432230491636\n",
      "Iteration 1325, the loss is 22.338206056401564, parameters k is 13.711000556838352 and b is -41.58541246764579\n",
      "Iteration 1326, the loss is 22.29895563297274, parameters k is 13.704812701107127 and b is -41.58639270479994\n",
      "Iteration 1327, the loss is 22.259861190177514, parameters k is 13.698624845375901 and b is -41.587372941954094\n",
      "Iteration 1328, the loss is 22.22094470694579, parameters k is 13.692463404664439 and b is -41.58834922653907\n",
      "Iteration 1329, the loss is 22.182028223714063, parameters k is 13.686301963952976 and b is -41.58932551112405\n",
      "Iteration 1330, the loss is 22.143111740482322, parameters k is 13.680140523241514 and b is -41.59030179570903\n",
      "Iteration 1331, the loss is 22.104195257250584, parameters k is 13.673979082530051 and b is -41.59127808029401\n",
      "Iteration 1332, the loss is 22.06527877401885, parameters k is 13.667817641818589 and b is -41.59225436487899\n",
      "Iteration 1333, the loss is 22.02636229078713, parameters k is 13.661656201107126 and b is -41.59323064946397\n",
      "Iteration 1334, the loss is 21.987445807555353, parameters k is 13.655494760395664 and b is -41.59420693404895\n",
      "Iteration 1335, the loss is 21.948529324323626, parameters k is 13.649333319684201 and b is -41.59518321863393\n",
      "Iteration 1336, the loss is 21.909612841091892, parameters k is 13.643171878972739 and b is -41.59615950321891\n",
      "Iteration 1337, the loss is 21.870696357860158, parameters k is 13.637010438261276 and b is -41.597135787803886\n",
      "Iteration 1338, the loss is 21.831779874628428, parameters k is 13.630848997549814 and b is -41.598112072388865\n",
      "Iteration 1339, the loss is 21.792863391396676, parameters k is 13.624687556838351 and b is -41.599088356973844\n",
      "Iteration 1340, the loss is 21.753946908164963, parameters k is 13.618526116126889 and b is -41.600064641558824\n",
      "Iteration 1341, the loss is 21.7150304249332, parameters k is 13.612364675415426 and b is -41.6010409261438\n",
      "Iteration 1342, the loss is 21.676113941701466, parameters k is 13.606203234703964 and b is -41.60201721072878\n",
      "Iteration 1343, the loss is 21.637197458469732, parameters k is 13.600041793992501 and b is -41.60299349531376\n",
      "Iteration 1344, the loss is 21.598280975238005, parameters k is 13.593880353281039 and b is -41.60396977989874\n",
      "Iteration 1345, the loss is 21.559364492006267, parameters k is 13.587718912569576 and b is -41.60494606448372\n",
      "Iteration 1346, the loss is 21.52044800877452, parameters k is 13.581557471858114 and b is -41.6059223490687\n",
      "Iteration 1347, the loss is 21.481531525542806, parameters k is 13.575396031146651 and b is -41.60689863365368\n",
      "Iteration 1348, the loss is 21.442615042311047, parameters k is 13.569234590435189 and b is -41.60787491823866\n",
      "Iteration 1349, the loss is 21.403698559079324, parameters k is 13.563073149723726 and b is -41.60885120282364\n",
      "Iteration 1350, the loss is 21.364782075847593, parameters k is 13.556911709012264 and b is -41.609827487408616\n",
      "Iteration 1351, the loss is 21.32586559261586, parameters k is 13.550750268300801 and b is -41.610803771993595\n",
      "Iteration 1352, the loss is 21.286949109384103, parameters k is 13.544588827589338 and b is -41.611780056578574\n",
      "Iteration 1353, the loss is 21.24803262615238, parameters k is 13.538427386877876 and b is -41.61275634116355\n",
      "Iteration 1354, the loss is 21.20911614292065, parameters k is 13.532265946166413 and b is -41.61373262574853\n",
      "Iteration 1355, the loss is 21.170199659688908, parameters k is 13.526104505454951 and b is -41.61470891033351\n",
      "Iteration 1356, the loss is 21.13128317645715, parameters k is 13.519943064743488 and b is -41.61568519491849\n",
      "Iteration 1357, the loss is 21.092366693225408, parameters k is 13.513781624032026 and b is -41.61666147950347\n",
      "Iteration 1358, the loss is 21.0534502099937, parameters k is 13.507620183320563 and b is -41.61763776408845\n",
      "Iteration 1359, the loss is 21.014533726761968, parameters k is 13.5014587426091 and b is -41.61861404867343\n",
      "Iteration 1360, the loss is 20.975617243530206, parameters k is 13.495297301897638 and b is -41.61959033325841\n",
      "Iteration 1361, the loss is 20.936700760298493, parameters k is 13.489135861186176 and b is -41.62056661784339\n",
      "Iteration 1362, the loss is 20.897784277066773, parameters k is 13.482974420474713 and b is -41.62154290242837\n",
      "Iteration 1363, the loss is 20.858867793835014, parameters k is 13.47681297976325 and b is -41.622519187013346\n",
      "Iteration 1364, the loss is 20.819951310603265, parameters k is 13.470651539051788 and b is -41.623495471598325\n",
      "Iteration 1365, the loss is 20.78103482737155, parameters k is 13.464490098340326 and b is -41.624471756183304\n",
      "Iteration 1366, the loss is 20.742118344139797, parameters k is 13.458328657628863 and b is -41.62544804076828\n",
      "Iteration 1367, the loss is 20.703201860908056, parameters k is 13.4521672169174 and b is -41.62642432535326\n",
      "Iteration 1368, the loss is 20.664285377676322, parameters k is 13.446005776205938 and b is -41.62740060993824\n",
      "Iteration 1369, the loss is 20.62536889444462, parameters k is 13.439844335494476 and b is -41.62837689452322\n",
      "Iteration 1370, the loss is 20.586452411212857, parameters k is 13.433682894783013 and b is -41.6293531791082\n",
      "Iteration 1371, the loss is 20.547535927981123, parameters k is 13.42752145407155 and b is -41.63032946369318\n",
      "Iteration 1372, the loss is 20.50861944474939, parameters k is 13.421360013360088 and b is -41.63130574827816\n",
      "Iteration 1373, the loss is 20.46970296151766, parameters k is 13.415198572648626 and b is -41.63228203286314\n",
      "Iteration 1374, the loss is 20.430786478285942, parameters k is 13.409037131937163 and b is -41.63325831744812\n",
      "Iteration 1375, the loss is 20.391869995054176, parameters k is 13.4028756912257 and b is -41.6342346020331\n",
      "Iteration 1376, the loss is 20.35295351182243, parameters k is 13.396714250514238 and b is -41.635210886618076\n",
      "Iteration 1377, the loss is 20.314140110188475, parameters k is 13.390552809802776 and b is -41.636187171203055\n",
      "Iteration 1378, the loss is 20.27543261122516, parameters k is 13.384407724822537 and b is -41.63715950321887\n",
      "Iteration 1379, the loss is 20.236725112261894, parameters k is 13.3782626398423 and b is -41.63813183523468\n",
      "Iteration 1380, the loss is 20.198017613298543, parameters k is 13.372117554862061 and b is -41.639104167250494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1381, the loss is 20.15931011433524, parameters k is 13.365972469881823 and b is -41.64007649926631\n",
      "Iteration 1382, the loss is 20.120602615371915, parameters k is 13.359827384901585 and b is -41.64104883128212\n",
      "Iteration 1383, the loss is 20.081895116408603, parameters k is 13.353682299921347 and b is -41.64202116329793\n",
      "Iteration 1384, the loss is 20.04318761744529, parameters k is 13.34753721494111 and b is -41.642993495313746\n",
      "Iteration 1385, the loss is 20.004480118481958, parameters k is 13.341392129960871 and b is -41.64396582732956\n",
      "Iteration 1386, the loss is 19.965772619518663, parameters k is 13.335247044980633 and b is -41.64493815934537\n",
      "Iteration 1387, the loss is 19.927065120555334, parameters k is 13.329101960000395 and b is -41.645910491361185\n",
      "Iteration 1388, the loss is 19.888357621592018, parameters k is 13.322956875020157 and b is -41.646882823377\n",
      "Iteration 1389, the loss is 19.849650122628727, parameters k is 13.31681179003992 and b is -41.64785515539281\n",
      "Iteration 1390, the loss is 19.810942623665397, parameters k is 13.310666705059681 and b is -41.648827487408624\n",
      "Iteration 1391, the loss is 19.772235124702114, parameters k is 13.304521620079443 and b is -41.64979981942444\n",
      "Iteration 1392, the loss is 19.733527625738773, parameters k is 13.298376535099205 and b is -41.65077215144025\n",
      "Iteration 1393, the loss is 19.69482012677548, parameters k is 13.292231450118967 and b is -41.65174448345606\n",
      "Iteration 1394, the loss is 19.656112627812153, parameters k is 13.286086365138729 and b is -41.65271681547188\n",
      "Iteration 1395, the loss is 19.61740512884882, parameters k is 13.279941280158491 and b is -41.65368914748769\n",
      "Iteration 1396, the loss is 19.578697629885525, parameters k is 13.273796195178253 and b is -41.6546614795035\n",
      "Iteration 1397, the loss is 19.539990130922224, parameters k is 13.267651110198015 and b is -41.655633811519316\n",
      "Iteration 1398, the loss is 19.501282631958897, parameters k is 13.261506025217777 and b is -41.65660614353513\n",
      "Iteration 1399, the loss is 19.462575132995568, parameters k is 13.255360940237539 and b is -41.65757847555094\n",
      "Iteration 1400, the loss is 19.42386763403227, parameters k is 13.249215855257301 and b is -41.658550807566755\n",
      "Iteration 1401, the loss is 19.385160135068958, parameters k is 13.243070770277063 and b is -41.65952313958257\n",
      "Iteration 1402, the loss is 19.34645263610564, parameters k is 13.236925685296825 and b is -41.66049547159838\n",
      "Iteration 1403, the loss is 19.307745137142323, parameters k is 13.230780600316587 and b is -41.661467803614194\n",
      "Iteration 1404, the loss is 19.269037638179018, parameters k is 13.224635515336349 and b is -41.66244013563001\n",
      "Iteration 1405, the loss is 19.230330139215702, parameters k is 13.21849043035611 and b is -41.66341246764582\n",
      "Iteration 1406, the loss is 19.19162264025239, parameters k is 13.212345345375873 and b is -41.66438479966163\n",
      "Iteration 1407, the loss is 19.152915141289068, parameters k is 13.206200260395635 and b is -41.665357131677446\n",
      "Iteration 1408, the loss is 19.114207642325745, parameters k is 13.200055175415397 and b is -41.66632946369326\n",
      "Iteration 1409, the loss is 19.07550014336244, parameters k is 13.193910090435159 and b is -41.66730179570907\n",
      "Iteration 1410, the loss is 19.036792644399128, parameters k is 13.18776500545492 and b is -41.668274127724885\n",
      "Iteration 1411, the loss is 18.998085145435816, parameters k is 13.181619920474683 and b is -41.6692464597407\n",
      "Iteration 1412, the loss is 18.9593776464725, parameters k is 13.175474835494445 and b is -41.67021879175651\n",
      "Iteration 1413, the loss is 18.92067014750918, parameters k is 13.169329750514207 and b is -41.671191123772324\n",
      "Iteration 1414, the loss is 18.88196264854586, parameters k is 13.163184665533969 and b is -41.67216345578814\n",
      "Iteration 1415, the loss is 18.843255149582554, parameters k is 13.15703958055373 and b is -41.67313578780395\n",
      "Iteration 1416, the loss is 18.80454765061924, parameters k is 13.150894495573493 and b is -41.67410811981976\n",
      "Iteration 1417, the loss is 18.76584015165592, parameters k is 13.144749410593255 and b is -41.675080451835576\n",
      "Iteration 1418, the loss is 18.727132652692607, parameters k is 13.138604325613016 and b is -41.67605278385139\n",
      "Iteration 1419, the loss is 18.68842515372931, parameters k is 13.132459240632778 and b is -41.6770251158672\n",
      "Iteration 1420, the loss is 18.64971765476597, parameters k is 13.12631415565254 and b is -41.677997447883016\n",
      "Iteration 1421, the loss is 18.611010155802685, parameters k is 13.120169070672302 and b is -41.67896977989883\n",
      "Iteration 1422, the loss is 18.57230265683936, parameters k is 13.114023985692064 and b is -41.67994211191464\n",
      "Iteration 1423, the loss is 18.533595157876046, parameters k is 13.107878900711826 and b is -41.680914443930455\n",
      "Iteration 1424, the loss is 18.494887658912724, parameters k is 13.101733815731588 and b is -41.68188677594627\n",
      "Iteration 1425, the loss is 18.456180159949415, parameters k is 13.09558873075135 and b is -41.68285910796208\n",
      "Iteration 1426, the loss is 18.417472660986093, parameters k is 13.089443645771112 and b is -41.683831439977894\n",
      "Iteration 1427, the loss is 18.3787651620228, parameters k is 13.083298560790874 and b is -41.68480377199371\n",
      "Iteration 1428, the loss is 18.34005766305948, parameters k is 13.077153475810636 and b is -41.68577610400952\n",
      "Iteration 1429, the loss is 18.301350164096156, parameters k is 13.071008390830398 and b is -41.68674843602533\n",
      "Iteration 1430, the loss is 18.26274005570278, parameters k is 13.06486330585016 and b is -41.687720768041146\n",
      "Iteration 1431, the loss is 18.224380279987024, parameters k is 13.058745952095219 and b is -41.688689147487786\n",
      "Iteration 1432, the loss is 18.18602050427126, parameters k is 13.052628598340277 and b is -41.689657526934425\n",
      "Iteration 1433, the loss is 18.147660728555493, parameters k is 13.046511244585336 and b is -41.690625906381065\n",
      "Iteration 1434, the loss is 18.10930095283973, parameters k is 13.040393890830394 and b is -41.691594285827705\n",
      "Iteration 1435, the loss is 18.07094117712398, parameters k is 13.034276537075453 and b is -41.692562665274345\n",
      "Iteration 1436, the loss is 18.032581401408198, parameters k is 13.028159183320511 and b is -41.693531044720984\n",
      "Iteration 1437, the loss is 17.99422162569243, parameters k is 13.02204182956557 and b is -41.694499424167624\n",
      "Iteration 1438, the loss is 17.95586184997665, parameters k is 13.015924475810628 and b is -41.695467803614264\n",
      "Iteration 1439, the loss is 17.917502074260895, parameters k is 13.009807122055687 and b is -41.696436183060904\n",
      "Iteration 1440, the loss is 17.879142298545126, parameters k is 13.003689768300745 and b is -41.69740456250754\n",
      "Iteration 1441, the loss is 17.84078252282936, parameters k is 12.997572414545804 and b is -41.69837294195418\n",
      "Iteration 1442, the loss is 17.802422747113592, parameters k is 12.991455060790862 and b is -41.69934132140082\n",
      "Iteration 1443, the loss is 17.764062971397827, parameters k is 12.98533770703592 and b is -41.70030970084746\n",
      "Iteration 1444, the loss is 17.72570319568206, parameters k is 12.97922035328098 and b is -41.7012780802941\n",
      "Iteration 1445, the loss is 17.68734341996629, parameters k is 12.973102999526038 and b is -41.70224645974074\n",
      "Iteration 1446, the loss is 17.648983644250542, parameters k is 12.966985645771096 and b is -41.70321483918738\n",
      "Iteration 1447, the loss is 17.610623868534745, parameters k is 12.960868292016155 and b is -41.70418321863402\n",
      "Iteration 1448, the loss is 17.572264092818976, parameters k is 12.954750938261213 and b is -41.70515159808066\n",
      "Iteration 1449, the loss is 17.534001843604567, parameters k is 12.948633584506272 and b is -41.7061199775273\n",
      "Iteration 1450, the loss is 17.495849547517206, parameters k is 12.942532586482557 and b is -41.707084404404775\n",
      "Iteration 1451, the loss is 17.457697251429824, parameters k is 12.936431588458841 and b is -41.70804883128225\n",
      "Iteration 1452, the loss is 17.419544955342452, parameters k is 12.930330590435126 and b is -41.70901325815972\n",
      "Iteration 1453, the loss is 17.38139265925511, parameters k is 12.924229592411411 and b is -41.709977685037195\n",
      "Iteration 1454, the loss is 17.343240363167705, parameters k is 12.918128594387696 and b is -41.71094211191467\n",
      "Iteration 1455, the loss is 17.30508806708036, parameters k is 12.91202759636398 and b is -41.71190653879214\n",
      "Iteration 1456, the loss is 17.266935770992998, parameters k is 12.905926598340265 and b is -41.712870965669616\n",
      "Iteration 1457, the loss is 17.22878347490561, parameters k is 12.89982560031655 and b is -41.71383539254709\n",
      "Iteration 1458, the loss is 17.19063117881825, parameters k is 12.893724602292835 and b is -41.71479981942456\n",
      "Iteration 1459, the loss is 17.152478882730886, parameters k is 12.88762360426912 and b is -41.71576424630204\n",
      "Iteration 1460, the loss is 17.114330705424024, parameters k is 12.881522606245404 and b is -41.71672867317951\n",
      "Iteration 1461, the loss is 17.076408887918703, parameters k is 12.875439900711807 and b is -41.71768914748781\n",
      "Iteration 1462, the loss is 17.038487070413336, parameters k is 12.86935719517821 and b is -41.71864962179611\n",
      "Iteration 1463, the loss is 17.000565252907975, parameters k is 12.863274489644613 and b is -41.71961009610441\n",
      "Iteration 1464, the loss is 16.962643435402637, parameters k is 12.857191784111016 and b is -41.72057057041271\n",
      "Iteration 1465, the loss is 16.924721617897266, parameters k is 12.85110907857742 and b is -41.72153104472101\n",
      "Iteration 1466, the loss is 16.886799800391927, parameters k is 12.845026373043822 and b is -41.72249151902931\n",
      "Iteration 1467, the loss is 16.848877982886556, parameters k is 12.838943667510225 and b is -41.72345199333761\n",
      "Iteration 1468, the loss is 16.810956165381196, parameters k is 12.832860961976628 and b is -41.72441246764591\n",
      "Iteration 1469, the loss is 16.773034347875843, parameters k is 12.826778256443031 and b is -41.72537294195421\n",
      "Iteration 1470, the loss is 16.73511253037048, parameters k is 12.820695550909434 and b is -41.72633341626251\n",
      "Iteration 1471, the loss is 16.6973028485923, parameters k is 12.814612845375837 and b is -41.72729389057081\n",
      "Iteration 1472, the loss is 16.65962686734774, parameters k is 12.80854975644303 and b is -41.72825041230994\n",
      "Iteration 1473, the loss is 16.621950886103217, parameters k is 12.802486667510223 and b is -41.72920693404907\n",
      "Iteration 1474, the loss is 16.58427490485866, parameters k is 12.796423578577416 and b is -41.730163455788194\n",
      "Iteration 1475, the loss is 16.546598923614088, parameters k is 12.790360489644609 and b is -41.73111997752732\n",
      "Iteration 1476, the loss is 16.508922942369548, parameters k is 12.784297400711802 and b is -41.73207649926645\n",
      "Iteration 1477, the loss is 16.471246961125008, parameters k is 12.778234311778995 and b is -41.733033021005575\n",
      "Iteration 1478, the loss is 16.433570979880443, parameters k is 12.772171222846188 and b is -41.7339895427447\n",
      "Iteration 1479, the loss is 16.3958949986359, parameters k is 12.76610813391338 and b is -41.73494606448383\n",
      "Iteration 1480, the loss is 16.358219017391352, parameters k is 12.760045044980574 and b is -41.735902586222956\n",
      "Iteration 1481, the loss is 16.320543036146812, parameters k is 12.753981956047767 and b is -41.73685910796208\n",
      "Iteration 1482, the loss is 16.282867054902265, parameters k is 12.74791886711496 and b is -41.73781562970121\n",
      "Iteration 1483, the loss is 16.245191073657715, parameters k is 12.741855778182153 and b is -41.73877215144034\n",
      "Iteration 1484, the loss is 16.20751509241317, parameters k is 12.735792689249346 and b is -41.739728673179464\n",
      "Iteration 1485, the loss is 16.169839111168624, parameters k is 12.729729600316539 and b is -41.74068519491859\n",
      "Iteration 1486, the loss is 16.132163129924063, parameters k is 12.723666511383732 and b is -41.74164171665772\n",
      "Iteration 1487, the loss is 16.094487148679512, parameters k is 12.717603422450924 and b is -41.742598238396845\n",
      "Iteration 1488, the loss is 16.056811167434965, parameters k is 12.711540333518117 and b is -41.74355476013597\n",
      "Iteration 1489, the loss is 16.019135186190418, parameters k is 12.70547724458531 and b is -41.7445112818751\n",
      "Iteration 1490, the loss is 15.981459204945873, parameters k is 12.699414155652503 and b is -41.745467803614225\n",
      "Iteration 1491, the loss is 15.94378322370132, parameters k is 12.693351066719696 and b is -41.74642432535335\n",
      "Iteration 1492, the loss is 15.90610724245675, parameters k is 12.68728797778689 and b is -41.74738084709248\n",
      "Iteration 1493, the loss is 15.868569172879079, parameters k is 12.681224888854082 and b is -41.748337368831606\n",
      "Iteration 1494, the loss is 15.831194626904198, parameters k is 12.675186084506256 and b is -41.74928993800157\n",
      "Iteration 1495, the loss is 15.793820080929319, parameters k is 12.66914728015843 and b is -41.75024250717153\n",
      "Iteration 1496, the loss is 15.75644553495443, parameters k is 12.663108475810605 and b is -41.75119507634149\n",
      "Iteration 1497, the loss is 15.71907098897954, parameters k is 12.657069671462779 and b is -41.75214764551145\n",
      "Iteration 1498, the loss is 15.681696443004663, parameters k is 12.651030867114953 and b is -41.75310021468141\n",
      "Iteration 1499, the loss is 15.644321897029787, parameters k is 12.644992062767127 and b is -41.75405278385137\n",
      "Iteration 1500, the loss is 15.606947351054886, parameters k is 12.638953258419301 and b is -41.75500535302133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1501, the loss is 15.569572805080012, parameters k is 12.632914454071475 and b is -41.75595792219129\n",
      "Iteration 1502, the loss is 15.532198259105133, parameters k is 12.62687564972365 and b is -41.75691049136125\n",
      "Iteration 1503, the loss is 15.494823713130272, parameters k is 12.620836845375823 and b is -41.757863060531214\n",
      "Iteration 1504, the loss is 15.457449167155373, parameters k is 12.614798041027997 and b is -41.758815629701175\n",
      "Iteration 1505, the loss is 15.420074621180493, parameters k is 12.608759236680172 and b is -41.759768198871136\n",
      "Iteration 1506, the loss is 15.382700075205614, parameters k is 12.602720432332346 and b is -41.7607207680411\n",
      "Iteration 1507, the loss is 15.345325529230724, parameters k is 12.59668162798452 and b is -41.76167333721106\n",
      "Iteration 1508, the loss is 15.307950983255841, parameters k is 12.590642823636694 and b is -41.76262590638102\n",
      "Iteration 1509, the loss is 15.270576437280958, parameters k is 12.584604019288868 and b is -41.76357847555098\n",
      "Iteration 1510, the loss is 15.233201891306082, parameters k is 12.578565214941042 and b is -41.76453104472094\n",
      "Iteration 1511, the loss is 15.195827345331182, parameters k is 12.572526410593216 and b is -41.7654836138909\n",
      "Iteration 1512, the loss is 15.15845279935634, parameters k is 12.56648760624539 and b is -41.76643618306086\n",
      "Iteration 1513, the loss is 15.121078253381452, parameters k is 12.560448801897564 and b is -41.76738875223082\n",
      "Iteration 1514, the loss is 15.083703707406562, parameters k is 12.554409997549739 and b is -41.76834132140078\n",
      "Iteration 1515, the loss is 15.046329161431682, parameters k is 12.548371193201913 and b is -41.769293890570744\n",
      "Iteration 1516, the loss is 15.008954615456794, parameters k is 12.542332388854087 and b is -41.770246459740704\n",
      "Iteration 1517, the loss is 14.971580069481915, parameters k is 12.53629358450626 and b is -41.771199028910665\n",
      "Iteration 1518, the loss is 14.93420552350702, parameters k is 12.530254780158435 and b is -41.772151598080626\n",
      "Iteration 1519, the loss is 14.896830977532142, parameters k is 12.524215975810609 and b is -41.77310416725059\n",
      "Iteration 1520, the loss is 14.859456431557293, parameters k is 12.518177171462783 and b is -41.77405673642055\n",
      "Iteration 1521, the loss is 14.82208188558239, parameters k is 12.512138367114957 and b is -41.77500930559051\n",
      "Iteration 1522, the loss is 14.784707339607495, parameters k is 12.506099562767131 and b is -41.77596187476047\n",
      "Iteration 1523, the loss is 14.747332793632626, parameters k is 12.500060758419306 and b is -41.77691444393043\n",
      "Iteration 1524, the loss is 14.709958247657733, parameters k is 12.49402195407148 and b is -41.77786701310039\n",
      "Iteration 1525, the loss is 14.672583701682864, parameters k is 12.487983149723654 and b is -41.77881958227035\n",
      "Iteration 1526, the loss is 14.635209155707978, parameters k is 12.481944345375828 and b is -41.77977215144031\n",
      "Iteration 1527, the loss is 14.597834609733091, parameters k is 12.475905541028002 and b is -41.78072472061027\n",
      "Iteration 1528, the loss is 14.560460063758217, parameters k is 12.469866736680176 and b is -41.781677289780234\n",
      "Iteration 1529, the loss is 14.523085517783338, parameters k is 12.46382793233235 and b is -41.782629858950195\n",
      "Iteration 1530, the loss is 14.48571097180846, parameters k is 12.457789127984524 and b is -41.783582428120155\n",
      "Iteration 1531, the loss is 14.448336425833572, parameters k is 12.451750323636698 and b is -41.784534997290116\n",
      "Iteration 1532, the loss is 14.410961879858693, parameters k is 12.445711519288873 and b is -41.78548756646008\n",
      "Iteration 1533, the loss is 14.373587333883815, parameters k is 12.439672714941047 and b is -41.78644013563004\n",
      "Iteration 1534, the loss is 14.336212787908929, parameters k is 12.43363391059322 and b is -41.7873927048\n",
      "Iteration 1535, the loss is 14.298838241934046, parameters k is 12.427595106245395 and b is -41.78834527396996\n",
      "Iteration 1536, the loss is 14.261579150908178, parameters k is 12.421556301897569 and b is -41.78929784313992\n",
      "Iteration 1537, the loss is 14.224479340539471, parameters k is 12.415539663557649 and b is -41.79024645974071\n",
      "Iteration 1538, the loss is 14.187379530170773, parameters k is 12.409523025217728 and b is -41.791195076341495\n",
      "Iteration 1539, the loss is 14.150279719802084, parameters k is 12.403506386877808 and b is -41.79214369294228\n",
      "Iteration 1540, the loss is 14.113179909433388, parameters k is 12.397489748537888 and b is -41.79309230954307\n",
      "Iteration 1541, the loss is 14.076080099064683, parameters k is 12.391473110197968 and b is -41.79404092614386\n",
      "Iteration 1542, the loss is 14.038980288696001, parameters k is 12.385456471858047 and b is -41.794989542744645\n",
      "Iteration 1543, the loss is 14.001880478327301, parameters k is 12.379439833518127 and b is -41.79593815934543\n",
      "Iteration 1544, the loss is 13.964780667958612, parameters k is 12.373423195178207 and b is -41.79688677594622\n",
      "Iteration 1545, the loss is 13.927680857589923, parameters k is 12.367406556838286 and b is -41.79783539254701\n",
      "Iteration 1546, the loss is 13.890581047221215, parameters k is 12.361389918498366 and b is -41.798784009147795\n",
      "Iteration 1547, the loss is 13.853481236852529, parameters k is 12.355373280158446 and b is -41.79973262574858\n",
      "Iteration 1548, the loss is 13.816381426483836, parameters k is 12.349356641818526 and b is -41.80068124234937\n",
      "Iteration 1549, the loss is 13.779281616115128, parameters k is 12.343340003478605 and b is -41.80162985895016\n",
      "Iteration 1550, the loss is 13.742181805746439, parameters k is 12.337323365138685 and b is -41.802578475550945\n",
      "Iteration 1551, the loss is 13.705081995377753, parameters k is 12.331306726798765 and b is -41.80352709215173\n",
      "Iteration 1552, the loss is 13.667982185009047, parameters k is 12.325290088458845 and b is -41.80447570875252\n",
      "Iteration 1553, the loss is 13.630882374640356, parameters k is 12.319273450118924 and b is -41.80542432535331\n",
      "Iteration 1554, the loss is 13.59378256427165, parameters k is 12.313256811779004 and b is -41.806372941954095\n",
      "Iteration 1555, the loss is 13.556682753902962, parameters k is 12.307240173439084 and b is -41.80732155855488\n",
      "Iteration 1556, the loss is 13.51958294353426, parameters k is 12.301223535099163 and b is -41.80827017515567\n",
      "Iteration 1557, the loss is 13.482483133165571, parameters k is 12.295206896759243 and b is -41.80921879175646\n",
      "Iteration 1558, the loss is 13.445383322796877, parameters k is 12.289190258419323 and b is -41.810167408357245\n",
      "Iteration 1559, the loss is 13.408283512428184, parameters k is 12.283173620079403 and b is -41.81111602495803\n",
      "Iteration 1560, the loss is 13.37118370205948, parameters k is 12.277156981739482 and b is -41.81206464155882\n",
      "Iteration 1561, the loss is 13.334083891690787, parameters k is 12.271140343399562 and b is -41.81301325815961\n",
      "Iteration 1562, the loss is 13.296984081322094, parameters k is 12.265123705059642 and b is -41.813961874760395\n",
      "Iteration 1563, the loss is 13.259909795335604, parameters k is 12.259107066719722 and b is -41.81491049136118\n",
      "Iteration 1564, the loss is 13.223172786584957, parameters k is 12.253120029170315 and b is -41.8158551553928\n",
      "Iteration 1565, the loss is 13.186435777834326, parameters k is 12.247132991620909 and b is -41.816799819424425\n",
      "Iteration 1566, the loss is 13.149698769083672, parameters k is 12.241145954071502 and b is -41.817744483456046\n",
      "Iteration 1567, the loss is 13.112961760333016, parameters k is 12.235158916522096 and b is -41.81868914748767\n",
      "Iteration 1568, the loss is 13.076224751582378, parameters k is 12.22917187897269 and b is -41.81963381151929\n",
      "Iteration 1569, the loss is 13.039487742831746, parameters k is 12.223184841423283 and b is -41.82057847555091\n",
      "Iteration 1570, the loss is 13.002750734081078, parameters k is 12.217197803873876 and b is -41.82152313958253\n",
      "Iteration 1571, the loss is 12.966013725330443, parameters k is 12.21121076632447 and b is -41.82246780361415\n",
      "Iteration 1572, the loss is 12.9292767165798, parameters k is 12.205223728775064 and b is -41.823412467645774\n",
      "Iteration 1573, the loss is 12.892539707829142, parameters k is 12.199236691225657 and b is -41.824357131677395\n",
      "Iteration 1574, the loss is 12.855802699078504, parameters k is 12.19324965367625 and b is -41.82530179570902\n",
      "Iteration 1575, the loss is 12.819065690327868, parameters k is 12.187262616126844 and b is -41.82624645974064\n",
      "Iteration 1576, the loss is 12.782328681577223, parameters k is 12.181275578577438 and b is -41.82719112377226\n",
      "Iteration 1577, the loss is 12.745591672826567, parameters k is 12.175288541028031 and b is -41.82813578780388\n",
      "Iteration 1578, the loss is 12.708982390662248, parameters k is 12.169301503478625 and b is -41.8290804518355\n",
      "Iteration 1579, the loss is 12.672517571487267, parameters k is 12.163336616126847 and b is -41.83002116329795\n",
      "Iteration 1580, the loss is 12.636052752312269, parameters k is 12.157371728775068 and b is -41.8309618747604\n",
      "Iteration 1581, the loss is 12.599587933137276, parameters k is 12.15140684142329 and b is -41.831902586222846\n",
      "Iteration 1582, the loss is 12.563123113962295, parameters k is 12.145441954071512 and b is -41.832843297685294\n",
      "Iteration 1583, the loss is 12.526658294787298, parameters k is 12.139477066719733 and b is -41.83378400914774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1584, the loss is 12.490193475612312, parameters k is 12.133512179367955 and b is -41.83472472061019\n",
      "Iteration 1585, the loss is 12.453728656437319, parameters k is 12.127547292016176 and b is -41.83566543207264\n",
      "Iteration 1586, the loss is 12.417263837262336, parameters k is 12.121582404664398 and b is -41.836606143535086\n",
      "Iteration 1587, the loss is 12.380799018087327, parameters k is 12.11561751731262 and b is -41.837546854997534\n",
      "Iteration 1588, the loss is 12.344338339359423, parameters k is 12.109652629960841 and b is -41.83848756645998\n",
      "Iteration 1589, the loss is 12.308135676869457, parameters k is 12.10370913391341 and b is -41.839424325353264\n",
      "Iteration 1590, the loss is 12.27193301437949, parameters k is 12.09776563786598 and b is -41.840361084246545\n",
      "Iteration 1591, the loss is 12.23573035188953, parameters k is 12.091822141818549 and b is -41.84129784313983\n",
      "Iteration 1592, the loss is 12.199527689399545, parameters k is 12.085878645771118 and b is -41.84223460203311\n",
      "Iteration 1593, the loss is 12.163325026909602, parameters k is 12.079935149723687 and b is -41.84317136092639\n",
      "Iteration 1594, the loss is 12.127122364419623, parameters k is 12.073991653676256 and b is -41.84410811981967\n",
      "Iteration 1595, the loss is 12.09091970192964, parameters k is 12.068048157628825 and b is -41.845044878712955\n",
      "Iteration 1596, the loss is 12.054717039439694, parameters k is 12.062104661581394 and b is -41.845981637606236\n",
      "Iteration 1597, the loss is 12.018514376949723, parameters k is 12.056161165533963 and b is -41.84691839649952\n",
      "Iteration 1598, the loss is 11.982311714459748, parameters k is 12.050217669486532 and b is -41.8478551553928\n",
      "Iteration 1599, the loss is 11.946109051969783, parameters k is 12.044274173439101 and b is -41.84879191428608\n",
      "Iteration 1600, the loss is 11.909906389479804, parameters k is 12.03833067739167 and b is -41.849728673179364\n",
      "Iteration 1601, the loss is 11.87370372698985, parameters k is 12.03238718134424 and b is -41.850665432072645\n",
      "Iteration 1602, the loss is 11.837501064499872, parameters k is 12.026443685296808 and b is -41.85160219096593\n",
      "Iteration 1603, the loss is 11.801298402009902, parameters k is 12.020500189249377 and b is -41.85253894985921\n",
      "Iteration 1604, the loss is 11.765095739519936, parameters k is 12.014556693201946 and b is -41.85347570875249\n",
      "Iteration 1605, the loss is 11.72889307702999, parameters k is 12.008613197154515 and b is -41.85441246764577\n",
      "Iteration 1606, the loss is 11.692690414540007, parameters k is 12.002669701107084 and b is -41.855349226539055\n",
      "Iteration 1607, the loss is 11.656487752050023, parameters k is 11.996726205059653 and b is -41.856285985432336\n",
      "Iteration 1608, the loss is 11.620285089560074, parameters k is 11.990782709012223 and b is -41.85722274432562\n",
      "Iteration 1609, the loss is 11.584082427070088, parameters k is 11.984839212964792 and b is -41.8581595032189\n",
      "Iteration 1610, the loss is 11.54787976458013, parameters k is 11.97889571691736 and b is -41.85909626211218\n",
      "Iteration 1611, the loss is 11.511802895574375, parameters k is 11.97295222086993 and b is -41.860033021005464\n",
      "Iteration 1612, the loss is 11.475933080581457, parameters k is 11.967036167510246 and b is -41.86096582732957\n",
      "Iteration 1613, the loss is 11.440063265588535, parameters k is 11.961120114150562 and b is -41.86189863365368\n",
      "Iteration 1614, the loss is 11.404193450595605, parameters k is 11.955204060790878 and b is -41.86283143997779\n",
      "Iteration 1615, the loss is 11.368323635602685, parameters k is 11.949288007431194 and b is -41.8637642463019\n",
      "Iteration 1616, the loss is 11.332453820609752, parameters k is 11.94337195407151 and b is -41.864697052626006\n",
      "Iteration 1617, the loss is 11.296584005616825, parameters k is 11.937455900711827 and b is -41.865629858950115\n",
      "Iteration 1618, the loss is 11.260714190623908, parameters k is 11.931539847352143 and b is -41.86656266527422\n",
      "Iteration 1619, the loss is 11.22484437563098, parameters k is 11.92562379399246 and b is -41.86749547159833\n",
      "Iteration 1620, the loss is 11.188974560638057, parameters k is 11.919707740632775 and b is -41.86842827792244\n",
      "Iteration 1621, the loss is 11.153104745645134, parameters k is 11.913791687273092 and b is -41.86936108424655\n",
      "Iteration 1622, the loss is 11.117234930652197, parameters k is 11.907875633913408 and b is -41.87029389057066\n",
      "Iteration 1623, the loss is 11.081365115659285, parameters k is 11.901959580553724 and b is -41.871226696894766\n",
      "Iteration 1624, the loss is 11.045495300666348, parameters k is 11.89604352719404 and b is -41.872159503218874\n",
      "Iteration 1625, the loss is 11.009625485673423, parameters k is 11.890127473834356 and b is -41.87309230954298\n",
      "Iteration 1626, the loss is 10.9737556706805, parameters k is 11.884211420474672 and b is -41.87402511586709\n",
      "Iteration 1627, the loss is 10.937885855687588, parameters k is 11.878295367114989 and b is -41.8749579221912\n",
      "Iteration 1628, the loss is 10.902016040694646, parameters k is 11.872379313755305 and b is -41.87589072851531\n",
      "Iteration 1629, the loss is 10.86614622570173, parameters k is 11.866463260395621 and b is -41.87682353483942\n",
      "Iteration 1630, the loss is 10.830276410708805, parameters k is 11.860547207035937 and b is -41.877756341163526\n",
      "Iteration 1631, the loss is 10.794406595715884, parameters k is 11.854631153676253 and b is -41.878689147487634\n",
      "Iteration 1632, the loss is 10.758536780722963, parameters k is 11.84871510031657 and b is -41.87962195381174\n",
      "Iteration 1633, the loss is 10.72266696573004, parameters k is 11.842799046956886 and b is -41.88055476013585\n",
      "Iteration 1634, the loss is 10.686797150737107, parameters k is 11.836882993597202 and b is -41.88148756645996\n",
      "Iteration 1635, the loss is 10.650927335744178, parameters k is 11.830966940237518 and b is -41.88242037278407\n",
      "Iteration 1636, the loss is 10.615057520751241, parameters k is 11.825050886877834 and b is -41.88335317910818\n",
      "Iteration 1637, the loss is 10.579187705758322, parameters k is 11.81913483351815 and b is -41.884285985432285\n",
      "Iteration 1638, the loss is 10.543317890765412, parameters k is 11.813218780158467 and b is -41.885218791756394\n",
      "Iteration 1639, the loss is 10.507448075772473, parameters k is 11.807302726798783 and b is -41.8861515980805\n",
      "Iteration 1640, the loss is 10.471578260779564, parameters k is 11.801386673439099 and b is -41.88708440440461\n",
      "Iteration 1641, the loss is 10.43570844578663, parameters k is 11.795470620079415 and b is -41.88801721072872\n",
      "Iteration 1642, the loss is 10.39983863079371, parameters k is 11.789554566719731 and b is -41.88895001705283\n",
      "Iteration 1643, the loss is 10.36396881580079, parameters k is 11.783638513360048 and b is -41.88988282337694\n",
      "Iteration 1644, the loss is 10.328103052178522, parameters k is 11.777722460000364 and b is -41.890815629701045\n",
      "Iteration 1645, the loss is 10.292604522399262, parameters k is 11.771837244585344 and b is -41.89174448345599\n",
      "Iteration 1646, the loss is 10.257105992620016, parameters k is 11.765952029170323 and b is -41.89267333721093\n",
      "Iteration 1647, the loss is 10.221607462840748, parameters k is 11.760066813755303 and b is -41.89360219096587\n",
      "Iteration 1648, the loss is 10.186108933061492, parameters k is 11.754181598340283 and b is -41.894531044720814\n",
      "Iteration 1649, the loss is 10.150610403282242, parameters k is 11.748296382925263 and b is -41.89545989847576\n",
      "Iteration 1650, the loss is 10.115111873502979, parameters k is 11.742411167510243 and b is -41.8963887522307\n",
      "Iteration 1651, the loss is 10.079613343723715, parameters k is 11.736525952095223 and b is -41.89731760598564\n",
      "Iteration 1652, the loss is 10.044255520864606, parameters k is 11.730640736680202 and b is -41.898246459740584\n",
      "Iteration 1653, the loss is 10.00912768519287, parameters k is 11.724786473834353 and b is -41.89917136092635\n",
      "Iteration 1654, the loss is 9.973999849521146, parameters k is 11.718932210988504 and b is -41.90009626211212\n",
      "Iteration 1655, the loss is 9.938872013849409, parameters k is 11.713077948142654 and b is -41.90102116329789\n",
      "Iteration 1656, the loss is 9.90374417817767, parameters k is 11.707223685296805 and b is -41.90194606448366\n",
      "Iteration 1657, the loss is 9.868616342505948, parameters k is 11.701369422450956 and b is -41.90287096566943\n",
      "Iteration 1658, the loss is 9.833488506834216, parameters k is 11.695515159605106 and b is -41.9037958668552\n",
      "Iteration 1659, the loss is 9.798458532979154, parameters k is 11.689660896759257 and b is -41.90472076804097\n",
      "Iteration 1660, the loss is 9.763585690683184, parameters k is 11.683827827589296 and b is -41.90564171665757\n",
      "Iteration 1661, the loss is 9.728712848387206, parameters k is 11.677994758419334 and b is -41.90656266527417\n",
      "Iteration 1662, the loss is 9.693840006091246, parameters k is 11.672161689249373 and b is -41.907483613890776\n",
      "Iteration 1663, the loss is 9.659124034035615, parameters k is 11.666328620079412 and b is -41.90840456250738\n",
      "Iteration 1664, the loss is 9.62496754253459, parameters k is 11.66054870110708 and b is -41.90931760598564\n",
      "Iteration 1665, the loss is 9.590960468200315, parameters k is 11.65478843826123 and b is -41.91022669689473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1666, the loss is 9.556953393866042, parameters k is 11.64902817541538 and b is -41.91113578780382\n",
      "Iteration 1667, the loss is 9.522946319531776, parameters k is 11.643267912569529 and b is -41.91204487871291\n",
      "Iteration 1668, the loss is 9.488972491984688, parameters k is 11.637507649723679 and b is -41.912953969622\n",
      "Iteration 1669, the loss is 9.455225283911105, parameters k is 11.631769363162414 and b is -41.913859107961926\n",
      "Iteration 1670, the loss is 9.42147807583752, parameters k is 11.62603107660115 and b is -41.91476424630185\n",
      "Iteration 1671, the loss is 9.387794139888536, parameters k is 11.620292790039885 and b is -41.915669384641774\n",
      "Iteration 1672, the loss is 9.354332592038665, parameters k is 11.614578823636723 and b is -41.916570570412524\n",
      "Iteration 1673, the loss is 9.320910372488353, parameters k is 11.608864857233561 and b is -41.917471756183275\n",
      "Iteration 1674, the loss is 9.287652936167047, parameters k is 11.603168155652533 and b is -41.91836898938486\n",
      "Iteration 1675, the loss is 9.254523957916804, parameters k is 11.597471454071504 and b is -41.919266222586444\n",
      "Iteration 1676, the loss is 9.221663918881342, parameters k is 11.59180606869601 and b is -41.920159503218855\n",
      "Iteration 1677, the loss is 9.189148512851029, parameters k is 11.586172023241465 and b is -41.92104883128209\n",
      "Iteration 1678, the loss is 9.156859719324622, parameters k is 11.580559100316563 and b is -41.921934206776164\n",
      "Iteration 1679, the loss is 9.124570925798245, parameters k is 11.574946177391661 and b is -41.922819582270236\n",
      "Iteration 1680, the loss is 9.092282132271851, parameters k is 11.569333254466759 and b is -41.92370495776431\n",
      "Iteration 1681, the loss is 9.059993338745464, parameters k is 11.563720331541857 and b is -41.92459033325838\n",
      "Iteration 1682, the loss is 9.02770454521908, parameters k is 11.558107408616955 and b is -41.92547570875245\n",
      "Iteration 1683, the loss is 8.995415751692693, parameters k is 11.552494485692053 and b is -41.92636108424652\n",
      "Iteration 1684, the loss is 8.963126958166296, parameters k is 11.546881562767151 and b is -41.927246459740594\n",
      "Iteration 1685, the loss is 8.930838164639919, parameters k is 11.541268639842249 and b is -41.928131835234666\n",
      "Iteration 1686, the loss is 8.898549371113523, parameters k is 11.535655716917347 and b is -41.92901721072874\n",
      "Iteration 1687, the loss is 8.866300078265386, parameters k is 11.530042793992445 and b is -41.92990258622281\n",
      "Iteration 1688, the loss is 8.834466907090821, parameters k is 11.524460250514185 and b is -41.93078400914771\n",
      "Iteration 1689, the loss is 8.80286024396579, parameters k is 11.518907169486518 and b is -41.93166147950344\n",
      "Iteration 1690, the loss is 8.771421382976355, parameters k is 11.51335408845885 and b is -41.93253894985917\n",
      "Iteration 1691, the loss is 8.74039825866586, parameters k is 11.50785254498059 and b is -41.933408515076565\n",
      "Iteration 1692, the loss is 8.709375134355371, parameters k is 11.50235100150233 and b is -41.93427808029396\n",
      "Iteration 1693, the loss is 8.678516964744158, parameters k is 11.49684945802407 and b is -41.93514764551135\n",
      "Iteration 1694, the loss is 8.647832270337585, parameters k is 11.491378131937113 and b is -41.93601325815957\n",
      "Iteration 1695, the loss is 8.61714757593102, parameters k is 11.485906805850156 and b is -41.93687887080779\n",
      "Iteration 1696, the loss is 8.586462881524445, parameters k is 11.4804354797632 and b is -41.93774448345601\n",
      "Iteration 1697, the loss is 8.55582932022101, parameters k is 11.474964153676243 and b is -41.93861009610423\n",
      "Iteration 1698, the loss is 8.52539313132116, parameters k is 11.469512297945018 and b is -41.93947175618328\n",
      "Iteration 1699, the loss is 8.495178599788872, parameters k is 11.464082853280987 and b is -41.94032946369316\n",
      "Iteration 1700, the loss is 8.46496406825659, parameters k is 11.458653408616955 and b is -41.94118717120304\n",
      "Iteration 1701, the loss is 8.434749536724306, parameters k is 11.453223963952924 and b is -41.94204487871292\n",
      "Iteration 1702, the loss is 8.404535005192022, parameters k is 11.447794519288893 and b is -41.9429025862228\n",
      "Iteration 1703, the loss is 8.374382921423354, parameters k is 11.442365074624862 and b is -41.94376029373268\n",
      "Iteration 1704, the loss is 8.344560343818241, parameters k is 11.436967384901541 and b is -41.944614048673394\n",
      "Iteration 1705, the loss is 8.315136188552902, parameters k is 11.43159922086992 and b is -41.945463851044934\n",
      "Iteration 1706, the loss is 8.285831818186546, parameters k is 11.426252361186126 and b is -41.94630970084731\n",
      "Iteration 1707, the loss is 8.256549491998522, parameters k is 11.420905501502332 and b is -41.94715555064968\n",
      "Iteration 1708, the loss is 8.227463245661411, parameters k is 11.415578452095218 and b is -41.947997447882884\n",
      "Iteration 1709, the loss is 8.198376999324307, parameters k is 11.410251402688104 and b is -41.948839345116085\n",
      "Iteration 1710, the loss is 8.16929075298719, parameters k is 11.40492435328099 and b is -41.949681242349286\n",
      "Iteration 1711, the loss is 8.140204506650077, parameters k is 11.399597303873875 and b is -41.95052313958249\n",
      "Iteration 1712, the loss is 8.111118260312965, parameters k is 11.394270254466761 and b is -41.95136503681569\n",
      "Iteration 1713, the loss is 8.082113004731395, parameters k is 11.388943205059647 and b is -41.95220693404889\n",
      "Iteration 1714, the loss is 8.053495490122945, parameters k is 11.383659080553718 and b is -41.95304092614375\n",
      "Iteration 1715, the loss is 8.02487797551449, parameters k is 11.37837495604779 and b is -41.95387491823861\n",
      "Iteration 1716, the loss is 7.9962604609060515, parameters k is 11.37309083154186 and b is -41.95470891033347\n",
      "Iteration 1717, the loss is 7.967642946297603, parameters k is 11.367806707035932 and b is -41.955542902428334\n",
      "Iteration 1718, the loss is 7.939072234474253, parameters k is 11.362522582530003 and b is -41.956376894523196\n",
      "Iteration 1719, the loss is 7.910716871450396, parameters k is 11.357257849328422 and b is -41.957206934048884\n",
      "Iteration 1720, the loss is 7.882605571075408, parameters k is 11.35202059043514 and b is -41.958033021005406\n",
      "Iteration 1721, the loss is 7.854494270700422, parameters k is 11.34678333154186 and b is -41.95885910796193\n",
      "Iteration 1722, the loss is 7.82648225222316, parameters k is 11.341546072648578 and b is -41.95968519491845\n",
      "Iteration 1723, the loss is 7.798778513017415, parameters k is 11.33633475446676 and b is -41.9605073293058\n",
      "Iteration 1724, the loss is 7.771347866202939, parameters k is 11.331151025217748 and b is -41.96132551112398\n",
      "Iteration 1725, the loss is 7.744034837405109, parameters k is 11.32598865565253 and b is -41.96213974037299\n",
      "Iteration 1726, the loss is 7.716721808607279, parameters k is 11.320826286087312 and b is -41.962953969622\n",
      "Iteration 1727, the loss is 7.689408779809452, parameters k is 11.315663916522094 and b is -41.96376819887101\n",
      "Iteration 1728, the loss is 7.662202694431594, parameters k is 11.310501546956877 and b is -41.96458242812002\n",
      "Iteration 1729, the loss is 7.635484145418866, parameters k is 11.305395825613003 and b is -41.96538875223069\n",
      "Iteration 1730, the loss is 7.608817768694003, parameters k is 11.300290104269129 and b is -41.96619507634136\n",
      "Iteration 1731, the loss is 7.582313226191287, parameters k is 11.295204758419326 and b is -41.96699744788286\n",
      "Iteration 1732, the loss is 7.555808683688563, parameters k is 11.290119412569522 and b is -41.967799819424364\n",
      "Iteration 1733, the loss is 7.529304141185843, parameters k is 11.285034066719719 and b is -41.96860219096587\n",
      "Iteration 1734, the loss is 7.502799598683127, parameters k is 11.279948720869916 and b is -41.96940456250737\n",
      "Iteration 1735, the loss is 7.4763722993165915, parameters k is 11.274863375020113 and b is -41.970206934048875\n",
      "Iteration 1736, the loss is 7.45006075804052, parameters k is 11.26979641652209 and b is -41.971005353021205\n",
      "Iteration 1737, the loss is 7.423749216764452, parameters k is 11.264729458024066 and b is -41.971803771993535\n",
      "Iteration 1738, the loss is 7.397437675488378, parameters k is 11.259662499526042 and b is -41.972602190965866\n",
      "Iteration 1739, the loss is 7.371126134212306, parameters k is 11.254595541028019 and b is -41.973400609938196\n",
      "Iteration 1740, the loss is 7.344814592936233, parameters k is 11.249528582529996 and b is -41.974199028910526\n",
      "Iteration 1741, the loss is 7.31850305166016, parameters k is 11.244461624031972 and b is -41.974997447882856\n",
      "Iteration 1742, the loss is 7.292191510384092, parameters k is 11.239394665533949 and b is -41.97579586685519\n",
      "Iteration 1743, the loss is 7.26587996910802, parameters k is 11.234327707035925 and b is -41.97659428582752\n",
      "Iteration 1744, the loss is 7.239638518772222, parameters k is 11.229260748537902 and b is -41.97739270479985\n",
      "Iteration 1745, the loss is 7.213533916026316, parameters k is 11.224213627984541 and b is -41.97818717120301\n",
      "Iteration 1746, the loss is 7.1874293132804095, parameters k is 11.219166507431181 and b is -41.978981637606175\n",
      "Iteration 1747, the loss is 7.161442380489278, parameters k is 11.21411938687782 and b is -41.97977610400934\n",
      "Iteration 1748, the loss is 7.135845693075132, parameters k is 11.209121586482564 and b is -41.980562665274164\n",
      "Iteration 1749, the loss is 7.110249005660975, parameters k is 11.204123786087306 and b is -41.98134922653899\n",
      "Iteration 1750, the loss is 7.084652318246819, parameters k is 11.19912598569205 and b is -41.98213578780381\n",
      "Iteration 1751, the loss is 7.059055630832672, parameters k is 11.194128185296792 and b is -41.98292234906864\n",
      "Iteration 1752, the loss is 7.033654934774205, parameters k is 11.189130384901535 and b is -41.98370891033346\n",
      "Iteration 1753, the loss is 7.008544388075597, parameters k is 11.184180209012206 and b is -41.98448756645995\n",
      "Iteration 1754, the loss is 6.983433841377007, parameters k is 11.179230033122877 and b is -41.98526622258643\n",
      "Iteration 1755, the loss is 6.958473086690604, parameters k is 11.174279857233548 and b is -41.98604487871292\n",
      "Iteration 1756, the loss is 6.934137725902232, parameters k is 11.16940672877505 and b is -41.98681167713189\n",
      "Iteration 1757, the loss is 6.909823474067567, parameters k is 11.16453360031655 and b is -41.98757847555086\n",
      "Iteration 1758, the loss is 6.88576898981907, parameters k is 11.159688752490464 and b is -41.98834132140066\n",
      "Iteration 1759, the loss is 6.861714505570569, parameters k is 11.154843904664377 and b is -41.98910416725046\n",
      "Iteration 1760, the loss is 6.837697264276248, parameters k is 11.14999905683829 and b is -41.98986701310026\n",
      "Iteration 1761, the loss is 6.813869756561198, parameters k is 11.145177066719713 and b is -41.99062590638089\n",
      "Iteration 1762, the loss is 6.790042248846151, parameters k is 11.140355076601136 and b is -41.991384799661525\n",
      "Iteration 1763, the loss is 6.766214741131112, parameters k is 11.135533086482559 and b is -41.99214369294216\n",
      "Iteration 1764, the loss is 6.742387233416063, parameters k is 11.130711096363981 and b is -41.99290258622279\n",
      "Iteration 1765, the loss is 6.718559725701025, parameters k is 11.125889106245404 and b is -41.99366147950342\n",
      "Iteration 1766, the loss is 6.694732217985978, parameters k is 11.121067116126827 and b is -41.994420372784056\n",
      "Iteration 1767, the loss is 6.670946713410734, parameters k is 11.11624512600825 and b is -41.99517926606469\n",
      "Iteration 1768, the loss is 6.647339984145479, parameters k is 11.111445460000345 and b is -41.99593420677615\n",
      "Iteration 1769, the loss is 6.623755315176449, parameters k is 11.10664579399244 and b is -41.99668914748761\n",
      "Iteration 1770, the loss is 6.600418159686501, parameters k is 11.101873669486512 and b is -41.9974401356299\n",
      "Iteration 1771, the loss is 6.577081004196553, parameters k is 11.097101544980584 and b is -41.998191123772195\n",
      "Iteration 1772, the loss is 6.553787213980762, parameters k is 11.092329420474655 and b is -41.99894211191449\n",
      "Iteration 1773, the loss is 6.530867353003283, parameters k is 11.087585548933154 and b is -41.99968914748761\n",
      "Iteration 1774, the loss is 6.508619287774465, parameters k is 11.082920697154497 and b is -42.00042432535322\n",
      "Iteration 1775, the loss is 6.4865437535011266, parameters k is 11.078279485692047 and b is -42.00115555064966\n",
      "Iteration 1776, the loss is 6.464592723216159, parameters k is 11.073638274229596 and b is -42.001886775946105\n",
      "Iteration 1777, the loss is 6.442891688912839, parameters k is 11.069027141818529 and b is -42.00261404867338\n",
      "Iteration 1778, the loss is 6.421315470409661, parameters k is 11.064438784111019 and b is -42.00333736883148\n",
      "Iteration 1779, the loss is 6.399739251906476, parameters k is 11.059850426403509 and b is -42.00406068898958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1780, the loss is 6.378163033403297, parameters k is 11.055262068695999 and b is -42.004784009147684\n",
      "Iteration 1781, the loss is 6.356645563616237, parameters k is 11.05067371098849 and b is -42.005507329305786\n",
      "Iteration 1782, the loss is 6.335286846014017, parameters k is 11.0461084916209 and b is -42.00622669689472\n",
      "Iteration 1783, the loss is 6.3139281284118045, parameters k is 11.041543272253312 and b is -42.00694606448366\n",
      "Iteration 1784, the loss is 6.292748651026302, parameters k is 11.036978052885724 and b is -42.00766543207259\n",
      "Iteration 1785, the loss is 6.271862225895761, parameters k is 11.032463604269124 and b is -42.00837689452319\n",
      "Iteration 1786, the loss is 6.250975800765234, parameters k is 11.027949155652523 and b is -42.009088356973784\n",
      "Iteration 1787, the loss is 6.230266603337274, parameters k is 11.023434707035923 and b is -42.00979981942438\n",
      "Iteration 1788, the loss is 6.209846802209901, parameters k is 11.01897098569205 and b is -42.01050337673664\n",
      "Iteration 1789, the loss is 6.189427001082519, parameters k is 11.014507264348177 and b is -42.01120693404889\n",
      "Iteration 1790, the loss is 6.169031058562802, parameters k is 11.010043543004304 and b is -42.01191049136115\n",
      "Iteration 1791, the loss is 6.148854555078413, parameters k is 11.005606533122881 and b is -42.01261009610423\n",
      "Iteration 1792, the loss is 6.128754441061221, parameters k is 11.001169523241458 and b is -42.013309700847316\n",
      "Iteration 1793, the loss is 6.108879481210231, parameters k is 10.996759493597189 and b is -42.014005353021226\n",
      "Iteration 1794, the loss is 6.089401968679861, parameters k is 10.992400076601141 and b is -42.014693100056796\n",
      "Iteration 1795, the loss is 6.069924456149505, parameters k is 10.988040659605094 and b is -42.015380847092366\n",
      "Iteration 1796, the loss is 6.050574878481771, parameters k is 10.983681242609046 and b is -42.01606859412794\n",
      "Iteration 1797, the loss is 6.031603772037493, parameters k is 10.979379043004304 and b is -42.01674843602517\n",
      "Iteration 1798, the loss is 6.0126588573510515, parameters k is 10.975076843399561 and b is -42.0174282779224\n",
      "Iteration 1799, the loss is 5.994011078719164, parameters k is 10.970794023241458 and b is -42.01810416725046\n",
      "Iteration 1800, the loss is 5.975963970221017, parameters k is 10.966591191225648 and b is -42.018768198871015\n",
      "Iteration 1801, the loss is 5.958091262774305, parameters k is 10.962411643794818 and b is -42.0194282779224\n",
      "Iteration 1802, the loss is 5.940376743329347, parameters k is 10.958254238656478 and b is -42.020084404404614\n",
      "Iteration 1803, the loss is 5.922684681158474, parameters k is 10.954096833518138 and b is -42.020740530886826\n",
      "Iteration 1804, the loss is 5.905374580155372, parameters k is 10.949965341423276 and b is -42.02139270479987\n",
      "Iteration 1805, the loss is 5.888585038613465, parameters k is 10.945918177391656 and b is -42.022033021005406\n",
      "Iteration 1806, the loss is 5.871878980094197, parameters k is 10.941871013360036 and b is -42.02267333721094\n",
      "Iteration 1807, the loss is 5.8553223434804265, parameters k is 10.937852098340272 and b is -42.0233097008473\n",
      "Iteration 1808, the loss is 5.8387657068666625, parameters k is 10.933833183320509 and b is -42.02394606448366\n",
      "Iteration 1809, the loss is 5.822305232611038, parameters k is 10.929814268300746 and b is -42.02458242812002\n",
      "Iteration 1810, the loss is 5.805945753355301, parameters k is 10.925819329565568 and b is -42.025214839187214\n",
      "Iteration 1811, the loss is 5.789700866087217, parameters k is 10.921824390830391 and b is -42.02584725025441\n",
      "Iteration 1812, the loss is 5.773572250701535, parameters k is 10.917857823636716 and b is -42.02647570875243\n",
      "Iteration 1813, the loss is 5.757479578659948, parameters k is 10.91389125644304 and b is -42.02710416725045\n",
      "Iteration 1814, the loss is 5.741707871422458, parameters k is 10.909951495573475 and b is -42.027728673179304\n",
      "Iteration 1815, the loss is 5.726292504370314, parameters k is 10.906061991620906 and b is -42.02834527396982\n",
      "Iteration 1816, the loss is 5.711156458702474, parameters k is 10.902219396759245 and b is -42.028953969621995\n",
      "Iteration 1817, the loss is 5.696036638292805, parameters k is 10.898376801897584 and b is -42.02956266527417\n",
      "Iteration 1818, the loss is 5.681200459530779, parameters k is 10.894560365138691 and b is -42.03016740835717\n",
      "Iteration 1819, the loss is 5.666549440174169, parameters k is 10.890772410593236 and b is -42.03076819887101\n",
      "Iteration 1820, the loss is 5.652020097844966, parameters k is 10.887007689249362 and b is -42.03136503681567\n",
      "Iteration 1821, the loss is 5.637490755515752, parameters k is 10.883242967905488 and b is -42.031961874760334\n",
      "Iteration 1822, the loss is 5.622961413186547, parameters k is 10.879478246561614 and b is -42.032558712705\n",
      "Iteration 1823, the loss is 5.608432877897182, parameters k is 10.87571352521774 and b is -42.03315555064966\n",
      "Iteration 1824, the loss is 5.5940777506825325, parameters k is 10.871971384901535 and b is -42.03374843602516\n",
      "Iteration 1825, the loss is 5.5797226234678865, parameters k is 10.86822924458533 and b is -42.03434132140065\n",
      "Iteration 1826, the loss is 5.56536749625324, parameters k is 10.864487104269124 and b is -42.03493420677615\n",
      "Iteration 1827, the loss is 5.551012369038596, parameters k is 10.860744963952918 and b is -42.035527092151646\n",
      "Iteration 1828, the loss is 5.536742406767637, parameters k is 10.857002823636712 and b is -42.03611997752714\n",
      "Iteration 1829, the loss is 5.522572055612922, parameters k is 10.853284825612997 and b is -42.036708910333466\n",
      "Iteration 1830, the loss is 5.508460753785065, parameters k is 10.849566827589282 and b is -42.03729784313979\n",
      "Iteration 1831, the loss is 5.494609588912119, parameters k is 10.845890746561613 and b is -42.03787887080777\n",
      "Iteration 1832, the loss is 5.480805415486382, parameters k is 10.842214665533945 and b is -42.03845989847576\n",
      "Iteration 1833, the loss is 5.467137879517657, parameters k is 10.838563019288886 and b is -42.039036973574575\n",
      "Iteration 1834, the loss is 5.453523496050704, parameters k is 10.834911373043827 and b is -42.03961404867339\n",
      "Iteration 1835, the loss is 5.440033718088822, parameters k is 10.83128352126517 and b is -42.04018717120304\n",
      "Iteration 1836, the loss is 5.426543940126939, parameters k is 10.827655669486514 and b is -42.04076029373268\n",
      "Iteration 1837, the loss is 5.41305416216505, parameters k is 10.824027817707858 and b is -42.041333416262326\n",
      "Iteration 1838, the loss is 5.39964569305469, parameters k is 10.820399965929202 and b is -42.04190653879197\n",
      "Iteration 1839, the loss is 5.38634074541269, parameters k is 10.816795390830388 and b is -42.04247570875244\n",
      "Iteration 1840, the loss is 5.373266509445243, parameters k is 10.813224009407463 and b is -42.043040926143746\n",
      "Iteration 1841, the loss is 5.3601922734778, parameters k is 10.809652627984539 and b is -42.04360614353505\n",
      "Iteration 1842, the loss is 5.347118037510357, parameters k is 10.806081246561615 and b is -42.044171360926356\n",
      "Iteration 1843, the loss is 5.33411973264684, parameters k is 10.80250986513869 and b is -42.04473657831766\n",
      "Iteration 1844, the loss is 5.321689055124992, parameters k is 10.799016278182169 and b is -42.04528993800145\n",
      "Iteration 1845, the loss is 5.309559734947191, parameters k is 10.795573446166358 and b is -42.045835392546905\n",
      "Iteration 1846, the loss is 5.297632038402744, parameters k is 10.792153072648572 and b is -42.04637689452319\n",
      "Iteration 1847, the loss is 5.285811457647036, parameters k is 10.7887572485379 and b is -42.046914443930305\n",
      "Iteration 1848, the loss is 5.2739908768913235, parameters k is 10.785361424427228 and b is -42.04745199333742\n",
      "Iteration 1849, the loss is 5.262230037963749, parameters k is 10.781965600316555 and b is -42.04798954274453\n",
      "Iteration 1850, the loss is 5.250813412564858, parameters k is 10.77861683944699 and b is -42.048519187013305\n",
      "Iteration 1851, the loss is 5.239605232859135, parameters k is 10.775295738656476 and b is -42.04904487871291\n",
      "Iteration 1852, the loss is 5.2286665224474715, parameters k is 10.772022424427227 and b is -42.04956266527418\n",
      "Iteration 1853, the loss is 5.2178581147941685, parameters k is 10.768775212964776 and b is -42.050076499266275\n",
      "Iteration 1854, the loss is 5.207128285542818, parameters k is 10.765528001502325 and b is -42.05059033325837\n",
      "Iteration 1855, the loss is 5.19675681335168, parameters k is 10.762330311779005 and b is -42.051096262112125\n",
      "Iteration 1856, the loss is 5.186757639969716, parameters k is 10.759207001502325 and b is -42.05159033325837\n",
      "Iteration 1857, the loss is 5.1768316433889625, parameters k is 10.756083691225646 and b is -42.05208440440461\n",
      "Iteration 1858, the loss is 5.1671478389758025, parameters k is 10.753010021265172 and b is -42.05257057041251\n",
      "Iteration 1859, the loss is 5.157464034562641, parameters k is 10.749936351304699 and b is -42.053056736420416\n",
      "Iteration 1860, the loss is 5.147799118641966, parameters k is 10.746862681344226 and b is -42.05354290242832\n",
      "Iteration 1861, the loss is 5.138269452692546, parameters k is 10.743813560790866 and b is -42.054025115867056\n",
      "Iteration 1862, the loss is 5.12873978674313, parameters k is 10.740764440237506 and b is -42.05450732930579\n",
      "Iteration 1863, the loss is 5.119210120793708, parameters k is 10.737715319684145 and b is -42.05498954274453\n",
      "Iteration 1864, the loss is 5.109713888192669, parameters k is 10.734666199130785 and b is -42.055471756183266\n",
      "Iteration 1865, the loss is 5.100356216494944, parameters k is 10.731641434308651 and b is -42.05595001705283\n",
      "Iteration 1866, the loss is 5.091125306439318, parameters k is 10.728640444190074 and b is -42.05642432535323\n",
      "Iteration 1867, the loss is 5.081894396383698, parameters k is 10.725639454071496 and b is -42.056898633653624\n",
      "Iteration 1868, the loss is 5.072788577814243, parameters k is 10.722638463952919 and b is -42.05737294195402\n",
      "Iteration 1869, the loss is 5.063859530329792, parameters k is 10.719686936284935 and b is -42.05783934511608\n",
      "Iteration 1870, the loss is 5.054930482845343, parameters k is 10.716735408616952 and b is -42.05830574827814\n",
      "Iteration 1871, the loss is 5.046019530487311, parameters k is 10.713783880948968 and b is -42.058772151440195\n",
      "Iteration 1872, the loss is 5.03723758183694, parameters k is 10.710855578577426 and b is -42.05923460203308\n",
      "Iteration 1873, the loss is 5.028637169706137, parameters k is 10.707955675415372 and b is -42.0596931000568\n",
      "Iteration 1874, the loss is 5.020169623339621, parameters k is 10.705075060790866 and b is -42.06014764551134\n",
      "Iteration 1875, the loss is 5.011798640022273, parameters k is 10.702217098340274 and b is -42.06059823839672\n",
      "Iteration 1876, the loss is 5.003427656704922, parameters k is 10.699359135889681 and b is -42.0610488312821\n",
      "Iteration 1877, the loss is 4.99520399389465, parameters k is 10.696501173439088 and b is -42.06149942416748\n",
      "Iteration 1878, the loss is 4.987355266656983, parameters k is 10.693712882925254 and b is -42.061938159345345\n",
      "Iteration 1879, the loss is 4.979781467584882, parameters k is 10.690994137865966 and b is -42.0623650368157\n",
      "Iteration 1880, the loss is 4.97220766851278, parameters k is 10.688275392806677 and b is -42.06279191428605\n",
      "Iteration 1881, the loss is 4.964648172413942, parameters k is 10.685556647747388 and b is -42.063218791756405\n",
      "Iteration 1882, the loss is 4.95726134562882, parameters k is 10.682866554862013 and b is -42.06364171665759\n",
      "Iteration 1883, the loss is 4.950025548581926, parameters k is 10.680204861186123 and b is -42.064060688989606\n",
      "Iteration 1884, the loss is 4.942893356010477, parameters k is 10.677566689249364 and b is -42.064475708752454\n",
      "Iteration 1885, the loss is 4.935761163439016, parameters k is 10.674928517312605 and b is -42.0648907285153\n",
      "Iteration 1886, the loss is 4.928661734229523, parameters k is 10.672290345375846 and b is -42.06530574827815\n",
      "Iteration 1887, the loss is 4.921654708702143, parameters k is 10.669675378972684 and b is -42.06571681547182\n",
      "Iteration 1888, the loss is 4.914668469716913, parameters k is 10.667060412569523 and b is -42.0661278826655\n",
      "Iteration 1889, the loss is 4.907779806059579, parameters k is 10.664467552885728 and b is -42.066534997290006\n",
      "Iteration 1890, the loss is 4.900891142402242, parameters k is 10.661874693201934 and b is -42.066942111914514\n",
      "Iteration 1891, the loss is 4.894002478744911, parameters k is 10.65928183351814 and b is -42.06734922653902\n",
      "Iteration 1892, the loss is 4.887167871747761, parameters k is 10.656688973834346 and b is -42.06775634116353\n",
      "Iteration 1893, the loss is 4.880436294238478, parameters k is 10.654123284111025 and b is -42.068159503218865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1894, the loss is 4.873828186972217, parameters k is 10.651583847352132 and b is -42.068558712705034\n",
      "Iteration 1895, the loss is 4.867278894337204, parameters k is 10.64904441059324 and b is -42.0689579221912\n",
      "Iteration 1896, the loss is 4.860806056967739, parameters k is 10.646531124031975 and b is -42.0693531791082\n",
      "Iteration 1897, the loss is 4.854401067953423, parameters k is 10.644017837470711 and b is -42.06974843602519\n",
      "Iteration 1898, the loss is 4.8481043934772945, parameters k is 10.64153353509917 and b is -42.07013974037302\n",
      "Iteration 1899, the loss is 4.8418933070505386, parameters k is 10.639071616126838 and b is -42.07052709215168\n",
      "Iteration 1900, the loss is 4.835781293182823, parameters k is 10.636609697154507 and b is -42.070914443930334\n",
      "Iteration 1901, the loss is 4.829936630120564, parameters k is 10.63422146197664 and b is -42.07128993800148\n",
      "Iteration 1902, the loss is 4.8240919670583, parameters k is 10.631833226798774 and b is -42.07166543207262\n",
      "Iteration 1903, the loss is 4.818290488355787, parameters k is 10.629444991620908 and b is -42.072040926143764\n",
      "Iteration 1904, the loss is 4.8125539000905375, parameters k is 10.627078867114978 and b is -42.07241246764574\n",
      "Iteration 1905, the loss is 4.806872003048879, parameters k is 10.624712742609049 and b is -42.07278400914772\n",
      "Iteration 1906, the loss is 4.801261858260562, parameters k is 10.622369705059642 and b is -42.07315159808052\n",
      "Iteration 1907, the loss is 4.795855795627868, parameters k is 10.62007260031656 and b is -42.073511281874985\n",
      "Iteration 1908, the loss is 4.790469723922728, parameters k is 10.617775495573477 and b is -42.07387096566945\n",
      "Iteration 1909, the loss is 4.785172615529498, parameters k is 10.615501608221699 and b is -42.07422669689475\n",
      "Iteration 1910, the loss is 4.779889233367029, parameters k is 10.61322772086992 and b is -42.074582428120046\n",
      "Iteration 1911, the loss is 4.7748017266710425, parameters k is 10.61097717343909 and b is -42.07493420677617\n",
      "Iteration 1912, the loss is 4.769936718226448, parameters k is 10.608797847352134 and b is -42.07527412772479\n",
      "Iteration 1913, the loss is 4.765071709781847, parameters k is 10.606618521265178 and b is -42.07561404867341\n",
      "Iteration 1914, the loss is 4.76020670133725, parameters k is 10.604439195178221 and b is -42.07595396962203\n",
      "Iteration 1915, the loss is 4.755428972654471, parameters k is 10.602259869091265 and b is -42.076293890570646\n",
      "Iteration 1916, the loss is 4.750772176456556, parameters k is 10.600127602292845 and b is -42.076625906380926\n",
      "Iteration 1917, the loss is 4.7461153802586376, parameters k is 10.597995335494426 and b is -42.076957922191205\n",
      "Iteration 1918, the loss is 4.741458584060724, parameters k is 10.595863068696007 and b is -42.077289938001485\n",
      "Iteration 1919, the loss is 4.7368017878628095, parameters k is 10.593730801897587 and b is -42.077621953811764\n",
      "Iteration 1920, the loss is 4.732144991664894, parameters k is 10.591598535099168 and b is -42.077953969622044\n",
      "Iteration 1921, the loss is 4.72748819546698, parameters k is 10.589466268300749 and b is -42.07828598543232\n",
      "Iteration 1922, the loss is 4.722831399269065, parameters k is 10.58733400150233 and b is -42.0786180012426\n",
      "Iteration 1923, the loss is 4.718211389071614, parameters k is 10.58520173470391 and b is -42.07895001705288\n",
      "Iteration 1924, the loss is 4.713674755450117, parameters k is 10.583092159605096 and b is -42.07927808029399\n",
      "Iteration 1925, the loss is 4.709263568704558, parameters k is 10.5810089797632 and b is -42.07960219096593\n",
      "Iteration 1926, the loss is 4.704924429439671, parameters k is 10.578949958024069 and b is -42.079922349068696\n",
      "Iteration 1927, the loss is 4.700725363117556, parameters k is 10.576925339446994 and b is -42.08023855460229\n",
      "Iteration 1928, the loss is 4.696526296795444, parameters k is 10.57490072086992 and b is -42.08055476013588\n",
      "Iteration 1929, the loss is 4.692330626073807, parameters k is 10.572876102292845 and b is -42.080870965669476\n",
      "Iteration 1930, the loss is 4.688231519255983, parameters k is 10.570875701107074 and b is -42.0811832186339\n",
      "Iteration 1931, the loss is 4.684133224062491, parameters k is 10.568875299921302 and b is -42.08149547159833\n",
      "Iteration 1932, the loss is 4.680196133376447, parameters k is 10.566902977786915 and b is -42.081803771993584\n",
      "Iteration 1933, the loss is 4.676412989482114, parameters k is 10.564981284111026 and b is -42.0821041672505\n",
      "Iteration 1934, the loss is 4.6726493211006215, parameters k is 10.563059590435136 and b is -42.08240456250741\n",
      "Iteration 1935, the loss is 4.668967353721655, parameters k is 10.561163782134741 and b is -42.08270100519516\n",
      "Iteration 1936, the loss is 4.665302789300483, parameters k is 10.559267973834347 and b is -42.08299744788291\n",
      "Iteration 1937, the loss is 4.661806702657474, parameters k is 10.557420588458852 and b is -42.08328598543232\n",
      "Iteration 1938, the loss is 4.658311106870348, parameters k is 10.555573203083357 and b is -42.08357452298173\n",
      "Iteration 1939, the loss is 4.6549363736206875, parameters k is 10.55375202324146 and b is -42.08385910796196\n",
      "Iteration 1940, the loss is 4.651757205959948, parameters k is 10.551987531146597 and b is -42.08413578780386\n",
      "Iteration 1941, the loss is 4.648660995110555, parameters k is 10.550246106245412 and b is -42.08440851507659\n",
      "Iteration 1942, the loss is 4.645708957877102, parameters k is 10.54852947581063 and b is -42.084677289780146\n",
      "Iteration 1943, the loss is 4.6428587666538945, parameters k is 10.54686150150233 and b is -42.08493815934536\n",
      "Iteration 1944, the loss is 4.640015576577917, parameters k is 10.545193527194028 and b is -42.08519902891058\n",
      "Iteration 1945, the loss is 4.637288868531967, parameters k is 10.543556244585332 and b is -42.08545594590663\n",
      "Iteration 1946, the loss is 4.634641832221998, parameters k is 10.541944633913396 and b is -42.08570891033351\n",
      "Iteration 1947, the loss is 4.632074380538141, parameters k is 10.5403617742296 and b is -42.08595792219121\n",
      "Iteration 1948, the loss is 4.629506928854278, parameters k is 10.538778914545805 and b is -42.08620693404892\n",
      "Iteration 1949, the loss is 4.626953579445409, parameters k is 10.53719605486201 and b is -42.08645594590662\n",
      "Iteration 1950, the loss is 4.6244646524208886, parameters k is 10.535637570672286 and b is -42.08670100519516\n",
      "Iteration 1951, the loss is 4.622015149920285, parameters k is 10.534079086482562 and b is -42.0869460644837\n",
      "Iteration 1952, the loss is 4.619616075137955, parameters k is 10.53254907264857 and b is -42.08718717120306\n",
      "Iteration 1953, the loss is 4.617217000355623, parameters k is 10.531019058814577 and b is -42.08742827792243\n",
      "Iteration 1954, the loss is 4.614817925573289, parameters k is 10.529489044980584 and b is -42.08766938464179\n",
      "Iteration 1955, the loss is 4.612418850790957, parameters k is 10.527959031146592 and b is -42.08791049136116\n",
      "Iteration 1956, the loss is 4.610032790300848, parameters k is 10.5264290173126 and b is -42.08815159808052\n",
      "Iteration 1957, the loss is 4.607732314879713, parameters k is 10.524921639842244 and b is -42.08838875223072\n",
      "Iteration 1958, the loss is 4.605474930906521, parameters k is 10.523437388854102 and b is -42.088621953811746\n",
      "Iteration 1959, the loss is 4.603217546933326, parameters k is 10.52195313786596 and b is -42.08885515539277\n",
      "Iteration 1960, the loss is 4.600960162960131, parameters k is 10.520468886877818 and b is -42.0890883569738\n",
      "Iteration 1961, the loss is 4.5987027789869375, parameters k is 10.518984635889677 and b is -42.08932155855482\n",
      "Iteration 1962, the loss is 4.5964453950137445, parameters k is 10.517500384901535 and b is -42.08955476013585\n",
      "Iteration 1963, the loss is 4.594188011040551, parameters k is 10.516016133913393 and b is -42.08978796171687\n",
      "Iteration 1964, the loss is 4.591963617036469, parameters k is 10.514531882925251 and b is -42.0900211632979\n",
      "Iteration 1965, the loss is 4.589850995254279, parameters k is 10.51309596395292 and b is -42.090246459740584\n",
      "Iteration 1966, the loss is 4.58774268107831, parameters k is 10.511660044980587 and b is -42.09047175618327\n",
      "Iteration 1967, the loss is 4.585735729768506, parameters k is 10.510256797945015 and b is -42.09069310005679\n",
      "Iteration 1968, the loss is 4.583867561617772, parameters k is 10.50890675644304 and b is -42.09090653879197\n",
      "Iteration 1969, the loss is 4.58199939346704, parameters k is 10.507556714941064 and b is -42.09111997752715\n",
      "Iteration 1970, the loss is 4.58013122531631, parameters k is 10.506206673439088 and b is -42.09133341626233\n",
      "Iteration 1971, the loss is 4.578263057165576, parameters k is 10.504856631937113 and b is -42.09154685499751\n",
      "Iteration 1972, the loss is 4.576442457934737, parameters k is 10.503506590435137 and b is -42.09176029373269\n",
      "Iteration 1973, the loss is 4.5747288461306495, parameters k is 10.502201620079406 and b is -42.09196582732953\n",
      "Iteration 1974, the loss is 4.573047822316306, parameters k is 10.500920843399564 and b is -42.0921674083572\n",
      "Iteration 1975, the loss is 4.57138266629512, parameters k is 10.499640066719722 and b is -42.092368989384866\n",
      "Iteration 1976, the loss is 4.569763018687748, parameters k is 10.498382851304703 and b is -42.09256661784337\n",
      "Iteration 1977, the loss is 4.568143371080375, parameters k is 10.497125635889683 and b is -42.09276424630187\n",
      "Iteration 1978, the loss is 4.566523723473005, parameters k is 10.495868420474663 and b is -42.09296187476037\n",
      "Iteration 1979, the loss is 4.564905708186712, parameters k is 10.494611205059643 and b is -42.09315950321887\n",
      "Iteration 1980, the loss is 4.56341309800592, parameters k is 10.493404301897588 and b is -42.093349226539026\n",
      "Iteration 1981, the loss is 4.561920487825136, parameters k is 10.492197398735533 and b is -42.09353894985918\n",
      "Iteration 1982, the loss is 4.56042787764434, parameters k is 10.490990495573477 and b is -42.093728673179335\n",
      "Iteration 1983, the loss is 4.558935267463551, parameters k is 10.489783592411422 and b is -42.09391839649949\n",
      "Iteration 1984, the loss is 4.557442657282763, parameters k is 10.488576689249367 and b is -42.094108119819644\n",
      "Iteration 1985, the loss is 4.555952709272029, parameters k is 10.487369786087312 and b is -42.0942978431398\n",
      "Iteration 1986, the loss is 4.5545357952425745, parameters k is 10.486187566719723 and b is -42.09448361389079\n",
      "Iteration 1987, the loss is 4.553185228205344, parameters k is 10.485030635889684 and b is -42.0946654320726\n",
      "Iteration 1988, the loss is 4.551870507523218, parameters k is 10.483897902688103 and b is -42.09484329768525\n",
      "Iteration 1989, the loss is 4.550555786841092, parameters k is 10.482765169486521 and b is -42.0950211632979\n",
      "Iteration 1990, the loss is 4.5492465535918605, parameters k is 10.48163243628494 and b is -42.09519902891055\n",
      "Iteration 1991, the loss is 4.547995907330519, parameters k is 10.480527718893637 and b is -42.095372941954025\n",
      "Iteration 1992, the loss is 4.546745261069182, parameters k is 10.479423001502333 and b is -42.0955468549975\n",
      "Iteration 1993, the loss is 4.545494614807839, parameters k is 10.47831828411103 and b is -42.09572076804098\n",
      "Iteration 1994, the loss is 4.544248214457804, parameters k is 10.477213566719726 and b is -42.09589468108445\n",
      "Iteration 1995, the loss is 4.543051685350801, parameters k is 10.476132991620911 and b is -42.09606464155876\n",
      "Iteration 1996, the loss is 4.541855156243794, parameters k is 10.475052416522097 and b is -42.09623460203307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1997, the loss is 4.540658627136789, parameters k is 10.473971841423282 and b is -42.09640456250738\n",
      "Iteration 1998, the loss is 4.539462098029784, parameters k is 10.472891266324467 and b is -42.09657452298169\n",
      "Iteration 1999, the loss is 4.538265568922777, parameters k is 10.471810691225652 and b is -42.096744483456\n",
      "Iteration 2000, the loss is 4.537069039815773, parameters k is 10.470730116126838 and b is -42.09691444393031\n",
      "Iteration 2001, the loss is 4.535876827009578, parameters k is 10.469649541028023 and b is -42.09708440440462\n",
      "Iteration 2002, the loss is 4.53472622554912, parameters k is 10.468589803873872 and b is -42.097250412309755\n",
      "Iteration 2003, the loss is 4.533595139533046, parameters k is 10.467530066719721 and b is -42.09741642021489\n",
      "Iteration 2004, the loss is 4.532495839561911, parameters k is 10.46649419122565 and b is -42.09757847555086\n",
      "Iteration 2005, the loss is 4.531396539590779, parameters k is 10.465458315731578 and b is -42.09774053088683\n",
      "Iteration 2006, the loss is 4.530312970772084, parameters k is 10.464422440237506 and b is -42.0979025862228\n",
      "Iteration 2007, the loss is 4.529310481485726, parameters k is 10.463433133913394 and b is -42.09805673642043\n",
      "Iteration 2008, the loss is 4.528326136493145, parameters k is 10.462443827589283 and b is -42.09821088661806\n",
      "Iteration 2009, the loss is 4.527370203516497, parameters k is 10.461477714941061 and b is -42.09836108424652\n",
      "Iteration 2010, the loss is 4.526414270539847, parameters k is 10.46051160229284 and b is -42.09851128187498\n",
      "Iteration 2011, the loss is 4.525461014098509, parameters k is 10.459545489644618 and b is -42.098661479503434\n",
      "Iteration 2012, the loss is 4.524554602904267, parameters k is 10.458604732727622 and b is -42.098807724562725\n",
      "Iteration 2013, the loss is 4.523648191710023, parameters k is 10.457663975810625 and b is -42.098953969622016\n",
      "Iteration 2014, the loss is 4.52274178051578, parameters k is 10.456723218893629 and b is -42.09910021468131\n",
      "Iteration 2015, the loss is 4.521835369321538, parameters k is 10.455782461976632 and b is -42.0992464597406\n",
      "Iteration 2016, the loss is 4.520928958127293, parameters k is 10.454841705059636 and b is -42.09939270479989\n",
      "Iteration 2017, the loss is 4.520022546933053, parameters k is 10.453900948142639 and b is -42.09953894985918\n",
      "Iteration 2018, the loss is 4.519116135738809, parameters k is 10.452960191225642 and b is -42.09968519491847\n",
      "Iteration 2019, the loss is 4.518209724544566, parameters k is 10.452019434308646 and b is -42.09983143997776\n",
      "Iteration 2020, the loss is 4.5173033133503235, parameters k is 10.45107867739165 and b is -42.099977685037054\n",
      "Iteration 2021, the loss is 4.516396902156079, parameters k is 10.450137920474653 and b is -42.100123930096345\n",
      "Iteration 2022, the loss is 4.515490490961837, parameters k is 10.449197163557656 and b is -42.100270175155636\n",
      "Iteration 2023, the loss is 4.514597633758729, parameters k is 10.44825640664066 and b is -42.10041642021493\n",
      "Iteration 2024, the loss is 4.513736218495868, parameters k is 10.447339254466746 and b is -42.100558712705045\n",
      "Iteration 2025, the loss is 4.51287480323301, parameters k is 10.446422102292832 and b is -42.10070100519516\n",
      "Iteration 2026, the loss is 4.512013387970152, parameters k is 10.445504950118918 and b is -42.10084329768528\n",
      "Iteration 2027, the loss is 4.511151972707296, parameters k is 10.444587797945005 and b is -42.1009855901754\n",
      "Iteration 2028, the loss is 4.510290557444437, parameters k is 10.44367064577109 and b is -42.101127882665516\n",
      "Iteration 2029, the loss is 4.509429142181579, parameters k is 10.442753493597177 and b is -42.10127017515563\n",
      "Iteration 2030, the loss is 4.508567726918721, parameters k is 10.441836341423263 and b is -42.10141246764575\n",
      "Iteration 2031, the loss is 4.5077063116558636, parameters k is 10.44091918924935 and b is -42.10155476013587\n",
      "Iteration 2032, the loss is 4.5068448963930035, parameters k is 10.440002037075436 and b is -42.10169705262599\n",
      "Iteration 2033, the loss is 4.505983481130146, parameters k is 10.439084884901522 and b is -42.101839345116105\n",
      "Iteration 2034, the loss is 4.505122065867289, parameters k is 10.438167732727608 and b is -42.10198163760622\n",
      "Iteration 2035, the loss is 4.504260650604429, parameters k is 10.437250580553695 and b is -42.10212393009634\n",
      "Iteration 2036, the loss is 4.503399235341571, parameters k is 10.43633342837978 and b is -42.10226622258646\n",
      "Iteration 2037, the loss is 4.502537820078714, parameters k is 10.435416276205867 and b is -42.102408515076576\n",
      "Iteration 2038, the loss is 4.501676404815854, parameters k is 10.434499124031953 and b is -42.10255080756669\n",
      "Iteration 2039, the loss is 4.500814989552993, parameters k is 10.43358197185804 and b is -42.10269310005681\n",
      "Iteration 2040, the loss is 4.499953574290139, parameters k is 10.432664819684126 and b is -42.10283539254693\n",
      "Iteration 2041, the loss is 4.499092159027281, parameters k is 10.431747667510212 and b is -42.10297768503705\n",
      "Iteration 2042, the loss is 4.498230743764423, parameters k is 10.430830515336298 and b is -42.103119977527165\n",
      "Iteration 2043, the loss is 4.497385605454072, parameters k is 10.429913363162385 and b is -42.10326227001728\n",
      "Iteration 2044, the loss is 4.496619089390677, parameters k is 10.429020199130765 and b is -42.103400609938234\n",
      "Iteration 2045, the loss is 4.495932897022722, parameters k is 10.428201544980567 and b is -42.10352709215167\n",
      "Iteration 2046, the loss is 4.49524670465477, parameters k is 10.42738289083037 and b is -42.10365357436511\n",
      "Iteration 2047, the loss is 4.494560512286822, parameters k is 10.426564236680171 and b is -42.10378005657855\n",
      "Iteration 2048, the loss is 4.493874319918867, parameters k is 10.425745582529974 and b is -42.10390653879199\n",
      "Iteration 2049, the loss is 4.493196057977685, parameters k is 10.424926928379776 and b is -42.10403302100543\n",
      "Iteration 2050, the loss is 4.4925478216835675, parameters k is 10.424131175415349 and b is -42.10415555064969\n",
      "Iteration 2051, the loss is 4.491899585389448, parameters k is 10.423335422450922 and b is -42.10427808029396\n",
      "Iteration 2052, the loss is 4.491251349095328, parameters k is 10.422539669486495 and b is -42.104400609938224\n",
      "Iteration 2053, the loss is 4.49060311280121, parameters k is 10.421743916522068 and b is -42.10452313958249\n",
      "Iteration 2054, the loss is 4.489966447151261, parameters k is 10.420948163557641 and b is -42.104645669226755\n",
      "Iteration 2055, the loss is 4.4893607733209855, parameters k is 10.420178999526021 and b is -42.104764246301855\n",
      "Iteration 2056, the loss is 4.488755099490706, parameters k is 10.4194098354944 and b is -42.104882823376954\n",
      "Iteration 2057, the loss is 4.488149425660428, parameters k is 10.41864067146278 and b is -42.10500140045205\n",
      "Iteration 2058, the loss is 4.4875437518301515, parameters k is 10.41787150743116 and b is -42.10511997752715\n",
      "Iteration 2059, the loss is 4.486938077999873, parameters k is 10.41710234339954 and b is -42.10523855460225\n",
      "Iteration 2060, the loss is 4.4863324041695956, parameters k is 10.41633317936792 and b is -42.10535713167735\n",
      "Iteration 2061, the loss is 4.485726730339315, parameters k is 10.4155640153363 and b is -42.10547570875245\n",
      "Iteration 2062, the loss is 4.485121056509039, parameters k is 10.414794851304679 and b is -42.10559428582755\n",
      "Iteration 2063, the loss is 4.484515382678762, parameters k is 10.414025687273059 and b is -42.10571286290265\n",
      "Iteration 2064, the loss is 4.483909708848484, parameters k is 10.413256523241438 and b is -42.10583143997775\n",
      "Iteration 2065, the loss is 4.4833040350182065, parameters k is 10.412487359209818 and b is -42.10595001705285\n",
      "Iteration 2066, the loss is 4.482698361187929, parameters k is 10.411718195178198 and b is -42.10606859412795\n",
      "Iteration 2067, the loss is 4.4820946330635705, parameters k is 10.410949031146577 and b is -42.10618717120305\n",
      "Iteration 2068, the loss is 4.481525370383133, parameters k is 10.410203293992428 and b is -42.10630179570897\n",
      "Iteration 2069, the loss is 4.480956107702692, parameters k is 10.409457556838278 and b is -42.1064164202149\n",
      "Iteration 2070, the loss is 4.480399910417421, parameters k is 10.408711819684129 and b is -42.106531044720825\n",
      "Iteration 2071, the loss is 4.479865661601286, parameters k is 10.407989323636698 and b is -42.106641716657585\n",
      "Iteration 2072, the loss is 4.4793449814904385, parameters k is 10.407266827589268 and b is -42.106752388594344\n",
      "Iteration 2073, the loss is 4.478843257627229, parameters k is 10.406566588458833 and b is -42.10685910796193\n",
      "Iteration 2074, the loss is 4.478341533764019, parameters k is 10.405866349328399 and b is -42.10696582732952\n",
      "Iteration 2075, the loss is 4.477839809900808, parameters k is 10.405166110197964 and b is -42.107072546697104\n",
      "Iteration 2076, the loss is 4.4773380860376015, parameters k is 10.40446587106753 and b is -42.10717926606469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2077, the loss is 4.47683636217439, parameters k is 10.403765631937095 and b is -42.10728598543228\n",
      "Iteration 2078, the loss is 4.476334638311179, parameters k is 10.40306539280666 and b is -42.107392704799864\n",
      "Iteration 2079, the loss is 4.475832914447967, parameters k is 10.402365153676225 and b is -42.10749942416745\n",
      "Iteration 2080, the loss is 4.475331190584759, parameters k is 10.40166491454579 and b is -42.10760614353504\n",
      "Iteration 2081, the loss is 4.474829466721548, parameters k is 10.400964675415356 and b is -42.10771286290262\n",
      "Iteration 2082, the loss is 4.474327742858337, parameters k is 10.400264436284921 and b is -42.10781958227021\n",
      "Iteration 2083, the loss is 4.473826018995125, parameters k is 10.399564197154486 and b is -42.1079263016378\n",
      "Iteration 2084, the loss is 4.473324295131915, parameters k is 10.398863958024052 and b is -42.10803302100538\n",
      "Iteration 2085, the loss is 4.472822571268704, parameters k is 10.398163718893617 and b is -42.10813974037297\n",
      "Iteration 2086, the loss is 4.472321726695288, parameters k is 10.397463479763182 and b is -42.108246459740556\n",
      "Iteration 2087, the loss is 4.471853390422165, parameters k is 10.396786888854091 and b is -42.10834922653898\n",
      "Iteration 2088, the loss is 4.471385054149044, parameters k is 10.396110297945 and b is -42.1084519933374\n",
      "Iteration 2089, the loss is 4.470916717875923, parameters k is 10.39543370703591 and b is -42.10855476013582\n",
      "Iteration 2090, the loss is 4.4704483816028, parameters k is 10.394757116126819 and b is -42.10865752693424\n",
      "Iteration 2091, the loss is 4.469990720508828, parameters k is 10.394080525217728 and b is -42.10876029373266\n",
      "Iteration 2092, the loss is 4.469554730490204, parameters k is 10.393427665533933 and b is -42.108859107961905\n",
      "Iteration 2093, the loss is 4.469128608948493, parameters k is 10.392774805850138 and b is -42.10895792219115\n",
      "Iteration 2094, the loss is 4.468755043692324, parameters k is 10.392170404664368 and b is -42.10904883128206\n",
      "Iteration 2095, the loss is 4.468381478436151, parameters k is 10.391566003478598 and b is -42.10913974037297\n",
      "Iteration 2096, the loss is 4.468007913179982, parameters k is 10.390961602292828 and b is -42.109230649463875\n",
      "Iteration 2097, the loss is 4.467634347923809, parameters k is 10.390357201107058 and b is -42.10932155855478\n",
      "Iteration 2098, the loss is 4.46727400727842, parameters k is 10.389752799921288 and b is -42.10941246764569\n",
      "Iteration 2099, the loss is 4.46692980967383, parameters k is 10.389172596363975 and b is -42.10949942416743\n",
      "Iteration 2100, the loss is 4.466585612069239, parameters k is 10.388592392806663 and b is -42.10958638068917\n",
      "Iteration 2101, the loss is 4.466241414464648, parameters k is 10.38801218924935 and b is -42.109673337210914\n",
      "Iteration 2102, the loss is 4.4658972168600535, parameters k is 10.387431985692038 and b is -42.109760293732656\n",
      "Iteration 2103, the loss is 4.4655530192554655, parameters k is 10.386851782134725 and b is -42.1098472502544\n",
      "Iteration 2104, the loss is 4.465208821650875, parameters k is 10.386271578577412 and b is -42.10993420677614\n",
      "Iteration 2105, the loss is 4.464864624046285, parameters k is 10.3856913750201 and b is -42.11002116329788\n",
      "Iteration 2106, the loss is 4.464520426441693, parameters k is 10.385111171462787 and b is -42.11010811981962\n",
      "Iteration 2107, the loss is 4.464176228837102, parameters k is 10.384530967905475 and b is -42.11019507634136\n",
      "Iteration 2108, the loss is 4.463832031232511, parameters k is 10.383950764348162 and b is -42.110282032863104\n",
      "Iteration 2109, the loss is 4.4634878336279185, parameters k is 10.38337056079085 and b is -42.110368989384845\n",
      "Iteration 2110, the loss is 4.463143636023327, parameters k is 10.382790357233537 and b is -42.11045594590659\n",
      "Iteration 2111, the loss is 4.462799438418738, parameters k is 10.382210153676224 and b is -42.11054290242833\n",
      "Iteration 2112, the loss is 4.462455240814145, parameters k is 10.381629950118912 and b is -42.11062985895007\n",
      "Iteration 2113, the loss is 4.462111043209554, parameters k is 10.3810497465616 and b is -42.11071681547181\n",
      "Iteration 2114, the loss is 4.461775503302044, parameters k is 10.380469543004287 and b is -42.11080377199355\n",
      "Iteration 2115, the loss is 4.461463379233457, parameters k is 10.379917062767133 and b is -42.11088677594612\n",
      "Iteration 2116, the loss is 4.461151255164869, parameters k is 10.379364582529979 and b is -42.11096977989869\n",
      "Iteration 2117, the loss is 4.4608391310962805, parameters k is 10.378812102292825 and b is -42.11105278385126\n",
      "Iteration 2118, the loss is 4.460527007027693, parameters k is 10.37825962205567 and b is -42.111135787803825\n",
      "Iteration 2119, the loss is 4.460214882959104, parameters k is 10.377707141818517 and b is -42.11121879175639\n",
      "Iteration 2120, the loss is 4.459902758890516, parameters k is 10.377154661581363 and b is -42.11130179570896\n",
      "Iteration 2121, the loss is 4.459600487600238, parameters k is 10.376602181344209 and b is -42.11138479966153\n",
      "Iteration 2122, the loss is 4.4593134159835515, parameters k is 10.376072254466738 and b is -42.11146385104493\n",
      "Iteration 2123, the loss is 4.459026344366868, parameters k is 10.375542327589267 and b is -42.11154290242833\n",
      "Iteration 2124, the loss is 4.4587392727501864, parameters k is 10.375012400711796 and b is -42.111621953811735\n",
      "Iteration 2125, the loss is 4.458452201133499, parameters k is 10.374482473834325 and b is -42.11170100519514\n",
      "Iteration 2126, the loss is 4.458165129516817, parameters k is 10.373952546956854 and b is -42.11178005657854\n",
      "Iteration 2127, the loss is 4.457879552912907, parameters k is 10.373422620079383 and b is -42.11185910796194\n",
      "Iteration 2128, the loss is 4.457619384854662, parameters k is 10.372918112174245 and b is -42.11193420677617\n",
      "Iteration 2129, the loss is 4.457359216796416, parameters k is 10.372413604269108 and b is -42.1120093055904\n",
      "Iteration 2130, the loss is 4.457099048738171, parameters k is 10.37190909636397 and b is -42.11208440440463\n",
      "Iteration 2131, the loss is 4.4568388806799275, parameters k is 10.371404588458832 and b is -42.112159503218855\n",
      "Iteration 2132, the loss is 4.456578712621681, parameters k is 10.370900080553694 and b is -42.112234602033084\n",
      "Iteration 2133, the loss is 4.456318544563433, parameters k is 10.370395572648556 and b is -42.11230970084731\n",
      "Iteration 2134, the loss is 4.456058376505189, parameters k is 10.369891064743419 and b is -42.11238479966154\n",
      "Iteration 2135, the loss is 4.455798208446945, parameters k is 10.36938655683828 and b is -42.11245989847577\n",
      "Iteration 2136, the loss is 4.4555380403887, parameters k is 10.368882048933143 and b is -42.11253499729\n",
      "Iteration 2137, the loss is 4.455277872330454, parameters k is 10.368377541028005 and b is -42.11261009610423\n",
      "Iteration 2138, the loss is 4.4550177042722074, parameters k is 10.367873033122867 and b is -42.112685194918456\n",
      "Iteration 2139, the loss is 4.454757536213963, parameters k is 10.36736852521773 and b is -42.112760293732684\n",
      "Iteration 2140, the loss is 4.454497368155718, parameters k is 10.366864017312592 and b is -42.11283539254691\n",
      "Iteration 2141, the loss is 4.454237200097473, parameters k is 10.366359509407454 and b is -42.11291049136114\n",
      "Iteration 2142, the loss is 4.453982534870122, parameters k is 10.365855001502316 and b is -42.11298559017537\n",
      "Iteration 2143, the loss is 4.453746171014944, parameters k is 10.365374062767138 and b is -42.11305673642043\n",
      "Iteration 2144, the loss is 4.453509807159761, parameters k is 10.36489312403196 and b is -42.113127882665495\n",
      "Iteration 2145, the loss is 4.453273443304581, parameters k is 10.364412185296782 and b is -42.11319902891056\n",
      "Iteration 2146, the loss is 4.453038684233797, parameters k is 10.363931246561604 and b is -42.11327017515562\n",
      "Iteration 2147, the loss is 4.452835108485756, parameters k is 10.363476513360023 and b is -42.11333736883151\n",
      "Iteration 2148, the loss is 4.452649624629106, parameters k is 10.3630505034786 and b is -42.113400609938225\n",
      "Iteration 2149, the loss is 4.452464140772456, parameters k is 10.362624493597178 and b is -42.11346385104494\n",
      "Iteration 2150, the loss is 4.452282223793412, parameters k is 10.362198483715755 and b is -42.11352709215166\n",
      "Iteration 2151, the loss is 4.452116511447392, parameters k is 10.361795746561604 and b is -42.113586380689206\n",
      "Iteration 2152, the loss is 4.451950799101376, parameters k is 10.361393009407454 and b is -42.113645669226756\n",
      "Iteration 2153, the loss is 4.451790790894437, parameters k is 10.360990272253304 and b is -42.113704957764305\n",
      "Iteration 2154, the loss is 4.451643708575039, parameters k is 10.360610772253304 and b is -42.11376029373268\n",
      "Iteration 2155, the loss is 4.451496626255646, parameters k is 10.360231272253305 and b is -42.11381562970106\n",
      "Iteration 2156, the loss is 4.451349543936249, parameters k is 10.359851772253306 and b is -42.113870965669435\n",
      "Iteration 2157, the loss is 4.451202461616851, parameters k is 10.359472272253306 and b is -42.11392630163781\n",
      "Iteration 2158, the loss is 4.451055379297458, parameters k is 10.359092772253307 and b is -42.11398163760619\n",
      "Iteration 2159, the loss is 4.450908296978059, parameters k is 10.358713272253308 and b is -42.114036973574564\n",
      "Iteration 2160, the loss is 4.450761214658665, parameters k is 10.358333772253308 and b is -42.11409230954294\n",
      "Iteration 2161, the loss is 4.450614132339267, parameters k is 10.35795427225331 and b is -42.114147645511316\n",
      "Iteration 2162, the loss is 4.450467050019872, parameters k is 10.35757477225331 and b is -42.11420298147969\n",
      "Iteration 2163, the loss is 4.450319967700476, parameters k is 10.35719527225331 and b is -42.11425831744807\n",
      "Iteration 2164, the loss is 4.450172885381079, parameters k is 10.356815772253311 and b is -42.114313653416446\n",
      "Iteration 2165, the loss is 4.450025803061684, parameters k is 10.356436272253312 and b is -42.11436898938482\n",
      "Iteration 2166, the loss is 4.449878720742288, parameters k is 10.356056772253313 and b is -42.1144243253532\n",
      "Iteration 2167, the loss is 4.449731638422892, parameters k is 10.355677272253313 and b is -42.114479661321575\n",
      "Iteration 2168, the loss is 4.449584556103496, parameters k is 10.355297772253314 and b is -42.11453499728995\n",
      "Iteration 2169, the loss is 4.449443011680749, parameters k is 10.354918272253315 and b is -42.11459033325833\n",
      "Iteration 2170, the loss is 4.449315003650939, parameters k is 10.354564199130785 and b is -42.11464171665754\n",
      "Iteration 2171, the loss is 4.449186995621125, parameters k is 10.354210126008255 and b is -42.11469310005675\n",
      "Iteration 2172, the loss is 4.449058987591313, parameters k is 10.353856052885725 and b is -42.11474448345596\n",
      "Iteration 2173, the loss is 4.448930979561501, parameters k is 10.353501979763195 and b is -42.11479586685517\n",
      "Iteration 2174, the loss is 4.4488029715316895, parameters k is 10.353147906640665 and b is -42.11484725025438\n",
      "Iteration 2175, the loss is 4.448676060117874, parameters k is 10.352793833518135 and b is -42.11489863365359\n",
      "Iteration 2176, the loss is 4.448565102088969, parameters k is 10.352464124031968 and b is -42.114946064483625\n",
      "Iteration 2177, the loss is 4.448454144060062, parameters k is 10.352134414545802 and b is -42.11499349531366\n",
      "Iteration 2178, the loss is 4.448343186031156, parameters k is 10.351804705059635 and b is -42.1150409261437\n",
      "Iteration 2179, the loss is 4.44823222800225, parameters k is 10.351474995573469 and b is -42.115088356973736\n",
      "Iteration 2180, the loss is 4.448121269973343, parameters k is 10.351145286087302 and b is -42.11513578780377\n",
      "Iteration 2181, the loss is 4.448010311944439, parameters k is 10.350815576601136 and b is -42.11518321863381\n",
      "Iteration 2182, the loss is 4.447905823404126, parameters k is 10.350485867114969 and b is -42.11523064946385\n",
      "Iteration 2183, the loss is 4.447810443335601, parameters k is 10.350180106245404 and b is -42.11527412772472\n",
      "Iteration 2184, the loss is 4.447715063267072, parameters k is 10.349874345375838 and b is -42.11531760598559\n",
      "Iteration 2185, the loss is 4.447619683198551, parameters k is 10.349568584506272 and b is -42.11536108424646\n",
      "Iteration 2186, the loss is 4.447525593116847, parameters k is 10.349262823636707 and b is -42.11540456250733\n",
      "Iteration 2187, the loss is 4.447447324826918, parameters k is 10.348985865138683 and b is -42.11544408819903\n",
      "Iteration 2188, the loss is 4.447369056536985, parameters k is 10.34870890664066 and b is -42.115483613890724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2189, the loss is 4.44729974937464, parameters k is 10.348431948142636 and b is -42.11552313958242\n",
      "Iteration 2190, the loss is 4.447247450846213, parameters k is 10.348205456047774 and b is -42.11555476013578\n",
      "Iteration 2191, the loss is 4.447195152317778, parameters k is 10.347978963952912 and b is -42.11558638068914\n",
      "Iteration 2192, the loss is 4.447142853789352, parameters k is 10.34775247185805 and b is -42.115618001242495\n",
      "Iteration 2193, the loss is 4.44709055526092, parameters k is 10.347525979763187 and b is -42.11564962179585\n",
      "Iteration 2194, the loss is 4.447038256732493, parameters k is 10.347299487668325 and b is -42.11568124234921\n",
      "Iteration 2195, the loss is 4.446985958204063, parameters k is 10.347072995573463 and b is -42.11571286290257\n",
      "Iteration 2196, the loss is 4.446933659675632, parameters k is 10.3468465034786 and b is -42.11574448345593\n",
      "Iteration 2197, the loss is 4.446881361147204, parameters k is 10.346620011383738 and b is -42.115776104009285\n",
      "Iteration 2198, the loss is 4.446829062618773, parameters k is 10.346393519288876 and b is -42.11580772456264\n",
      "Iteration 2199, the loss is 4.446780530999052, parameters k is 10.346167027194014 and b is -42.115839345116\n",
      "Iteration 2200, the loss is 4.446738590976458, parameters k is 10.34596411217425 and b is -42.11586701310019\n",
      "Iteration 2201, the loss is 4.446696650953866, parameters k is 10.345761197154488 and b is -42.115894681084384\n",
      "Iteration 2202, the loss is 4.446654710931273, parameters k is 10.345558282134725 and b is -42.115922349068576\n",
      "Iteration 2203, the loss is 4.446612770908676, parameters k is 10.345355367114962 and b is -42.11595001705277\n",
      "Iteration 2204, the loss is 4.446570830886081, parameters k is 10.3451524520952 and b is -42.11597768503696\n",
      "Iteration 2205, the loss is 4.446528890863489, parameters k is 10.344949537075436 and b is -42.11600535302115\n",
      "Iteration 2206, the loss is 4.446486950840894, parameters k is 10.344746622055673 and b is -42.11603302100534\n",
      "Iteration 2207, the loss is 4.446445010818296, parameters k is 10.34454370703591 and b is -42.116060688989535\n",
      "Iteration 2208, the loss is 4.446403070795704, parameters k is 10.344340792016148 and b is -42.11608835697373\n",
      "Iteration 2209, the loss is 4.446361130773108, parameters k is 10.344137876996385 and b is -42.11611602495792\n",
      "Iteration 2210, the loss is 4.446319190750515, parameters k is 10.343934961976622 and b is -42.11614369294211\n",
      "Iteration 2211, the loss is 4.446277250727919, parameters k is 10.343732046956859 and b is -42.1161713609263\n",
      "Iteration 2212, the loss is 4.446235310705325, parameters k is 10.343529131937096 and b is -42.11619902891049\n",
      "Iteration 2213, the loss is 4.446193370682733, parameters k is 10.343326216917333 and b is -42.116226696894685\n",
      "Iteration 2214, the loss is 4.4461514306601355, parameters k is 10.34312330189757 and b is -42.11625436487888\n",
      "Iteration 2215, the loss is 4.446109490637539, parameters k is 10.342920386877807 and b is -42.11628203286307\n",
      "Iteration 2216, the loss is 4.446067550614945, parameters k is 10.342717471858045 and b is -42.11630970084726\n",
      "Iteration 2217, the loss is 4.446025610592351, parameters k is 10.342514556838282 and b is -42.11633736883145\n",
      "Iteration 2218, the loss is 4.445983670569761, parameters k is 10.342311641818519 and b is -42.116365036815644\n",
      "Iteration 2219, the loss is 4.445941730547164, parameters k is 10.342108726798756 and b is -42.116392704799836\n",
      "Iteration 2220, the loss is 4.445899790524567, parameters k is 10.341905811778993 and b is -42.11642037278403\n",
      "Iteration 2221, the loss is 4.445857850501974, parameters k is 10.34170289675923 and b is -42.11644804076822\n",
      "Iteration 2222, the loss is 4.4458159104793795, parameters k is 10.341499981739467 and b is -42.11647570875241\n",
      "Iteration 2223, the loss is 4.445773970456785, parameters k is 10.341297066719704 and b is -42.1165033767366\n",
      "Iteration 2224, the loss is 4.445732030434188, parameters k is 10.341094151699942 and b is -42.116531044720794\n",
      "Iteration 2225, the loss is 4.445690090411596, parameters k is 10.340891236680179 and b is -42.116558712704986\n",
      "Iteration 2226, the loss is 4.445648150389, parameters k is 10.340688321660416 and b is -42.11658638068918\n",
      "Iteration 2227, the loss is 4.445606210366404, parameters k is 10.340485406640653 and b is -42.11661404867337\n",
      "Iteration 2228, the loss is 4.445564270343813, parameters k is 10.34028249162089 and b is -42.11664171665756\n",
      "Iteration 2229, the loss is 4.445522330321216, parameters k is 10.340079576601127 and b is -42.11666938464175\n",
      "Iteration 2230, the loss is 4.445480390298622, parameters k is 10.339876661581364 and b is -42.116697052625945\n",
      "Iteration 2231, the loss is 4.445438450276029, parameters k is 10.339673746561601 and b is -42.11672472061014\n",
      "Iteration 2232, the loss is 4.445396510253434, parameters k is 10.339470831541838 and b is -42.11675238859433\n",
      "Iteration 2233, the loss is 4.445354570230841, parameters k is 10.339267916522076 and b is -42.11678005657852\n",
      "Iteration 2234, the loss is 4.445312630208245, parameters k is 10.339065001502313 and b is -42.11680772456271\n",
      "Iteration 2235, the loss is 4.445270690185652, parameters k is 10.33886208648255 and b is -42.1168353925469\n",
      "Iteration 2236, the loss is 4.445228750163051, parameters k is 10.338659171462787 and b is -42.116863060531095\n",
      "Iteration 2237, the loss is 4.445186810140461, parameters k is 10.338456256443024 and b is -42.11689072851529\n",
      "Iteration 2238, the loss is 4.445144870117865, parameters k is 10.338253341423261 and b is -42.11691839649948\n",
      "Iteration 2239, the loss is 4.445102930095273, parameters k is 10.338050426403498 and b is -42.11694606448367\n",
      "Iteration 2240, the loss is 4.445060990072677, parameters k is 10.337847511383735 and b is -42.11697373246786\n",
      "Iteration 2241, the loss is 4.445019050050084, parameters k is 10.337644596363972 and b is -42.117001400452054\n",
      "Iteration 2242, the loss is 4.44497711002749, parameters k is 10.33744168134421 and b is -42.117029068436246\n",
      "Iteration 2243, the loss is 4.444935170004893, parameters k is 10.337238766324447 and b is -42.11705673642044\n",
      "Iteration 2244, the loss is 4.4448932299823, parameters k is 10.337035851304684 and b is -42.11708440440463\n",
      "Iteration 2245, the loss is 4.444851289959704, parameters k is 10.336832936284921 and b is -42.11711207238882\n",
      "Iteration 2246, the loss is 4.44480934993711, parameters k is 10.336630021265158 and b is -42.11713974037301\n",
      "Iteration 2247, the loss is 4.444767409914515, parameters k is 10.336427106245395 and b is -42.117167408357204\n",
      "Iteration 2248, the loss is 4.44472546989192, parameters k is 10.336224191225632 and b is -42.117195076341396\n",
      "Iteration 2249, the loss is 4.444683529869328, parameters k is 10.33602127620587 and b is -42.11722274432559\n",
      "Iteration 2250, the loss is 4.444641589846732, parameters k is 10.335818361186107 and b is -42.11725041230978\n",
      "Iteration 2251, the loss is 4.444599649824137, parameters k is 10.335615446166344 and b is -42.11727808029397\n",
      "Iteration 2252, the loss is 4.4445577098015425, parameters k is 10.33541253114658 and b is -42.11730574827816\n",
      "Iteration 2253, the loss is 4.444515769778948, parameters k is 10.335209616126818 and b is -42.117333416262355\n",
      "Iteration 2254, the loss is 4.4444738297563555, parameters k is 10.335006701107055 and b is -42.11736108424655\n",
      "Iteration 2255, the loss is 4.444431889733761, parameters k is 10.334803786087292 and b is -42.11738875223074\n",
      "Iteration 2256, the loss is 4.444391066828061, parameters k is 10.33460087106753 and b is -42.11741642021493\n",
      "Iteration 2257, the loss is 4.444358979913405, parameters k is 10.33442331968413 and b is -42.11744013562995\n",
      "Iteration 2258, the loss is 4.444326892998746, parameters k is 10.334245768300732 and b is -42.11746385104497\n",
      "Iteration 2259, the loss is 4.444294806084092, parameters k is 10.334068216917334 and b is -42.117487566459985\n",
      "Iteration 2260, the loss is 4.4442627191694335, parameters k is 10.333890665533936 and b is -42.117511281875004\n",
      "Iteration 2261, the loss is 4.444230632254778, parameters k is 10.333713114150537 and b is -42.11753499729002\n",
      "Iteration 2262, the loss is 4.444198545340123, parameters k is 10.333535562767139 and b is -42.11755871270504\n",
      "Iteration 2263, the loss is 4.444166458425465, parameters k is 10.33335801138374 and b is -42.11758242812006\n",
      "Iteration 2264, the loss is 4.444134371510808, parameters k is 10.333180460000342 and b is -42.11760614353508\n",
      "Iteration 2265, the loss is 4.444102578176376, parameters k is 10.333002908616944 and b is -42.117629858950096\n",
      "Iteration 2266, the loss is 4.444078992797879, parameters k is 10.332850610197971 and b is -42.11764962179595\n",
      "Iteration 2267, the loss is 4.444055407419382, parameters k is 10.332698311778998 and b is -42.1176693846418\n",
      "Iteration 2268, the loss is 4.444031822040884, parameters k is 10.332546013360025 and b is -42.11768914748765\n",
      "Iteration 2269, the loss is 4.444011580616715, parameters k is 10.332393714941052 and b is -42.117708910333505\n",
      "Iteration 2270, the loss is 4.443996034437421, parameters k is 10.332270037075439 and b is -42.117724720610184\n",
      "Iteration 2271, the loss is 4.443980488258132, parameters k is 10.332146359209826 and b is -42.11774053088686\n",
      "Iteration 2272, the loss is 4.44396494207884, parameters k is 10.332022681344213 and b is -42.11775634116354\n",
      "Iteration 2273, the loss is 4.4439493958995495, parameters k is 10.3318990034786 and b is -42.11777215144022\n",
      "Iteration 2274, the loss is 4.443933849720261, parameters k is 10.331775325612988 and b is -42.1177879617169\n",
      "Iteration 2275, the loss is 4.4439183035409675, parameters k is 10.331651647747375 and b is -42.11780377199358\n",
      "Iteration 2276, the loss is 4.443902757361676, parameters k is 10.331527969881762 and b is -42.11781958227026\n",
      "Iteration 2277, the loss is 4.443887211182386, parameters k is 10.331404292016149 and b is -42.11783539254694\n",
      "Iteration 2278, the loss is 4.443871665003093, parameters k is 10.331280614150536 and b is -42.117851202823616\n",
      "Iteration 2279, the loss is 4.443856118823804, parameters k is 10.331156936284923 and b is -42.117867013100295\n",
      "Iteration 2280, the loss is 4.443840572644514, parameters k is 10.33103325841931 and b is -42.11788282337697\n",
      "Iteration 2281, the loss is 4.4438250264652215, parameters k is 10.330909580553698 and b is -42.11789863365365\n",
      "Iteration 2282, the loss is 4.443809480285929, parameters k is 10.330785902688085 and b is -42.11791444393033\n",
      "Iteration 2283, the loss is 4.4437939341066395, parameters k is 10.330662224822472 and b is -42.11793025420701\n",
      "Iteration 2284, the loss is 4.443778387927347, parameters k is 10.33053854695686 and b is -42.11794606448369\n",
      "Iteration 2285, the loss is 4.443762841748057, parameters k is 10.330414869091246 and b is -42.11796187476037\n",
      "Iteration 2286, the loss is 4.443749952034512, parameters k is 10.330291191225633 and b is -42.11797768503705\n",
      "Iteration 2287, the loss is 4.443739760376145, parameters k is 10.330190936284922 and b is -42.11798954274456\n",
      "Iteration 2288, the loss is 4.4437295687177825, parameters k is 10.33009068134421 and b is -42.11800140045207\n",
      "Iteration 2289, the loss is 4.443719377059415, parameters k is 10.329990426403498 and b is -42.118013258159586\n",
      "Iteration 2290, the loss is 4.443709185401055, parameters k is 10.329890171462786 and b is -42.1180251158671\n",
      "Iteration 2291, the loss is 4.44369899374269, parameters k is 10.329789916522074 and b is -42.11803697357461\n",
      "Iteration 2292, the loss is 4.443688802084322, parameters k is 10.329689661581362 and b is -42.118048831282124\n",
      "Iteration 2293, the loss is 4.443678610425958, parameters k is 10.32958940664065 and b is -42.11806068898964\n",
      "Iteration 2294, the loss is 4.443668418767597, parameters k is 10.329489151699939 and b is -42.11807254669715\n",
      "Iteration 2295, the loss is 4.44365822710923, parameters k is 10.329388896759227 and b is -42.11808440440466\n",
      "Iteration 2296, the loss is 4.443648035450867, parameters k is 10.329288641818515 and b is -42.118096262112175\n",
      "Iteration 2297, the loss is 4.443637843792501, parameters k is 10.329188386877803 and b is -42.11810811981969\n",
      "Iteration 2298, the loss is 4.443627652134135, parameters k is 10.329088131937091 and b is -42.1181199775272\n",
      "Iteration 2299, the loss is 4.443617460475773, parameters k is 10.32898787699638 and b is -42.11813183523471\n",
      "Iteration 2300, the loss is 4.4436072688174075, parameters k is 10.328887622055667 and b is -42.118143692942226\n",
      "Iteration 2301, the loss is 4.443597077159045, parameters k is 10.328787367114955 and b is -42.11815555064974\n",
      "Iteration 2302, the loss is 4.44358688550068, parameters k is 10.328687112174244 and b is -42.11816740835725\n",
      "Iteration 2303, the loss is 4.443576693842316, parameters k is 10.328586857233532 and b is -42.118179266064764\n",
      "Iteration 2304, the loss is 4.44356650218395, parameters k is 10.32848660229282 and b is -42.11819112377228\n",
      "Iteration 2305, the loss is 4.443556310525585, parameters k is 10.328386347352108 and b is -42.11820298147979\n",
      "Iteration 2306, the loss is 4.443546118867221, parameters k is 10.328286092411396 and b is -42.1182148391873\n",
      "Iteration 2307, the loss is 4.443535927208857, parameters k is 10.328185837470684 and b is -42.118226696894816\n",
      "Iteration 2308, the loss is 4.443525735550493, parameters k is 10.328085582529972 and b is -42.11823855460233\n",
      "Iteration 2309, the loss is 4.4435155438921266, parameters k is 10.32798532758926 and b is -42.11825041230984\n",
      "Iteration 2310, the loss is 4.443505352233764, parameters k is 10.327885072648549 and b is -42.118262270017354\n",
      "Iteration 2311, the loss is 4.443495160575397, parameters k is 10.327784817707837 and b is -42.11827412772487\n",
      "Iteration 2312, the loss is 4.4434849689170335, parameters k is 10.327684562767125 and b is -42.11828598543238\n",
      "Iteration 2313, the loss is 4.443474777258667, parameters k is 10.327584307826413 and b is -42.11829784313989\n",
      "Iteration 2314, the loss is 4.443464585600305, parameters k is 10.327484052885701 and b is -42.118309700847405\n",
      "Iteration 2315, the loss is 4.443454393941941, parameters k is 10.32738379794499 and b is -42.11832155855492\n",
      "Iteration 2316, the loss is 4.443444202283576, parameters k is 10.327283543004278 and b is -42.11833341626243\n",
      "Iteration 2317, the loss is 4.443434010625211, parameters k is 10.327183288063566 and b is -42.11834527396994\n",
      "Iteration 2318, the loss is 4.4434238189668465, parameters k is 10.327083033122854 and b is -42.118357131677456\n",
      "Iteration 2319, the loss is 4.44341362730848, parameters k is 10.326982778182142 and b is -42.11836898938497\n",
      "Iteration 2320, the loss is 4.443403435650119, parameters k is 10.32688252324143 and b is -42.11838084709248\n",
      "Iteration 2321, the loss is 4.443393243991754, parameters k is 10.326782268300718 and b is -42.118392704799994\n",
      "Iteration 2322, the loss is 4.443383052333391, parameters k is 10.326682013360006 and b is -42.11840456250751\n",
      "Iteration 2323, the loss is 4.443372860675023, parameters k is 10.326581758419294 and b is -42.11841642021502\n",
      "Iteration 2324, the loss is 4.44336266901666, parameters k is 10.326481503478583 and b is -42.11842827792253\n",
      "Iteration 2325, the loss is 4.443352477358293, parameters k is 10.32638124853787 and b is -42.118440135630046\n",
      "Iteration 2326, the loss is 4.443342285699931, parameters k is 10.326280993597159 and b is -42.11845199333756\n",
      "Iteration 2327, the loss is 4.443332094041567, parameters k is 10.326180738656447 and b is -42.11846385104507\n",
      "Iteration 2328, the loss is 4.443321902383202, parameters k is 10.326080483715735 and b is -42.118475708752584\n",
      "Iteration 2329, the loss is 4.443311710724838, parameters k is 10.325980228775023 and b is -42.1184875664601\n",
      "Iteration 2330, the loss is 4.4433015190664715, parameters k is 10.325879973834311 and b is -42.11849942416761\n",
      "Iteration 2331, the loss is 4.443291327408108, parameters k is 10.3257797188936 and b is -42.11851128187512\n",
      "Iteration 2332, the loss is 4.443281135749744, parameters k is 10.325679463952888 and b is -42.118523139582635\n",
      "Iteration 2333, the loss is 4.443270944091381, parameters k is 10.325579209012176 and b is -42.11853499729015\n",
      "Iteration 2334, the loss is 4.443260752433015, parameters k is 10.325478954071464 and b is -42.11854685499766\n",
      "Iteration 2335, the loss is 4.443250560774651, parameters k is 10.325378699130752 and b is -42.11855871270517\n",
      "Iteration 2336, the loss is 4.443240936077072, parameters k is 10.32527844419004 and b is -42.118570570412686\n",
      "Iteration 2337, the loss is 4.443235083458656, parameters k is 10.325202351304664 and b is -42.118578475551026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2338, the loss is 4.443229230840236, parameters k is 10.325126258419289 and b is -42.118586380689365\n",
      "Iteration 2339, the loss is 4.443223378221821, parameters k is 10.325050165533913 and b is -42.118594285827704\n",
      "Iteration 2340, the loss is 4.443217525603404, parameters k is 10.324974072648537 and b is -42.118602190966044\n",
      "Iteration 2341, the loss is 4.443211672984988, parameters k is 10.324897979763161 and b is -42.11861009610438\n",
      "Iteration 2342, the loss is 4.443205820366573, parameters k is 10.324821886877785 and b is -42.11861800124272\n",
      "Iteration 2343, the loss is 4.443199967748152, parameters k is 10.32474579399241 and b is -42.11862590638106\n",
      "Iteration 2344, the loss is 4.443194115129737, parameters k is 10.324669701107034 and b is -42.1186338115194\n",
      "Iteration 2345, the loss is 4.443188262511317, parameters k is 10.324593608221658 and b is -42.11864171665774\n",
      "Iteration 2346, the loss is 4.443182409892901, parameters k is 10.324517515336282 and b is -42.11864962179608\n",
      "Iteration 2347, the loss is 4.4431765572744855, parameters k is 10.324441422450906 and b is -42.11865752693442\n",
      "Iteration 2348, the loss is 4.44317070465607, parameters k is 10.32436532956553 and b is -42.11866543207276\n",
      "Iteration 2349, the loss is 4.443164852037652, parameters k is 10.324289236680155 and b is -42.1186733372111\n",
      "Iteration 2350, the loss is 4.443158999419234, parameters k is 10.324213143794779 and b is -42.11868124234944\n",
      "Iteration 2351, the loss is 4.443153146800818, parameters k is 10.324137050909403 and b is -42.11868914748778\n",
      "Iteration 2352, the loss is 4.443147294182399, parameters k is 10.324060958024027 and b is -42.11869705262612\n",
      "Iteration 2353, the loss is 4.4431414415639825, parameters k is 10.323984865138652 and b is -42.11870495776446\n",
      "Iteration 2354, the loss is 4.443135588945569, parameters k is 10.323908772253276 and b is -42.1187128629028\n",
      "Iteration 2355, the loss is 4.443129736327153, parameters k is 10.3238326793679 and b is -42.118720768041136\n",
      "Iteration 2356, the loss is 4.443123883708733, parameters k is 10.323756586482524 and b is -42.118728673179476\n",
      "Iteration 2357, the loss is 4.443118031090314, parameters k is 10.323680493597148 and b is -42.118736578317815\n",
      "Iteration 2358, the loss is 4.443112178471898, parameters k is 10.323604400711773 and b is -42.118744483456155\n",
      "Iteration 2359, the loss is 4.443106325853481, parameters k is 10.323528307826397 and b is -42.118752388594494\n",
      "Iteration 2360, the loss is 4.443100473235065, parameters k is 10.323452214941021 and b is -42.118760293732834\n",
      "Iteration 2361, the loss is 4.443094620616648, parameters k is 10.323376122055645 and b is -42.11876819887117\n",
      "Iteration 2362, the loss is 4.443088767998232, parameters k is 10.32330002917027 and b is -42.11877610400951\n",
      "Iteration 2363, the loss is 4.4430829153798115, parameters k is 10.323223936284894 and b is -42.11878400914785\n",
      "Iteration 2364, the loss is 4.443077062761397, parameters k is 10.323147843399518 and b is -42.11879191428619\n",
      "Iteration 2365, the loss is 4.44307121014298, parameters k is 10.323071750514142 and b is -42.11879981942453\n",
      "Iteration 2366, the loss is 4.443065357524562, parameters k is 10.322995657628766 and b is -42.11880772456287\n",
      "Iteration 2367, the loss is 4.443059504906146, parameters k is 10.32291956474339 and b is -42.11881562970121\n",
      "Iteration 2368, the loss is 4.443053652287729, parameters k is 10.322843471858015 and b is -42.11882353483955\n",
      "Iteration 2369, the loss is 4.443047799669314, parameters k is 10.322767378972639 and b is -42.11883143997789\n",
      "Iteration 2370, the loss is 4.4430419470508955, parameters k is 10.322691286087263 and b is -42.11883934511623\n",
      "Iteration 2371, the loss is 4.443036094432477, parameters k is 10.322615193201887 and b is -42.11884725025457\n",
      "Iteration 2372, the loss is 4.443030241814062, parameters k is 10.322539100316511 and b is -42.11885515539291\n",
      "Iteration 2373, the loss is 4.443024389195646, parameters k is 10.322463007431136 and b is -42.11886306053125\n",
      "Iteration 2374, the loss is 4.443018536577228, parameters k is 10.32238691454576 and b is -42.118870965669586\n",
      "Iteration 2375, the loss is 4.443012683958812, parameters k is 10.322310821660384 and b is -42.118878870807926\n",
      "Iteration 2376, the loss is 4.443006831340395, parameters k is 10.322234728775008 and b is -42.118886775946265\n",
      "Iteration 2377, the loss is 4.443000978721978, parameters k is 10.322158635889632 and b is -42.118894681084605\n",
      "Iteration 2378, the loss is 4.442995126103559, parameters k is 10.322082543004257 and b is -42.118902586222944\n",
      "Iteration 2379, the loss is 4.442989273485142, parameters k is 10.32200645011888 and b is -42.118910491361284\n",
      "Iteration 2380, the loss is 4.442983420866725, parameters k is 10.321930357233505 and b is -42.11891839649962\n",
      "Iteration 2381, the loss is 4.442977568248309, parameters k is 10.32185426434813 and b is -42.11892630163796\n",
      "Iteration 2382, the loss is 4.44297171562989, parameters k is 10.321778171462753 and b is -42.1189342067763\n",
      "Iteration 2383, the loss is 4.442965863011473, parameters k is 10.321702078577378 and b is -42.11894211191464\n",
      "Iteration 2384, the loss is 4.4429600103930555, parameters k is 10.321625985692002 and b is -42.11895001705298\n",
      "Iteration 2385, the loss is 4.442954157774641, parameters k is 10.321549892806626 and b is -42.11895792219132\n",
      "Iteration 2386, the loss is 4.442948305156222, parameters k is 10.32147379992125 and b is -42.11896582732966\n",
      "Iteration 2387, the loss is 4.442942452537806, parameters k is 10.321397707035874 and b is -42.118973732468\n",
      "Iteration 2388, the loss is 4.442936599919388, parameters k is 10.321321614150499 and b is -42.11898163760634\n",
      "Iteration 2389, the loss is 4.442930747300972, parameters k is 10.321245521265123 and b is -42.11898954274468\n",
      "Iteration 2390, the loss is 4.442924894682554, parameters k is 10.321169428379747 and b is -42.11899744788302\n",
      "Iteration 2391, the loss is 4.44291904206414, parameters k is 10.321093335494371 and b is -42.11900535302136\n",
      "Iteration 2392, the loss is 4.442913189445724, parameters k is 10.321017242608995 and b is -42.1190132581597\n",
      "Iteration 2393, the loss is 4.442907336827303, parameters k is 10.32094114972362 and b is -42.11902116329804\n",
      "Iteration 2394, the loss is 4.442901484208889, parameters k is 10.320865056838244 and b is -42.119029068436376\n",
      "Iteration 2395, the loss is 4.44289563159047, parameters k is 10.320788963952868 and b is -42.119036973574715\n",
      "Iteration 2396, the loss is 4.442889778972053, parameters k is 10.320712871067492 and b is -42.119044878713055\n",
      "Iteration 2397, the loss is 4.442883926353638, parameters k is 10.320636778182116 and b is -42.119052783851394\n",
      "Iteration 2398, the loss is 4.442878073735221, parameters k is 10.32056068529674 and b is -42.119060688989734\n",
      "Iteration 2399, the loss is 4.442872221116804, parameters k is 10.320484592411365 and b is -42.11906859412807\n",
      "Iteration 2400, the loss is 4.442866368498386, parameters k is 10.320408499525989 and b is -42.11907649926641\n",
      "Iteration 2401, the loss is 4.442860515879967, parameters k is 10.320332406640613 and b is -42.11908440440475\n",
      "Iteration 2402, the loss is 4.442854663261555, parameters k is 10.320256313755237 and b is -42.11909230954309\n",
      "Iteration 2403, the loss is 4.442848810643136, parameters k is 10.320180220869862 and b is -42.11910021468143\n",
      "Iteration 2404, the loss is 4.442842958024719, parameters k is 10.320104127984486 and b is -42.11910811981977\n",
      "Iteration 2405, the loss is 4.442837105406299, parameters k is 10.32002803509911 and b is -42.11911602495811\n",
      "Iteration 2406, the loss is 4.442831252787884, parameters k is 10.319951942213734 and b is -42.11912393009645\n",
      "Iteration 2407, the loss is 4.442825400169467, parameters k is 10.319875849328358 and b is -42.11913183523479\n",
      "Iteration 2408, the loss is 4.442819547551052, parameters k is 10.319799756442983 and b is -42.11913974037313\n",
      "Iteration 2409, the loss is 4.4428136949326325, parameters k is 10.319723663557607 and b is -42.11914764551147\n",
      "Iteration 2410, the loss is 4.442807842314218, parameters k is 10.319647570672231 and b is -42.11915555064981\n",
      "Iteration 2411, the loss is 4.442801989695801, parameters k is 10.319571477786855 and b is -42.11916345578815\n",
      "Iteration 2412, the loss is 4.442796137077383, parameters k is 10.31949538490148 and b is -42.11917136092649\n",
      "Iteration 2413, the loss is 4.442790284458966, parameters k is 10.319419292016104 and b is -42.119179266064826\n",
      "Iteration 2414, the loss is 4.442785110842594, parameters k is 10.319343199130728 and b is -42.119187171203166\n",
      "Iteration 2415, the loss is 4.4427823035802385, parameters k is 10.319290363162349 and b is -42.11919112377234\n",
      "Iteration 2416, the loss is 4.442779496317883, parameters k is 10.31923752719397 and b is -42.11919507634151\n",
      "Iteration 2417, the loss is 4.442776689055522, parameters k is 10.31918469122559 and b is -42.119199028910685\n",
      "Iteration 2418, the loss is 4.442773881793165, parameters k is 10.319131855257211 and b is -42.11920298147986\n",
      "Iteration 2419, the loss is 4.442771074530807, parameters k is 10.319079019288832 and b is -42.11920693404903\n",
      "Iteration 2420, the loss is 4.44276826726845, parameters k is 10.319026183320453 and b is -42.119210886618205\n",
      "Iteration 2421, the loss is 4.442765460006092, parameters k is 10.318973347352074 and b is -42.11921483918738\n",
      "Iteration 2422, the loss is 4.442762652743735, parameters k is 10.318920511383695 and b is -42.11921879175655\n",
      "Iteration 2423, the loss is 4.442759845481379, parameters k is 10.318867675415316 and b is -42.119222744325725\n",
      "Iteration 2424, the loss is 4.442757038219021, parameters k is 10.318814839446937 and b is -42.1192266968949\n",
      "Iteration 2425, the loss is 4.442754230956661, parameters k is 10.318762003478557 and b is -42.11923064946407\n",
      "Iteration 2426, the loss is 4.442751423694307, parameters k is 10.318709167510178 and b is -42.119234602033245\n",
      "Iteration 2427, the loss is 4.442748616431948, parameters k is 10.3186563315418 and b is -42.11923855460242\n",
      "Iteration 2428, the loss is 4.4427458091695895, parameters k is 10.31860349557342 and b is -42.11924250717159\n",
      "Iteration 2429, the loss is 4.442743001907233, parameters k is 10.318550659605041 and b is -42.119246459740765\n",
      "Iteration 2430, the loss is 4.4427401946448715, parameters k is 10.318497823636662 and b is -42.11925041230994\n",
      "Iteration 2431, the loss is 4.442737387382516, parameters k is 10.318444987668283 and b is -42.11925436487911\n",
      "Iteration 2432, the loss is 4.44273458012016, parameters k is 10.318392151699904 and b is -42.119258317448285\n",
      "Iteration 2433, the loss is 4.442731772857802, parameters k is 10.318339315731524 and b is -42.11926227001746\n",
      "Iteration 2434, the loss is 4.442728965595442, parameters k is 10.318286479763145 and b is -42.11926622258663\n",
      "Iteration 2435, the loss is 4.442726158333086, parameters k is 10.318233643794766 and b is -42.119270175155805\n",
      "Iteration 2436, the loss is 4.44272335107073, parameters k is 10.318180807826387 and b is -42.11927412772498\n",
      "Iteration 2437, the loss is 4.442720543808371, parameters k is 10.318127971858008 and b is -42.11927808029415\n",
      "Iteration 2438, the loss is 4.4427177365460135, parameters k is 10.318075135889629 and b is -42.119282032863325\n",
      "Iteration 2439, the loss is 4.442714929283657, parameters k is 10.31802229992125 and b is -42.1192859854325\n",
      "Iteration 2440, the loss is 4.4427121220213, parameters k is 10.31796946395287 and b is -42.11928993800167\n",
      "Iteration 2441, the loss is 4.44270931475894, parameters k is 10.317916627984491 and b is -42.119293890570844\n",
      "Iteration 2442, the loss is 4.442706507496583, parameters k is 10.317863792016112 and b is -42.11929784314002\n",
      "Iteration 2443, the loss is 4.442703700234224, parameters k is 10.317810956047733 and b is -42.11930179570919\n",
      "Iteration 2444, the loss is 4.442700892971868, parameters k is 10.317758120079354 and b is -42.119305748278364\n",
      "Iteration 2445, the loss is 4.44269808570951, parameters k is 10.317705284110975 and b is -42.11930970084754\n",
      "Iteration 2446, the loss is 4.442695278447152, parameters k is 10.317652448142596 and b is -42.11931365341671\n",
      "Iteration 2447, the loss is 4.442692471184795, parameters k is 10.317599612174217 and b is -42.119317605985884\n",
      "Iteration 2448, the loss is 4.442689663922435, parameters k is 10.317546776205837 and b is -42.11932155855506\n",
      "Iteration 2449, the loss is 4.44268685666008, parameters k is 10.317493940237458 and b is -42.11932551112423\n",
      "Iteration 2450, the loss is 4.44268404939772, parameters k is 10.31744110426908 and b is -42.119329463693404\n",
      "Iteration 2451, the loss is 4.4426812421353645, parameters k is 10.3173882683007 and b is -42.11933341626258\n",
      "Iteration 2452, the loss is 4.442678434873005, parameters k is 10.317335432332321 and b is -42.11933736883175\n",
      "Iteration 2453, the loss is 4.4426756276106465, parameters k is 10.317282596363942 and b is -42.119341321400924\n",
      "Iteration 2454, the loss is 4.442672820348293, parameters k is 10.317229760395563 and b is -42.1193452739701\n",
      "Iteration 2455, the loss is 4.442670013085932, parameters k is 10.317176924427184 and b is -42.11934922653927\n",
      "Iteration 2456, the loss is 4.442667205823574, parameters k is 10.317124088458804 and b is -42.119353179108444\n",
      "Iteration 2457, the loss is 4.4426643985612175, parameters k is 10.317071252490425 and b is -42.11935713167762\n",
      "Iteration 2458, the loss is 4.442661591298861, parameters k is 10.317018416522046 and b is -42.11936108424679\n",
      "Iteration 2459, the loss is 4.442658784036502, parameters k is 10.316965580553667 and b is -42.119365036815964\n",
      "Iteration 2460, the loss is 4.442655976774145, parameters k is 10.316912744585288 and b is -42.11936898938514\n",
      "Iteration 2461, the loss is 4.442653169511788, parameters k is 10.316859908616909 and b is -42.11937294195431\n",
      "Iteration 2462, the loss is 4.442650362249431, parameters k is 10.31680707264853 and b is -42.119376894523484\n",
      "Iteration 2463, the loss is 4.4426476660746905, parameters k is 10.31675423668015 and b is -42.11938084709266\n",
      "Iteration 2464, the loss is 4.442646888370302, parameters k is 10.316726349328372 and b is -42.11938084709266\n",
      "Iteration 2465, the loss is 4.442646110665914, parameters k is 10.316698461976593 and b is -42.11938084709266\n",
      "Iteration 2466, the loss is 4.442645332961521, parameters k is 10.316670574624814 and b is -42.11938084709266\n",
      "Iteration 2467, the loss is 4.442644555257134, parameters k is 10.316642687273035 and b is -42.11938084709266\n",
      "Iteration 2468, the loss is 4.4426437775527425, parameters k is 10.316614799921256 and b is -42.11938084709266\n",
      "Iteration 2469, the loss is 4.442642999848355, parameters k is 10.316586912569477 and b is -42.11938084709266\n",
      "Iteration 2470, the loss is 4.442642222143967, parameters k is 10.316559025217698 and b is -42.11938084709266\n",
      "Iteration 2471, the loss is 4.442641444439578, parameters k is 10.316531137865919 and b is -42.11938084709266\n",
      "Iteration 2472, the loss is 4.442640666735185, parameters k is 10.31650325051414 and b is -42.11938084709266\n",
      "Iteration 2473, the loss is 4.4426398890308, parameters k is 10.316475363162361 and b is -42.11938084709266\n",
      "Iteration 2474, the loss is 4.442639111326409, parameters k is 10.316447475810582 and b is -42.11938084709266\n",
      "Iteration 2475, the loss is 4.44263833362202, parameters k is 10.316419588458803 and b is -42.11938084709266\n",
      "Iteration 2476, the loss is 4.442637555917627, parameters k is 10.316391701107024 and b is -42.11938084709266\n",
      "Iteration 2477, the loss is 4.442636778213241, parameters k is 10.316363813755245 and b is -42.11938084709266\n",
      "Iteration 2478, the loss is 4.442636000508849, parameters k is 10.316335926403466 and b is -42.11938084709266\n",
      "Iteration 2479, the loss is 4.442635222804465, parameters k is 10.316308039051687 and b is -42.11938084709266\n",
      "Iteration 2480, the loss is 4.442634445100075, parameters k is 10.316280151699909 and b is -42.11938084709266\n",
      "Iteration 2481, the loss is 4.442633667395686, parameters k is 10.31625226434813 and b is -42.11938084709266\n",
      "Iteration 2482, the loss is 4.4426328896912946, parameters k is 10.31622437699635 and b is -42.11938084709266\n",
      "Iteration 2483, the loss is 4.4426321119869066, parameters k is 10.316196489644572 and b is -42.11938084709266\n",
      "Iteration 2484, the loss is 4.442631334282515, parameters k is 10.316168602292793 and b is -42.11938084709266\n",
      "Iteration 2485, the loss is 4.44263055657813, parameters k is 10.316140714941014 and b is -42.11938084709266\n",
      "Iteration 2486, the loss is 4.442629778873737, parameters k is 10.316112827589235 and b is -42.11938084709266\n",
      "Iteration 2487, the loss is 4.44262900116935, parameters k is 10.316084940237456 and b is -42.11938084709266\n",
      "Iteration 2488, the loss is 4.442628223464962, parameters k is 10.316057052885677 and b is -42.11938084709266\n",
      "Iteration 2489, the loss is 4.442627445760569, parameters k is 10.316029165533898 and b is -42.11938084709266\n",
      "Iteration 2490, the loss is 4.442626668056182, parameters k is 10.316001278182119 and b is -42.11938084709266\n",
      "Iteration 2491, the loss is 4.442625890351794, parameters k is 10.31597339083034 and b is -42.11938084709266\n",
      "Iteration 2492, the loss is 4.442625112647404, parameters k is 10.315945503478561 and b is -42.11938084709266\n",
      "Iteration 2493, the loss is 4.442624334943014, parameters k is 10.315917616126782 and b is -42.11938084709266\n",
      "Iteration 2494, the loss is 4.442623557238623, parameters k is 10.315889728775003 and b is -42.11938084709266\n",
      "Iteration 2495, the loss is 4.442622779534236, parameters k is 10.315861841423224 and b is -42.11938084709266\n",
      "Iteration 2496, the loss is 4.4426220018298475, parameters k is 10.315833954071445 and b is -42.11938084709266\n",
      "Iteration 2497, the loss is 4.4426212241254595, parameters k is 10.315806066719666 and b is -42.11938084709266\n",
      "Iteration 2498, the loss is 4.442620446421067, parameters k is 10.315778179367888 and b is -42.11938084709266\n",
      "Iteration 2499, the loss is 4.442619668716678, parameters k is 10.315750292016109 and b is -42.11938084709266\n",
      "Iteration 2500, the loss is 4.442618891012289, parameters k is 10.31572240466433 and b is -42.11938084709266\n",
      "Iteration 2501, the loss is 4.442618113307897, parameters k is 10.31569451731255 and b is -42.11938084709266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2502, the loss is 4.44261733560351, parameters k is 10.315666629960772 and b is -42.11938084709266\n",
      "Iteration 2503, the loss is 4.442616557899122, parameters k is 10.315638742608993 and b is -42.11938084709266\n",
      "Iteration 2504, the loss is 4.442615780194735, parameters k is 10.315610855257214 and b is -42.11938084709266\n",
      "Iteration 2505, the loss is 4.442615002490344, parameters k is 10.315582967905435 and b is -42.11938084709266\n",
      "Iteration 2506, the loss is 4.442614224785955, parameters k is 10.315555080553656 and b is -42.11938084709266\n",
      "Iteration 2507, the loss is 4.442613447081566, parameters k is 10.315527193201877 and b is -42.11938084709266\n",
      "Iteration 2508, the loss is 4.442612669377176, parameters k is 10.315499305850098 and b is -42.11938084709266\n",
      "Iteration 2509, the loss is 4.442611891672788, parameters k is 10.31547141849832 and b is -42.11938084709266\n",
      "Iteration 2510, the loss is 4.442611113968397, parameters k is 10.31544353114654 and b is -42.11938084709266\n",
      "Iteration 2511, the loss is 4.442610336264006, parameters k is 10.315415643794761 and b is -42.11938084709266\n",
      "Iteration 2512, the loss is 4.442609558559619, parameters k is 10.315387756442982 and b is -42.11938084709266\n",
      "Iteration 2513, the loss is 4.442608780855228, parameters k is 10.315359869091203 and b is -42.11938084709266\n",
      "Iteration 2514, the loss is 4.44260800315084, parameters k is 10.315331981739424 and b is -42.11938084709266\n",
      "Iteration 2515, the loss is 4.442607225446451, parameters k is 10.315304094387646 and b is -42.11938084709266\n",
      "Iteration 2516, the loss is 4.442606447742063, parameters k is 10.315276207035867 and b is -42.11938084709266\n",
      "Iteration 2517, the loss is 4.442605670037675, parameters k is 10.315248319684088 and b is -42.11938084709266\n",
      "Iteration 2518, the loss is 4.44260489233328, parameters k is 10.315220432332309 and b is -42.11938084709266\n",
      "Iteration 2519, the loss is 4.442604114628894, parameters k is 10.31519254498053 and b is -42.11938084709266\n",
      "Iteration 2520, the loss is 4.442603336924505, parameters k is 10.31516465762875 and b is -42.11938084709266\n",
      "Iteration 2521, the loss is 4.442602559220114, parameters k is 10.315136770276972 and b is -42.11938084709266\n",
      "Iteration 2522, the loss is 4.442601781515724, parameters k is 10.315108882925193 and b is -42.11938084709266\n",
      "Iteration 2523, the loss is 4.442601003811336, parameters k is 10.315080995573414 and b is -42.11938084709266\n",
      "Iteration 2524, the loss is 4.442600226106946, parameters k is 10.315053108221635 and b is -42.11938084709266\n",
      "Iteration 2525, the loss is 4.442599448402556, parameters k is 10.315025220869856 and b is -42.11938084709266\n",
      "Iteration 2526, the loss is 4.442598670698169, parameters k is 10.314997333518077 and b is -42.11938084709266\n",
      "Iteration 2527, the loss is 4.4425978929937795, parameters k is 10.314969446166298 and b is -42.11938084709266\n",
      "Iteration 2528, the loss is 4.442597115289391, parameters k is 10.31494155881452 and b is -42.11938084709266\n",
      "Iteration 2529, the loss is 4.442596337585001, parameters k is 10.31491367146274 and b is -42.11938084709266\n",
      "Iteration 2530, the loss is 4.442595559880611, parameters k is 10.314885784110961 and b is -42.11938084709266\n",
      "Iteration 2531, the loss is 4.442594782176223, parameters k is 10.314857896759182 and b is -42.11938084709266\n",
      "Iteration 2532, the loss is 4.442594004471835, parameters k is 10.314830009407403 and b is -42.11938084709266\n",
      "Iteration 2533, the loss is 4.442593226767444, parameters k is 10.314802122055625 and b is -42.11938084709266\n",
      "Iteration 2534, the loss is 4.442592449063051, parameters k is 10.314774234703846 and b is -42.11938084709266\n",
      "Iteration 2535, the loss is 4.442591671358667, parameters k is 10.314746347352067 and b is -42.11938084709266\n",
      "Iteration 2536, the loss is 4.442590893654277, parameters k is 10.314718460000288 and b is -42.11938084709266\n",
      "Iteration 2537, the loss is 4.442590115949887, parameters k is 10.314690572648509 and b is -42.11938084709266\n",
      "Iteration 2538, the loss is 4.442589338245496, parameters k is 10.31466268529673 and b is -42.11938084709266\n",
      "Iteration 2539, the loss is 4.442588560541108, parameters k is 10.31463479794495 and b is -42.11938084709266\n",
      "Iteration 2540, the loss is 4.4425877828367195, parameters k is 10.314606910593172 and b is -42.11938084709266\n",
      "Iteration 2541, the loss is 4.442587005132332, parameters k is 10.314579023241393 and b is -42.11938084709266\n",
      "Iteration 2542, the loss is 4.44258622742794, parameters k is 10.314551135889614 and b is -42.11938084709266\n",
      "Iteration 2543, the loss is 4.442585449723552, parameters k is 10.314523248537835 and b is -42.11938084709266\n",
      "Iteration 2544, the loss is 4.442584672019162, parameters k is 10.314495361186056 and b is -42.11938084709266\n",
      "Iteration 2545, the loss is 4.442583894314772, parameters k is 10.314467473834277 and b is -42.11938084709266\n",
      "Iteration 2546, the loss is 4.442583116610386, parameters k is 10.314439586482498 and b is -42.11938084709266\n",
      "Iteration 2547, the loss is 4.442582338905994, parameters k is 10.31441169913072 and b is -42.11938084709266\n",
      "Iteration 2548, the loss is 4.4425815612016075, parameters k is 10.31438381177894 and b is -42.11938084709266\n",
      "Iteration 2549, the loss is 4.442580783497218, parameters k is 10.314355924427161 and b is -42.11938084709266\n",
      "Iteration 2550, the loss is 4.442580005792828, parameters k is 10.314328037075382 and b is -42.11938084709266\n",
      "Iteration 2551, the loss is 4.442579228088436, parameters k is 10.314300149723604 and b is -42.11938084709266\n",
      "Iteration 2552, the loss is 4.442578450384049, parameters k is 10.314272262371825 and b is -42.11938084709266\n",
      "Iteration 2553, the loss is 4.442577672679661, parameters k is 10.314244375020046 and b is -42.11938084709266\n",
      "Iteration 2554, the loss is 4.4425768949752715, parameters k is 10.314216487668267 and b is -42.11938084709266\n",
      "Iteration 2555, the loss is 4.442576117270882, parameters k is 10.314188600316488 and b is -42.11938084709266\n",
      "Iteration 2556, the loss is 4.442575339566491, parameters k is 10.314160712964709 and b is -42.11938084709266\n",
      "Iteration 2557, the loss is 4.442574561862103, parameters k is 10.31413282561293 and b is -42.11938084709266\n",
      "Iteration 2558, the loss is 4.442573784157717, parameters k is 10.314104938261151 and b is -42.11938084709266\n",
      "Iteration 2559, the loss is 4.442573006453325, parameters k is 10.314077050909372 and b is -42.11938084709266\n",
      "Iteration 2560, the loss is 4.442572228748935, parameters k is 10.314049163557593 and b is -42.11938084709266\n",
      "Iteration 2561, the loss is 4.442571451044545, parameters k is 10.314021276205814 and b is -42.11938084709266\n",
      "Iteration 2562, the loss is 4.442570673340155, parameters k is 10.313993388854035 and b is -42.11938084709266\n",
      "Iteration 2563, the loss is 4.442569895635769, parameters k is 10.313965501502256 and b is -42.11938084709266\n",
      "Iteration 2564, the loss is 4.442569117931378, parameters k is 10.313937614150477 and b is -42.11938084709266\n",
      "Iteration 2565, the loss is 4.442568340226987, parameters k is 10.313909726798698 and b is -42.11938084709266\n",
      "Iteration 2566, the loss is 4.4425675625226, parameters k is 10.31388183944692 and b is -42.11938084709266\n",
      "Iteration 2567, the loss is 4.442566784818208, parameters k is 10.31385395209514 and b is -42.11938084709266\n",
      "Iteration 2568, the loss is 4.44256600711382, parameters k is 10.313826064743361 and b is -42.11938084709266\n",
      "Iteration 2569, the loss is 4.44256522940943, parameters k is 10.313798177391583 and b is -42.11938084709266\n",
      "Iteration 2570, the loss is 4.442564451705042, parameters k is 10.313770290039804 and b is -42.11938084709266\n",
      "Iteration 2571, the loss is 4.4425636740006516, parameters k is 10.313742402688025 and b is -42.11938084709266\n",
      "Iteration 2572, the loss is 4.4425628962962636, parameters k is 10.313714515336246 and b is -42.11938084709266\n",
      "Iteration 2573, the loss is 4.442562118591874, parameters k is 10.313686627984467 and b is -42.11938084709266\n",
      "Iteration 2574, the loss is 4.442561340887485, parameters k is 10.313658740632688 and b is -42.11938084709266\n",
      "Iteration 2575, the loss is 4.442560563183098, parameters k is 10.313630853280909 and b is -42.11938084709266\n",
      "Iteration 2576, the loss is 4.442559785478707, parameters k is 10.31360296592913 and b is -42.11938084709266\n",
      "Iteration 2577, the loss is 4.442559007774316, parameters k is 10.313575078577351 and b is -42.11938084709266\n",
      "Iteration 2578, the loss is 4.44255823006993, parameters k is 10.313547191225572 and b is -42.11938084709266\n",
      "Iteration 2579, the loss is 4.442557452365539, parameters k is 10.313519303873793 and b is -42.11938084709266\n",
      "Iteration 2580, the loss is 4.442556674661152, parameters k is 10.313491416522014 and b is -42.11938084709266\n",
      "Iteration 2581, the loss is 4.442555896956762, parameters k is 10.313463529170235 and b is -42.11938084709266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2582, the loss is 4.442555119252373, parameters k is 10.313435641818456 and b is -42.11938084709266\n",
      "Iteration 2583, the loss is 4.442554341547983, parameters k is 10.313407754466677 and b is -42.11938084709266\n",
      "Iteration 2584, the loss is 4.442553563843595, parameters k is 10.313379867114898 and b is -42.11938084709266\n",
      "Iteration 2585, the loss is 4.4425527861392045, parameters k is 10.31335197976312 and b is -42.11938084709266\n",
      "Iteration 2586, the loss is 4.442552008434815, parameters k is 10.31332409241134 and b is -42.11938084709266\n",
      "Iteration 2587, the loss is 4.442551230730425, parameters k is 10.313296205059562 and b is -42.11938084709266\n",
      "Iteration 2588, the loss is 4.442550453026035, parameters k is 10.313268317707783 and b is -42.11938084709266\n",
      "Iteration 2589, the loss is 4.442549675321647, parameters k is 10.313240430356004 and b is -42.11938084709266\n",
      "Iteration 2590, the loss is 4.4425488976172565, parameters k is 10.313212543004225 and b is -42.11938084709266\n",
      "Iteration 2591, the loss is 4.4425481199128685, parameters k is 10.313184655652446 and b is -42.11938084709266\n",
      "Iteration 2592, the loss is 4.4425473422084805, parameters k is 10.313156768300667 and b is -42.11938084709266\n",
      "Iteration 2593, the loss is 4.442546564504089, parameters k is 10.313128880948888 and b is -42.11938084709266\n",
      "Iteration 2594, the loss is 4.442545786799701, parameters k is 10.313100993597109 and b is -42.11938084709266\n",
      "Iteration 2595, the loss is 4.442545009095311, parameters k is 10.31307310624533 and b is -42.11938084709266\n",
      "Iteration 2596, the loss is 4.442544231390924, parameters k is 10.313045218893551 and b is -42.11938084709266\n",
      "Iteration 2597, the loss is 4.4425434536865325, parameters k is 10.313017331541772 and b is -42.11938084709266\n",
      "Iteration 2598, the loss is 4.4425426759821445, parameters k is 10.312989444189993 and b is -42.11938084709266\n",
      "Iteration 2599, the loss is 4.442541898277758, parameters k is 10.312961556838214 and b is -42.11938084709266\n",
      "Iteration 2600, the loss is 4.442541120573366, parameters k is 10.312933669486435 and b is -42.11938084709266\n",
      "Iteration 2601, the loss is 4.442540342868976, parameters k is 10.312905782134656 and b is -42.11938084709266\n",
      "Iteration 2602, the loss is 4.442539565164586, parameters k is 10.312877894782877 and b is -42.11938084709266\n",
      "Iteration 2603, the loss is 4.442538787460199, parameters k is 10.312850007431098 and b is -42.11938084709266\n",
      "Iteration 2604, the loss is 4.442538009755808, parameters k is 10.31282212007932 and b is -42.11938084709266\n",
      "Iteration 2605, the loss is 4.44253723205142, parameters k is 10.31279423272754 and b is -42.11938084709266\n",
      "Iteration 2606, the loss is 4.442536454347029, parameters k is 10.312766345375762 and b is -42.11938084709266\n",
      "Iteration 2607, the loss is 4.442535676642641, parameters k is 10.312738458023983 and b is -42.11938084709266\n",
      "Iteration 2608, the loss is 4.442534898938253, parameters k is 10.312710570672204 and b is -42.11938084709266\n",
      "Iteration 2609, the loss is 4.442534121233863, parameters k is 10.312682683320425 and b is -42.11938084709266\n",
      "Iteration 2610, the loss is 4.442533343529474, parameters k is 10.312654795968646 and b is -42.11938084709266\n",
      "Iteration 2611, the loss is 4.442532565825084, parameters k is 10.312626908616867 and b is -42.11938084709266\n",
      "Iteration 2612, the loss is 4.442531788120693, parameters k is 10.312599021265088 and b is -42.11938084709266\n",
      "Iteration 2613, the loss is 4.442531010416307, parameters k is 10.312571133913309 and b is -42.11938084709266\n",
      "Iteration 2614, the loss is 4.442530232711914, parameters k is 10.31254324656153 and b is -42.11938084709266\n",
      "Iteration 2615, the loss is 4.442529455007529, parameters k is 10.312515359209751 and b is -42.11938084709266\n",
      "Iteration 2616, the loss is 4.44252867730314, parameters k is 10.312487471857972 and b is -42.11938084709266\n",
      "Iteration 2617, the loss is 4.442527899598752, parameters k is 10.312459584506193 and b is -42.11938084709266\n",
      "Iteration 2618, the loss is 4.442527121894362, parameters k is 10.312431697154414 and b is -42.11938084709266\n",
      "Iteration 2619, the loss is 4.442526344189971, parameters k is 10.312403809802635 and b is -42.11938084709266\n",
      "Iteration 2620, the loss is 4.442525566485582, parameters k is 10.312375922450856 and b is -42.11938084709266\n",
      "Iteration 2621, the loss is 4.4425247887811885, parameters k is 10.312348035099077 and b is -42.11938084709266\n",
      "Iteration 2622, the loss is 4.4425240110768005, parameters k is 10.312320147747299 and b is -42.11938084709266\n",
      "Iteration 2623, the loss is 4.4425232333724125, parameters k is 10.31229226039552 and b is -42.11938084709266\n",
      "Iteration 2624, the loss is 4.442522455668025, parameters k is 10.31226437304374 and b is -42.11938084709266\n",
      "Iteration 2625, the loss is 4.442521677963633, parameters k is 10.312236485691962 and b is -42.11938084709266\n",
      "Iteration 2626, the loss is 4.442520900259246, parameters k is 10.312208598340183 and b is -42.11938084709266\n",
      "Iteration 2627, the loss is 4.442520122554857, parameters k is 10.312180710988404 and b is -42.11938084709266\n",
      "Iteration 2628, the loss is 4.442519344850467, parameters k is 10.312152823636625 and b is -42.11938084709266\n",
      "Iteration 2629, the loss is 4.44251856714608, parameters k is 10.312124936284846 and b is -42.11938084709266\n",
      "Iteration 2630, the loss is 4.442517789441688, parameters k is 10.312097048933067 and b is -42.11938084709266\n",
      "Iteration 2631, the loss is 4.442517011737299, parameters k is 10.312069161581288 and b is -42.11938084709266\n",
      "Iteration 2632, the loss is 4.44251623403291, parameters k is 10.31204127422951 and b is -42.11938084709266\n",
      "Iteration 2633, the loss is 4.442515456328522, parameters k is 10.31201338687773 and b is -42.11938084709266\n",
      "Iteration 2634, the loss is 4.442514678624132, parameters k is 10.311985499525951 and b is -42.11938084709266\n",
      "Iteration 2635, the loss is 4.442513900919741, parameters k is 10.311957612174172 and b is -42.11938084709266\n",
      "Iteration 2636, the loss is 4.442513123215357, parameters k is 10.311929724822393 and b is -42.11938084709266\n",
      "Iteration 2637, the loss is 4.442512345510963, parameters k is 10.311901837470614 and b is -42.11938084709266\n",
      "Iteration 2638, the loss is 4.442511567806575, parameters k is 10.311873950118835 and b is -42.11938084709266\n",
      "Iteration 2639, the loss is 4.442510790102185, parameters k is 10.311846062767057 and b is -42.11938084709266\n",
      "Iteration 2640, the loss is 4.442510012397795, parameters k is 10.311818175415278 and b is -42.11938084709266\n",
      "Iteration 2641, the loss is 4.442509234693409, parameters k is 10.311790288063499 and b is -42.11938084709266\n",
      "Iteration 2642, the loss is 4.442508456989017, parameters k is 10.31176240071172 and b is -42.11938084709266\n",
      "Iteration 2643, the loss is 4.4425076792846285, parameters k is 10.31173451335994 and b is -42.11938084709266\n",
      "Iteration 2644, the loss is 4.442506901580239, parameters k is 10.311706626008162 and b is -42.11938084709266\n",
      "Iteration 2645, the loss is 4.442506123875851, parameters k is 10.311678738656383 and b is -42.11938084709266\n",
      "Iteration 2646, the loss is 4.442505346171459, parameters k is 10.311650851304604 and b is -42.11938084709266\n",
      "Iteration 2647, the loss is 4.442504568467072, parameters k is 10.311622963952825 and b is -42.11938084709266\n",
      "Iteration 2648, the loss is 4.4425037907626805, parameters k is 10.311595076601046 and b is -42.11938084709266\n",
      "Iteration 2649, the loss is 4.4425030130582925, parameters k is 10.311567189249267 and b is -42.11938084709266\n",
      "Iteration 2650, the loss is 4.4425022353539045, parameters k is 10.311539301897488 and b is -42.11938084709266\n",
      "Iteration 2651, the loss is 4.442501457649515, parameters k is 10.31151141454571 and b is -42.11938084709266\n",
      "Iteration 2652, the loss is 4.442500679945126, parameters k is 10.31148352719393 and b is -42.11938084709266\n",
      "Iteration 2653, the loss is 4.442499902240738, parameters k is 10.311455639842151 and b is -42.11938084709266\n",
      "Iteration 2654, the loss is 4.442499124536347, parameters k is 10.311427752490372 and b is -42.11938084709266\n",
      "Iteration 2655, the loss is 4.442498346831958, parameters k is 10.311399865138593 and b is -42.11938084709266\n",
      "Iteration 2656, the loss is 4.44249756912757, parameters k is 10.311371977786814 and b is -42.11938084709266\n",
      "Iteration 2657, the loss is 4.442496791423178, parameters k is 10.311344090435036 and b is -42.11938084709266\n",
      "Iteration 2658, the loss is 4.442496013718788, parameters k is 10.311316203083257 and b is -42.11938084709266\n",
      "Iteration 2659, the loss is 4.442495236014403, parameters k is 10.311288315731478 and b is -42.11938084709266\n",
      "Iteration 2660, the loss is 4.442494458310011, parameters k is 10.311260428379699 and b is -42.11938084709266\n",
      "Iteration 2661, the loss is 4.4424936806056206, parameters k is 10.31123254102792 and b is -42.11938084709266\n",
      "Iteration 2662, the loss is 4.442492902901233, parameters k is 10.31120465367614 and b is -42.11938084709266\n",
      "Iteration 2663, the loss is 4.4424921251968446, parameters k is 10.311176766324362 and b is -42.11938084709266\n",
      "Iteration 2664, the loss is 4.442491347492456, parameters k is 10.311148878972583 and b is -42.11938084709266\n",
      "Iteration 2665, the loss is 4.442490569788067, parameters k is 10.311120991620804 and b is -42.11938084709266\n",
      "Iteration 2666, the loss is 4.442489792083678, parameters k is 10.311093104269025 and b is -42.11938084709266\n",
      "Iteration 2667, the loss is 4.442489014379287, parameters k is 10.311065216917246 and b is -42.11938084709266\n",
      "Iteration 2668, the loss is 4.442488236674895, parameters k is 10.311037329565467 and b is -42.11938084709266\n",
      "Iteration 2669, the loss is 4.4424874589705095, parameters k is 10.311009442213688 and b is -42.11938084709266\n",
      "Iteration 2670, the loss is 4.442486681266119, parameters k is 10.31098155486191 and b is -42.11938084709266\n",
      "Iteration 2671, the loss is 4.442485903561729, parameters k is 10.31095366751013 and b is -42.11938084709266\n",
      "Iteration 2672, the loss is 4.442485125857341, parameters k is 10.310925780158351 and b is -42.11938084709266\n",
      "Iteration 2673, the loss is 4.442484348152952, parameters k is 10.310897892806572 and b is -42.11938084709266\n",
      "Iteration 2674, the loss is 4.4424835704485615, parameters k is 10.310870005454793 and b is -42.11938084709266\n",
      "Iteration 2675, the loss is 4.442482792744174, parameters k is 10.310842118103015 and b is -42.11938084709266\n",
      "Iteration 2676, the loss is 4.442482015039785, parameters k is 10.310814230751236 and b is -42.11938084709266\n",
      "Iteration 2677, the loss is 4.442481237335397, parameters k is 10.310786343399457 and b is -42.11938084709266\n",
      "Iteration 2678, the loss is 4.442480459631003, parameters k is 10.310758456047678 and b is -42.11938084709266\n",
      "Iteration 2679, the loss is 4.442479681926616, parameters k is 10.310730568695899 and b is -42.11938084709266\n",
      "Iteration 2680, the loss is 4.442478904222227, parameters k is 10.31070268134412 and b is -42.11938084709266\n",
      "Iteration 2681, the loss is 4.442478126517836, parameters k is 10.31067479399234 and b is -42.11938084709266\n",
      "Iteration 2682, the loss is 4.442477348813449, parameters k is 10.310646906640562 and b is -42.11938084709266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2683, the loss is 4.442476571109057, parameters k is 10.310619019288783 and b is -42.11938084709266\n",
      "Iteration 2684, the loss is 4.442475793404672, parameters k is 10.310591131937004 and b is -42.11938084709266\n",
      "Iteration 2685, the loss is 4.442475015700281, parameters k is 10.310563244585225 and b is -42.11938084709266\n",
      "Iteration 2686, the loss is 4.442474237995892, parameters k is 10.310535357233446 and b is -42.11938084709266\n",
      "Iteration 2687, the loss is 4.4424734602915, parameters k is 10.310507469881667 and b is -42.11938084709266\n",
      "Iteration 2688, the loss is 4.44247268258711, parameters k is 10.310479582529888 and b is -42.11938084709266\n",
      "Iteration 2689, the loss is 4.442471904882724, parameters k is 10.31045169517811 and b is -42.11938084709266\n",
      "Iteration 2690, the loss is 4.442471127178334, parameters k is 10.31042380782633 and b is -42.11938084709266\n",
      "Iteration 2691, the loss is 4.442470349473944, parameters k is 10.310395920474551 and b is -42.11938084709266\n",
      "Iteration 2692, the loss is 4.442469571769555, parameters k is 10.310368033122773 and b is -42.11938084709266\n",
      "Iteration 2693, the loss is 4.442468794065167, parameters k is 10.310340145770994 and b is -42.11938084709266\n",
      "Iteration 2694, the loss is 4.442468016360776, parameters k is 10.310312258419215 and b is -42.11938084709266\n",
      "Iteration 2695, the loss is 4.442467238656388, parameters k is 10.310284371067436 and b is -42.11938084709266\n",
      "Iteration 2696, the loss is 4.442466460952, parameters k is 10.310256483715657 and b is -42.11938084709266\n",
      "Iteration 2697, the loss is 4.442465683247609, parameters k is 10.310228596363878 and b is -42.11938084709266\n",
      "Iteration 2698, the loss is 4.442464905543221, parameters k is 10.310200709012099 and b is -42.11938084709266\n",
      "Iteration 2699, the loss is 4.442464127838831, parameters k is 10.31017282166032 and b is -42.11938084709266\n",
      "Iteration 2700, the loss is 4.442463350134441, parameters k is 10.310144934308541 and b is -42.11938084709266\n",
      "Iteration 2701, the loss is 4.442462572430053, parameters k is 10.310117046956762 and b is -42.11938084709266\n",
      "Iteration 2702, the loss is 4.442461794725663, parameters k is 10.310089159604983 and b is -42.11938084709266\n",
      "Iteration 2703, the loss is 4.442461017021273, parameters k is 10.310061272253204 and b is -42.11938084709266\n",
      "Iteration 2704, the loss is 4.442460239316887, parameters k is 10.310033384901425 and b is -42.11938084709266\n",
      "Iteration 2705, the loss is 4.4424594616124935, parameters k is 10.310005497549646 and b is -42.11938084709266\n",
      "Iteration 2706, the loss is 4.4424586839081055, parameters k is 10.309977610197867 and b is -42.11938084709266\n",
      "Iteration 2707, the loss is 4.4424579062037175, parameters k is 10.309949722846088 and b is -42.11938084709266\n",
      "Iteration 2708, the loss is 4.442457128499327, parameters k is 10.30992183549431 and b is -42.11938084709266\n",
      "Iteration 2709, the loss is 4.442456350794938, parameters k is 10.30989394814253 and b is -42.11938084709266\n",
      "Iteration 2710, the loss is 4.442455573090552, parameters k is 10.309866060790752 and b is -42.11938084709266\n",
      "Iteration 2711, the loss is 4.442454795386162, parameters k is 10.309838173438973 and b is -42.11938084709266\n",
      "Iteration 2712, the loss is 4.442454017681769, parameters k is 10.309810286087194 and b is -42.11938084709266\n",
      "Iteration 2713, the loss is 4.442453239977383, parameters k is 10.309782398735415 and b is -42.11938084709266\n",
      "Iteration 2714, the loss is 4.442452462272992, parameters k is 10.309754511383636 and b is -42.11938084709266\n",
      "Iteration 2715, the loss is 4.442451684568604, parameters k is 10.309726624031857 and b is -42.11938084709266\n",
      "Iteration 2716, the loss is 4.442450906864214, parameters k is 10.309698736680078 and b is -42.11938084709266\n",
      "Iteration 2717, the loss is 4.442450129159826, parameters k is 10.309670849328299 and b is -42.11938084709266\n",
      "Iteration 2718, the loss is 4.442449351455439, parameters k is 10.30964296197652 and b is -42.11938084709266\n",
      "Iteration 2719, the loss is 4.442448573751047, parameters k is 10.309615074624741 and b is -42.11938084709266\n",
      "Iteration 2720, the loss is 4.442447796046659, parameters k is 10.309587187272962 and b is -42.11938084709266\n",
      "Iteration 2721, the loss is 4.442447018342269, parameters k is 10.309559299921183 and b is -42.11938084709266\n",
      "Iteration 2722, the loss is 4.442446240637877, parameters k is 10.309531412569404 and b is -42.11938084709266\n",
      "Iteration 2723, the loss is 4.442445462933491, parameters k is 10.309503525217625 and b is -42.11938084709266\n",
      "Iteration 2724, the loss is 4.442444685229101, parameters k is 10.309475637865846 and b is -42.11938084709266\n",
      "Iteration 2725, the loss is 4.442443907524713, parameters k is 10.309447750514067 and b is -42.11938084709266\n",
      "Iteration 2726, the loss is 4.4424431298203215, parameters k is 10.309419863162288 and b is -42.11938084709266\n",
      "Iteration 2727, the loss is 4.442442352115931, parameters k is 10.30939197581051 and b is -42.11938084709266\n",
      "Iteration 2728, the loss is 4.442441574411545, parameters k is 10.30936408845873 and b is -42.11938084709266\n",
      "Iteration 2729, the loss is 4.442440796707153, parameters k is 10.309336201106952 and b is -42.11938084709266\n",
      "Iteration 2730, the loss is 4.442440019002766, parameters k is 10.309308313755173 and b is -42.11938084709266\n",
      "Iteration 2731, the loss is 4.442439241298374, parameters k is 10.309280426403394 and b is -42.11938084709266\n",
      "Iteration 2732, the loss is 4.442438463593986, parameters k is 10.309252539051615 and b is -42.11938084709266\n",
      "Iteration 2733, the loss is 4.442437685889597, parameters k is 10.309224651699836 and b is -42.11938084709266\n",
      "Iteration 2734, the loss is 4.442436908185209, parameters k is 10.309196764348057 and b is -42.11938084709266\n",
      "Iteration 2735, the loss is 4.442436130480821, parameters k is 10.309168876996278 and b is -42.11938084709266\n",
      "Iteration 2736, the loss is 4.442435352776431, parameters k is 10.309140989644499 and b is -42.11938084709266\n",
      "Iteration 2737, the loss is 4.44243457507204, parameters k is 10.30911310229272 and b is -42.11938084709266\n",
      "Iteration 2738, the loss is 4.442433797367651, parameters k is 10.309085214940941 and b is -42.11938084709266\n",
      "Iteration 2739, the loss is 4.442433019663262, parameters k is 10.309057327589162 and b is -42.11938084709266\n",
      "Iteration 2740, the loss is 4.4424322419588735, parameters k is 10.309029440237383 and b is -42.11938084709266\n",
      "Iteration 2741, the loss is 4.442431464254484, parameters k is 10.309001552885604 and b is -42.11938084709266\n",
      "Iteration 2742, the loss is 4.442430686550093, parameters k is 10.308973665533825 and b is -42.11938084709266\n",
      "Iteration 2743, the loss is 4.4424300869812, parameters k is 10.308945778182046 and b is -42.11938084709266\n",
      "Iteration 2744, the loss is 4.442430071206821, parameters k is 10.308945388853983 and b is -42.119376894523484\n",
      "Iteration 2745, the loss is 4.442430055432443, parameters k is 10.30894499952592 and b is -42.11937294195431\n",
      "Iteration 2746, the loss is 4.442430039658061, parameters k is 10.308944610197857 and b is -42.11936898938514\n",
      "Iteration 2747, the loss is 4.442430023883683, parameters k is 10.308944220869794 and b is -42.119365036815964\n",
      "Iteration 2748, the loss is 4.442430008109306, parameters k is 10.30894383154173 and b is -42.11936108424679\n",
      "Iteration 2749, the loss is 4.442429992334922, parameters k is 10.308943442213668 and b is -42.11935713167762\n",
      "Iteration 2750, the loss is 4.442429976560545, parameters k is 10.308943052885605 and b is -42.119353179108444\n",
      "Iteration 2751, the loss is 4.442429960786164, parameters k is 10.308942663557541 and b is -42.11934922653927\n",
      "Iteration 2752, the loss is 4.442429945011784, parameters k is 10.308942274229478 and b is -42.1193452739701\n",
      "Iteration 2753, the loss is 4.442429929237406, parameters k is 10.308941884901415 and b is -42.119341321400924\n",
      "Iteration 2754, the loss is 4.442429913463026, parameters k is 10.308941495573352 and b is -42.11933736883175\n",
      "Iteration 2755, the loss is 4.4424298976886485, parameters k is 10.308941106245289 and b is -42.11933341626258\n",
      "Iteration 2756, the loss is 4.4424298819142685, parameters k is 10.308940716917226 and b is -42.119329463693404\n",
      "Iteration 2757, the loss is 4.442429866139888, parameters k is 10.308940327589163 and b is -42.11932551112423\n",
      "Iteration 2758, the loss is 4.442429850365509, parameters k is 10.3089399382611 and b is -42.11932155855506\n",
      "Iteration 2759, the loss is 4.442429834591129, parameters k is 10.308939548933036 and b is -42.119317605985884\n",
      "Iteration 2760, the loss is 4.442429818816751, parameters k is 10.308939159604973 and b is -42.11931365341671\n",
      "Iteration 2761, the loss is 4.44242980304237, parameters k is 10.30893877027691 and b is -42.11930970084754\n",
      "Iteration 2762, the loss is 4.442429787267994, parameters k is 10.308938380948847 and b is -42.119305748278364\n",
      "Iteration 2763, the loss is 4.442429771493613, parameters k is 10.308937991620784 and b is -42.11930179570919\n",
      "Iteration 2764, the loss is 4.442429755719233, parameters k is 10.30893760229272 and b is -42.11929784314002\n",
      "Iteration 2765, the loss is 4.442429739944854, parameters k is 10.308937212964658 and b is -42.119293890570844\n",
      "Iteration 2766, the loss is 4.442429724170475, parameters k is 10.308936823636595 and b is -42.11928993800167\n",
      "Iteration 2767, the loss is 4.442429708396095, parameters k is 10.308936434308531 and b is -42.1192859854325\n",
      "Iteration 2768, the loss is 4.442429692621714, parameters k is 10.308936044980468 and b is -42.119282032863325\n",
      "Iteration 2769, the loss is 4.442429676847336, parameters k is 10.308935655652405 and b is -42.11927808029415\n",
      "Iteration 2770, the loss is 4.442429661072957, parameters k is 10.308935266324342 and b is -42.11927412772498\n",
      "Iteration 2771, the loss is 4.442429645298577, parameters k is 10.308934876996279 and b is -42.119270175155805\n",
      "Iteration 2772, the loss is 4.442429629524195, parameters k is 10.308934487668216 and b is -42.11926622258663\n",
      "Iteration 2773, the loss is 4.442429613749818, parameters k is 10.308934098340153 and b is -42.11926227001746\n",
      "Iteration 2774, the loss is 4.442429597975438, parameters k is 10.30893370901209 and b is -42.119258317448285\n",
      "Iteration 2775, the loss is 4.442429582201058, parameters k is 10.308933319684026 and b is -42.11925436487911\n",
      "Iteration 2776, the loss is 4.44242956642668, parameters k is 10.308932930355963 and b is -42.11925041230994\n",
      "Iteration 2777, the loss is 4.4424295506523, parameters k is 10.3089325410279 and b is -42.119246459740765\n",
      "Iteration 2778, the loss is 4.442429534877921, parameters k is 10.308932151699837 and b is -42.11924250717159\n",
      "Iteration 2779, the loss is 4.442429519103541, parameters k is 10.308931762371774 and b is -42.11923855460242\n",
      "Iteration 2780, the loss is 4.442429507124544, parameters k is 10.30893137304371 and b is -42.119234602033245\n",
      "Iteration 2781, the loss is 4.442429492471832, parameters k is 10.308903485691932 and b is -42.119234602033245\n",
      "Iteration 2782, the loss is 4.442429476697452, parameters k is 10.308903096363869 and b is -42.11923064946407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2783, the loss is 4.442429460923077, parameters k is 10.308902707035806 and b is -42.1192266968949\n",
      "Iteration 2784, the loss is 4.442429445148697, parameters k is 10.308902317707743 and b is -42.119222744325725\n",
      "Iteration 2785, the loss is 4.442429429374316, parameters k is 10.30890192837968 and b is -42.11921879175655\n",
      "Iteration 2786, the loss is 4.442429413599936, parameters k is 10.308901539051616 and b is -42.11921483918738\n",
      "Iteration 2787, the loss is 4.442429397825558, parameters k is 10.308901149723553 and b is -42.119210886618205\n",
      "Iteration 2788, the loss is 4.442429382051175, parameters k is 10.30890076039549 and b is -42.11920693404903\n",
      "Iteration 2789, the loss is 4.442429366276798, parameters k is 10.308900371067427 and b is -42.11920298147986\n",
      "Iteration 2790, the loss is 4.442429350502416, parameters k is 10.308899981739364 and b is -42.119199028910685\n",
      "Iteration 2791, the loss is 4.44242933472804, parameters k is 10.3088995924113 and b is -42.11919507634151\n",
      "Iteration 2792, the loss is 4.442429318953659, parameters k is 10.308899203083238 and b is -42.11919112377234\n",
      "Iteration 2793, the loss is 4.442429303179282, parameters k is 10.308898813755174 and b is -42.119187171203166\n",
      "Iteration 2794, the loss is 4.4424292874049005, parameters k is 10.308898424427111 and b is -42.11918321863399\n",
      "Iteration 2795, the loss is 4.442429271630521, parameters k is 10.308898035099048 and b is -42.11917926606482\n",
      "Iteration 2796, the loss is 4.442429255856142, parameters k is 10.308897645770985 and b is -42.119175313495646\n",
      "Iteration 2797, the loss is 4.442429240081763, parameters k is 10.308897256442922 and b is -42.11917136092647\n",
      "Iteration 2798, the loss is 4.442429224307385, parameters k is 10.308896867114859 and b is -42.1191674083573\n",
      "Iteration 2799, the loss is 4.442429208533004, parameters k is 10.308896477786796 and b is -42.119163455788126\n",
      "Iteration 2800, the loss is 4.442429192758625, parameters k is 10.308896088458733 and b is -42.11915950321895\n",
      "Iteration 2801, the loss is 4.442429176984246, parameters k is 10.30889569913067 and b is -42.11915555064978\n",
      "Iteration 2802, the loss is 4.442429161209867, parameters k is 10.308895309802606 and b is -42.119151598080606\n",
      "Iteration 2803, the loss is 4.4424291454354865, parameters k is 10.308894920474543 and b is -42.11914764551143\n",
      "Iteration 2804, the loss is 4.442429129661107, parameters k is 10.30889453114648 and b is -42.11914369294226\n",
      "Iteration 2805, the loss is 4.442429113886727, parameters k is 10.308894141818417 and b is -42.119139740373086\n",
      "Iteration 2806, the loss is 4.442429098112346, parameters k is 10.308893752490354 and b is -42.11913578780391\n",
      "Iteration 2807, the loss is 4.442429082337967, parameters k is 10.30889336316229 and b is -42.11913183523474\n",
      "Iteration 2808, the loss is 4.442429066563591, parameters k is 10.308892973834228 and b is -42.119127882665566\n",
      "Iteration 2809, the loss is 4.44242905078921, parameters k is 10.308892584506165 and b is -42.11912393009639\n",
      "Iteration 2810, the loss is 4.442429035014831, parameters k is 10.308892195178101 and b is -42.11911997752722\n",
      "Iteration 2811, the loss is 4.4424290192404525, parameters k is 10.308891805850038 and b is -42.119116024958046\n",
      "Iteration 2812, the loss is 4.4424290034660725, parameters k is 10.308891416521975 and b is -42.11911207238887\n",
      "Iteration 2813, the loss is 4.442428987691693, parameters k is 10.308891027193912 and b is -42.1191081198197\n",
      "Iteration 2814, the loss is 4.442428971917315, parameters k is 10.308890637865849 and b is -42.119104167250526\n",
      "Iteration 2815, the loss is 4.442428956142935, parameters k is 10.308890248537786 and b is -42.11910021468135\n",
      "Iteration 2816, the loss is 4.442428940368554, parameters k is 10.308889859209723 and b is -42.11909626211218\n",
      "Iteration 2817, the loss is 4.442428924594177, parameters k is 10.30888946988166 and b is -42.11909230954301\n",
      "Iteration 2818, the loss is 4.442428908819795, parameters k is 10.308889080553596 and b is -42.11908835697383\n",
      "Iteration 2819, the loss is 4.442428893045416, parameters k is 10.308888691225533 and b is -42.11908440440466\n",
      "Iteration 2820, the loss is 4.442428877271037, parameters k is 10.30888830189747 and b is -42.11908045183549\n",
      "Iteration 2821, the loss is 4.442428861496656, parameters k is 10.308887912569407 and b is -42.11907649926631\n",
      "Iteration 2822, the loss is 4.442428845722278, parameters k is 10.308887523241344 and b is -42.11907254669714\n",
      "Iteration 2823, the loss is 4.4424288299479, parameters k is 10.30888713391328 and b is -42.11906859412797\n",
      "Iteration 2824, the loss is 4.44242881417352, parameters k is 10.308886744585218 and b is -42.11906464155879\n",
      "Iteration 2825, the loss is 4.442428798399141, parameters k is 10.308886355257155 and b is -42.11906068898962\n",
      "Iteration 2826, the loss is 4.442428782624761, parameters k is 10.308885965929091 and b is -42.11905673642045\n",
      "Iteration 2827, the loss is 4.442428766850383, parameters k is 10.308885576601028 and b is -42.119052783851274\n",
      "Iteration 2828, the loss is 4.442428751076003, parameters k is 10.308885187272965 and b is -42.1190488312821\n",
      "Iteration 2829, the loss is 4.44242873530162, parameters k is 10.308884797944902 and b is -42.11904487871293\n",
      "Iteration 2830, the loss is 4.442428719527244, parameters k is 10.308884408616839 and b is -42.119040926143754\n",
      "Iteration 2831, the loss is 4.442428703752862, parameters k is 10.308884019288776 and b is -42.11903697357458\n",
      "Iteration 2832, the loss is 4.442428687978483, parameters k is 10.308883629960713 and b is -42.11903302100541\n",
      "Iteration 2833, the loss is 4.442428672204105, parameters k is 10.30888324063265 and b is -42.119029068436234\n",
      "Iteration 2834, the loss is 4.442428656429725, parameters k is 10.308882851304586 and b is -42.11902511586706\n",
      "Iteration 2835, the loss is 4.442428640655346, parameters k is 10.308882461976523 and b is -42.11902116329789\n",
      "Iteration 2836, the loss is 4.442428624880965, parameters k is 10.30888207264846 and b is -42.119017210728714\n",
      "Iteration 2837, the loss is 4.442428609106587, parameters k is 10.308881683320397 and b is -42.11901325815954\n",
      "Iteration 2838, the loss is 4.442428593332208, parameters k is 10.308881293992334 and b is -42.11900930559037\n",
      "Iteration 2839, the loss is 4.442428577557828, parameters k is 10.30888090466427 and b is -42.119005353021194\n",
      "Iteration 2840, the loss is 4.442428561783448, parameters k is 10.308880515336208 and b is -42.11900140045202\n",
      "Iteration 2841, the loss is 4.442428546009069, parameters k is 10.308880126008145 and b is -42.11899744788285\n",
      "Iteration 2842, the loss is 4.442428530234692, parameters k is 10.308879736680082 and b is -42.118993495313674\n",
      "Iteration 2843, the loss is 4.44242851446031, parameters k is 10.308879347352018 and b is -42.1189895427445\n",
      "Iteration 2844, the loss is 4.442428498685933, parameters k is 10.308878958023955 and b is -42.11898559017533\n",
      "Iteration 2845, the loss is 4.442428482911554, parameters k is 10.308878568695892 and b is -42.118981637606154\n",
      "Iteration 2846, the loss is 4.442428467137172, parameters k is 10.308878179367829 and b is -42.11897768503698\n",
      "Iteration 2847, the loss is 4.442428451362794, parameters k is 10.308877790039766 and b is -42.11897373246781\n",
      "Iteration 2848, the loss is 4.442428435588412, parameters k is 10.308877400711703 and b is -42.118969779898634\n",
      "Iteration 2849, the loss is 4.442428419814033, parameters k is 10.30887701138364 and b is -42.11896582732946\n",
      "Iteration 2850, the loss is 4.442428404039655, parameters k is 10.308876622055577 and b is -42.11896187476029\n",
      "Iteration 2851, the loss is 4.442428388265275, parameters k is 10.308876232727513 and b is -42.118957922191115\n",
      "Iteration 2852, the loss is 4.442428372490899, parameters k is 10.30887584339945 and b is -42.11895396962194\n",
      "Iteration 2853, the loss is 4.442428356716517, parameters k is 10.308875454071387 and b is -42.11895001705277\n",
      "Iteration 2854, the loss is 4.442428340942136, parameters k is 10.308875064743324 and b is -42.118946064483595\n",
      "Iteration 2855, the loss is 4.442428325167758, parameters k is 10.308874675415261 and b is -42.11894211191442\n",
      "Iteration 2856, the loss is 4.44242830939338, parameters k is 10.308874286087198 and b is -42.11893815934525\n",
      "Iteration 2857, the loss is 4.442428293619001, parameters k is 10.308873896759135 and b is -42.118934206776075\n",
      "Iteration 2858, the loss is 4.44242827784462, parameters k is 10.308873507431072 and b is -42.1189302542069\n",
      "Iteration 2859, the loss is 4.44242826207024, parameters k is 10.308873118103008 and b is -42.11892630163773\n",
      "Iteration 2860, the loss is 4.442428246295861, parameters k is 10.308872728774945 and b is -42.118922349068555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2861, the loss is 4.442428230521482, parameters k is 10.308872339446882 and b is -42.11891839649938\n",
      "Iteration 2862, the loss is 4.442428214747101, parameters k is 10.308871950118819 and b is -42.11891444393021\n",
      "Iteration 2863, the loss is 4.442428198972722, parameters k is 10.308871560790756 and b is -42.118910491361035\n",
      "Iteration 2864, the loss is 4.442428183198344, parameters k is 10.308871171462693 and b is -42.11890653879186\n",
      "Iteration 2865, the loss is 4.442428167423966, parameters k is 10.30887078213463 and b is -42.11890258622269\n",
      "Iteration 2866, the loss is 4.442428151649583, parameters k is 10.308870392806567 and b is -42.118898633653515\n",
      "Iteration 2867, the loss is 4.442428135875205, parameters k is 10.308870003478503 and b is -42.11889468108434\n",
      "Iteration 2868, the loss is 4.442428120100824, parameters k is 10.30886961415044 and b is -42.11889072851517\n",
      "Iteration 2869, the loss is 4.442428104326446, parameters k is 10.308869224822377 and b is -42.118886775945995\n",
      "Iteration 2870, the loss is 4.442428088552068, parameters k is 10.308868835494314 and b is -42.11888282337682\n",
      "Iteration 2871, the loss is 4.44242807277769, parameters k is 10.308868446166251 and b is -42.11887887080765\n",
      "Iteration 2872, the loss is 4.442428057003308, parameters k is 10.308868056838188 and b is -42.118874918238475\n",
      "Iteration 2873, the loss is 4.442428041228928, parameters k is 10.308867667510125 and b is -42.1188709656693\n",
      "Iteration 2874, the loss is 4.442428025454549, parameters k is 10.308867278182062 and b is -42.11886701310013\n",
      "Iteration 2875, the loss is 4.442428009680171, parameters k is 10.308866888853998 and b is -42.118863060530956\n",
      "Iteration 2876, the loss is 4.442427993905787, parameters k is 10.308866499525935 and b is -42.11885910796178\n",
      "Iteration 2877, the loss is 4.442427978131412, parameters k is 10.308866110197872 and b is -42.11885515539261\n",
      "Iteration 2878, the loss is 4.44242796235703, parameters k is 10.30886572086981 and b is -42.118851202823436\n",
      "Iteration 2879, the loss is 4.442427946582651, parameters k is 10.308865331541746 and b is -42.11884725025426\n",
      "Iteration 2880, the loss is 4.442427930808274, parameters k is 10.308864942213683 and b is -42.11884329768509\n",
      "Iteration 2881, the loss is 4.442427915033895, parameters k is 10.30886455288562 and b is -42.118839345115916\n",
      "Iteration 2882, the loss is 4.442427899259514, parameters k is 10.308864163557557 and b is -42.11883539254674\n",
      "Iteration 2883, the loss is 4.442427883485134, parameters k is 10.308863774229494 and b is -42.11883143997757\n",
      "Iteration 2884, the loss is 4.442427867710756, parameters k is 10.30886338490143 and b is -42.118827487408396\n",
      "Iteration 2885, the loss is 4.442427851936376, parameters k is 10.308862995573367 and b is -42.11882353483922\n",
      "Iteration 2886, the loss is 4.442427836161998, parameters k is 10.308862606245304 and b is -42.11881958227005\n",
      "Iteration 2887, the loss is 4.442427820387619, parameters k is 10.308862216917241 and b is -42.118815629700876\n",
      "Iteration 2888, the loss is 4.442427804613239, parameters k is 10.308861827589178 and b is -42.1188116771317\n",
      "Iteration 2889, the loss is 4.442427788838859, parameters k is 10.308861438261115 and b is -42.11880772456253\n",
      "Iteration 2890, the loss is 4.4424277730644794, parameters k is 10.308861048933052 and b is -42.118803771993356\n",
      "Iteration 2891, the loss is 4.442427757290099, parameters k is 10.308860659604989 and b is -42.11879981942418\n",
      "Iteration 2892, the loss is 4.442427741515724, parameters k is 10.308860270276925 and b is -42.11879586685501\n",
      "Iteration 2893, the loss is 4.442427725741343, parameters k is 10.308859880948862 and b is -42.118791914285836\n",
      "Iteration 2894, the loss is 4.442427709966964, parameters k is 10.3088594916208 and b is -42.11878796171666\n",
      "Iteration 2895, the loss is 4.442427694192583, parameters k is 10.308859102292736 and b is -42.11878400914749\n",
      "Iteration 2896, the loss is 4.442427678418201, parameters k is 10.308858712964673 and b is -42.118780056578316\n",
      "Iteration 2897, the loss is 4.442427662643822, parameters k is 10.30885832363661 and b is -42.11877610400914\n",
      "Iteration 2898, the loss is 4.442427646869442, parameters k is 10.308857934308547 and b is -42.11877215143997\n",
      "Iteration 2899, the loss is 4.442427631095066, parameters k is 10.308857544980484 and b is -42.1187681988708\n",
      "Iteration 2900, the loss is 4.442427615320684, parameters k is 10.30885715565242 and b is -42.11876424630162\n",
      "Iteration 2901, the loss is 4.442427599546308, parameters k is 10.308856766324357 and b is -42.11876029373245\n",
      "Iteration 2902, the loss is 4.442427583771926, parameters k is 10.308856376996294 and b is -42.11875634116328\n",
      "Iteration 2903, the loss is 4.442427567997548, parameters k is 10.308855987668231 and b is -42.1187523885941\n",
      "Iteration 2904, the loss is 4.442427552223167, parameters k is 10.308855598340168 and b is -42.11874843602493\n",
      "Iteration 2905, the loss is 4.442427536448789, parameters k is 10.308855209012105 and b is -42.11874448345576\n",
      "Iteration 2906, the loss is 4.442427520674408, parameters k is 10.308854819684042 and b is -42.11874053088658\n",
      "Iteration 2907, the loss is 4.44242750490003, parameters k is 10.308854430355979 and b is -42.11873657831741\n",
      "Iteration 2908, the loss is 4.442427489125651, parameters k is 10.308854041027915 and b is -42.11873262574824\n",
      "Iteration 2909, the loss is 4.442427473351272, parameters k is 10.308853651699852 and b is -42.11872867317906\n",
      "Iteration 2910, the loss is 4.442427457576892, parameters k is 10.30885326237179 and b is -42.11872472060989\n",
      "Iteration 2911, the loss is 4.442427441802512, parameters k is 10.308852873043726 and b is -42.11872076804072\n",
      "Iteration 2912, the loss is 4.442427426028131, parameters k is 10.308852483715663 and b is -42.118716815471544\n",
      "Iteration 2913, the loss is 4.442427410253755, parameters k is 10.3088520943876 and b is -42.11871286290237\n",
      "Iteration 2914, the loss is 4.442427394479375, parameters k is 10.308851705059537 and b is -42.1187089103332\n",
      "Iteration 2915, the loss is 4.442427378704993, parameters k is 10.308851315731474 and b is -42.118704957764024\n",
      "Iteration 2916, the loss is 4.442427362930614, parameters k is 10.30885092640341 and b is -42.11870100519485\n",
      "Iteration 2917, the loss is 4.442427347156235, parameters k is 10.308850537075347 and b is -42.11869705262568\n",
      "Iteration 2918, the loss is 4.442427331381856, parameters k is 10.308850147747284 and b is -42.118693100056504\n",
      "Iteration 2919, the loss is 4.442427315607478, parameters k is 10.308849758419221 and b is -42.11868914748733\n",
      "Iteration 2920, the loss is 4.442427299833098, parameters k is 10.308849369091158 and b is -42.11868519491816\n",
      "Iteration 2921, the loss is 4.442427284058717, parameters k is 10.308848979763095 and b is -42.118681242348984\n",
      "Iteration 2922, the loss is 4.442427268284337, parameters k is 10.308848590435032 and b is -42.11867728977981\n",
      "Iteration 2923, the loss is 4.442427252509958, parameters k is 10.308848201106969 and b is -42.11867333721064\n",
      "Iteration 2924, the loss is 4.442427236735578, parameters k is 10.308847811778906 and b is -42.118669384641464\n",
      "Iteration 2925, the loss is 4.4424272209612, parameters k is 10.308847422450842 and b is -42.11866543207229\n",
      "Iteration 2926, the loss is 4.442427205186821, parameters k is 10.30884703312278 and b is -42.11866147950312\n",
      "Iteration 2927, the loss is 4.442427189412442, parameters k is 10.308846643794716 and b is -42.118657526933944\n",
      "Iteration 2928, the loss is 4.442427173638062, parameters k is 10.308846254466653 and b is -42.11865357436477\n",
      "Iteration 2929, the loss is 4.442427157863682, parameters k is 10.30884586513859 and b is -42.1186496217956\n",
      "Iteration 2930, the loss is 4.442427142089304, parameters k is 10.308845475810527 and b is -42.118645669226424\n",
      "Iteration 2931, the loss is 4.442427126314925, parameters k is 10.308845086482464 and b is -42.11864171665725\n",
      "Iteration 2932, the loss is 4.442427110540544, parameters k is 10.3088446971544 and b is -42.11863776408808\n",
      "Iteration 2933, the loss is 4.442427094766166, parameters k is 10.308844307826337 and b is -42.118633811518905\n",
      "Iteration 2934, the loss is 4.442427078991787, parameters k is 10.308843918498274 and b is -42.11862985894973\n",
      "Iteration 2935, the loss is 4.442427063217407, parameters k is 10.308843529170211 and b is -42.11862590638056\n",
      "Iteration 2936, the loss is 4.442427047443027, parameters k is 10.308843139842148 and b is -42.118621953811385\n",
      "Iteration 2937, the loss is 4.442427035676885, parameters k is 10.308842750514085 and b is -42.11861800124221\n",
      "Iteration 2938, the loss is 4.442427020811318, parameters k is 10.308814863162306 and b is -42.11861800124221\n",
      "Iteration 2939, the loss is 4.442427005036939, parameters k is 10.308814473834243 and b is -42.11861404867304\n",
      "Iteration 2940, the loss is 4.44242698926256, parameters k is 10.30881408450618 and b is -42.118610096103865\n",
      "Iteration 2941, the loss is 4.442426973488181, parameters k is 10.308813695178117 and b is -42.11860614353469\n",
      "Iteration 2942, the loss is 4.442426957713802, parameters k is 10.308813305850054 and b is -42.11860219096552\n",
      "Iteration 2943, the loss is 4.442426941939423, parameters k is 10.30881291652199 and b is -42.118598238396345\n",
      "Iteration 2944, the loss is 4.442426926165043, parameters k is 10.308812527193927 and b is -42.11859428582717\n",
      "Iteration 2945, the loss is 4.442426910390662, parameters k is 10.308812137865864 and b is -42.118590333258\n",
      "Iteration 2946, the loss is 4.4424268946162835, parameters k is 10.308811748537801 and b is -42.118586380688825\n",
      "Iteration 2947, the loss is 4.442426878841906, parameters k is 10.308811359209738 and b is -42.11858242811965\n",
      "Iteration 2948, the loss is 4.442426863067524, parameters k is 10.308810969881675 and b is -42.11857847555048\n",
      "Iteration 2949, the loss is 4.442426847293146, parameters k is 10.308810580553612 and b is -42.118574522981305\n",
      "Iteration 2950, the loss is 4.442426831518766, parameters k is 10.308810191225549 and b is -42.11857057041213\n",
      "Iteration 2951, the loss is 4.442426815744385, parameters k is 10.308809801897485 and b is -42.11856661784296\n",
      "Iteration 2952, the loss is 4.442426799970009, parameters k is 10.308809412569422 and b is -42.118562665273785\n",
      "Iteration 2953, the loss is 4.442426784195629, parameters k is 10.30880902324136 and b is -42.11855871270461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2954, the loss is 4.442426768421248, parameters k is 10.308808633913296 and b is -42.11855476013544\n",
      "Iteration 2955, the loss is 4.4424267526468695, parameters k is 10.308808244585233 and b is -42.118550807566265\n",
      "Iteration 2956, the loss is 4.442426736872491, parameters k is 10.30880785525717 and b is -42.11854685499709\n",
      "Iteration 2957, the loss is 4.442426721098111, parameters k is 10.308807465929107 and b is -42.11854290242792\n",
      "Iteration 2958, the loss is 4.44242670532373, parameters k is 10.308807076601044 and b is -42.118538949858745\n",
      "Iteration 2959, the loss is 4.442426689549351, parameters k is 10.30880668727298 and b is -42.11853499728957\n",
      "Iteration 2960, the loss is 4.442426673774973, parameters k is 10.308806297944917 and b is -42.1185310447204\n",
      "Iteration 2961, the loss is 4.442426658000595, parameters k is 10.308805908616854 and b is -42.118527092151226\n",
      "Iteration 2962, the loss is 4.442426642226212, parameters k is 10.308805519288791 and b is -42.11852313958205\n",
      "Iteration 2963, the loss is 4.442426626451834, parameters k is 10.308805129960728 and b is -42.11851918701288\n",
      "Iteration 2964, the loss is 4.442426610677454, parameters k is 10.308804740632665 and b is -42.118515234443706\n",
      "Iteration 2965, the loss is 4.442426594903075, parameters k is 10.308804351304602 and b is -42.11851128187453\n",
      "Iteration 2966, the loss is 4.442426579128696, parameters k is 10.308803961976539 and b is -42.11850732930536\n",
      "Iteration 2967, the loss is 4.4424265633543145, parameters k is 10.308803572648475 and b is -42.118503376736186\n",
      "Iteration 2968, the loss is 4.442426547579935, parameters k is 10.308803183320412 and b is -42.11849942416701\n",
      "Iteration 2969, the loss is 4.442426531805557, parameters k is 10.30880279399235 and b is -42.11849547159784\n",
      "Iteration 2970, the loss is 4.442426516031178, parameters k is 10.308802404664286 and b is -42.118491519028666\n",
      "Iteration 2971, the loss is 4.442426500256798, parameters k is 10.308802015336223 and b is -42.11848756645949\n",
      "Iteration 2972, the loss is 4.442426484482421, parameters k is 10.30880162600816 and b is -42.11848361389032\n",
      "Iteration 2973, the loss is 4.44242646870804, parameters k is 10.308801236680097 and b is -42.118479661321146\n",
      "Iteration 2974, the loss is 4.442426452933662, parameters k is 10.308800847352034 and b is -42.11847570875197\n",
      "Iteration 2975, the loss is 4.442426437159284, parameters k is 10.30880045802397 and b is -42.1184717561828\n",
      "Iteration 2976, the loss is 4.4424264213849005, parameters k is 10.308800068695907 and b is -42.118467803613626\n",
      "Iteration 2977, the loss is 4.442426405610524, parameters k is 10.308799679367844 and b is -42.11846385104445\n",
      "Iteration 2978, the loss is 4.442426389836141, parameters k is 10.308799290039781 and b is -42.11845989847528\n",
      "Iteration 2979, the loss is 4.442426374061761, parameters k is 10.308798900711718 and b is -42.118455945906106\n",
      "Iteration 2980, the loss is 4.442426358287385, parameters k is 10.308798511383655 and b is -42.11845199333693\n",
      "Iteration 2981, the loss is 4.4424263425130075, parameters k is 10.308798122055592 and b is -42.11844804076776\n",
      "Iteration 2982, the loss is 4.442426326738626, parameters k is 10.308797732727529 and b is -42.118444088198586\n",
      "Iteration 2983, the loss is 4.4424263109642474, parameters k is 10.308797343399466 and b is -42.11844013562941\n",
      "Iteration 2984, the loss is 4.442426295189866, parameters k is 10.308796954071402 and b is -42.11843618306024\n",
      "Iteration 2985, the loss is 4.442426279415487, parameters k is 10.30879656474334 and b is -42.11843223049107\n",
      "Iteration 2986, the loss is 4.442426263641111, parameters k is 10.308796175415276 and b is -42.11842827792189\n",
      "Iteration 2987, the loss is 4.442426247866728, parameters k is 10.308795786087213 and b is -42.11842432535272\n",
      "Iteration 2988, the loss is 4.44242623209235, parameters k is 10.30879539675915 and b is -42.11842037278355\n",
      "Iteration 2989, the loss is 4.442426216317971, parameters k is 10.308795007431087 and b is -42.11841642021437\n",
      "Iteration 2990, the loss is 4.44242620054359, parameters k is 10.308794618103024 and b is -42.1184124676452\n",
      "Iteration 2991, the loss is 4.442426184769209, parameters k is 10.30879422877496 and b is -42.11840851507603\n",
      "Iteration 2992, the loss is 4.44242616899483, parameters k is 10.308793839446897 and b is -42.11840456250685\n",
      "Iteration 2993, the loss is 4.4424261532204525, parameters k is 10.308793450118834 and b is -42.11840060993768\n",
      "Iteration 2994, the loss is 4.442426137446073, parameters k is 10.308793060790771 and b is -42.11839665736851\n",
      "Iteration 2995, the loss is 4.4424261216716925, parameters k is 10.308792671462708 and b is -42.118392704799334\n",
      "Iteration 2996, the loss is 4.442426105897314, parameters k is 10.308792282134645 and b is -42.11838875223016\n",
      "Iteration 2997, the loss is 4.442426090122932, parameters k is 10.308791892806582 and b is -42.11838479966099\n",
      "Iteration 2998, the loss is 4.442426074348555, parameters k is 10.308791503478519 and b is -42.118380847091814\n",
      "Iteration 2999, the loss is 4.442426058574175, parameters k is 10.308791114150456 and b is -42.11837689452264\n",
      "Iteration 3000, the loss is 4.442426042799797, parameters k is 10.308790724822392 and b is -42.11837294195347\n",
      "Iteration 3001, the loss is 4.44242602702542, parameters k is 10.30879033549433 and b is -42.118368989384294\n",
      "Iteration 3002, the loss is 4.442426011251036, parameters k is 10.308789946166266 and b is -42.11836503681512\n",
      "Iteration 3003, the loss is 4.442425995476661, parameters k is 10.308789556838203 and b is -42.11836108424595\n",
      "Iteration 3004, the loss is 4.442425979702278, parameters k is 10.30878916751014 and b is -42.118357131676774\n",
      "Iteration 3005, the loss is 4.4424259639279, parameters k is 10.308788778182077 and b is -42.1183531791076\n",
      "Iteration 3006, the loss is 4.442425948153521, parameters k is 10.308788388854014 and b is -42.11834922653843\n",
      "Iteration 3007, the loss is 4.442425932379143, parameters k is 10.30878799952595 and b is -42.118345273969254\n",
      "Iteration 3008, the loss is 4.442425916604761, parameters k is 10.308787610197887 and b is -42.11834132140008\n",
      "Iteration 3009, the loss is 4.442425900830381, parameters k is 10.308787220869824 and b is -42.11833736883091\n",
      "Iteration 3010, the loss is 4.442425885056004, parameters k is 10.308786831541761 and b is -42.118333416261734\n",
      "Iteration 3011, the loss is 4.442425869281624, parameters k is 10.308786442213698 and b is -42.11832946369256\n",
      "Iteration 3012, the loss is 4.4424258535072445, parameters k is 10.308786052885635 and b is -42.11832551112339\n",
      "Iteration 3013, the loss is 4.442425837732864, parameters k is 10.308785663557572 and b is -42.118321558554214\n",
      "Iteration 3014, the loss is 4.442425821958486, parameters k is 10.308785274229509 and b is -42.11831760598504\n",
      "Iteration 3015, the loss is 4.442425806184103, parameters k is 10.308784884901446 and b is -42.11831365341587\n",
      "Iteration 3016, the loss is 4.442425790409725, parameters k is 10.308784495573383 and b is -42.118309700846694\n",
      "Iteration 3017, the loss is 4.442425774635344, parameters k is 10.30878410624532 and b is -42.11830574827752\n",
      "Iteration 3018, the loss is 4.442425758860966, parameters k is 10.308783716917256 and b is -42.11830179570835\n",
      "Iteration 3019, the loss is 4.442425743086586, parameters k is 10.308783327589193 and b is -42.118297843139175\n",
      "Iteration 3020, the loss is 4.442425727312209, parameters k is 10.30878293826113 and b is -42.11829389057\n",
      "Iteration 3021, the loss is 4.442425711537829, parameters k is 10.308782548933067 and b is -42.11828993800083\n",
      "Iteration 3022, the loss is 4.442425695763447, parameters k is 10.308782159605004 and b is -42.118285985431655\n",
      "Iteration 3023, the loss is 4.442425679989068, parameters k is 10.30878177027694 and b is -42.11828203286248\n",
      "Iteration 3024, the loss is 4.44242566421469, parameters k is 10.308781380948878 and b is -42.11827808029331\n",
      "Iteration 3025, the loss is 4.442425648440309, parameters k is 10.308780991620814 and b is -42.118274127724135\n",
      "Iteration 3026, the loss is 4.442425632665932, parameters k is 10.308780602292751 and b is -42.11827017515496\n",
      "Iteration 3027, the loss is 4.442425616891553, parameters k is 10.308780212964688 and b is -42.11826622258579\n",
      "Iteration 3028, the loss is 4.442425601117172, parameters k is 10.308779823636625 and b is -42.118262270016615\n",
      "Iteration 3029, the loss is 4.442425585342793, parameters k is 10.308779434308562 and b is -42.11825831744744\n",
      "Iteration 3030, the loss is 4.442425569568414, parameters k is 10.308779044980499 and b is -42.11825436487827\n",
      "Iteration 3031, the loss is 4.442425553794036, parameters k is 10.308778655652436 and b is -42.118250412309095\n",
      "Iteration 3032, the loss is 4.442425538019657, parameters k is 10.308778266324373 and b is -42.11824645973992\n",
      "Iteration 3033, the loss is 4.442425522245277, parameters k is 10.30877787699631 and b is -42.11824250717075\n",
      "Iteration 3034, the loss is 4.442425506470898, parameters k is 10.308777487668246 and b is -42.118238554601575\n",
      "Iteration 3035, the loss is 4.442425490696516, parameters k is 10.308777098340183 and b is -42.1182346020324\n",
      "Iteration 3036, the loss is 4.442425474922138, parameters k is 10.30877670901212 and b is -42.11823064946323\n",
      "Iteration 3037, the loss is 4.442425459147757, parameters k is 10.308776319684057 and b is -42.118226696894055\n",
      "Iteration 3038, the loss is 4.442425443373379, parameters k is 10.308775930355994 and b is -42.11822274432488\n",
      "Iteration 3039, the loss is 4.442425427599, parameters k is 10.30877554102793 and b is -42.11821879175571\n",
      "Iteration 3040, the loss is 4.44242541182462, parameters k is 10.308775151699868 and b is -42.118214839186535\n",
      "Iteration 3041, the loss is 4.44242539605024, parameters k is 10.308774762371804 and b is -42.11821088661736\n",
      "Iteration 3042, the loss is 4.44242538027586, parameters k is 10.308774373043741 and b is -42.11820693404819\n",
      "Iteration 3043, the loss is 4.442425364501484, parameters k is 10.308773983715678 and b is -42.118202981479016\n",
      "Iteration 3044, the loss is 4.442425348727101, parameters k is 10.308773594387615 and b is -42.11819902890984\n",
      "Iteration 3045, the loss is 4.442425332952723, parameters k is 10.308773205059552 and b is -42.11819507634067\n",
      "Iteration 3046, the loss is 4.442425317178346, parameters k is 10.308772815731489 and b is -42.118191123771496\n",
      "Iteration 3047, the loss is 4.442425301403964, parameters k is 10.308772426403426 and b is -42.11818717120232\n",
      "Iteration 3048, the loss is 4.442425285629586, parameters k is 10.308772037075363 and b is -42.11818321863315\n",
      "Iteration 3049, the loss is 4.442425269855206, parameters k is 10.3087716477473 and b is -42.118179266063976\n",
      "Iteration 3050, the loss is 4.442425254080824, parameters k is 10.308771258419236 and b is -42.1181753134948\n",
      "Iteration 3051, the loss is 4.442425238306448, parameters k is 10.308770869091173 and b is -42.11817136092563\n",
      "Iteration 3052, the loss is 4.442425222532069, parameters k is 10.30877047976311 and b is -42.118167408356456\n",
      "Iteration 3053, the loss is 4.442425206757686, parameters k is 10.308770090435047 and b is -42.11816345578728\n",
      "Iteration 3054, the loss is 4.442425190983308, parameters k is 10.308769701106984 and b is -42.11815950321811\n",
      "Iteration 3055, the loss is 4.442425175208929, parameters k is 10.30876931177892 and b is -42.118155550648936\n",
      "Iteration 3056, the loss is 4.44242515943455, parameters k is 10.308768922450858 and b is -42.11815159807976\n",
      "Iteration 3057, the loss is 4.44242514366017, parameters k is 10.308768533122795 and b is -42.11814764551059\n",
      "Iteration 3058, the loss is 4.442425127885787, parameters k is 10.308768143794731 and b is -42.118143692941416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3059, the loss is 4.442425112111413, parameters k is 10.308767754466668 and b is -42.11813974037224\n",
      "Iteration 3060, the loss is 4.442425096337033, parameters k is 10.308767365138605 and b is -42.11813578780307\n",
      "Iteration 3061, the loss is 4.4424250805626535, parameters k is 10.308766975810542 and b is -42.118131835233896\n",
      "Iteration 3062, the loss is 4.4424250647882735, parameters k is 10.308766586482479 and b is -42.11812788266472\n",
      "Iteration 3063, the loss is 4.442425049013894, parameters k is 10.308766197154416 and b is -42.11812393009555\n",
      "Iteration 3064, the loss is 4.442425033239514, parameters k is 10.308765807826353 and b is -42.118119977526376\n",
      "Iteration 3065, the loss is 4.442425017465136, parameters k is 10.30876541849829 and b is -42.1181160249572\n",
      "Iteration 3066, the loss is 4.442425001690757, parameters k is 10.308765029170226 and b is -42.11811207238803\n",
      "Iteration 3067, the loss is 4.442424985916376, parameters k is 10.308764639842163 and b is -42.11810811981886\n",
      "Iteration 3068, the loss is 4.442424970141998, parameters k is 10.3087642505141 and b is -42.11810416724968\n",
      "Iteration 3069, the loss is 4.442424954367619, parameters k is 10.308763861186037 and b is -42.11810021468051\n",
      "Iteration 3070, the loss is 4.442424938593238, parameters k is 10.308763471857974 and b is -42.11809626211134\n",
      "Iteration 3071, the loss is 4.442424922818861, parameters k is 10.30876308252991 and b is -42.11809230954216\n",
      "Iteration 3072, the loss is 4.442424907044479, parameters k is 10.308762693201848 and b is -42.11808835697299\n",
      "Iteration 3073, the loss is 4.442424891270102, parameters k is 10.308762303873785 and b is -42.11808440440382\n",
      "Iteration 3074, the loss is 4.44242487549572, parameters k is 10.308761914545721 and b is -42.11808045183464\n",
      "Iteration 3075, the loss is 4.442424859721339, parameters k is 10.308761525217658 and b is -42.11807649926547\n",
      "Iteration 3076, the loss is 4.442424843946961, parameters k is 10.308761135889595 and b is -42.1180725466963\n",
      "Iteration 3077, the loss is 4.44242482817258, parameters k is 10.308760746561532 and b is -42.118068594127124\n",
      "Iteration 3078, the loss is 4.442424812398204, parameters k is 10.308760357233469 and b is -42.11806464155795\n",
      "Iteration 3079, the loss is 4.442424796623826, parameters k is 10.308759967905406 and b is -42.11806068898878\n",
      "Iteration 3080, the loss is 4.4424247808494455, parameters k is 10.308759578577343 and b is -42.118056736419604\n",
      "Iteration 3081, the loss is 4.442424765075064, parameters k is 10.30875918924928 and b is -42.11805278385043\n",
      "Iteration 3082, the loss is 4.442424749300686, parameters k is 10.308758799921216 and b is -42.11804883128126\n",
      "Iteration 3083, the loss is 4.442424733526305, parameters k is 10.308758410593153 and b is -42.118044878712084\n",
      "Iteration 3084, the loss is 4.442424717751927, parameters k is 10.30875802126509 and b is -42.11804092614291\n",
      "Iteration 3085, the loss is 4.442424701977548, parameters k is 10.308757631937027 and b is -42.11803697357374\n",
      "Iteration 3086, the loss is 4.442424686203166, parameters k is 10.308757242608964 and b is -42.118033021004564\n",
      "Iteration 3087, the loss is 4.44242467042879, parameters k is 10.3087568532809 and b is -42.11802906843539\n",
      "Iteration 3088, the loss is 4.4424246546544115, parameters k is 10.308756463952838 and b is -42.11802511586622\n",
      "Iteration 3089, the loss is 4.44242463888003, parameters k is 10.308756074624775 and b is -42.118021163297044\n",
      "Iteration 3090, the loss is 4.442424623105651, parameters k is 10.308755685296711 and b is -42.11801721072787\n",
      "Iteration 3091, the loss is 4.442424607331272, parameters k is 10.308755295968648 and b is -42.1180132581587\n",
      "Iteration 3092, the loss is 4.4424245915568905, parameters k is 10.308754906640585 and b is -42.118009305589524\n",
      "Iteration 3093, the loss is 4.442424575782513, parameters k is 10.308754517312522 and b is -42.11800535302035\n",
      "Iteration 3094, the loss is 4.442424564229228, parameters k is 10.308754127984459 and b is -42.11800140045118\n",
      "Iteration 3095, the loss is 4.442424549150802, parameters k is 10.30872624063268 and b is -42.11800140045118\n",
      "Iteration 3096, the loss is 4.442424533376423, parameters k is 10.308725851304617 and b is -42.117997447882004\n",
      "Iteration 3097, the loss is 4.442424517602045, parameters k is 10.308725461976554 and b is -42.11799349531283\n",
      "Iteration 3098, the loss is 4.4424245018276665, parameters k is 10.30872507264849 and b is -42.11798954274366\n",
      "Iteration 3099, the loss is 4.4424244860532855, parameters k is 10.308724683320428 and b is -42.117985590174484\n",
      "Iteration 3100, the loss is 4.442424470278908, parameters k is 10.308724293992364 and b is -42.11798163760531\n",
      "Iteration 3101, the loss is 4.442424454504529, parameters k is 10.308723904664301 and b is -42.11797768503614\n",
      "Iteration 3102, the loss is 4.442424438730148, parameters k is 10.308723515336238 and b is -42.117973732466965\n",
      "Iteration 3103, the loss is 4.44242442295577, parameters k is 10.308723126008175 and b is -42.11796977989779\n",
      "Iteration 3104, the loss is 4.44242440718139, parameters k is 10.308722736680112 and b is -42.11796582732862\n",
      "Iteration 3105, the loss is 4.442424391407012, parameters k is 10.308722347352049 and b is -42.117961874759445\n",
      "Iteration 3106, the loss is 4.442424375632627, parameters k is 10.308721958023986 and b is -42.11795792219027\n",
      "Iteration 3107, the loss is 4.4424243598582525, parameters k is 10.308721568695923 and b is -42.1179539696211\n",
      "Iteration 3108, the loss is 4.442424344083872, parameters k is 10.30872117936786 and b is -42.117950017051925\n",
      "Iteration 3109, the loss is 4.442424328309493, parameters k is 10.308720790039796 and b is -42.11794606448275\n",
      "Iteration 3110, the loss is 4.442424312535113, parameters k is 10.308720400711733 and b is -42.11794211191358\n",
      "Iteration 3111, the loss is 4.442424296760735, parameters k is 10.30872001138367 and b is -42.117938159344405\n",
      "Iteration 3112, the loss is 4.442424280986355, parameters k is 10.308719622055607 and b is -42.11793420677523\n",
      "Iteration 3113, the loss is 4.442424265211976, parameters k is 10.308719232727544 and b is -42.11793025420606\n",
      "Iteration 3114, the loss is 4.442424249437597, parameters k is 10.30871884339948 and b is -42.117926301636885\n",
      "Iteration 3115, the loss is 4.442424233663215, parameters k is 10.308718454071418 and b is -42.11792234906771\n",
      "Iteration 3116, the loss is 4.442424217888834, parameters k is 10.308718064743355 and b is -42.11791839649854\n",
      "Iteration 3117, the loss is 4.442424202114459, parameters k is 10.308717675415291 and b is -42.117914443929365\n",
      "Iteration 3118, the loss is 4.442424186340079, parameters k is 10.308717286087228 and b is -42.11791049136019\n",
      "Iteration 3119, the loss is 4.4424241705657, parameters k is 10.308716896759165 and b is -42.11790653879102\n",
      "Iteration 3120, the loss is 4.442424154791317, parameters k is 10.308716507431102 and b is -42.117902586221845\n",
      "Iteration 3121, the loss is 4.44242413901694, parameters k is 10.308716118103039 and b is -42.11789863365267\n",
      "Iteration 3122, the loss is 4.442424123242561, parameters k is 10.308715728774976 and b is -42.1178946810835\n",
      "Iteration 3123, the loss is 4.442424107468179, parameters k is 10.308715339446913 and b is -42.117890728514325\n",
      "Iteration 3124, the loss is 4.442424091693801, parameters k is 10.30871495011885 and b is -42.11788677594515\n",
      "Iteration 3125, the loss is 4.442424075919422, parameters k is 10.308714560790786 and b is -42.11788282337598\n",
      "Iteration 3126, the loss is 4.4424240601450435, parameters k is 10.308714171462723 and b is -42.117878870806805\n",
      "Iteration 3127, the loss is 4.442424044370665, parameters k is 10.30871378213466 and b is -42.11787491823763\n",
      "Iteration 3128, the loss is 4.442424028596286, parameters k is 10.308713392806597 and b is -42.11787096566846\n",
      "Iteration 3129, the loss is 4.442424012821904, parameters k is 10.308713003478534 and b is -42.117867013099286\n",
      "Iteration 3130, the loss is 4.442423997047526, parameters k is 10.30871261415047 and b is -42.11786306053011\n",
      "Iteration 3131, the loss is 4.442423981273146, parameters k is 10.308712224822408 and b is -42.11785910796094\n",
      "Iteration 3132, the loss is 4.442423965498767, parameters k is 10.308711835494345 and b is -42.117855155391766\n",
      "Iteration 3133, the loss is 4.442423949724388, parameters k is 10.308711446166281 and b is -42.11785120282259\n",
      "Iteration 3134, the loss is 4.442423933950006, parameters k is 10.308711056838218 and b is -42.11784725025342\n",
      "Iteration 3135, the loss is 4.4424239181756295, parameters k is 10.308710667510155 and b is -42.117843297684246\n",
      "Iteration 3136, the loss is 4.442423902401251, parameters k is 10.308710278182092 and b is -42.11783934511507\n",
      "Iteration 3137, the loss is 4.442423886626869, parameters k is 10.308709888854029 and b is -42.1178353925459\n",
      "Iteration 3138, the loss is 4.44242387085249, parameters k is 10.308709499525966 and b is -42.117831439976726\n",
      "Iteration 3139, the loss is 4.442423855078112, parameters k is 10.308709110197903 and b is -42.11782748740755\n",
      "Iteration 3140, the loss is 4.442423839303732, parameters k is 10.30870872086984 and b is -42.11782353483838\n",
      "Iteration 3141, the loss is 4.442423823529351, parameters k is 10.308708331541776 and b is -42.117819582269206\n",
      "Iteration 3142, the loss is 4.442423807754973, parameters k is 10.308707942213713 and b is -42.11781562970003\n",
      "Iteration 3143, the loss is 4.442423791980596, parameters k is 10.30870755288565 and b is -42.11781167713086\n",
      "Iteration 3144, the loss is 4.442423776206216, parameters k is 10.308707163557587 and b is -42.117807724561686\n",
      "Iteration 3145, the loss is 4.442423760431835, parameters k is 10.308706774229524 and b is -42.11780377199251\n",
      "Iteration 3146, the loss is 4.442423744657456, parameters k is 10.30870638490146 and b is -42.11779981942334\n",
      "Iteration 3147, the loss is 4.442423728883076, parameters k is 10.308705995573398 and b is -42.117795866854166\n",
      "Iteration 3148, the loss is 4.442423713108696, parameters k is 10.308705606245335 and b is -42.11779191428499\n",
      "Iteration 3149, the loss is 4.442423697334319, parameters k is 10.308705216917271 and b is -42.11778796171582\n",
      "Iteration 3150, the loss is 4.442423681559936, parameters k is 10.308704827589208 and b is -42.117784009146646\n",
      "Iteration 3151, the loss is 4.44242366578556, parameters k is 10.308704438261145 and b is -42.11778005657747\n",
      "Iteration 3152, the loss is 4.442423650011178, parameters k is 10.308704048933082 and b is -42.1177761040083\n",
      "Iteration 3153, the loss is 4.442423634236799, parameters k is 10.308703659605019 and b is -42.11777215143913\n",
      "Iteration 3154, the loss is 4.44242361846242, parameters k is 10.308703270276956 and b is -42.11776819886995\n",
      "Iteration 3155, the loss is 4.442423602688042, parameters k is 10.308702880948893 and b is -42.11776424630078\n",
      "Iteration 3156, the loss is 4.4424235869136615, parameters k is 10.30870249162083 and b is -42.11776029373161\n",
      "Iteration 3157, the loss is 4.442423571139281, parameters k is 10.308702102292767 and b is -42.11775634116243\n",
      "Iteration 3158, the loss is 4.442423555364903, parameters k is 10.308701712964703 and b is -42.11775238859326\n",
      "Iteration 3159, the loss is 4.442423539590524, parameters k is 10.30870132363664 and b is -42.11774843602409\n",
      "Iteration 3160, the loss is 4.442423523816143, parameters k is 10.308700934308577 and b is -42.11774448345491\n",
      "Iteration 3161, the loss is 4.442423508041762, parameters k is 10.308700544980514 and b is -42.11774053088574\n",
      "Iteration 3162, the loss is 4.442423492267385, parameters k is 10.308700155652451 and b is -42.11773657831657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3163, the loss is 4.442423476493008, parameters k is 10.308699766324388 and b is -42.117732625747394\n",
      "Iteration 3164, the loss is 4.442423460718624, parameters k is 10.308699376996325 and b is -42.11772867317822\n",
      "Iteration 3165, the loss is 4.442423444944246, parameters k is 10.308698987668262 and b is -42.11772472060905\n",
      "Iteration 3166, the loss is 4.442423429169867, parameters k is 10.308698598340198 and b is -42.117720768039874\n",
      "Iteration 3167, the loss is 4.442423413395488, parameters k is 10.308698209012135 and b is -42.1177168154707\n",
      "Iteration 3168, the loss is 4.442423397621107, parameters k is 10.308697819684072 and b is -42.11771286290153\n",
      "Iteration 3169, the loss is 4.442423381846729, parameters k is 10.308697430356009 and b is -42.117708910332354\n",
      "Iteration 3170, the loss is 4.442423366072347, parameters k is 10.308697041027946 and b is -42.11770495776318\n",
      "Iteration 3171, the loss is 4.442423350297971, parameters k is 10.308696651699883 and b is -42.11770100519401\n",
      "Iteration 3172, the loss is 4.442423334523592, parameters k is 10.30869626237182 and b is -42.117697052624834\n",
      "Iteration 3173, the loss is 4.44242331874921, parameters k is 10.308695873043757 and b is -42.11769310005566\n",
      "Iteration 3174, the loss is 4.442423302974832, parameters k is 10.308695483715693 and b is -42.11768914748649\n",
      "Iteration 3175, the loss is 4.442423287200453, parameters k is 10.30869509438763 and b is -42.117685194917314\n",
      "Iteration 3176, the loss is 4.4424232714260725, parameters k is 10.308694705059567 and b is -42.11768124234814\n",
      "Iteration 3177, the loss is 4.442423255651693, parameters k is 10.308694315731504 and b is -42.11767728977897\n",
      "Iteration 3178, the loss is 4.442423239877317, parameters k is 10.308693926403441 and b is -42.117673337209794\n",
      "Iteration 3179, the loss is 4.442423224102935, parameters k is 10.308693537075378 and b is -42.11766938464062\n",
      "Iteration 3180, the loss is 4.442423208328552, parameters k is 10.308693147747315 and b is -42.11766543207145\n",
      "Iteration 3181, the loss is 4.442423192554174, parameters k is 10.308692758419252 and b is -42.117661479502274\n",
      "Iteration 3182, the loss is 4.4424231767797995, parameters k is 10.308692369091188 and b is -42.1176575269331\n",
      "Iteration 3183, the loss is 4.4424231610054195, parameters k is 10.308691979763125 and b is -42.11765357436393\n",
      "Iteration 3184, the loss is 4.44242314523104, parameters k is 10.308691590435062 and b is -42.117649621794754\n",
      "Iteration 3185, the loss is 4.4424231294566585, parameters k is 10.308691201106999 and b is -42.11764566922558\n",
      "Iteration 3186, the loss is 4.442423113682279, parameters k is 10.308690811778936 and b is -42.11764171665641\n",
      "Iteration 3187, the loss is 4.442423097907899, parameters k is 10.308690422450873 and b is -42.117637764087235\n",
      "Iteration 3188, the loss is 4.442423082133521, parameters k is 10.30869003312281 and b is -42.11763381151806\n",
      "Iteration 3189, the loss is 4.44242306635914, parameters k is 10.308689643794747 and b is -42.11762985894889\n",
      "Iteration 3190, the loss is 4.44242305058476, parameters k is 10.308689254466683 and b is -42.117625906379715\n",
      "Iteration 3191, the loss is 4.442423034810382, parameters k is 10.30868886513862 and b is -42.11762195381054\n",
      "Iteration 3192, the loss is 4.442423019036005, parameters k is 10.308688475810557 and b is -42.11761800124137\n",
      "Iteration 3193, the loss is 4.442423003261623, parameters k is 10.308688086482494 and b is -42.117614048672195\n",
      "Iteration 3194, the loss is 4.442422987487244, parameters k is 10.308687697154431 and b is -42.11761009610302\n",
      "Iteration 3195, the loss is 4.442422971712864, parameters k is 10.308687307826368 and b is -42.11760614353385\n",
      "Iteration 3196, the loss is 4.442422955938485, parameters k is 10.308686918498305 and b is -42.117602190964675\n",
      "Iteration 3197, the loss is 4.442422940164105, parameters k is 10.308686529170242 and b is -42.1175982383955\n",
      "Iteration 3198, the loss is 4.442422924389724, parameters k is 10.308686139842179 and b is -42.11759428582633\n",
      "Iteration 3199, the loss is 4.442422908615348, parameters k is 10.308685750514115 and b is -42.117590333257155\n",
      "Iteration 3200, the loss is 4.442422892840967, parameters k is 10.308685361186052 and b is -42.11758638068798\n",
      "Iteration 3201, the loss is 4.442422877066589, parameters k is 10.30868497185799 and b is -42.11758242811881\n",
      "Iteration 3202, the loss is 4.4424228612922105, parameters k is 10.308684582529926 and b is -42.117578475549635\n",
      "Iteration 3203, the loss is 4.442422845517829, parameters k is 10.308684193201863 and b is -42.11757452298046\n",
      "Iteration 3204, the loss is 4.4424228297434505, parameters k is 10.3086838038738 and b is -42.11757057041129\n",
      "Iteration 3205, the loss is 4.442422813969068, parameters k is 10.308683414545737 and b is -42.117566617842115\n",
      "Iteration 3206, the loss is 4.442422798194692, parameters k is 10.308683025217674 and b is -42.11756266527294\n",
      "Iteration 3207, the loss is 4.44242278242031, parameters k is 10.30868263588961 and b is -42.11755871270377\n",
      "Iteration 3208, the loss is 4.4424227666459295, parameters k is 10.308682246561547 and b is -42.117554760134595\n",
      "Iteration 3209, the loss is 4.442422750871553, parameters k is 10.308681857233484 and b is -42.11755080756542\n",
      "Iteration 3210, the loss is 4.442422735097173, parameters k is 10.308681467905421 and b is -42.11754685499625\n",
      "Iteration 3211, the loss is 4.442422719322792, parameters k is 10.308681078577358 and b is -42.117542902427076\n",
      "Iteration 3212, the loss is 4.442422703548416, parameters k is 10.308680689249295 and b is -42.1175389498579\n",
      "Iteration 3213, the loss is 4.442422687774036, parameters k is 10.308680299921232 and b is -42.11753499728873\n",
      "Iteration 3214, the loss is 4.442422671999653, parameters k is 10.308679910593169 and b is -42.117531044719556\n",
      "Iteration 3215, the loss is 4.442422656225277, parameters k is 10.308679521265105 and b is -42.11752709215038\n",
      "Iteration 3216, the loss is 4.442422640450897, parameters k is 10.308679131937042 and b is -42.11752313958121\n",
      "Iteration 3217, the loss is 4.44242262467652, parameters k is 10.30867874260898 and b is -42.117519187012036\n",
      "Iteration 3218, the loss is 4.442422608902137, parameters k is 10.308678353280916 and b is -42.11751523444286\n",
      "Iteration 3219, the loss is 4.442422593127756, parameters k is 10.308677963952853 and b is -42.11751128187369\n",
      "Iteration 3220, the loss is 4.442422577353381, parameters k is 10.30867757462479 and b is -42.117507329304516\n",
      "Iteration 3221, the loss is 4.442422561579, parameters k is 10.308677185296727 and b is -42.11750337673534\n",
      "Iteration 3222, the loss is 4.442422545804621, parameters k is 10.308676795968664 and b is -42.11749942416617\n",
      "Iteration 3223, the loss is 4.4424225300302425, parameters k is 10.3086764066406 and b is -42.117495471596996\n",
      "Iteration 3224, the loss is 4.442422514255861, parameters k is 10.308676017312537 and b is -42.11749151902782\n",
      "Iteration 3225, the loss is 4.4424224984814815, parameters k is 10.308675627984474 and b is -42.11748756645865\n",
      "Iteration 3226, the loss is 4.442422482707105, parameters k is 10.308675238656411 and b is -42.117483613889476\n",
      "Iteration 3227, the loss is 4.442422466932722, parameters k is 10.308674849328348 and b is -42.1174796613203\n",
      "Iteration 3228, the loss is 4.442422451158342, parameters k is 10.308674460000285 and b is -42.11747570875113\n",
      "Iteration 3229, the loss is 4.442422435383967, parameters k is 10.308674070672222 and b is -42.117471756181956\n",
      "Iteration 3230, the loss is 4.442422419609584, parameters k is 10.308673681344159 and b is -42.11746780361278\n",
      "Iteration 3231, the loss is 4.442422403835205, parameters k is 10.308673292016096 and b is -42.11746385104361\n",
      "Iteration 3232, the loss is 4.442422388060827, parameters k is 10.308672902688032 and b is -42.117459898474436\n",
      "Iteration 3233, the loss is 4.442422372286444, parameters k is 10.30867251335997 and b is -42.11745594590526\n",
      "Iteration 3234, the loss is 4.442422356512069, parameters k is 10.308672124031906 and b is -42.11745199333609\n",
      "Iteration 3235, the loss is 4.442422340737691, parameters k is 10.308671734703843 and b is -42.11744804076692\n",
      "Iteration 3236, the loss is 4.442422324963308, parameters k is 10.30867134537578 and b is -42.11744408819774\n",
      "Iteration 3237, the loss is 4.442422309188932, parameters k is 10.308670956047717 and b is -42.11744013562857\n",
      "Iteration 3238, the loss is 4.442422293414553, parameters k is 10.308670566719654 and b is -42.1174361830594\n",
      "Iteration 3239, the loss is 4.442422277640169, parameters k is 10.30867017739159 and b is -42.11743223049022\n",
      "Iteration 3240, the loss is 4.442422261865793, parameters k is 10.308669788063527 and b is -42.11742827792105\n",
      "Iteration 3241, the loss is 4.442422246091412, parameters k is 10.308669398735464 and b is -42.11742432535188\n",
      "Iteration 3242, the loss is 4.4424222303170335, parameters k is 10.308669009407401 and b is -42.1174203727827\n",
      "Iteration 3243, the loss is 4.442422214542656, parameters k is 10.308668620079338 and b is -42.11741642021353\n",
      "Iteration 3244, the loss is 4.442422198768274, parameters k is 10.308668230751275 and b is -42.11741246764436\n",
      "Iteration 3245, the loss is 4.442422182993894, parameters k is 10.308667841423212 and b is -42.117408515075184\n",
      "Iteration 3246, the loss is 4.442422167219516, parameters k is 10.308667452095149 and b is -42.11740456250601\n",
      "Iteration 3247, the loss is 4.442422151445136, parameters k is 10.308667062767086 and b is -42.11740060993684\n",
      "Iteration 3248, the loss is 4.442422135670756, parameters k is 10.308666673439022 and b is -42.117396657367664\n",
      "Iteration 3249, the loss is 4.44242211989638, parameters k is 10.30866628411096 and b is -42.11739270479849\n",
      "Iteration 3250, the loss is 4.442422104121996, parameters k is 10.308665894782896 and b is -42.11738875222932\n",
      "Iteration 3251, the loss is 4.442422092781567, parameters k is 10.308665505454833 and b is -42.117384799660144\n",
      "Iteration 3252, the loss is 4.442422077490291, parameters k is 10.308637618103054 and b is -42.117384799660144\n",
      "Iteration 3253, the loss is 4.442422061715911, parameters k is 10.308637228774991 and b is -42.11738084709097\n",
      "Iteration 3254, the loss is 4.442422045941532, parameters k is 10.308636839446928 and b is -42.1173768945218\n",
      "Iteration 3255, the loss is 4.442422030167153, parameters k is 10.308636450118865 and b is -42.117372941952624\n",
      "Iteration 3256, the loss is 4.442422014392771, parameters k is 10.308636060790802 and b is -42.11736898938345\n",
      "Iteration 3257, the loss is 4.442421998618393, parameters k is 10.308635671462739 and b is -42.11736503681428\n",
      "Iteration 3258, the loss is 4.4424219828440155, parameters k is 10.308635282134675 and b is -42.117361084245104\n",
      "Iteration 3259, the loss is 4.442421967069633, parameters k is 10.308634892806612 and b is -42.11735713167593\n",
      "Iteration 3260, the loss is 4.442421951295254, parameters k is 10.30863450347855 and b is -42.11735317910676\n",
      "Iteration 3261, the loss is 4.442421935520876, parameters k is 10.308634114150486 and b is -42.117349226537584\n",
      "Iteration 3262, the loss is 4.4424219197464945, parameters k is 10.308633724822423 and b is -42.11734527396841\n",
      "Iteration 3263, the loss is 4.442421903972118, parameters k is 10.30863333549436 and b is -42.11734132139924\n",
      "Iteration 3264, the loss is 4.442421888197737, parameters k is 10.308632946166297 and b is -42.117337368830064\n",
      "Iteration 3265, the loss is 4.442421872423357, parameters k is 10.308632556838234 and b is -42.11733341626089\n",
      "Iteration 3266, the loss is 4.442421856648978, parameters k is 10.30863216751017 and b is -42.11732946369172\n",
      "Iteration 3267, the loss is 4.442421840874597, parameters k is 10.308631778182107 and b is -42.117325511122544\n",
      "Iteration 3268, the loss is 4.442421825100218, parameters k is 10.308631388854044 and b is -42.11732155855337\n",
      "Iteration 3269, the loss is 4.442421809325839, parameters k is 10.308630999525981 and b is -42.1173176059842\n",
      "Iteration 3270, the loss is 4.442421793551459, parameters k is 10.308630610197918 and b is -42.117313653415025\n",
      "Iteration 3271, the loss is 4.442421777777081, parameters k is 10.308630220869855 and b is -42.11730970084585\n",
      "Iteration 3272, the loss is 4.442421762002701, parameters k is 10.308629831541792 and b is -42.11730574827668\n",
      "Iteration 3273, the loss is 4.442421746228321, parameters k is 10.308629442213729 and b is -42.117301795707505\n",
      "Iteration 3274, the loss is 4.442421730453944, parameters k is 10.308629052885665 and b is -42.11729784313833\n",
      "Iteration 3275, the loss is 4.44242171467956, parameters k is 10.308628663557602 and b is -42.11729389056916\n",
      "Iteration 3276, the loss is 4.442421698905185, parameters k is 10.30862827422954 and b is -42.117289937999985\n",
      "Iteration 3277, the loss is 4.442421683130806, parameters k is 10.308627884901476 and b is -42.11728598543081\n",
      "Iteration 3278, the loss is 4.442421667356425, parameters k is 10.308627495573413 and b is -42.11728203286164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3279, the loss is 4.442421651582044, parameters k is 10.30862710624535 and b is -42.117278080292465\n",
      "Iteration 3280, the loss is 4.442421635807666, parameters k is 10.308626716917287 and b is -42.11727412772329\n",
      "Iteration 3281, the loss is 4.442421620033287, parameters k is 10.308626327589224 and b is -42.11727017515412\n",
      "Iteration 3282, the loss is 4.442421604258907, parameters k is 10.30862593826116 and b is -42.117266222584945\n",
      "Iteration 3283, the loss is 4.442421588484528, parameters k is 10.308625548933097 and b is -42.11726227001577\n",
      "Iteration 3284, the loss is 4.442421572710149, parameters k is 10.308625159605034 and b is -42.1172583174466\n",
      "Iteration 3285, the loss is 4.442421556935768, parameters k is 10.308624770276971 and b is -42.117254364877425\n",
      "Iteration 3286, the loss is 4.442421541161391, parameters k is 10.308624380948908 and b is -42.11725041230825\n",
      "Iteration 3287, the loss is 4.442421525387011, parameters k is 10.308623991620845 and b is -42.11724645973908\n",
      "Iteration 3288, the loss is 4.442421509612631, parameters k is 10.308623602292782 and b is -42.117242507169905\n",
      "Iteration 3289, the loss is 4.442421493838252, parameters k is 10.308623212964719 and b is -42.11723855460073\n",
      "Iteration 3290, the loss is 4.442421478063873, parameters k is 10.308622823636655 and b is -42.11723460203156\n",
      "Iteration 3291, the loss is 4.442421462289495, parameters k is 10.308622434308592 and b is -42.117230649462385\n",
      "Iteration 3292, the loss is 4.442421446515116, parameters k is 10.30862204498053 and b is -42.11722669689321\n",
      "Iteration 3293, the loss is 4.442421430740736, parameters k is 10.308621655652466 and b is -42.11722274432404\n",
      "Iteration 3294, the loss is 4.4424214149663515, parameters k is 10.308621266324403 and b is -42.117218791754865\n",
      "Iteration 3295, the loss is 4.442421399191975, parameters k is 10.30862087699634 and b is -42.11721483918569\n",
      "Iteration 3296, the loss is 4.442421383417597, parameters k is 10.308620487668277 and b is -42.11721088661652\n",
      "Iteration 3297, the loss is 4.442421367643217, parameters k is 10.308620098340214 and b is -42.117206934047346\n",
      "Iteration 3298, the loss is 4.442421351868839, parameters k is 10.30861970901215 and b is -42.11720298147817\n",
      "Iteration 3299, the loss is 4.442421336094458, parameters k is 10.308619319684087 and b is -42.117199028909\n",
      "Iteration 3300, the loss is 4.442421320320078, parameters k is 10.308618930356024 and b is -42.117195076339826\n",
      "Iteration 3301, the loss is 4.442421304545699, parameters k is 10.308618541027961 and b is -42.11719112377065\n",
      "Iteration 3302, the loss is 4.442421288771321, parameters k is 10.308618151699898 and b is -42.11718717120148\n",
      "Iteration 3303, the loss is 4.442421272996939, parameters k is 10.308617762371835 and b is -42.117183218632306\n",
      "Iteration 3304, the loss is 4.442421257222561, parameters k is 10.308617373043772 and b is -42.11717926606313\n",
      "Iteration 3305, the loss is 4.442421241448181, parameters k is 10.308616983715709 and b is -42.11717531349396\n",
      "Iteration 3306, the loss is 4.442421225673801, parameters k is 10.308616594387646 and b is -42.117171360924786\n",
      "Iteration 3307, the loss is 4.442421209899424, parameters k is 10.308616205059582 and b is -42.11716740835561\n",
      "Iteration 3308, the loss is 4.442421194125043, parameters k is 10.30861581573152 and b is -42.11716345578644\n",
      "Iteration 3309, the loss is 4.442421178350665, parameters k is 10.308615426403456 and b is -42.117159503217266\n",
      "Iteration 3310, the loss is 4.442421162576285, parameters k is 10.308615037075393 and b is -42.11715555064809\n",
      "Iteration 3311, the loss is 4.442421146801907, parameters k is 10.30861464774733 and b is -42.11715159807892\n",
      "Iteration 3312, the loss is 4.442421131027527, parameters k is 10.308614258419267 and b is -42.117147645509746\n",
      "Iteration 3313, the loss is 4.442421115253147, parameters k is 10.308613869091204 and b is -42.11714369294057\n",
      "Iteration 3314, the loss is 4.442421099478764, parameters k is 10.30861347976314 and b is -42.1171397403714\n",
      "Iteration 3315, the loss is 4.442421083704389, parameters k is 10.308613090435077 and b is -42.117135787802226\n",
      "Iteration 3316, the loss is 4.442421067930007, parameters k is 10.308612701107014 and b is -42.11713183523305\n",
      "Iteration 3317, the loss is 4.44242105215563, parameters k is 10.308612311778951 and b is -42.11712788266388\n",
      "Iteration 3318, the loss is 4.4424210363812495, parameters k is 10.308611922450888 and b is -42.11712393009471\n",
      "Iteration 3319, the loss is 4.442421020606871, parameters k is 10.308611533122825 and b is -42.11711997752553\n",
      "Iteration 3320, the loss is 4.442421004832492, parameters k is 10.308611143794762 and b is -42.11711602495636\n",
      "Iteration 3321, the loss is 4.4424209890581094, parameters k is 10.308610754466699 and b is -42.11711207238719\n",
      "Iteration 3322, the loss is 4.4424209732837285, parameters k is 10.308610365138636 and b is -42.11710811981801\n",
      "Iteration 3323, the loss is 4.44242095750935, parameters k is 10.308609975810572 and b is -42.11710416724884\n",
      "Iteration 3324, the loss is 4.442420941734976, parameters k is 10.30860958648251 and b is -42.11710021467967\n",
      "Iteration 3325, the loss is 4.442420925960595, parameters k is 10.308609197154446 and b is -42.11709626211049\n",
      "Iteration 3326, the loss is 4.442420910186216, parameters k is 10.308608807826383 and b is -42.11709230954132\n",
      "Iteration 3327, the loss is 4.442420894411834, parameters k is 10.30860841849832 and b is -42.11708835697215\n",
      "Iteration 3328, the loss is 4.442420878637457, parameters k is 10.308608029170257 and b is -42.11708440440297\n",
      "Iteration 3329, the loss is 4.442420862863073, parameters k is 10.308607639842194 and b is -42.1170804518338\n",
      "Iteration 3330, the loss is 4.442420847088698, parameters k is 10.30860725051413 and b is -42.11707649926463\n",
      "Iteration 3331, the loss is 4.442420831314316, parameters k is 10.308606861186068 and b is -42.117072546695454\n",
      "Iteration 3332, the loss is 4.442420815539938, parameters k is 10.308606471858004 and b is -42.11706859412628\n",
      "Iteration 3333, the loss is 4.442420799765555, parameters k is 10.308606082529941 and b is -42.11706464155711\n",
      "Iteration 3334, the loss is 4.44242078399118, parameters k is 10.308605693201878 and b is -42.117060688987934\n",
      "Iteration 3335, the loss is 4.4424207682168015, parameters k is 10.308605303873815 and b is -42.11705673641876\n",
      "Iteration 3336, the loss is 4.442420752442421, parameters k is 10.308604914545752 and b is -42.11705278384959\n",
      "Iteration 3337, the loss is 4.4424207366680415, parameters k is 10.308604525217689 and b is -42.117048831280414\n",
      "Iteration 3338, the loss is 4.442420720893662, parameters k is 10.308604135889626 and b is -42.11704487871124\n",
      "Iteration 3339, the loss is 4.442420705119282, parameters k is 10.308603746561563 and b is -42.11704092614207\n",
      "Iteration 3340, the loss is 4.442420689344904, parameters k is 10.3086033572335 and b is -42.117036973572894\n",
      "Iteration 3341, the loss is 4.442420673570523, parameters k is 10.308602967905436 and b is -42.11703302100372\n",
      "Iteration 3342, the loss is 4.442420657796144, parameters k is 10.308602578577373 and b is -42.11702906843455\n",
      "Iteration 3343, the loss is 4.442420642021765, parameters k is 10.30860218924931 and b is -42.117025115865374\n",
      "Iteration 3344, the loss is 4.442420626247387, parameters k is 10.308601799921247 and b is -42.1170211632962\n",
      "Iteration 3345, the loss is 4.442420610473006, parameters k is 10.308601410593184 and b is -42.11701721072703\n",
      "Iteration 3346, the loss is 4.442420594698625, parameters k is 10.30860102126512 and b is -42.117013258157854\n",
      "Iteration 3347, the loss is 4.442420578924248, parameters k is 10.308600631937058 and b is -42.11700930558868\n",
      "Iteration 3348, the loss is 4.442420563149868, parameters k is 10.308600242608994 and b is -42.11700535301951\n",
      "Iteration 3349, the loss is 4.442420547375487, parameters k is 10.308599853280931 and b is -42.117001400450334\n",
      "Iteration 3350, the loss is 4.442420531601109, parameters k is 10.308599463952868 and b is -42.11699744788116\n",
      "Iteration 3351, the loss is 4.442420515826727, parameters k is 10.308599074624805 and b is -42.11699349531199\n",
      "Iteration 3352, the loss is 4.442420500052348, parameters k is 10.308598685296742 and b is -42.116989542742814\n",
      "Iteration 3353, the loss is 4.442420484277972, parameters k is 10.308598295968679 and b is -42.11698559017364\n",
      "Iteration 3354, the loss is 4.442420468503592, parameters k is 10.308597906640616 and b is -42.11698163760447\n",
      "Iteration 3355, the loss is 4.442420452729213, parameters k is 10.308597517312553 and b is -42.116977685035295\n",
      "Iteration 3356, the loss is 4.4424204369548335, parameters k is 10.30859712798449 and b is -42.11697373246612\n",
      "Iteration 3357, the loss is 4.442420421180454, parameters k is 10.308596738656426 and b is -42.11696977989695\n",
      "Iteration 3358, the loss is 4.442420405406075, parameters k is 10.308596349328363 and b is -42.116965827327775\n",
      "Iteration 3359, the loss is 4.442420389631693, parameters k is 10.3085959600003 and b is -42.1169618747586\n",
      "Iteration 3360, the loss is 4.442420373857314, parameters k is 10.308595570672237 and b is -42.11695792218943\n",
      "Iteration 3361, the loss is 4.442420358082936, parameters k is 10.308595181344174 and b is -42.116953969620255\n",
      "Iteration 3362, the loss is 4.442420342308557, parameters k is 10.30859479201611 and b is -42.11695001705108\n",
      "Iteration 3363, the loss is 4.442420326534178, parameters k is 10.308594402688048 and b is -42.11694606448191\n",
      "Iteration 3364, the loss is 4.442420310759799, parameters k is 10.308594013359984 and b is -42.116942111912735\n",
      "Iteration 3365, the loss is 4.44242029498542, parameters k is 10.308593624031921 and b is -42.11693815934356\n",
      "Iteration 3366, the loss is 4.442420279211037, parameters k is 10.308593234703858 and b is -42.11693420677439\n",
      "Iteration 3367, the loss is 4.442420263436659, parameters k is 10.308592845375795 and b is -42.116930254205215\n",
      "Iteration 3368, the loss is 4.442420247662279, parameters k is 10.308592456047732 and b is -42.11692630163604\n",
      "Iteration 3369, the loss is 4.4424202318879, parameters k is 10.308592066719669 and b is -42.11692234906687\n",
      "Iteration 3370, the loss is 4.442420216113521, parameters k is 10.308591677391606 and b is -42.116918396497695\n",
      "Iteration 3371, the loss is 4.44242020033914, parameters k is 10.308591288063543 and b is -42.11691444392852\n",
      "Iteration 3372, the loss is 4.44242018456476, parameters k is 10.30859089873548 and b is -42.11691049135935\n",
      "Iteration 3373, the loss is 4.442420168790384, parameters k is 10.308590509407416 and b is -42.116906538790175\n",
      "Iteration 3374, the loss is 4.442420153016004, parameters k is 10.308590120079353 and b is -42.116902586221\n",
      "Iteration 3375, the loss is 4.442420137241624, parameters k is 10.30858973075129 and b is -42.11689863365183\n",
      "Iteration 3376, the loss is 4.4424201214672445, parameters k is 10.308589341423227 and b is -42.116894681082655\n",
      "Iteration 3377, the loss is 4.4424201056928645, parameters k is 10.308588952095164 and b is -42.11689072851348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3378, the loss is 4.442420089918488, parameters k is 10.3085885627671 and b is -42.11688677594431\n",
      "Iteration 3379, the loss is 4.4424200741441044, parameters k is 10.308588173439038 and b is -42.116882823375136\n",
      "Iteration 3380, the loss is 4.442420058369724, parameters k is 10.308587784110975 and b is -42.11687887080596\n",
      "Iteration 3381, the loss is 4.442420042595347, parameters k is 10.308587394782911 and b is -42.11687491823679\n",
      "Iteration 3382, the loss is 4.442420026820966, parameters k is 10.308587005454848 and b is -42.116870965667616\n",
      "Iteration 3383, the loss is 4.4424200110465915, parameters k is 10.308586616126785 and b is -42.11686701309844\n",
      "Iteration 3384, the loss is 4.442419995272211, parameters k is 10.308586226798722 and b is -42.11686306052927\n",
      "Iteration 3385, the loss is 4.442419979497829, parameters k is 10.308585837470659 and b is -42.116859107960096\n",
      "Iteration 3386, the loss is 4.4424199637234505, parameters k is 10.308585448142596 and b is -42.11685515539092\n",
      "Iteration 3387, the loss is 4.4424199479490705, parameters k is 10.308585058814533 and b is -42.11685120282175\n",
      "Iteration 3388, the loss is 4.442419932174692, parameters k is 10.30858466948647 and b is -42.116847250252576\n",
      "Iteration 3389, the loss is 4.442419916400313, parameters k is 10.308584280158406 and b is -42.1168432976834\n",
      "Iteration 3390, the loss is 4.442419900625933, parameters k is 10.308583890830343 and b is -42.11683934511423\n",
      "Iteration 3391, the loss is 4.442419884851554, parameters k is 10.30858350150228 and b is -42.116835392545056\n",
      "Iteration 3392, the loss is 4.442419869077174, parameters k is 10.308583112174217 and b is -42.11683143997588\n",
      "Iteration 3393, the loss is 4.442419853302791, parameters k is 10.308582722846154 and b is -42.11682748740671\n",
      "Iteration 3394, the loss is 4.442419837528416, parameters k is 10.30858233351809 and b is -42.116823534837536\n",
      "Iteration 3395, the loss is 4.442419821754035, parameters k is 10.308581944190028 and b is -42.11681958226836\n",
      "Iteration 3396, the loss is 4.442419805979655, parameters k is 10.308581554861965 and b is -42.11681562969919\n",
      "Iteration 3397, the loss is 4.442419790205277, parameters k is 10.308581165533901 and b is -42.116811677130016\n",
      "Iteration 3398, the loss is 4.442419774430899, parameters k is 10.308580776205838 and b is -42.11680772456084\n",
      "Iteration 3399, the loss is 4.442419758656517, parameters k is 10.308580386877775 and b is -42.11680377199167\n",
      "Iteration 3400, the loss is 4.442419742882138, parameters k is 10.308579997549712 and b is -42.116799819422496\n",
      "Iteration 3401, the loss is 4.442419727107758, parameters k is 10.308579608221649 and b is -42.11679586685332\n",
      "Iteration 3402, the loss is 4.442419711333377, parameters k is 10.308579218893586 and b is -42.11679191428415\n",
      "Iteration 3403, the loss is 4.442419695559001, parameters k is 10.308578829565523 and b is -42.11678796171498\n",
      "Iteration 3404, the loss is 4.442419679784624, parameters k is 10.30857844023746 and b is -42.1167840091458\n",
      "Iteration 3405, the loss is 4.442419664010242, parameters k is 10.308578050909396 and b is -42.11678005657663\n",
      "Iteration 3406, the loss is 4.44241964823586, parameters k is 10.308577661581333 and b is -42.11677610400746\n",
      "Iteration 3407, the loss is 4.442419632461484, parameters k is 10.30857727225327 and b is -42.11677215143828\n",
      "Iteration 3408, the loss is 4.44241962133391, parameters k is 10.308576882925207 and b is -42.11676819886911\n",
      "Iteration 3409, the loss is 4.442419605829774, parameters k is 10.308548995573428 and b is -42.11676819886911\n",
      "Iteration 3410, the loss is 4.442419590055397, parameters k is 10.308548606245365 and b is -42.11676424629994\n",
      "Iteration 3411, the loss is 4.442419574281015, parameters k is 10.308548216917302 and b is -42.11676029373076\n",
      "Iteration 3412, the loss is 4.442419558506635, parameters k is 10.308547827589239 and b is -42.11675634116159\n",
      "Iteration 3413, the loss is 4.44241954273226, parameters k is 10.308547438261176 and b is -42.11675238859242\n",
      "Iteration 3414, the loss is 4.4424195269578775, parameters k is 10.308547048933113 and b is -42.116748436023244\n",
      "Iteration 3415, the loss is 4.442419511183498, parameters k is 10.30854665960505 and b is -42.11674448345407\n",
      "Iteration 3416, the loss is 4.442419495409119, parameters k is 10.308546270276986 and b is -42.1167405308849\n",
      "Iteration 3417, the loss is 4.442419479634738, parameters k is 10.308545880948923 and b is -42.116736578315724\n",
      "Iteration 3418, the loss is 4.44241946386036, parameters k is 10.30854549162086 and b is -42.11673262574655\n",
      "Iteration 3419, the loss is 4.442419448085981, parameters k is 10.308545102292797 and b is -42.11672867317738\n",
      "Iteration 3420, the loss is 4.442419432311603, parameters k is 10.308544712964734 and b is -42.116724720608204\n",
      "Iteration 3421, the loss is 4.442419416537222, parameters k is 10.30854432363667 and b is -42.11672076803903\n",
      "Iteration 3422, the loss is 4.442419400762845, parameters k is 10.308543934308608 and b is -42.11671681546986\n",
      "Iteration 3423, the loss is 4.442419384988465, parameters k is 10.308543544980544 and b is -42.116712862900684\n",
      "Iteration 3424, the loss is 4.442419369214085, parameters k is 10.308543155652481 and b is -42.11670891033151\n",
      "Iteration 3425, the loss is 4.442419353439704, parameters k is 10.308542766324418 and b is -42.11670495776234\n",
      "Iteration 3426, the loss is 4.442419337665324, parameters k is 10.308542376996355 and b is -42.116701005193164\n",
      "Iteration 3427, the loss is 4.442419321890945, parameters k is 10.308541987668292 and b is -42.11669705262399\n",
      "Iteration 3428, the loss is 4.442419306116567, parameters k is 10.308541598340229 and b is -42.11669310005482\n",
      "Iteration 3429, the loss is 4.442419290342187, parameters k is 10.308541209012166 and b is -42.116689147485644\n",
      "Iteration 3430, the loss is 4.442419274567806, parameters k is 10.308540819684103 and b is -42.11668519491647\n",
      "Iteration 3431, the loss is 4.442419258793428, parameters k is 10.30854043035604 and b is -42.1166812423473\n",
      "Iteration 3432, the loss is 4.4424192430190494, parameters k is 10.308540041027976 and b is -42.116677289778124\n",
      "Iteration 3433, the loss is 4.4424192272446685, parameters k is 10.308539651699913 and b is -42.11667333720895\n",
      "Iteration 3434, the loss is 4.4424192114702885, parameters k is 10.30853926237185 and b is -42.11666938463978\n",
      "Iteration 3435, the loss is 4.44241919569591, parameters k is 10.308538873043787 and b is -42.116665432070604\n",
      "Iteration 3436, the loss is 4.442419179921529, parameters k is 10.308538483715724 and b is -42.11666147950143\n",
      "Iteration 3437, the loss is 4.442419164147153, parameters k is 10.30853809438766 and b is -42.11665752693226\n",
      "Iteration 3438, the loss is 4.442419148372773, parameters k is 10.308537705059598 and b is -42.116653574363085\n",
      "Iteration 3439, the loss is 4.442419132598393, parameters k is 10.308537315731535 and b is -42.11664962179391\n",
      "Iteration 3440, the loss is 4.442419116824014, parameters k is 10.308536926403471 and b is -42.11664566922474\n",
      "Iteration 3441, the loss is 4.442419101049632, parameters k is 10.308536537075408 and b is -42.116641716655565\n",
      "Iteration 3442, the loss is 4.4424190852752545, parameters k is 10.308536147747345 and b is -42.11663776408639\n",
      "Iteration 3443, the loss is 4.442419069500875, parameters k is 10.308535758419282 and b is -42.11663381151722\n",
      "Iteration 3444, the loss is 4.442419053726496, parameters k is 10.308535369091219 and b is -42.116629858948045\n",
      "Iteration 3445, the loss is 4.442419037952115, parameters k is 10.308534979763156 and b is -42.11662590637887\n",
      "Iteration 3446, the loss is 4.442419022177737, parameters k is 10.308534590435093 and b is -42.1166219538097\n",
      "Iteration 3447, the loss is 4.442419006403359, parameters k is 10.30853420110703 and b is -42.116618001240525\n",
      "Iteration 3448, the loss is 4.44241899062898, parameters k is 10.308533811778966 and b is -42.11661404867135\n",
      "Iteration 3449, the loss is 4.442418974854599, parameters k is 10.308533422450903 and b is -42.11661009610218\n",
      "Iteration 3450, the loss is 4.442418959080219, parameters k is 10.30853303312284 and b is -42.116606143533005\n",
      "Iteration 3451, the loss is 4.442418943305839, parameters k is 10.308532643794777 and b is -42.11660219096383\n",
      "Iteration 3452, the loss is 4.4424189275314605, parameters k is 10.308532254466714 and b is -42.11659823839466\n",
      "Iteration 3453, the loss is 4.442418911757081, parameters k is 10.30853186513865 and b is -42.116594285825485\n",
      "Iteration 3454, the loss is 4.442418895982703, parameters k is 10.308531475810588 and b is -42.11659033325631\n",
      "Iteration 3455, the loss is 4.442418880208322, parameters k is 10.308531086482525 and b is -42.11658638068714\n",
      "Iteration 3456, the loss is 4.442418864433942, parameters k is 10.308530697154461 and b is -42.116582428117965\n",
      "Iteration 3457, the loss is 4.442418848659566, parameters k is 10.308530307826398 and b is -42.11657847554879\n",
      "Iteration 3458, the loss is 4.442418832885185, parameters k is 10.308529918498335 and b is -42.11657452297962\n",
      "Iteration 3459, the loss is 4.442418817110803, parameters k is 10.308529529170272 and b is -42.116570570410445\n",
      "Iteration 3460, the loss is 4.442418801336425, parameters k is 10.308529139842209 and b is -42.11656661784127\n",
      "Iteration 3461, the loss is 4.4424187855620465, parameters k is 10.308528750514146 and b is -42.1165626652721\n",
      "Iteration 3462, the loss is 4.442418769787667, parameters k is 10.308528361186083 and b is -42.116558712702926\n",
      "Iteration 3463, the loss is 4.4424187540132865, parameters k is 10.30852797185802 and b is -42.11655476013375\n",
      "Iteration 3464, the loss is 4.442418738238908, parameters k is 10.308527582529956 and b is -42.11655080756458\n",
      "Iteration 3465, the loss is 4.442418722464528, parameters k is 10.308527193201893 and b is -42.116546854995406\n",
      "Iteration 3466, the loss is 4.442418706690147, parameters k is 10.30852680387383 and b is -42.11654290242623\n",
      "Iteration 3467, the loss is 4.442418690915771, parameters k is 10.308526414545767 and b is -42.11653894985706\n",
      "Iteration 3468, the loss is 4.442418675141389, parameters k is 10.308526025217704 and b is -42.116534997287886\n",
      "Iteration 3469, the loss is 4.442418659367009, parameters k is 10.30852563588964 and b is -42.11653104471871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3470, the loss is 4.442418643592632, parameters k is 10.308525246561578 and b is -42.11652709214954\n",
      "Iteration 3471, the loss is 4.4424186278182525, parameters k is 10.308524857233515 and b is -42.116523139580366\n",
      "Iteration 3472, the loss is 4.4424186120438725, parameters k is 10.308524467905452 and b is -42.11651918701119\n",
      "Iteration 3473, the loss is 4.442418596269493, parameters k is 10.308524078577388 and b is -42.11651523444202\n",
      "Iteration 3474, the loss is 4.442418580495113, parameters k is 10.308523689249325 and b is -42.116511281872846\n",
      "Iteration 3475, the loss is 4.442418564720734, parameters k is 10.308523299921262 and b is -42.11650732930367\n",
      "Iteration 3476, the loss is 4.442418548946356, parameters k is 10.308522910593199 and b is -42.1165033767345\n",
      "Iteration 3477, the loss is 4.442418533171978, parameters k is 10.308522521265136 and b is -42.116499424165326\n",
      "Iteration 3478, the loss is 4.442418517397595, parameters k is 10.308522131937073 and b is -42.11649547159615\n",
      "Iteration 3479, the loss is 4.442418501623218, parameters k is 10.30852174260901 and b is -42.11649151902698\n",
      "Iteration 3480, the loss is 4.442418485848837, parameters k is 10.308521353280947 and b is -42.116487566457806\n",
      "Iteration 3481, the loss is 4.4424184700744584, parameters k is 10.308520963952883 and b is -42.11648361388863\n",
      "Iteration 3482, the loss is 4.442418454300079, parameters k is 10.30852057462482 and b is -42.11647966131946\n",
      "Iteration 3483, the loss is 4.4424184385257, parameters k is 10.308520185296757 and b is -42.116475708750286\n",
      "Iteration 3484, the loss is 4.442418422751325, parameters k is 10.308519795968694 and b is -42.11647175618111\n",
      "Iteration 3485, the loss is 4.442418406976938, parameters k is 10.308519406640631 and b is -42.11646780361194\n",
      "Iteration 3486, the loss is 4.442418391202562, parameters k is 10.308519017312568 and b is -42.11646385104277\n",
      "Iteration 3487, the loss is 4.4424183754281845, parameters k is 10.308518627984505 and b is -42.11645989847359\n",
      "Iteration 3488, the loss is 4.4424183596538, parameters k is 10.308518238656442 and b is -42.11645594590442\n",
      "Iteration 3489, the loss is 4.4424183438794245, parameters k is 10.308517849328378 and b is -42.11645199333525\n",
      "Iteration 3490, the loss is 4.442418328105043, parameters k is 10.308517460000315 and b is -42.11644804076607\n",
      "Iteration 3491, the loss is 4.4424183123306635, parameters k is 10.308517070672252 and b is -42.1164440881969\n",
      "Iteration 3492, the loss is 4.442418296556285, parameters k is 10.308516681344189 and b is -42.11644013562773\n",
      "Iteration 3493, the loss is 4.442418280781909, parameters k is 10.308516292016126 and b is -42.11643618305855\n",
      "Iteration 3494, the loss is 4.442418265007526, parameters k is 10.308515902688063 and b is -42.11643223048938\n",
      "Iteration 3495, the loss is 4.442418249233148, parameters k is 10.30851551336 and b is -42.11642827792021\n",
      "Iteration 3496, the loss is 4.442418233458766, parameters k is 10.308515124031937 and b is -42.11642432535103\n",
      "Iteration 3497, the loss is 4.442418217684387, parameters k is 10.308514734703873 and b is -42.11642037278186\n",
      "Iteration 3498, the loss is 4.442418201910011, parameters k is 10.30851434537581 and b is -42.11641642021269\n",
      "Iteration 3499, the loss is 4.4424181861356296, parameters k is 10.308513956047747 and b is -42.116412467643514\n",
      "Iteration 3500, the loss is 4.4424181703612495, parameters k is 10.308513566719684 and b is -42.11640851507434\n",
      "Iteration 3501, the loss is 4.44241815458687, parameters k is 10.308513177391621 and b is -42.11640456250517\n",
      "Iteration 3502, the loss is 4.442418138812491, parameters k is 10.308512788063558 and b is -42.116400609935994\n",
      "Iteration 3503, the loss is 4.442418123038111, parameters k is 10.308512398735495 and b is -42.11639665736682\n",
      "Iteration 3504, the loss is 4.442418107263731, parameters k is 10.308512009407432 and b is -42.11639270479765\n",
      "Iteration 3505, the loss is 4.442418091489351, parameters k is 10.308511620079368 and b is -42.116388752228474\n",
      "Iteration 3506, the loss is 4.442418075714975, parameters k is 10.308511230751305 and b is -42.1163847996593\n",
      "Iteration 3507, the loss is 4.442418059940592, parameters k is 10.308510841423242 and b is -42.11638084709013\n",
      "Iteration 3508, the loss is 4.442418044166215, parameters k is 10.30851045209518 and b is -42.116376894520954\n",
      "Iteration 3509, the loss is 4.442418028391835, parameters k is 10.308510062767116 and b is -42.11637294195178\n",
      "Iteration 3510, the loss is 4.442418012617455, parameters k is 10.308509673439053 and b is -42.11636898938261\n",
      "Iteration 3511, the loss is 4.442417996843075, parameters k is 10.30850928411099 and b is -42.116365036813434\n",
      "Iteration 3512, the loss is 4.442417981068696, parameters k is 10.308508894782927 and b is -42.11636108424426\n",
      "Iteration 3513, the loss is 4.442417965294318, parameters k is 10.308508505454864 and b is -42.11635713167509\n",
      "Iteration 3514, the loss is 4.442417949519939, parameters k is 10.3085081161268 and b is -42.116353179105914\n",
      "Iteration 3515, the loss is 4.442417933745558, parameters k is 10.308507726798737 and b is -42.11634922653674\n",
      "Iteration 3516, the loss is 4.442417917971178, parameters k is 10.308507337470674 and b is -42.11634527396757\n",
      "Iteration 3517, the loss is 4.4424179021968, parameters k is 10.308506948142611 and b is -42.116341321398394\n",
      "Iteration 3518, the loss is 4.442417886422421, parameters k is 10.308506558814548 and b is -42.11633736882922\n",
      "Iteration 3519, the loss is 4.442417870648041, parameters k is 10.308506169486485 and b is -42.11633341626005\n",
      "Iteration 3520, the loss is 4.442417854873662, parameters k is 10.308505780158422 and b is -42.116329463690874\n",
      "Iteration 3521, the loss is 4.442417839099284, parameters k is 10.308505390830359 and b is -42.1163255111217\n",
      "Iteration 3522, the loss is 4.442417823324903, parameters k is 10.308505001502295 and b is -42.11632155855253\n",
      "Iteration 3523, the loss is 4.442417807550523, parameters k is 10.308504612174232 and b is -42.116317605983355\n",
      "Iteration 3524, the loss is 4.442417791776144, parameters k is 10.30850422284617 and b is -42.11631365341418\n",
      "Iteration 3525, the loss is 4.442417776001763, parameters k is 10.308503833518106 and b is -42.11630970084501\n",
      "Iteration 3526, the loss is 4.4424177602273875, parameters k is 10.308503444190043 and b is -42.116305748275835\n",
      "Iteration 3527, the loss is 4.442417744453008, parameters k is 10.30850305486198 and b is -42.11630179570666\n",
      "Iteration 3528, the loss is 4.442417728678627, parameters k is 10.308502665533917 and b is -42.11629784313749\n",
      "Iteration 3529, the loss is 4.4424177129042475, parameters k is 10.308502276205854 and b is -42.116293890568315\n",
      "Iteration 3530, the loss is 4.4424176971298674, parameters k is 10.30850188687779 and b is -42.11628993799914\n",
      "Iteration 3531, the loss is 4.442417681355493, parameters k is 10.308501497549727 and b is -42.11628598542997\n",
      "Iteration 3532, the loss is 4.442417665581108, parameters k is 10.308501108221664 and b is -42.116282032860795\n",
      "Iteration 3533, the loss is 4.442417649806731, parameters k is 10.308500718893601 and b is -42.11627808029162\n",
      "Iteration 3534, the loss is 4.442417634032352, parameters k is 10.308500329565538 and b is -42.11627412772245\n",
      "Iteration 3535, the loss is 4.44241761825797, parameters k is 10.308499940237475 and b is -42.116270175153275\n",
      "Iteration 3536, the loss is 4.442417602483593, parameters k is 10.308499550909412 and b is -42.1162662225841\n",
      "Iteration 3537, the loss is 4.44241758670921, parameters k is 10.308499161581349 and b is -42.11626227001493\n",
      "Iteration 3538, the loss is 4.442417570934835, parameters k is 10.308498772253285 and b is -42.116258317445755\n",
      "Iteration 3539, the loss is 4.4424175551604534, parameters k is 10.308498382925222 and b is -42.11625436487658\n",
      "Iteration 3540, the loss is 4.442417539386076, parameters k is 10.30849799359716 and b is -42.11625041230741\n",
      "Iteration 3541, the loss is 4.442417523611696, parameters k is 10.308497604269096 and b is -42.116246459738235\n",
      "Iteration 3542, the loss is 4.442417507837314, parameters k is 10.308497214941033 and b is -42.11624250716906\n",
      "Iteration 3543, the loss is 4.442417492062935, parameters k is 10.30849682561297 and b is -42.11623855459989\n",
      "Iteration 3544, the loss is 4.442417476288556, parameters k is 10.308496436284907 and b is -42.116234602030715\n",
      "Iteration 3545, the loss is 4.442417460514177, parameters k is 10.308496046956844 and b is -42.11623064946154\n",
      "Iteration 3546, the loss is 4.4424174447397995, parameters k is 10.30849565762878 and b is -42.11622669689237\n",
      "Iteration 3547, the loss is 4.4424174289654195, parameters k is 10.308495268300717 and b is -42.116222744323196\n",
      "Iteration 3548, the loss is 4.442417413191039, parameters k is 10.308494878972654 and b is -42.11621879175402\n",
      "Iteration 3549, the loss is 4.4424173974166585, parameters k is 10.308494489644591 and b is -42.11621483918485\n",
      "Iteration 3550, the loss is 4.442417381642282, parameters k is 10.308494100316528 and b is -42.116210886615676\n",
      "Iteration 3551, the loss is 4.442417365867899, parameters k is 10.308493710988465 and b is -42.1162069340465\n",
      "Iteration 3552, the loss is 4.442417350093521, parameters k is 10.308493321660402 and b is -42.11620298147733\n",
      "Iteration 3553, the loss is 4.442417334319139, parameters k is 10.308492932332339 and b is -42.116199028908156\n",
      "Iteration 3554, the loss is 4.442417318544761, parameters k is 10.308492543004276 and b is -42.11619507633898\n",
      "Iteration 3555, the loss is 4.44241730277038, parameters k is 10.308492153676212 and b is -42.11619112376981\n",
      "Iteration 3556, the loss is 4.442417286996005, parameters k is 10.30849176434815 and b is -42.116187171200636\n",
      "Iteration 3557, the loss is 4.442417271221623, parameters k is 10.308491375020086 and b is -42.11618321863146\n",
      "Iteration 3558, the loss is 4.4424172554472445, parameters k is 10.308490985692023 and b is -42.11617926606229\n",
      "Iteration 3559, the loss is 4.442417239672866, parameters k is 10.30849059636396 and b is -42.116175313493116\n",
      "Iteration 3560, the loss is 4.442417223898487, parameters k is 10.308490207035897 and b is -42.11617136092394\n",
      "Iteration 3561, the loss is 4.442417208124107, parameters k is 10.308489817707834 and b is -42.11616740835477\n",
      "Iteration 3562, the loss is 4.442417192349727, parameters k is 10.30848942837977 and b is -42.116163455785596\n",
      "Iteration 3563, the loss is 4.44241717657535, parameters k is 10.308489039051707 and b is -42.11615950321642\n",
      "Iteration 3564, the loss is 4.442417160800971, parameters k is 10.308488649723644 and b is -42.11615555064725\n",
      "Iteration 3565, the loss is 4.442417149886249, parameters k is 10.308488260395581 and b is -42.116151598078076\n",
      "Iteration 3566, the loss is 4.44241713416926, parameters k is 10.308460373043802 and b is -42.116151598078076\n",
      "Iteration 3567, the loss is 4.44241711839488, parameters k is 10.30845998371574 and b is -42.1161476455089\n",
      "Iteration 3568, the loss is 4.442417102620503, parameters k is 10.308459594387676 and b is -42.11614369293973\n",
      "Iteration 3569, the loss is 4.442417086846121, parameters k is 10.308459205059613 and b is -42.116139740370556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3570, the loss is 4.442417071071743, parameters k is 10.30845881573155 and b is -42.11613578780138\n",
      "Iteration 3571, the loss is 4.442417055297364, parameters k is 10.308458426403487 and b is -42.11613183523221\n",
      "Iteration 3572, the loss is 4.442417039522983, parameters k is 10.308458037075424 and b is -42.11612788266304\n",
      "Iteration 3573, the loss is 4.442417023748605, parameters k is 10.30845764774736 and b is -42.11612393009386\n",
      "Iteration 3574, the loss is 4.442417007974225, parameters k is 10.308457258419297 and b is -42.11611997752469\n",
      "Iteration 3575, the loss is 4.442416992199847, parameters k is 10.308456869091234 and b is -42.11611602495552\n",
      "Iteration 3576, the loss is 4.442416976425468, parameters k is 10.308456479763171 and b is -42.11611207238634\n",
      "Iteration 3577, the loss is 4.4424169606510855, parameters k is 10.308456090435108 and b is -42.11610811981717\n",
      "Iteration 3578, the loss is 4.4424169448767055, parameters k is 10.308455701107045 and b is -42.116104167248\n",
      "Iteration 3579, the loss is 4.442416929102329, parameters k is 10.308455311778982 and b is -42.11610021467882\n",
      "Iteration 3580, the loss is 4.442416913327947, parameters k is 10.308454922450919 and b is -42.11609626210965\n",
      "Iteration 3581, the loss is 4.442416897553568, parameters k is 10.308454533122855 and b is -42.11609230954048\n",
      "Iteration 3582, the loss is 4.442416881779191, parameters k is 10.308454143794792 and b is -42.116088356971304\n",
      "Iteration 3583, the loss is 4.442416866004811, parameters k is 10.30845375446673 and b is -42.11608440440213\n",
      "Iteration 3584, the loss is 4.442416850230434, parameters k is 10.308453365138666 and b is -42.11608045183296\n",
      "Iteration 3585, the loss is 4.442416834456052, parameters k is 10.308452975810603 and b is -42.116076499263784\n",
      "Iteration 3586, the loss is 4.442416818681674, parameters k is 10.30845258648254 and b is -42.11607254669461\n",
      "Iteration 3587, the loss is 4.442416802907293, parameters k is 10.308452197154477 and b is -42.11606859412544\n",
      "Iteration 3588, the loss is 4.442416787132914, parameters k is 10.308451807826414 and b is -42.116064641556264\n",
      "Iteration 3589, the loss is 4.442416771358533, parameters k is 10.30845141849835 and b is -42.11606068898709\n",
      "Iteration 3590, the loss is 4.442416755584157, parameters k is 10.308451029170287 and b is -42.11605673641792\n",
      "Iteration 3591, the loss is 4.442416739809775, parameters k is 10.308450639842224 and b is -42.116052783848744\n",
      "Iteration 3592, the loss is 4.442416724035397, parameters k is 10.308450250514161 and b is -42.11604883127957\n",
      "Iteration 3593, the loss is 4.442416708261019, parameters k is 10.308449861186098 and b is -42.1160448787104\n",
      "Iteration 3594, the loss is 4.442416692486636, parameters k is 10.308449471858035 and b is -42.116040926141224\n",
      "Iteration 3595, the loss is 4.442416676712261, parameters k is 10.308449082529972 and b is -42.11603697357205\n",
      "Iteration 3596, the loss is 4.44241666093788, parameters k is 10.308448693201909 and b is -42.11603302100288\n",
      "Iteration 3597, the loss is 4.442416645163499, parameters k is 10.308448303873845 and b is -42.116029068433704\n",
      "Iteration 3598, the loss is 4.44241662938912, parameters k is 10.308447914545782 and b is -42.11602511586453\n",
      "Iteration 3599, the loss is 4.442416613614741, parameters k is 10.30844752521772 and b is -42.11602116329536\n",
      "Iteration 3600, the loss is 4.442416597840358, parameters k is 10.308447135889656 and b is -42.116017210726184\n",
      "Iteration 3601, the loss is 4.4424165820659836, parameters k is 10.308446746561593 and b is -42.11601325815701\n",
      "Iteration 3602, the loss is 4.442416566291602, parameters k is 10.30844635723353 and b is -42.11600930558784\n",
      "Iteration 3603, the loss is 4.442416550517223, parameters k is 10.308445967905467 and b is -42.116005353018664\n",
      "Iteration 3604, the loss is 4.442416534742841, parameters k is 10.308445578577404 and b is -42.11600140044949\n",
      "Iteration 3605, the loss is 4.442416518968464, parameters k is 10.30844518924934 and b is -42.11599744788032\n",
      "Iteration 3606, the loss is 4.4424165031940825, parameters k is 10.308444799921277 and b is -42.115993495311145\n",
      "Iteration 3607, the loss is 4.442416487419704, parameters k is 10.308444410593214 and b is -42.11598954274197\n",
      "Iteration 3608, the loss is 4.442416471645323, parameters k is 10.308444021265151 and b is -42.1159855901728\n",
      "Iteration 3609, the loss is 4.442416455870947, parameters k is 10.308443631937088 and b is -42.115981637603625\n",
      "Iteration 3610, the loss is 4.442416440096566, parameters k is 10.308443242609025 and b is -42.11597768503445\n",
      "Iteration 3611, the loss is 4.442416424322185, parameters k is 10.308442853280962 and b is -42.11597373246528\n",
      "Iteration 3612, the loss is 4.4424164085478095, parameters k is 10.308442463952899 and b is -42.115969779896105\n",
      "Iteration 3613, the loss is 4.44241639277343, parameters k is 10.308442074624836 and b is -42.11596582732693\n",
      "Iteration 3614, the loss is 4.44241637699905, parameters k is 10.308441685296772 and b is -42.11596187475776\n",
      "Iteration 3615, the loss is 4.44241636122467, parameters k is 10.30844129596871 and b is -42.115957922188585\n",
      "Iteration 3616, the loss is 4.442416345450291, parameters k is 10.308440906640646 and b is -42.11595396961941\n",
      "Iteration 3617, the loss is 4.442416329675909, parameters k is 10.308440517312583 and b is -42.11595001705024\n",
      "Iteration 3618, the loss is 4.44241631390153, parameters k is 10.30844012798452 and b is -42.115946064481065\n",
      "Iteration 3619, the loss is 4.442416298127154, parameters k is 10.308439738656457 and b is -42.11594211191189\n",
      "Iteration 3620, the loss is 4.442416282352772, parameters k is 10.308439349328394 and b is -42.11593815934272\n",
      "Iteration 3621, the loss is 4.442416266578394, parameters k is 10.30843896000033 and b is -42.115934206773545\n",
      "Iteration 3622, the loss is 4.442416250804015, parameters k is 10.308438570672267 and b is -42.11593025420437\n",
      "Iteration 3623, the loss is 4.442416235029634, parameters k is 10.308438181344204 and b is -42.1159263016352\n",
      "Iteration 3624, the loss is 4.442416219255255, parameters k is 10.308437792016141 and b is -42.115922349066025\n",
      "Iteration 3625, the loss is 4.442416203480875, parameters k is 10.308437402688078 and b is -42.11591839649685\n",
      "Iteration 3626, the loss is 4.442416187706496, parameters k is 10.308437013360015 and b is -42.11591444392768\n",
      "Iteration 3627, the loss is 4.442416171932116, parameters k is 10.308436624031952 and b is -42.115910491358505\n",
      "Iteration 3628, the loss is 4.44241615615774, parameters k is 10.308436234703889 and b is -42.11590653878933\n",
      "Iteration 3629, the loss is 4.442416140383357, parameters k is 10.308435845375826 and b is -42.11590258622016\n",
      "Iteration 3630, the loss is 4.442416124608981, parameters k is 10.308435456047762 and b is -42.115898633650986\n",
      "Iteration 3631, the loss is 4.442416108834599, parameters k is 10.3084350667197 and b is -42.11589468108181\n",
      "Iteration 3632, the loss is 4.442416093060218, parameters k is 10.308434677391636 and b is -42.11589072851264\n",
      "Iteration 3633, the loss is 4.442416077285841, parameters k is 10.308434288063573 and b is -42.115886775943466\n",
      "Iteration 3634, the loss is 4.44241606151146, parameters k is 10.30843389873551 and b is -42.11588282337429\n",
      "Iteration 3635, the loss is 4.442416045737082, parameters k is 10.308433509407447 and b is -42.11587887080512\n",
      "Iteration 3636, the loss is 4.442416029962702, parameters k is 10.308433120079384 and b is -42.115874918235946\n",
      "Iteration 3637, the loss is 4.442416014188321, parameters k is 10.30843273075132 and b is -42.11587096566677\n",
      "Iteration 3638, the loss is 4.442415998413943, parameters k is 10.308432341423257 and b is -42.1158670130976\n",
      "Iteration 3639, the loss is 4.442415982639566, parameters k is 10.308431952095194 and b is -42.115863060528426\n",
      "Iteration 3640, the loss is 4.442415966865185, parameters k is 10.308431562767131 and b is -42.11585910795925\n",
      "Iteration 3641, the loss is 4.442415951090805, parameters k is 10.308431173439068 and b is -42.11585515539008\n",
      "Iteration 3642, the loss is 4.442415935316428, parameters k is 10.308430784111005 and b is -42.115851202820906\n",
      "Iteration 3643, the loss is 4.442415919542047, parameters k is 10.308430394782942 and b is -42.11584725025173\n",
      "Iteration 3644, the loss is 4.442415903767668, parameters k is 10.308430005454879 and b is -42.11584329768256\n",
      "Iteration 3645, the loss is 4.442415887993289, parameters k is 10.308429616126816 and b is -42.115839345113386\n",
      "Iteration 3646, the loss is 4.442415872218907, parameters k is 10.308429226798753 and b is -42.11583539254421\n",
      "Iteration 3647, the loss is 4.442415856444531, parameters k is 10.30842883747069 and b is -42.11583143997504\n",
      "Iteration 3648, the loss is 4.442415840670148, parameters k is 10.308428448142626 and b is -42.115827487405866\n",
      "Iteration 3649, the loss is 4.442415824895769, parameters k is 10.308428058814563 and b is -42.11582353483669\n",
      "Iteration 3650, the loss is 4.44241580912139, parameters k is 10.3084276694865 and b is -42.11581958226752\n",
      "Iteration 3651, the loss is 4.442415793347012, parameters k is 10.308427280158437 and b is -42.115815629698346\n",
      "Iteration 3652, the loss is 4.4424157775726325, parameters k is 10.308426890830374 and b is -42.11581167712917\n",
      "Iteration 3653, the loss is 4.442415761798256, parameters k is 10.30842650150231 and b is -42.11580772456\n",
      "Iteration 3654, the loss is 4.442415746023872, parameters k is 10.308426112174248 and b is -42.11580377199083\n",
      "Iteration 3655, the loss is 4.442415730249494, parameters k is 10.308425722846184 and b is -42.11579981942165\n",
      "Iteration 3656, the loss is 4.442415714475114, parameters k is 10.308425333518121 and b is -42.11579586685248\n",
      "Iteration 3657, the loss is 4.442415698700734, parameters k is 10.308424944190058 and b is -42.11579191428331\n",
      "Iteration 3658, the loss is 4.442415682926356, parameters k is 10.308424554861995 and b is -42.11578796171413\n",
      "Iteration 3659, the loss is 4.4424156671519786, parameters k is 10.308424165533932 and b is -42.11578400914496\n",
      "Iteration 3660, the loss is 4.442415651377595, parameters k is 10.308423776205869 and b is -42.11578005657579\n",
      "Iteration 3661, the loss is 4.4424156356032185, parameters k is 10.308423386877806 and b is -42.11577610400661\n",
      "Iteration 3662, the loss is 4.442415619828837, parameters k is 10.308422997549743 and b is -42.11577215143744\n",
      "Iteration 3663, the loss is 4.4424156040544585, parameters k is 10.30842260822168 and b is -42.11576819886827\n",
      "Iteration 3664, the loss is 4.442415588280081, parameters k is 10.308422218893616 and b is -42.11576424629909\n",
      "Iteration 3665, the loss is 4.442415572505698, parameters k is 10.308421829565553 and b is -42.11576029372992\n",
      "Iteration 3666, the loss is 4.442415556731318, parameters k is 10.30842144023749 and b is -42.11575634116075\n",
      "Iteration 3667, the loss is 4.442415540956942, parameters k is 10.308421050909427 and b is -42.115752388591574\n",
      "Iteration 3668, the loss is 4.442415525182562, parameters k is 10.308420661581364 and b is -42.1157484360224\n",
      "Iteration 3669, the loss is 4.442415509408183, parameters k is 10.3084202722533 and b is -42.11574448345323\n",
      "Iteration 3670, the loss is 4.4424154936338045, parameters k is 10.308419882925238 and b is -42.115740530884054\n",
      "Iteration 3671, the loss is 4.4424154778594245, parameters k is 10.308419493597174 and b is -42.11573657831488\n",
      "Iteration 3672, the loss is 4.4424154620850445, parameters k is 10.308419104269111 and b is -42.11573262574571\n",
      "Iteration 3673, the loss is 4.442415446310664, parameters k is 10.308418714941048 and b is -42.115728673176534\n",
      "Iteration 3674, the loss is 4.442415430536285, parameters k is 10.308418325612985 and b is -42.11572472060736\n",
      "Iteration 3675, the loss is 4.442415414761906, parameters k is 10.308417936284922 and b is -42.11572076803819\n",
      "Iteration 3676, the loss is 4.442415398987525, parameters k is 10.308417546956859 and b is -42.115716815469014\n",
      "Iteration 3677, the loss is 4.442415383213147, parameters k is 10.308417157628796 and b is -42.11571286289984\n",
      "Iteration 3678, the loss is 4.442415367438769, parameters k is 10.308416768300733 and b is -42.11570891033067\n",
      "Iteration 3679, the loss is 4.44241535166439, parameters k is 10.30841637897267 and b is -42.115704957761494\n",
      "Iteration 3680, the loss is 4.44241533589001, parameters k is 10.308415989644606 and b is -42.11570100519232\n",
      "Iteration 3681, the loss is 4.442415320115631, parameters k is 10.308415600316543 and b is -42.11569705262315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3682, the loss is 4.442415304341249, parameters k is 10.30841521098848 and b is -42.115693100053974\n",
      "Iteration 3683, the loss is 4.442415288566872, parameters k is 10.308414821660417 and b is -42.1156891474848\n",
      "Iteration 3684, the loss is 4.4424152727924895, parameters k is 10.308414432332354 and b is -42.11568519491563\n",
      "Iteration 3685, the loss is 4.442415257018113, parameters k is 10.30841404300429 and b is -42.115681242346454\n",
      "Iteration 3686, the loss is 4.442415241243733, parameters k is 10.308413653676228 and b is -42.11567728977728\n",
      "Iteration 3687, the loss is 4.442415225469351, parameters k is 10.308413264348165 and b is -42.11567333720811\n",
      "Iteration 3688, the loss is 4.442415209694972, parameters k is 10.308412875020101 and b is -42.115669384638935\n",
      "Iteration 3689, the loss is 4.442415193920596, parameters k is 10.308412485692038 and b is -42.11566543206976\n",
      "Iteration 3690, the loss is 4.442415178146215, parameters k is 10.308412096363975 and b is -42.11566147950059\n",
      "Iteration 3691, the loss is 4.4424151623718355, parameters k is 10.308411707035912 and b is -42.115657526931415\n",
      "Iteration 3692, the loss is 4.442415146597456, parameters k is 10.308411317707849 and b is -42.11565357436224\n",
      "Iteration 3693, the loss is 4.4424151308230755, parameters k is 10.308410928379786 and b is -42.11564962179307\n",
      "Iteration 3694, the loss is 4.442415115048697, parameters k is 10.308410539051723 and b is -42.115645669223895\n",
      "Iteration 3695, the loss is 4.442415099274318, parameters k is 10.30841014972366 and b is -42.11564171665472\n",
      "Iteration 3696, the loss is 4.442415083499939, parameters k is 10.308409760395596 and b is -42.11563776408555\n",
      "Iteration 3697, the loss is 4.442415067725558, parameters k is 10.308409371067533 and b is -42.115633811516375\n",
      "Iteration 3698, the loss is 4.442415051951178, parameters k is 10.30840898173947 and b is -42.1156298589472\n",
      "Iteration 3699, the loss is 4.442415036176801, parameters k is 10.308408592411407 and b is -42.11562590637803\n",
      "Iteration 3700, the loss is 4.442415020402422, parameters k is 10.308408203083344 and b is -42.115621953808855\n",
      "Iteration 3701, the loss is 4.44241500462804, parameters k is 10.30840781375528 and b is -42.11561800123968\n",
      "Iteration 3702, the loss is 4.442414988853661, parameters k is 10.308407424427218 and b is -42.11561404867051\n",
      "Iteration 3703, the loss is 4.442414973079283, parameters k is 10.308407035099155 and b is -42.115610096101335\n",
      "Iteration 3704, the loss is 4.442414957304904, parameters k is 10.308406645771091 and b is -42.11560614353216\n",
      "Iteration 3705, the loss is 4.442414941530525, parameters k is 10.308406256443028 and b is -42.11560219096299\n",
      "Iteration 3706, the loss is 4.442414925756143, parameters k is 10.308405867114965 and b is -42.115598238393815\n",
      "Iteration 3707, the loss is 4.442414909981767, parameters k is 10.308405477786902 and b is -42.11559428582464\n",
      "Iteration 3708, the loss is 4.4424148942073876, parameters k is 10.308405088458839 and b is -42.11559033325547\n",
      "Iteration 3709, the loss is 4.442414878433005, parameters k is 10.308404699130776 and b is -42.115586380686295\n",
      "Iteration 3710, the loss is 4.4424148626586275, parameters k is 10.308404309802713 and b is -42.11558242811712\n",
      "Iteration 3711, the loss is 4.442414846884249, parameters k is 10.30840392047465 and b is -42.11557847554795\n",
      "Iteration 3712, the loss is 4.44241483110987, parameters k is 10.308403531146586 and b is -42.115574522978775\n",
      "Iteration 3713, the loss is 4.44241481533549, parameters k is 10.308403141818523 and b is -42.1155705704096\n",
      "Iteration 3714, the loss is 4.442414799561108, parameters k is 10.30840275249046 and b is -42.11556661784043\n",
      "Iteration 3715, the loss is 4.44241478378673, parameters k is 10.308402363162397 and b is -42.115562665271256\n",
      "Iteration 3716, the loss is 4.442414768012351, parameters k is 10.308401973834334 and b is -42.11555871270208\n",
      "Iteration 3717, the loss is 4.442414752237972, parameters k is 10.30840158450627 and b is -42.11555476013291\n",
      "Iteration 3718, the loss is 4.442414736463592, parameters k is 10.308401195178208 and b is -42.115550807563736\n",
      "Iteration 3719, the loss is 4.4424147206892135, parameters k is 10.308400805850145 and b is -42.11554685499456\n",
      "Iteration 3720, the loss is 4.442414704914834, parameters k is 10.308400416522081 and b is -42.11554290242539\n",
      "Iteration 3721, the loss is 4.442414689295918, parameters k is 10.308400027194018 and b is -42.115538949856216\n",
      "Iteration 3722, the loss is 4.442414678283124, parameters k is 10.30837213984224 and b is -42.115538949856216\n",
      "Iteration 3723, the loss is 4.442414662508748, parameters k is 10.308371750514176 and b is -42.11553499728704\n",
      "Iteration 3724, the loss is 4.442414646734367, parameters k is 10.308371361186113 and b is -42.11553104471787\n",
      "Iteration 3725, the loss is 4.442414630959987, parameters k is 10.30837097185805 and b is -42.115527092148696\n",
      "Iteration 3726, the loss is 4.442414615185604, parameters k is 10.308370582529987 and b is -42.11552313957952\n",
      "Iteration 3727, the loss is 4.442414599411229, parameters k is 10.308370193201924 and b is -42.11551918701035\n",
      "Iteration 3728, the loss is 4.442414583636849, parameters k is 10.30836980387386 and b is -42.115515234441176\n",
      "Iteration 3729, the loss is 4.4424145678624685, parameters k is 10.308369414545798 and b is -42.115511281872\n",
      "Iteration 3730, the loss is 4.442414552088092, parameters k is 10.308369025217734 and b is -42.11550732930283\n",
      "Iteration 3731, the loss is 4.442414536313709, parameters k is 10.308368635889671 and b is -42.115503376733656\n",
      "Iteration 3732, the loss is 4.442414520539332, parameters k is 10.308368246561608 and b is -42.11549942416448\n",
      "Iteration 3733, the loss is 4.442414504764952, parameters k is 10.308367857233545 and b is -42.11549547159531\n",
      "Iteration 3734, the loss is 4.442414488990575, parameters k is 10.308367467905482 and b is -42.115491519026136\n",
      "Iteration 3735, the loss is 4.44241447321619, parameters k is 10.308367078577419 and b is -42.11548756645696\n",
      "Iteration 3736, the loss is 4.442414457441814, parameters k is 10.308366689249356 and b is -42.11548361388779\n",
      "Iteration 3737, the loss is 4.442414441667433, parameters k is 10.308366299921293 and b is -42.115479661318616\n",
      "Iteration 3738, the loss is 4.4424144258930545, parameters k is 10.30836591059323 and b is -42.11547570874944\n",
      "Iteration 3739, the loss is 4.442414410118673, parameters k is 10.308365521265166 and b is -42.11547175618027\n",
      "Iteration 3740, the loss is 4.442414394344295, parameters k is 10.308365131937103 and b is -42.1154678036111\n",
      "Iteration 3741, the loss is 4.442414378569915, parameters k is 10.30836474260904 and b is -42.11546385104192\n",
      "Iteration 3742, the loss is 4.442414362795537, parameters k is 10.308364353280977 and b is -42.11545989847275\n",
      "Iteration 3743, the loss is 4.442414347021158, parameters k is 10.308363963952914 and b is -42.11545594590358\n",
      "Iteration 3744, the loss is 4.44241433124678, parameters k is 10.30836357462485 and b is -42.1154519933344\n",
      "Iteration 3745, the loss is 4.4424143154724, parameters k is 10.308363185296788 and b is -42.11544804076523\n",
      "Iteration 3746, the loss is 4.442414299698019, parameters k is 10.308362795968725 and b is -42.11544408819606\n",
      "Iteration 3747, the loss is 4.44241428392364, parameters k is 10.308362406640661 and b is -42.11544013562688\n",
      "Iteration 3748, the loss is 4.4424142681492595, parameters k is 10.308362017312598 and b is -42.11543618305771\n",
      "Iteration 3749, the loss is 4.4424142523748795, parameters k is 10.308361627984535 and b is -42.11543223048854\n",
      "Iteration 3750, the loss is 4.442414236600502, parameters k is 10.308361238656472 and b is -42.115428277919364\n",
      "Iteration 3751, the loss is 4.442414220826122, parameters k is 10.308360849328409 and b is -42.11542432535019\n",
      "Iteration 3752, the loss is 4.44241420505174, parameters k is 10.308360460000346 and b is -42.11542037278102\n",
      "Iteration 3753, the loss is 4.442414189277364, parameters k is 10.308360070672283 and b is -42.115416420211844\n",
      "Iteration 3754, the loss is 4.442414173502985, parameters k is 10.30835968134422 and b is -42.11541246764267\n",
      "Iteration 3755, the loss is 4.442414157728605, parameters k is 10.308359292016156 and b is -42.1154085150735\n",
      "Iteration 3756, the loss is 4.442414141954225, parameters k is 10.308358902688093 and b is -42.115404562504324\n",
      "Iteration 3757, the loss is 4.4424141261798455, parameters k is 10.30835851336003 and b is -42.11540060993515\n",
      "Iteration 3758, the loss is 4.442414110405469, parameters k is 10.308358124031967 and b is -42.11539665736598\n",
      "Iteration 3759, the loss is 4.442414094631086, parameters k is 10.308357734703904 and b is -42.115392704796804\n",
      "Iteration 3760, the loss is 4.442414078856708, parameters k is 10.30835734537584 and b is -42.11538875222763\n",
      "Iteration 3761, the loss is 4.44241406308233, parameters k is 10.308356956047778 and b is -42.11538479965846\n",
      "Iteration 3762, the loss is 4.442414047307947, parameters k is 10.308356566719715 and b is -42.115380847089284\n",
      "Iteration 3763, the loss is 4.4424140315335725, parameters k is 10.308356177391651 and b is -42.11537689452011\n",
      "Iteration 3764, the loss is 4.44241401575919, parameters k is 10.308355788063588 and b is -42.11537294195094\n",
      "Iteration 3765, the loss is 4.442413999984812, parameters k is 10.308355398735525 and b is -42.115368989381764\n",
      "Iteration 3766, the loss is 4.442413984210431, parameters k is 10.308355009407462 and b is -42.11536503681259\n",
      "Iteration 3767, the loss is 4.442413968436055, parameters k is 10.308354620079399 and b is -42.11536108424342\n",
      "Iteration 3768, the loss is 4.442413952661672, parameters k is 10.308354230751336 and b is -42.115357131674244\n",
      "Iteration 3769, the loss is 4.442413936887291, parameters k is 10.308353841423273 and b is -42.11535317910507\n",
      "Iteration 3770, the loss is 4.442413921112913, parameters k is 10.30835345209521 and b is -42.1153492265359\n",
      "Iteration 3771, the loss is 4.442413905338536, parameters k is 10.308353062767146 and b is -42.115345273966724\n",
      "Iteration 3772, the loss is 4.442413889564157, parameters k is 10.308352673439083 and b is -42.11534132139755\n",
      "Iteration 3773, the loss is 4.442413873789777, parameters k is 10.30835228411102 and b is -42.11533736882838\n",
      "Iteration 3774, the loss is 4.442413858015398, parameters k is 10.308351894782957 and b is -42.115333416259205\n",
      "Iteration 3775, the loss is 4.4424138422410175, parameters k is 10.308351505454894 and b is -42.11532946369003\n",
      "Iteration 3776, the loss is 4.442413826466638, parameters k is 10.30835111612683 and b is -42.11532551112086\n",
      "Iteration 3777, the loss is 4.442413810692258, parameters k is 10.308350726798768 and b is -42.115321558551685\n",
      "Iteration 3778, the loss is 4.44241379491788, parameters k is 10.308350337470705 and b is -42.11531760598251\n",
      "Iteration 3779, the loss is 4.442413779143497, parameters k is 10.308349948142641 and b is -42.11531365341334\n",
      "Iteration 3780, the loss is 4.442413763369122, parameters k is 10.308349558814578 and b is -42.115309700844165\n",
      "Iteration 3781, the loss is 4.442413747594743, parameters k is 10.308349169486515 and b is -42.11530574827499\n",
      "Iteration 3782, the loss is 4.442413731820361, parameters k is 10.308348780158452 and b is -42.11530179570582\n",
      "Iteration 3783, the loss is 4.442413716045982, parameters k is 10.308348390830389 and b is -42.115297843136645\n",
      "Iteration 3784, the loss is 4.442413700271603, parameters k is 10.308348001502326 and b is -42.11529389056747\n",
      "Iteration 3785, the loss is 4.442413684497223, parameters k is 10.308347612174263 and b is -42.1152899379983\n",
      "Iteration 3786, the loss is 4.442413668722843, parameters k is 10.3083472228462 and b is -42.115285985429125\n",
      "Iteration 3787, the loss is 4.442413652948466, parameters k is 10.308346833518137 and b is -42.11528203285995\n",
      "Iteration 3788, the loss is 4.442413637174087, parameters k is 10.308346444190073 and b is -42.11527808029078\n",
      "Iteration 3789, the loss is 4.442413621399705, parameters k is 10.30834605486201 and b is -42.115274127721605\n",
      "Iteration 3790, the loss is 4.442413605625325, parameters k is 10.308345665533947 and b is -42.11527017515243\n",
      "Iteration 3791, the loss is 4.442413589850948, parameters k is 10.308345276205884 and b is -42.11526622258326\n",
      "Iteration 3792, the loss is 4.442413574076566, parameters k is 10.308344886877821 and b is -42.115262270014085\n",
      "Iteration 3793, the loss is 4.442413558302187, parameters k is 10.308344497549758 and b is -42.11525831744491\n",
      "Iteration 3794, the loss is 4.44241354252781, parameters k is 10.308344108221695 and b is -42.11525436487574\n",
      "Iteration 3795, the loss is 4.442413526753428, parameters k is 10.308343718893632 and b is -42.115250412306565\n",
      "Iteration 3796, the loss is 4.4424135109790495, parameters k is 10.308343329565568 and b is -42.11524645973739\n",
      "Iteration 3797, the loss is 4.442413495204671, parameters k is 10.308342940237505 and b is -42.11524250716822\n",
      "Iteration 3798, the loss is 4.4424134794302885, parameters k is 10.308342550909442 and b is -42.115238554599046\n",
      "Iteration 3799, the loss is 4.442413463655913, parameters k is 10.308342161581379 and b is -42.11523460202987\n",
      "Iteration 3800, the loss is 4.442413447881535, parameters k is 10.308341772253316 and b is -42.1152306494607\n",
      "Iteration 3801, the loss is 4.442413432107151, parameters k is 10.308341382925253 and b is -42.115226696891526\n",
      "Iteration 3802, the loss is 4.442413416332773, parameters k is 10.30834099359719 and b is -42.11522274432235\n",
      "Iteration 3803, the loss is 4.442413400558395, parameters k is 10.308340604269127 and b is -42.11521879175318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3804, the loss is 4.4424133847840155, parameters k is 10.308340214941063 and b is -42.115214839184006\n",
      "Iteration 3805, the loss is 4.442413369009636, parameters k is 10.308339825613 and b is -42.11521088661483\n",
      "Iteration 3806, the loss is 4.4424133532352545, parameters k is 10.308339436284937 and b is -42.11520693404566\n",
      "Iteration 3807, the loss is 4.442413337460876, parameters k is 10.308339046956874 and b is -42.115202981476486\n",
      "Iteration 3808, the loss is 4.442413321686496, parameters k is 10.308338657628811 and b is -42.11519902890731\n",
      "Iteration 3809, the loss is 4.442413305912117, parameters k is 10.308338268300748 and b is -42.11519507633814\n",
      "Iteration 3810, the loss is 4.442413290137737, parameters k is 10.308337878972685 and b is -42.115191123768966\n",
      "Iteration 3811, the loss is 4.442413274363361, parameters k is 10.308337489644622 and b is -42.11518717119979\n",
      "Iteration 3812, the loss is 4.442413258588979, parameters k is 10.308337100316558 and b is -42.11518321863062\n",
      "Iteration 3813, the loss is 4.442413242814598, parameters k is 10.308336710988495 and b is -42.115179266061446\n",
      "Iteration 3814, the loss is 4.442413227040219, parameters k is 10.308336321660432 and b is -42.11517531349227\n",
      "Iteration 3815, the loss is 4.442413211265839, parameters k is 10.308335932332369 and b is -42.1151713609231\n",
      "Iteration 3816, the loss is 4.4424131954914605, parameters k is 10.308335543004306 and b is -42.115167408353926\n",
      "Iteration 3817, the loss is 4.442413179717083, parameters k is 10.308335153676243 and b is -42.11516345578475\n",
      "Iteration 3818, the loss is 4.442413163942701, parameters k is 10.30833476434818 and b is -42.11515950321558\n",
      "Iteration 3819, the loss is 4.442413148168323, parameters k is 10.308334375020117 and b is -42.115155550646406\n",
      "Iteration 3820, the loss is 4.442413132393943, parameters k is 10.308333985692054 and b is -42.11515159807723\n",
      "Iteration 3821, the loss is 4.442413116619564, parameters k is 10.30833359636399 and b is -42.11514764550806\n",
      "Iteration 3822, the loss is 4.442413100845186, parameters k is 10.308333207035927 and b is -42.11514369293889\n",
      "Iteration 3823, the loss is 4.442413085070807, parameters k is 10.308332817707864 and b is -42.11513974036971\n",
      "Iteration 3824, the loss is 4.4424130692964265, parameters k is 10.308332428379801 and b is -42.11513578780054\n",
      "Iteration 3825, the loss is 4.442413053522048, parameters k is 10.308332039051738 and b is -42.11513183523137\n",
      "Iteration 3826, the loss is 4.442413037747668, parameters k is 10.308331649723675 and b is -42.11512788266219\n",
      "Iteration 3827, the loss is 4.442413021973289, parameters k is 10.308331260395612 and b is -42.11512393009302\n",
      "Iteration 3828, the loss is 4.442413006198908, parameters k is 10.308330871067549 and b is -42.11511997752385\n",
      "Iteration 3829, the loss is 4.442412990424529, parameters k is 10.308330481739485 and b is -42.11511602495467\n",
      "Iteration 3830, the loss is 4.44241297465015, parameters k is 10.308330092411422 and b is -42.1151120723855\n",
      "Iteration 3831, the loss is 4.442412958875772, parameters k is 10.30832970308336 and b is -42.11510811981633\n",
      "Iteration 3832, the loss is 4.442412943101391, parameters k is 10.308329313755296 and b is -42.115104167247154\n",
      "Iteration 3833, the loss is 4.442412927327011, parameters k is 10.308328924427233 and b is -42.11510021467798\n",
      "Iteration 3834, the loss is 4.442412911552633, parameters k is 10.30832853509917 and b is -42.11509626210881\n",
      "Iteration 3835, the loss is 4.442412895778253, parameters k is 10.308328145771107 and b is -42.115092309539634\n",
      "Iteration 3836, the loss is 4.442412880003874, parameters k is 10.308327756443044 and b is -42.11508835697046\n",
      "Iteration 3837, the loss is 4.442412864229494, parameters k is 10.30832736711498 and b is -42.11508440440129\n",
      "Iteration 3838, the loss is 4.442412848455118, parameters k is 10.308326977786917 and b is -42.115080451832114\n",
      "Iteration 3839, the loss is 4.442412832680735, parameters k is 10.308326588458854 and b is -42.11507649926294\n",
      "Iteration 3840, the loss is 4.442412816906355, parameters k is 10.308326199130791 and b is -42.11507254669377\n",
      "Iteration 3841, the loss is 4.442412801131976, parameters k is 10.308325809802728 and b is -42.115068594124594\n",
      "Iteration 3842, the loss is 4.4424127853576, parameters k is 10.308325420474665 and b is -42.11506464155542\n",
      "Iteration 3843, the loss is 4.442412769583222, parameters k is 10.308325031146602 and b is -42.11506068898625\n",
      "Iteration 3844, the loss is 4.442412753808839, parameters k is 10.308324641818539 and b is -42.115056736417074\n",
      "Iteration 3845, the loss is 4.4424127380344585, parameters k is 10.308324252490475 and b is -42.1150527838479\n",
      "Iteration 3846, the loss is 4.442412722260078, parameters k is 10.308323863162412 and b is -42.11504883127873\n",
      "Iteration 3847, the loss is 4.442412706485702, parameters k is 10.30832347383435 and b is -42.115044878709554\n",
      "Iteration 3848, the loss is 4.442412690711319, parameters k is 10.308323084506286 and b is -42.11504092614038\n",
      "Iteration 3849, the loss is 4.442412674936941, parameters k is 10.308322695178223 and b is -42.11503697357121\n",
      "Iteration 3850, the loss is 4.442412659162563, parameters k is 10.30832230585016 and b is -42.115033021002034\n",
      "Iteration 3851, the loss is 4.442412643388184, parameters k is 10.308321916522097 and b is -42.11502906843286\n",
      "Iteration 3852, the loss is 4.4424126276138045, parameters k is 10.308321527194034 and b is -42.11502511586369\n",
      "Iteration 3853, the loss is 4.4424126118394245, parameters k is 10.30832113786597 and b is -42.115021163294514\n",
      "Iteration 3854, the loss is 4.442412596065043, parameters k is 10.308320748537907 and b is -42.11501721072534\n",
      "Iteration 3855, the loss is 4.442412580290666, parameters k is 10.308320359209844 and b is -42.11501325815617\n",
      "Iteration 3856, the loss is 4.442412564516286, parameters k is 10.308319969881781 and b is -42.115009305586995\n",
      "Iteration 3857, the loss is 4.442412548741907, parameters k is 10.308319580553718 and b is -42.11500535301782\n",
      "Iteration 3858, the loss is 4.442412532967528, parameters k is 10.308319191225655 and b is -42.11500140044865\n",
      "Iteration 3859, the loss is 4.442412517193146, parameters k is 10.308318801897592 and b is -42.114997447879475\n",
      "Iteration 3860, the loss is 4.442412501418768, parameters k is 10.308318412569529 and b is -42.1149934953103\n",
      "Iteration 3861, the loss is 4.442412485644393, parameters k is 10.308318023241466 and b is -42.11498954274113\n",
      "Iteration 3862, the loss is 4.4424124698700105, parameters k is 10.308317633913402 and b is -42.114985590171955\n",
      "Iteration 3863, the loss is 4.442412454095629, parameters k is 10.30831724458534 and b is -42.11498163760278\n",
      "Iteration 3864, the loss is 4.442412438321249, parameters k is 10.308316855257276 and b is -42.11497768503361\n",
      "Iteration 3865, the loss is 4.442412422546871, parameters k is 10.308316465929213 and b is -42.114973732464435\n",
      "Iteration 3866, the loss is 4.442412406772491, parameters k is 10.30831607660115 and b is -42.11496977989526\n",
      "Iteration 3867, the loss is 4.442412390998112, parameters k is 10.308315687273087 and b is -42.11496582732609\n",
      "Iteration 3868, the loss is 4.442412375223734, parameters k is 10.308315297945024 and b is -42.114961874756915\n",
      "Iteration 3869, the loss is 4.442412359449355, parameters k is 10.30831490861696 and b is -42.11495792218774\n",
      "Iteration 3870, the loss is 4.4424123436749765, parameters k is 10.308314519288897 and b is -42.11495396961857\n",
      "Iteration 3871, the loss is 4.442412327900596, parameters k is 10.308314129960834 and b is -42.114950017049395\n",
      "Iteration 3872, the loss is 4.442412312126214, parameters k is 10.308313740632771 and b is -42.11494606448022\n",
      "Iteration 3873, the loss is 4.4424122963518355, parameters k is 10.308313351304708 and b is -42.11494211191105\n",
      "Iteration 3874, the loss is 4.4424122805774555, parameters k is 10.308312961976645 and b is -42.114938159341875\n",
      "Iteration 3875, the loss is 4.4424122648030755, parameters k is 10.308312572648582 and b is -42.1149342067727\n",
      "Iteration 3876, the loss is 4.442412249028699, parameters k is 10.308312183320519 and b is -42.11493025420353\n",
      "Iteration 3877, the loss is 4.442412233254318, parameters k is 10.308311793992456 and b is -42.114926301634355\n",
      "Iteration 3878, the loss is 4.442412217848258, parameters k is 10.308311404664392 and b is -42.11492234906518\n",
      "Iteration 3879, the loss is 4.442412206622612, parameters k is 10.308283517312613 and b is -42.11492234906518\n",
      "Iteration 3880, the loss is 4.442412190848231, parameters k is 10.30828312798455 and b is -42.11491839649601\n",
      "Iteration 3881, the loss is 4.442412175073851, parameters k is 10.308282738656487 and b is -42.114914443926835\n",
      "Iteration 3882, the loss is 4.442412159299475, parameters k is 10.308282349328424 and b is -42.11491049135766\n",
      "Iteration 3883, the loss is 4.442412143525091, parameters k is 10.308281960000361 and b is -42.11490653878849\n",
      "Iteration 3884, the loss is 4.442412127750713, parameters k is 10.308281570672298 and b is -42.114902586219316\n",
      "Iteration 3885, the loss is 4.442412111976335, parameters k is 10.308281181344235 and b is -42.11489863365014\n",
      "Iteration 3886, the loss is 4.442412096201952, parameters k is 10.308280792016172 and b is -42.11489468108097\n",
      "Iteration 3887, the loss is 4.442412080427573, parameters k is 10.308280402688109 and b is -42.114890728511796\n",
      "Iteration 3888, the loss is 4.442412064653198, parameters k is 10.308280013360045 and b is -42.11488677594262\n",
      "Iteration 3889, the loss is 4.442412048878815, parameters k is 10.308279624031982 and b is -42.11488282337345\n",
      "Iteration 3890, the loss is 4.442412033104437, parameters k is 10.30827923470392 and b is -42.114878870804276\n",
      "Iteration 3891, the loss is 4.442412017330061, parameters k is 10.308278845375856 and b is -42.1148749182351\n",
      "Iteration 3892, the loss is 4.442412001555677, parameters k is 10.308278456047793 and b is -42.11487096566593\n",
      "Iteration 3893, the loss is 4.442411985781301, parameters k is 10.30827806671973 and b is -42.114867013096756\n",
      "Iteration 3894, the loss is 4.442411970006921, parameters k is 10.308277677391667 and b is -42.11486306052758\n",
      "Iteration 3895, the loss is 4.442411954232539, parameters k is 10.308277288063604 and b is -42.11485910795841\n",
      "Iteration 3896, the loss is 4.442411938458159, parameters k is 10.30827689873554 and b is -42.114855155389236\n",
      "Iteration 3897, the loss is 4.442411922683781, parameters k is 10.308276509407477 and b is -42.11485120282006\n",
      "Iteration 3898, the loss is 4.442411906909402, parameters k is 10.308276120079414 and b is -42.11484725025089\n",
      "Iteration 3899, the loss is 4.442411891135025, parameters k is 10.308275730751351 and b is -42.114843297681716\n",
      "Iteration 3900, the loss is 4.442411875360644, parameters k is 10.308275341423288 and b is -42.11483934511254\n",
      "Iteration 3901, the loss is 4.442411859586264, parameters k is 10.308274952095225 and b is -42.11483539254337\n",
      "Iteration 3902, the loss is 4.442411843811882, parameters k is 10.308274562767162 and b is -42.114831439974196\n",
      "Iteration 3903, the loss is 4.442411828037505, parameters k is 10.308274173439099 and b is -42.11482748740502\n",
      "Iteration 3904, the loss is 4.442411812263125, parameters k is 10.308273784111035 and b is -42.11482353483585\n",
      "Iteration 3905, the loss is 4.442411796488747, parameters k is 10.308273394782972 and b is -42.114819582266676\n",
      "Iteration 3906, the loss is 4.442411780714367, parameters k is 10.30827300545491 and b is -42.1148156296975\n",
      "Iteration 3907, the loss is 4.442411764939988, parameters k is 10.308272616126846 and b is -42.11481167712833\n",
      "Iteration 3908, the loss is 4.442411749165609, parameters k is 10.308272226798783 and b is -42.11480772455916\n",
      "Iteration 3909, the loss is 4.442411733391228, parameters k is 10.30827183747072 and b is -42.11480377198998\n",
      "Iteration 3910, the loss is 4.4424117176168485, parameters k is 10.308271448142657 and b is -42.11479981942081\n",
      "Iteration 3911, the loss is 4.44241170184247, parameters k is 10.308271058814594 and b is -42.11479586685164\n",
      "Iteration 3912, the loss is 4.4424116860680884, parameters k is 10.30827066948653 and b is -42.11479191428246\n",
      "Iteration 3913, the loss is 4.442411670293711, parameters k is 10.308270280158467 and b is -42.11478796171329\n",
      "Iteration 3914, the loss is 4.442411654519331, parameters k is 10.308269890830404 and b is -42.11478400914412\n",
      "Iteration 3915, the loss is 4.442411638744951, parameters k is 10.308269501502341 and b is -42.11478005657494\n",
      "Iteration 3916, the loss is 4.442411622970572, parameters k is 10.308269112174278 and b is -42.11477610400577\n",
      "Iteration 3917, the loss is 4.4424116071961945, parameters k is 10.308268722846215 and b is -42.1147721514366\n",
      "Iteration 3918, the loss is 4.4424115914218145, parameters k is 10.308268333518152 and b is -42.114768198867424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3919, the loss is 4.442411575647436, parameters k is 10.308267944190089 and b is -42.11476424629825\n",
      "Iteration 3920, the loss is 4.442411559873055, parameters k is 10.308267554862026 and b is -42.11476029372908\n",
      "Iteration 3921, the loss is 4.4424115440986744, parameters k is 10.308267165533962 and b is -42.114756341159904\n",
      "Iteration 3922, the loss is 4.442411528324297, parameters k is 10.3082667762059 and b is -42.11475238859073\n",
      "Iteration 3923, the loss is 4.442411512549916, parameters k is 10.308266386877836 and b is -42.11474843602156\n",
      "Iteration 3924, the loss is 4.442411496775538, parameters k is 10.308265997549773 and b is -42.114744483452384\n",
      "Iteration 3925, the loss is 4.4424114810011615, parameters k is 10.30826560822171 and b is -42.11474053088321\n",
      "Iteration 3926, the loss is 4.442411465226779, parameters k is 10.308265218893647 and b is -42.11473657831404\n",
      "Iteration 3927, the loss is 4.4424114494524, parameters k is 10.308264829565584 and b is -42.114732625744864\n",
      "Iteration 3928, the loss is 4.4424114336780205, parameters k is 10.30826444023752 and b is -42.11472867317569\n",
      "Iteration 3929, the loss is 4.44241141790364, parameters k is 10.308264050909457 and b is -42.11472472060652\n",
      "Iteration 3930, the loss is 4.442411402129261, parameters k is 10.308263661581394 and b is -42.114720768037344\n",
      "Iteration 3931, the loss is 4.442411386354882, parameters k is 10.308263272253331 and b is -42.11471681546817\n",
      "Iteration 3932, the loss is 4.442411370580503, parameters k is 10.308262882925268 and b is -42.114712862899\n",
      "Iteration 3933, the loss is 4.442411354806122, parameters k is 10.308262493597205 and b is -42.114708910329824\n",
      "Iteration 3934, the loss is 4.442411339031743, parameters k is 10.308262104269142 and b is -42.11470495776065\n",
      "Iteration 3935, the loss is 4.442411323257365, parameters k is 10.308261714941079 and b is -42.11470100519148\n",
      "Iteration 3936, the loss is 4.442411307482983, parameters k is 10.308261325613016 and b is -42.114697052622304\n",
      "Iteration 3937, the loss is 4.442411291708606, parameters k is 10.308260936284952 and b is -42.11469310005313\n",
      "Iteration 3938, the loss is 4.442411275934224, parameters k is 10.30826054695689 and b is -42.11468914748396\n",
      "Iteration 3939, the loss is 4.442411260159846, parameters k is 10.308260157628826 and b is -42.114685194914784\n",
      "Iteration 3940, the loss is 4.442411244385466, parameters k is 10.308259768300763 and b is -42.11468124234561\n",
      "Iteration 3941, the loss is 4.442411228611086, parameters k is 10.3082593789727 and b is -42.11467728977644\n",
      "Iteration 3942, the loss is 4.442411212836707, parameters k is 10.308258989644637 and b is -42.114673337207265\n",
      "Iteration 3943, the loss is 4.442411197062329, parameters k is 10.308258600316574 and b is -42.11466938463809\n",
      "Iteration 3944, the loss is 4.442411181287949, parameters k is 10.30825821098851 and b is -42.11466543206892\n",
      "Iteration 3945, the loss is 4.442411165513573, parameters k is 10.308257821660447 and b is -42.114661479499745\n",
      "Iteration 3946, the loss is 4.442411149739192, parameters k is 10.308257432332384 and b is -42.11465752693057\n",
      "Iteration 3947, the loss is 4.442411133964813, parameters k is 10.308257043004321 and b is -42.1146535743614\n",
      "Iteration 3948, the loss is 4.442411118190432, parameters k is 10.308256653676258 and b is -42.114649621792225\n",
      "Iteration 3949, the loss is 4.442411102416055, parameters k is 10.308256264348195 and b is -42.11464566922305\n",
      "Iteration 3950, the loss is 4.442411086641672, parameters k is 10.308255875020132 and b is -42.11464171665388\n",
      "Iteration 3951, the loss is 4.4424110708672915, parameters k is 10.308255485692069 and b is -42.114637764084705\n",
      "Iteration 3952, the loss is 4.442411055092916, parameters k is 10.308255096364006 and b is -42.11463381151553\n",
      "Iteration 3953, the loss is 4.442411039318534, parameters k is 10.308254707035942 and b is -42.11462985894636\n",
      "Iteration 3954, the loss is 4.442411023544155, parameters k is 10.30825431770788 and b is -42.114625906377185\n",
      "Iteration 3955, the loss is 4.442411007769776, parameters k is 10.308253928379816 and b is -42.11462195380801\n",
      "Iteration 3956, the loss is 4.4424109919954, parameters k is 10.308253539051753 and b is -42.11461800123884\n",
      "Iteration 3957, the loss is 4.442410976221017, parameters k is 10.30825314972369 and b is -42.114614048669665\n",
      "Iteration 3958, the loss is 4.442410960446639, parameters k is 10.308252760395627 and b is -42.11461009610049\n",
      "Iteration 3959, the loss is 4.4424109446722575, parameters k is 10.308252371067564 and b is -42.11460614353132\n",
      "Iteration 3960, the loss is 4.442410928897878, parameters k is 10.3082519817395 and b is -42.114602190962145\n",
      "Iteration 3961, the loss is 4.442410913123502, parameters k is 10.308251592411438 and b is -42.11459823839297\n",
      "Iteration 3962, the loss is 4.44241089734912, parameters k is 10.308251203083374 and b is -42.1145942858238\n",
      "Iteration 3963, the loss is 4.44241088157474, parameters k is 10.308250813755311 and b is -42.114590333254625\n",
      "Iteration 3964, the loss is 4.442410865800363, parameters k is 10.308250424427248 and b is -42.11458638068545\n",
      "Iteration 3965, the loss is 4.442410850025979, parameters k is 10.308250035099185 and b is -42.11458242811628\n",
      "Iteration 3966, the loss is 4.442410834251604, parameters k is 10.308249645771122 and b is -42.114578475547106\n",
      "Iteration 3967, the loss is 4.442410818477222, parameters k is 10.308249256443059 and b is -42.11457452297793\n",
      "Iteration 3968, the loss is 4.4424108027028435, parameters k is 10.308248867114996 and b is -42.11457057040876\n",
      "Iteration 3969, the loss is 4.442410786928465, parameters k is 10.308248477786933 and b is -42.114566617839586\n",
      "Iteration 3970, the loss is 4.442410771154084, parameters k is 10.30824808845887 and b is -42.11456266527041\n",
      "Iteration 3971, the loss is 4.442410755379704, parameters k is 10.308247699130806 and b is -42.11455871270124\n",
      "Iteration 3972, the loss is 4.4424107396053225, parameters k is 10.308247309802743 and b is -42.114554760132066\n",
      "Iteration 3973, the loss is 4.442410723830947, parameters k is 10.30824692047468 and b is -42.11455080756289\n",
      "Iteration 3974, the loss is 4.442410708056568, parameters k is 10.308246531146617 and b is -42.11454685499372\n",
      "Iteration 3975, the loss is 4.442410692282188, parameters k is 10.308246141818554 and b is -42.114542902424546\n",
      "Iteration 3976, the loss is 4.442410676507808, parameters k is 10.30824575249049 and b is -42.11453894985537\n",
      "Iteration 3977, the loss is 4.4424106607334295, parameters k is 10.308245363162428 and b is -42.1145349972862\n",
      "Iteration 3978, the loss is 4.44241064495905, parameters k is 10.308244973834364 and b is -42.114531044717026\n",
      "Iteration 3979, the loss is 4.442410629184669, parameters k is 10.308244584506301 and b is -42.11452709214785\n",
      "Iteration 3980, the loss is 4.442410613410292, parameters k is 10.308244195178238 and b is -42.11452313957868\n",
      "Iteration 3981, the loss is 4.442410597635911, parameters k is 10.308243805850175 and b is -42.114519187009506\n",
      "Iteration 3982, the loss is 4.442410581861532, parameters k is 10.308243416522112 and b is -42.11451523444033\n",
      "Iteration 3983, the loss is 4.442410566087154, parameters k is 10.308243027194049 and b is -42.11451128187116\n",
      "Iteration 3984, the loss is 4.442410550312772, parameters k is 10.308242637865986 and b is -42.114507329301986\n",
      "Iteration 3985, the loss is 4.442410534538394, parameters k is 10.308242248537923 and b is -42.11450337673281\n",
      "Iteration 3986, the loss is 4.442410518764016, parameters k is 10.30824185920986 and b is -42.11449942416364\n",
      "Iteration 3987, the loss is 4.442410502989635, parameters k is 10.308241469881796 and b is -42.114495471594466\n",
      "Iteration 3988, the loss is 4.442410487215256, parameters k is 10.308241080553733 and b is -42.11449151902529\n",
      "Iteration 3989, the loss is 4.442410471440876, parameters k is 10.30824069122567 and b is -42.11448756645612\n",
      "Iteration 3990, the loss is 4.442410455666497, parameters k is 10.308240301897607 and b is -42.11448361388695\n",
      "Iteration 3991, the loss is 4.442410439892117, parameters k is 10.308239912569544 and b is -42.11447966131777\n",
      "Iteration 3992, the loss is 4.442410424117736, parameters k is 10.30823952324148 and b is -42.1144757087486\n",
      "Iteration 3993, the loss is 4.442410408343356, parameters k is 10.308239133913418 and b is -42.11447175617943\n",
      "Iteration 3994, the loss is 4.442410392568979, parameters k is 10.308238744585354 and b is -42.11446780361025\n",
      "Iteration 3995, the loss is 4.442410376794599, parameters k is 10.308238355257291 and b is -42.11446385104108\n",
      "Iteration 3996, the loss is 4.4424103610202215, parameters k is 10.308237965929228 and b is -42.11445989847191\n",
      "Iteration 3997, the loss is 4.442410345245839, parameters k is 10.308237576601165 and b is -42.11445594590273\n",
      "Iteration 3998, the loss is 4.442410329471463, parameters k is 10.308237187273102 and b is -42.11445199333356\n",
      "Iteration 3999, the loss is 4.442410313697086, parameters k is 10.308236797945039 and b is -42.11444804076439\n",
      "Iteration 4000, the loss is 4.442410297922703, parameters k is 10.308236408616976 and b is -42.114444088195214\n",
      "Iteration 4001, the loss is 4.442410282148324, parameters k is 10.308236019288913 and b is -42.11444013562604\n",
      "Iteration 4002, the loss is 4.442410266373942, parameters k is 10.30823562996085 and b is -42.11443618305687\n",
      "Iteration 4003, the loss is 4.442410250599568, parameters k is 10.308235240632786 and b is -42.114432230487694\n",
      "Iteration 4004, the loss is 4.442410234825186, parameters k is 10.308234851304723 and b is -42.11442827791852\n",
      "Iteration 4005, the loss is 4.4424102190508075, parameters k is 10.30823446197666 and b is -42.11442432534935\n",
      "Iteration 4006, the loss is 4.442410203276428, parameters k is 10.308234072648597 and b is -42.114420372780174\n",
      "Iteration 4007, the loss is 4.442410187502047, parameters k is 10.308233683320534 and b is -42.114416420211\n",
      "Iteration 4008, the loss is 4.44241017172767, parameters k is 10.30823329399247 and b is -42.11441246764183\n",
      "Iteration 4009, the loss is 4.44241015595329, parameters k is 10.308232904664408 and b is -42.114408515072654\n",
      "Iteration 4010, the loss is 4.44241014017891, parameters k is 10.308232515336345 and b is -42.11440456250348\n",
      "Iteration 4011, the loss is 4.442410124404527, parameters k is 10.308232126008281 and b is -42.11440060993431\n",
      "Iteration 4012, the loss is 4.442410108630152, parameters k is 10.308231736680218 and b is -42.114396657365134\n",
      "Iteration 4013, the loss is 4.4424100928557735, parameters k is 10.308231347352155 and b is -42.11439270479596\n",
      "Iteration 4014, the loss is 4.442410077081392, parameters k is 10.308230958024092 and b is -42.11438875222679\n",
      "Iteration 4015, the loss is 4.442410061307013, parameters k is 10.308230568696029 and b is -42.114384799657614\n",
      "Iteration 4016, the loss is 4.442410045532633, parameters k is 10.308230179367966 and b is -42.11438084708844\n",
      "Iteration 4017, the loss is 4.442410029758256, parameters k is 10.308229790039903 and b is -42.11437689451927\n",
      "Iteration 4018, the loss is 4.4424100139838725, parameters k is 10.30822940071184 and b is -42.114372941950094\n",
      "Iteration 4019, the loss is 4.442409998209493, parameters k is 10.308229011383776 and b is -42.11436898938092\n",
      "Iteration 4020, the loss is 4.442409982435115, parameters k is 10.308228622055713 and b is -42.11436503681175\n",
      "Iteration 4021, the loss is 4.442409966660737, parameters k is 10.30822823272765 and b is -42.114361084242574\n",
      "Iteration 4022, the loss is 4.442409950886357, parameters k is 10.308227843399587 and b is -42.1143571316734\n",
      "Iteration 4023, the loss is 4.442409935111977, parameters k is 10.308227454071524 and b is -42.11435317910423\n",
      "Iteration 4024, the loss is 4.442409919337599, parameters k is 10.30822706474346 and b is -42.114349226535055\n",
      "Iteration 4025, the loss is 4.442409903563217, parameters k is 10.308226675415398 and b is -42.11434527396588\n",
      "Iteration 4026, the loss is 4.442409887788837, parameters k is 10.308226286087335 and b is -42.11434132139671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4027, the loss is 4.442409872014458, parameters k is 10.308225896759271 and b is -42.114337368827535\n",
      "Iteration 4028, the loss is 4.44240985624008, parameters k is 10.308225507431208 and b is -42.11433341625836\n",
      "Iteration 4029, the loss is 4.442409840465703, parameters k is 10.308225118103145 and b is -42.11432946368919\n",
      "Iteration 4030, the loss is 4.442409824691322, parameters k is 10.308224728775082 and b is -42.114325511120015\n",
      "Iteration 4031, the loss is 4.442409808916942, parameters k is 10.308224339447019 and b is -42.11432155855084\n",
      "Iteration 4032, the loss is 4.442409793142562, parameters k is 10.308223950118956 and b is -42.11431760598167\n",
      "Iteration 4033, the loss is 4.442409777368182, parameters k is 10.308223560790893 and b is -42.114313653412495\n",
      "Iteration 4034, the loss is 4.4424097615938045, parameters k is 10.30822317146283 and b is -42.11430970084332\n",
      "Iteration 4035, the loss is 4.4424097464006005, parameters k is 10.308222782134767 and b is -42.11430574827415\n",
      "Iteration 4036, the loss is 4.4424097349621, parameters k is 10.308194894782988 and b is -42.11430574827415\n",
      "Iteration 4037, the loss is 4.442409719187717, parameters k is 10.308194505454924 and b is -42.114301795704975\n",
      "Iteration 4038, the loss is 4.442409703413337, parameters k is 10.308194116126861 and b is -42.1142978431358\n",
      "Iteration 4039, the loss is 4.442409687638957, parameters k is 10.308193726798798 and b is -42.11429389056663\n",
      "Iteration 4040, the loss is 4.44240967186458, parameters k is 10.308193337470735 and b is -42.114289937997455\n",
      "Iteration 4041, the loss is 4.4424096560901996, parameters k is 10.308192948142672 and b is -42.11428598542828\n",
      "Iteration 4042, the loss is 4.442409640315817, parameters k is 10.308192558814609 and b is -42.11428203285911\n",
      "Iteration 4043, the loss is 4.442409624541442, parameters k is 10.308192169486546 and b is -42.114278080289935\n",
      "Iteration 4044, the loss is 4.442409608767062, parameters k is 10.308191780158483 and b is -42.11427412772076\n",
      "Iteration 4045, the loss is 4.442409592992681, parameters k is 10.30819139083042 and b is -42.11427017515159\n",
      "Iteration 4046, the loss is 4.442409577218302, parameters k is 10.308191001502356 and b is -42.114266222582415\n",
      "Iteration 4047, the loss is 4.442409561443921, parameters k is 10.308190612174293 and b is -42.11426227001324\n",
      "Iteration 4048, the loss is 4.442409545669544, parameters k is 10.30819022284623 and b is -42.11425831744407\n",
      "Iteration 4049, the loss is 4.442409529895162, parameters k is 10.308189833518167 and b is -42.114254364874895\n",
      "Iteration 4050, the loss is 4.442409514120782, parameters k is 10.308189444190104 and b is -42.11425041230572\n",
      "Iteration 4051, the loss is 4.442409498346405, parameters k is 10.30818905486204 and b is -42.11424645973655\n",
      "Iteration 4052, the loss is 4.442409482572025, parameters k is 10.308188665533978 and b is -42.114242507167376\n",
      "Iteration 4053, the loss is 4.4424094667976455, parameters k is 10.308188276205914 and b is -42.1142385545982\n",
      "Iteration 4054, the loss is 4.442409451023267, parameters k is 10.308187886877851 and b is -42.11423460202903\n",
      "Iteration 4055, the loss is 4.442409435248889, parameters k is 10.308187497549788 and b is -42.114230649459856\n",
      "Iteration 4056, the loss is 4.442409419474507, parameters k is 10.308187108221725 and b is -42.11422669689068\n",
      "Iteration 4057, the loss is 4.442409403700129, parameters k is 10.308186718893662 and b is -42.11422274432151\n",
      "Iteration 4058, the loss is 4.442409387925749, parameters k is 10.308186329565599 and b is -42.114218791752336\n",
      "Iteration 4059, the loss is 4.442409372151369, parameters k is 10.308185940237536 and b is -42.11421483918316\n",
      "Iteration 4060, the loss is 4.442409356376991, parameters k is 10.308185550909473 and b is -42.11421088661399\n",
      "Iteration 4061, the loss is 4.442409340602612, parameters k is 10.30818516158141 and b is -42.114206934044816\n",
      "Iteration 4062, the loss is 4.44240932482823, parameters k is 10.308184772253346 and b is -42.11420298147564\n",
      "Iteration 4063, the loss is 4.442409309053853, parameters k is 10.308184382925283 and b is -42.11419902890647\n",
      "Iteration 4064, the loss is 4.442409293279474, parameters k is 10.30818399359722 and b is -42.114195076337296\n",
      "Iteration 4065, the loss is 4.442409277505092, parameters k is 10.308183604269157 and b is -42.11419112376812\n",
      "Iteration 4066, the loss is 4.442409261730717, parameters k is 10.308183214941094 and b is -42.11418717119895\n",
      "Iteration 4067, the loss is 4.442409245956333, parameters k is 10.30818282561303 and b is -42.114183218629776\n",
      "Iteration 4068, the loss is 4.442409230181954, parameters k is 10.308182436284968 and b is -42.1141792660606\n",
      "Iteration 4069, the loss is 4.4424092144075775, parameters k is 10.308182046956905 and b is -42.11417531349143\n",
      "Iteration 4070, the loss is 4.4424091986331975, parameters k is 10.308181657628841 and b is -42.114171360922256\n",
      "Iteration 4071, the loss is 4.4424091828588175, parameters k is 10.308181268300778 and b is -42.11416740835308\n",
      "Iteration 4072, the loss is 4.4424091670844374, parameters k is 10.308180878972715 and b is -42.11416345578391\n",
      "Iteration 4073, the loss is 4.442409151310059, parameters k is 10.308180489644652 and b is -42.114159503214736\n",
      "Iteration 4074, the loss is 4.442409135535682, parameters k is 10.308180100316589 and b is -42.11415555064556\n",
      "Iteration 4075, the loss is 4.442409119761299, parameters k is 10.308179710988526 and b is -42.11415159807639\n",
      "Iteration 4076, the loss is 4.44240910398692, parameters k is 10.308179321660463 and b is -42.11414764550722\n",
      "Iteration 4077, the loss is 4.442409088212539, parameters k is 10.3081789323324 and b is -42.11414369293804\n",
      "Iteration 4078, the loss is 4.442409072438162, parameters k is 10.308178543004336 and b is -42.11413974036887\n",
      "Iteration 4079, the loss is 4.4424090566637835, parameters k is 10.308178153676273 and b is -42.1141357877997\n",
      "Iteration 4080, the loss is 4.442409040889403, parameters k is 10.30817776434821 and b is -42.11413183523052\n",
      "Iteration 4081, the loss is 4.442409025115023, parameters k is 10.308177375020147 and b is -42.11412788266135\n",
      "Iteration 4082, the loss is 4.442409009340644, parameters k is 10.308176985692084 and b is -42.11412393009218\n",
      "Iteration 4083, the loss is 4.442408993566265, parameters k is 10.30817659636402 and b is -42.114119977523\n",
      "Iteration 4084, the loss is 4.442408977791886, parameters k is 10.308176207035958 and b is -42.11411602495383\n",
      "Iteration 4085, the loss is 4.442408962017507, parameters k is 10.308175817707895 and b is -42.11411207238466\n",
      "Iteration 4086, the loss is 4.442408946243127, parameters k is 10.308175428379831 and b is -42.114108119815484\n",
      "Iteration 4087, the loss is 4.442408930468746, parameters k is 10.308175039051768 and b is -42.11410416724631\n",
      "Iteration 4088, the loss is 4.442408914694368, parameters k is 10.308174649723705 and b is -42.11410021467714\n",
      "Iteration 4089, the loss is 4.4424088989199895, parameters k is 10.308174260395642 and b is -42.114096262107964\n",
      "Iteration 4090, the loss is 4.442408883145608, parameters k is 10.308173871067579 and b is -42.11409230953879\n",
      "Iteration 4091, the loss is 4.44240886737123, parameters k is 10.308173481739516 and b is -42.11408835696962\n",
      "Iteration 4092, the loss is 4.442408851596849, parameters k is 10.308173092411453 and b is -42.114084404400444\n",
      "Iteration 4093, the loss is 4.442408835822473, parameters k is 10.30817270308339 and b is -42.11408045183127\n",
      "Iteration 4094, the loss is 4.44240882004809, parameters k is 10.308172313755326 and b is -42.1140764992621\n",
      "Iteration 4095, the loss is 4.44240880427371, parameters k is 10.308171924427263 and b is -42.114072546692924\n",
      "Iteration 4096, the loss is 4.442408788499333, parameters k is 10.3081715350992 and b is -42.11406859412375\n",
      "Iteration 4097, the loss is 4.442408772724951, parameters k is 10.308171145771137 and b is -42.11406464155458\n",
      "Iteration 4098, the loss is 4.442408756950571, parameters k is 10.308170756443074 and b is -42.114060688985404\n",
      "Iteration 4099, the loss is 4.442408741176196, parameters k is 10.308170367115011 and b is -42.11405673641623\n",
      "Iteration 4100, the loss is 4.442408725401814, parameters k is 10.308169977786948 and b is -42.11405278384706\n",
      "Iteration 4101, the loss is 4.442408709627434, parameters k is 10.308169588458885 and b is -42.114048831277884\n",
      "Iteration 4102, the loss is 4.442408693853058, parameters k is 10.308169199130822 and b is -42.11404487870871\n",
      "Iteration 4103, the loss is 4.442408678078677, parameters k is 10.308168809802758 and b is -42.11404092613954\n",
      "Iteration 4104, the loss is 4.442408662304298, parameters k is 10.308168420474695 and b is -42.114036973570364\n",
      "Iteration 4105, the loss is 4.442408646529918, parameters k is 10.308168031146632 and b is -42.11403302100119\n",
      "Iteration 4106, the loss is 4.442408630755539, parameters k is 10.308167641818569 and b is -42.11402906843202\n",
      "Iteration 4107, the loss is 4.442408614981158, parameters k is 10.308167252490506 and b is -42.114025115862844\n",
      "Iteration 4108, the loss is 4.442408599206778, parameters k is 10.308166863162443 and b is -42.11402116329367\n",
      "Iteration 4109, the loss is 4.4424085834324, parameters k is 10.30816647383438 and b is -42.1140172107245\n",
      "Iteration 4110, the loss is 4.442408567658021, parameters k is 10.308166084506317 and b is -42.114013258155325\n",
      "Iteration 4111, the loss is 4.4424085518836405, parameters k is 10.308165695178253 and b is -42.11400930558615\n",
      "Iteration 4112, the loss is 4.442408536109264, parameters k is 10.30816530585019 and b is -42.11400535301698\n",
      "Iteration 4113, the loss is 4.442408520334884, parameters k is 10.308164916522127 and b is -42.114001400447805\n",
      "Iteration 4114, the loss is 4.442408504560501, parameters k is 10.308164527194064 and b is -42.11399744787863\n",
      "Iteration 4115, the loss is 4.442408488786124, parameters k is 10.308164137866001 and b is -42.11399349530946\n",
      "Iteration 4116, the loss is 4.442408473011742, parameters k is 10.308163748537938 and b is -42.113989542740285\n",
      "Iteration 4117, the loss is 4.442408457237363, parameters k is 10.308163359209875 and b is -42.11398559017111\n",
      "Iteration 4118, the loss is 4.442408441462987, parameters k is 10.308162969881812 and b is -42.11398163760194\n",
      "Iteration 4119, the loss is 4.442408425688604, parameters k is 10.308162580553748 and b is -42.113977685032765\n",
      "Iteration 4120, the loss is 4.442408409914225, parameters k is 10.308162191225685 and b is -42.11397373246359\n",
      "Iteration 4121, the loss is 4.442408394139848, parameters k is 10.308161801897622 and b is -42.11396977989442\n",
      "Iteration 4122, the loss is 4.442408378365469, parameters k is 10.308161412569559 and b is -42.113965827325245\n",
      "Iteration 4123, the loss is 4.442408362591088, parameters k is 10.308161023241496 and b is -42.11396187475607\n",
      "Iteration 4124, the loss is 4.442408346816709, parameters k is 10.308160633913433 and b is -42.1139579221869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4125, the loss is 4.442408331042329, parameters k is 10.30816024458537 and b is -42.113953969617725\n",
      "Iteration 4126, the loss is 4.44240831526795, parameters k is 10.308159855257307 and b is -42.11395001704855\n",
      "Iteration 4127, the loss is 4.442408299493572, parameters k is 10.308159465929243 and b is -42.11394606447938\n",
      "Iteration 4128, the loss is 4.442408283719191, parameters k is 10.30815907660118 and b is -42.113942111910205\n",
      "Iteration 4129, the loss is 4.442408267944812, parameters k is 10.308158687273117 and b is -42.11393815934103\n",
      "Iteration 4130, the loss is 4.442408252170435, parameters k is 10.308158297945054 and b is -42.11393420677186\n",
      "Iteration 4131, the loss is 4.442408236396053, parameters k is 10.308157908616991 and b is -42.113930254202685\n",
      "Iteration 4132, the loss is 4.442408220621673, parameters k is 10.308157519288928 and b is -42.11392630163351\n",
      "Iteration 4133, the loss is 4.442408204847296, parameters k is 10.308157129960865 and b is -42.11392234906434\n",
      "Iteration 4134, the loss is 4.442408189072914, parameters k is 10.308156740632802 and b is -42.113918396495166\n",
      "Iteration 4135, the loss is 4.442408173298538, parameters k is 10.308156351304739 and b is -42.11391444392599\n",
      "Iteration 4136, the loss is 4.4424081575241585, parameters k is 10.308155961976675 and b is -42.11391049135682\n",
      "Iteration 4137, the loss is 4.442408141749776, parameters k is 10.308155572648612 and b is -42.113906538787646\n",
      "Iteration 4138, the loss is 4.442408125975397, parameters k is 10.30815518332055 and b is -42.11390258621847\n",
      "Iteration 4139, the loss is 4.4424081102010184, parameters k is 10.308154793992486 and b is -42.1138986336493\n",
      "Iteration 4140, the loss is 4.442408094426636, parameters k is 10.308154404664423 and b is -42.113894681080126\n",
      "Iteration 4141, the loss is 4.4424080786522575, parameters k is 10.30815401533636 and b is -42.11389072851095\n",
      "Iteration 4142, the loss is 4.44240806287788, parameters k is 10.308153626008297 and b is -42.11388677594178\n",
      "Iteration 4143, the loss is 4.4424080471035, parameters k is 10.308153236680234 and b is -42.113882823372606\n",
      "Iteration 4144, the loss is 4.442408031329119, parameters k is 10.30815284735217 and b is -42.11387887080343\n",
      "Iteration 4145, the loss is 4.442408015554741, parameters k is 10.308152458024107 and b is -42.11387491823426\n",
      "Iteration 4146, the loss is 4.442407999780363, parameters k is 10.308152068696044 and b is -42.113870965665086\n",
      "Iteration 4147, the loss is 4.442407984005982, parameters k is 10.308151679367981 and b is -42.11386701309591\n",
      "Iteration 4148, the loss is 4.442407968231602, parameters k is 10.308151290039918 and b is -42.11386306052674\n",
      "Iteration 4149, the loss is 4.442407952457224, parameters k is 10.308150900711855 and b is -42.113859107957566\n",
      "Iteration 4150, the loss is 4.4424079366828435, parameters k is 10.308150511383792 and b is -42.11385515538839\n",
      "Iteration 4151, the loss is 4.442407920908466, parameters k is 10.308150122055729 and b is -42.11385120281922\n",
      "Iteration 4152, the loss is 4.442407905134086, parameters k is 10.308149732727665 and b is -42.113847250250046\n",
      "Iteration 4153, the loss is 4.442407889359707, parameters k is 10.308149343399602 and b is -42.11384329768087\n",
      "Iteration 4154, the loss is 4.442407873585327, parameters k is 10.30814895407154 and b is -42.1138393451117\n",
      "Iteration 4155, the loss is 4.442407857810948, parameters k is 10.308148564743476 and b is -42.113835392542526\n",
      "Iteration 4156, the loss is 4.442407842036569, parameters k is 10.308148175415413 and b is -42.11383143997335\n",
      "Iteration 4157, the loss is 4.4424078262621896, parameters k is 10.30814778608735 and b is -42.11382748740418\n",
      "Iteration 4158, the loss is 4.442407810487808, parameters k is 10.308147396759287 and b is -42.11382353483501\n",
      "Iteration 4159, the loss is 4.442407794713431, parameters k is 10.308147007431224 and b is -42.11381958226583\n",
      "Iteration 4160, the loss is 4.442407778939046, parameters k is 10.30814661810316 and b is -42.11381562969666\n",
      "Iteration 4161, the loss is 4.44240776316467, parameters k is 10.308146228775097 and b is -42.11381167712749\n",
      "Iteration 4162, the loss is 4.442407747390291, parameters k is 10.308145839447034 and b is -42.11380772455831\n",
      "Iteration 4163, the loss is 4.44240773161591, parameters k is 10.308145450118971 and b is -42.11380377198914\n",
      "Iteration 4164, the loss is 4.442407715841536, parameters k is 10.308145060790908 and b is -42.11379981941997\n",
      "Iteration 4165, the loss is 4.442407700067154, parameters k is 10.308144671462845 and b is -42.11379586685079\n",
      "Iteration 4166, the loss is 4.442407684292775, parameters k is 10.308144282134782 and b is -42.11379191428162\n",
      "Iteration 4167, the loss is 4.442407668518396, parameters k is 10.308143892806719 and b is -42.11378796171245\n",
      "Iteration 4168, the loss is 4.442407652744018, parameters k is 10.308143503478655 and b is -42.113784009143274\n",
      "Iteration 4169, the loss is 4.4424076369696355, parameters k is 10.308143114150592 and b is -42.1137800565741\n",
      "Iteration 4170, the loss is 4.4424076211952555, parameters k is 10.30814272482253 and b is -42.11377610400493\n",
      "Iteration 4171, the loss is 4.44240760542088, parameters k is 10.308142335494466 and b is -42.113772151435754\n",
      "Iteration 4172, the loss is 4.442407589646497, parameters k is 10.308141946166403 and b is -42.11376819886658\n",
      "Iteration 4173, the loss is 4.44240757387212, parameters k is 10.30814155683834 and b is -42.11376424629741\n",
      "Iteration 4174, the loss is 4.442407558097739, parameters k is 10.308141167510277 and b is -42.113760293728234\n",
      "Iteration 4175, the loss is 4.442407542323361, parameters k is 10.308140778182214 and b is -42.11375634115906\n",
      "Iteration 4176, the loss is 4.442407526548981, parameters k is 10.30814038885415 and b is -42.11375238858989\n",
      "Iteration 4177, the loss is 4.4424075107746015, parameters k is 10.308139999526087 and b is -42.113748436020714\n",
      "Iteration 4178, the loss is 4.442407495000221, parameters k is 10.308139610198024 and b is -42.11374448345154\n",
      "Iteration 4179, the loss is 4.4424074792258414, parameters k is 10.308139220869961 and b is -42.11374053088237\n",
      "Iteration 4180, the loss is 4.442407463451464, parameters k is 10.308138831541898 and b is -42.113736578313194\n",
      "Iteration 4181, the loss is 4.442407447677082, parameters k is 10.308138442213835 and b is -42.11373262574402\n",
      "Iteration 4182, the loss is 4.442407431902703, parameters k is 10.308138052885772 and b is -42.11372867317485\n",
      "Iteration 4183, the loss is 4.442407416128325, parameters k is 10.308137663557709 and b is -42.113724720605674\n",
      "Iteration 4184, the loss is 4.442407400353947, parameters k is 10.308137274229646 and b is -42.1137207680365\n",
      "Iteration 4185, the loss is 4.442407384579566, parameters k is 10.308136884901582 and b is -42.11371681546733\n",
      "Iteration 4186, the loss is 4.4424073688051875, parameters k is 10.30813649557352 and b is -42.113712862898154\n",
      "Iteration 4187, the loss is 4.4424073530308075, parameters k is 10.308136106245456 and b is -42.11370891032898\n",
      "Iteration 4188, the loss is 4.442407337256423, parameters k is 10.308135716917393 and b is -42.11370495775981\n",
      "Iteration 4189, the loss is 4.442407321482048, parameters k is 10.30813532758933 and b is -42.113701005190634\n",
      "Iteration 4190, the loss is 4.44240730570767, parameters k is 10.308134938261267 and b is -42.11369705262146\n",
      "Iteration 4191, the loss is 4.44240728993329, parameters k is 10.308134548933204 and b is -42.11369310005229\n",
      "Iteration 4192, the loss is 4.442407274952941, parameters k is 10.30813415960514 and b is -42.113689147483115\n",
      "Iteration 4193, the loss is 4.442407263301581, parameters k is 10.308106272253362 and b is -42.113689147483115\n",
      "Iteration 4194, the loss is 4.4424072475272, parameters k is 10.308105882925299 and b is -42.11368519491394\n",
      "Iteration 4195, the loss is 4.44240723175282, parameters k is 10.308105493597235 and b is -42.11368124234477\n",
      "Iteration 4196, the loss is 4.442407215978443, parameters k is 10.308105104269172 and b is -42.113677289775595\n",
      "Iteration 4197, the loss is 4.442407200204064, parameters k is 10.30810471494111 and b is -42.11367333720642\n",
      "Iteration 4198, the loss is 4.442407184429684, parameters k is 10.308104325613046 and b is -42.11366938463725\n",
      "Iteration 4199, the loss is 4.442407168655305, parameters k is 10.308103936284983 and b is -42.113665432068075\n",
      "Iteration 4200, the loss is 4.442407152880926, parameters k is 10.30810354695692 and b is -42.1136614794989\n",
      "Iteration 4201, the loss is 4.442407137106546, parameters k is 10.308103157628857 and b is -42.11365752692973\n",
      "Iteration 4202, the loss is 4.442407121332166, parameters k is 10.308102768300794 and b is -42.113653574360555\n",
      "Iteration 4203, the loss is 4.442407105557788, parameters k is 10.30810237897273 and b is -42.11364962179138\n",
      "Iteration 4204, the loss is 4.4424070897834085, parameters k is 10.308101989644667 and b is -42.11364566922221\n",
      "Iteration 4205, the loss is 4.4424070740090285, parameters k is 10.308101600316604 and b is -42.113641716653035\n",
      "Iteration 4206, the loss is 4.44240705823465, parameters k is 10.308101210988541 and b is -42.11363776408386\n",
      "Iteration 4207, the loss is 4.44240704246027, parameters k is 10.308100821660478 and b is -42.11363381151469\n",
      "Iteration 4208, the loss is 4.442407026685889, parameters k is 10.308100432332415 and b is -42.113629858945515\n",
      "Iteration 4209, the loss is 4.44240701091151, parameters k is 10.308100043004352 and b is -42.11362590637634\n",
      "Iteration 4210, the loss is 4.442406995137133, parameters k is 10.308099653676289 and b is -42.11362195380717\n",
      "Iteration 4211, the loss is 4.442406979362754, parameters k is 10.308099264348225 and b is -42.113618001237995\n",
      "Iteration 4212, the loss is 4.442406963588372, parameters k is 10.308098875020162 and b is -42.11361404866882\n",
      "Iteration 4213, the loss is 4.442406947813991, parameters k is 10.3080984856921 and b is -42.11361009609965\n",
      "Iteration 4214, the loss is 4.442406932039612, parameters k is 10.308098096364036 and b is -42.113606143530475\n",
      "Iteration 4215, the loss is 4.442406916265235, parameters k is 10.308097707035973 and b is -42.1136021909613\n",
      "Iteration 4216, the loss is 4.442406900490854, parameters k is 10.30809731770791 and b is -42.11359823839213\n",
      "Iteration 4217, the loss is 4.442406884716477, parameters k is 10.308096928379847 and b is -42.113594285822955\n",
      "Iteration 4218, the loss is 4.442406868942095, parameters k is 10.308096539051784 and b is -42.11359033325378\n",
      "Iteration 4219, the loss is 4.442406853167716, parameters k is 10.30809614972372 and b is -42.11358638068461\n",
      "Iteration 4220, the loss is 4.442406837393337, parameters k is 10.308095760395657 and b is -42.113582428115436\n",
      "Iteration 4221, the loss is 4.44240682161896, parameters k is 10.308095371067594 and b is -42.11357847554626\n",
      "Iteration 4222, the loss is 4.44240680584458, parameters k is 10.308094981739531 and b is -42.11357452297709\n",
      "Iteration 4223, the loss is 4.4424067900702005, parameters k is 10.308094592411468 and b is -42.113570570407916\n",
      "Iteration 4224, the loss is 4.44240677429582, parameters k is 10.308094203083405 and b is -42.11356661783874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4225, the loss is 4.442406758521441, parameters k is 10.308093813755342 and b is -42.11356266526957\n",
      "Iteration 4226, the loss is 4.442406742747063, parameters k is 10.308093424427279 and b is -42.113558712700396\n",
      "Iteration 4227, the loss is 4.442406726972681, parameters k is 10.308093035099215 and b is -42.11355476013122\n",
      "Iteration 4228, the loss is 4.4424067111983, parameters k is 10.308092645771152 and b is -42.11355080756205\n",
      "Iteration 4229, the loss is 4.442406695423922, parameters k is 10.30809225644309 and b is -42.113546854992876\n",
      "Iteration 4230, the loss is 4.442406679649544, parameters k is 10.308091867115026 and b is -42.1135429024237\n",
      "Iteration 4231, the loss is 4.442406663875166, parameters k is 10.308091477786963 and b is -42.11353894985453\n",
      "Iteration 4232, the loss is 4.442406648100785, parameters k is 10.3080910884589 and b is -42.113534997285356\n",
      "Iteration 4233, the loss is 4.442406632326404, parameters k is 10.308090699130837 and b is -42.11353104471618\n",
      "Iteration 4234, the loss is 4.442406616552027, parameters k is 10.308090309802774 and b is -42.11352709214701\n",
      "Iteration 4235, the loss is 4.442406600777648, parameters k is 10.30808992047471 and b is -42.113523139577836\n",
      "Iteration 4236, the loss is 4.442406585003265, parameters k is 10.308089531146647 and b is -42.11351918700866\n",
      "Iteration 4237, the loss is 4.442406569228885, parameters k is 10.308089141818584 and b is -42.11351523443949\n",
      "Iteration 4238, the loss is 4.442406553454507, parameters k is 10.308088752490521 and b is -42.113511281870316\n",
      "Iteration 4239, the loss is 4.442406537680128, parameters k is 10.308088363162458 and b is -42.11350732930114\n",
      "Iteration 4240, the loss is 4.442406521905751, parameters k is 10.308087973834395 and b is -42.11350337673197\n",
      "Iteration 4241, the loss is 4.442406506131368, parameters k is 10.308087584506332 and b is -42.1134994241628\n",
      "Iteration 4242, the loss is 4.4424064903569915, parameters k is 10.308087195178269 and b is -42.11349547159362\n",
      "Iteration 4243, the loss is 4.442406474582613, parameters k is 10.308086805850206 and b is -42.11349151902445\n",
      "Iteration 4244, the loss is 4.442406458808232, parameters k is 10.308086416522142 and b is -42.11348756645528\n",
      "Iteration 4245, the loss is 4.442406443033854, parameters k is 10.30808602719408 and b is -42.1134836138861\n",
      "Iteration 4246, the loss is 4.442406427259475, parameters k is 10.308085637866016 and b is -42.11347966131693\n",
      "Iteration 4247, the loss is 4.442406411485096, parameters k is 10.308085248537953 and b is -42.11347570874776\n",
      "Iteration 4248, the loss is 4.442406395710715, parameters k is 10.30808485920989 and b is -42.11347175617858\n",
      "Iteration 4249, the loss is 4.442406379936334, parameters k is 10.308084469881827 and b is -42.11346780360941\n",
      "Iteration 4250, the loss is 4.442406364161956, parameters k is 10.308084080553764 and b is -42.11346385104024\n",
      "Iteration 4251, the loss is 4.4424063483875775, parameters k is 10.3080836912257 and b is -42.11345989847106\n",
      "Iteration 4252, the loss is 4.442406332613197, parameters k is 10.308083301897637 and b is -42.11345594590189\n",
      "Iteration 4253, the loss is 4.44240631683882, parameters k is 10.308082912569574 and b is -42.11345199333272\n",
      "Iteration 4254, the loss is 4.442406301064438, parameters k is 10.308082523241511 and b is -42.113448040763544\n",
      "Iteration 4255, the loss is 4.442406285290059, parameters k is 10.308082133913448 and b is -42.11344408819437\n",
      "Iteration 4256, the loss is 4.44240626951568, parameters k is 10.308081744585385 and b is -42.1134401356252\n",
      "Iteration 4257, the loss is 4.4424062537413, parameters k is 10.308081355257322 and b is -42.113436183056024\n",
      "Iteration 4258, the loss is 4.44240623796692, parameters k is 10.308080965929259 and b is -42.11343223048685\n",
      "Iteration 4259, the loss is 4.442406222192539, parameters k is 10.308080576601196 and b is -42.11342827791768\n",
      "Iteration 4260, the loss is 4.442406206418163, parameters k is 10.308080187273132 and b is -42.113424325348504\n",
      "Iteration 4261, the loss is 4.442406190643783, parameters k is 10.30807979794507 and b is -42.11342037277933\n",
      "Iteration 4262, the loss is 4.442406174869403, parameters k is 10.308079408617006 and b is -42.11341642021016\n",
      "Iteration 4263, the loss is 4.442406159095024, parameters k is 10.308079019288943 and b is -42.113412467640984\n",
      "Iteration 4264, the loss is 4.442406143320645, parameters k is 10.30807862996088 and b is -42.11340851507181\n",
      "Iteration 4265, the loss is 4.442406127546266, parameters k is 10.308078240632817 and b is -42.11340456250264\n",
      "Iteration 4266, the loss is 4.442406111771884, parameters k is 10.308077851304754 and b is -42.113400609933464\n",
      "Iteration 4267, the loss is 4.442406095997504, parameters k is 10.30807746197669 and b is -42.11339665736429\n",
      "Iteration 4268, the loss is 4.442406080223128, parameters k is 10.308077072648627 and b is -42.11339270479512\n",
      "Iteration 4269, the loss is 4.442406064448745, parameters k is 10.308076683320564 and b is -42.113388752225944\n",
      "Iteration 4270, the loss is 4.442406048674368, parameters k is 10.308076293992501 and b is -42.11338479965677\n",
      "Iteration 4271, the loss is 4.442406032899986, parameters k is 10.308075904664438 and b is -42.1133808470876\n",
      "Iteration 4272, the loss is 4.4424060171256095, parameters k is 10.308075515336375 and b is -42.113376894518424\n",
      "Iteration 4273, the loss is 4.442406001351229, parameters k is 10.308075126008312 and b is -42.11337294194925\n",
      "Iteration 4274, the loss is 4.44240598557685, parameters k is 10.308074736680249 and b is -42.11336898938008\n",
      "Iteration 4275, the loss is 4.442405969802469, parameters k is 10.308074347352186 and b is -42.113365036810904\n",
      "Iteration 4276, the loss is 4.442405954028092, parameters k is 10.308073958024123 and b is -42.11336108424173\n",
      "Iteration 4277, the loss is 4.442405938253713, parameters k is 10.30807356869606 and b is -42.11335713167256\n",
      "Iteration 4278, the loss is 4.442405922479331, parameters k is 10.308073179367996 and b is -42.113353179103385\n",
      "Iteration 4279, the loss is 4.442405906704953, parameters k is 10.308072790039933 and b is -42.11334922653421\n",
      "Iteration 4280, the loss is 4.442405890930573, parameters k is 10.30807240071187 and b is -42.11334527396504\n",
      "Iteration 4281, the loss is 4.442405875156192, parameters k is 10.308072011383807 and b is -42.113341321395865\n",
      "Iteration 4282, the loss is 4.442405859381816, parameters k is 10.308071622055744 and b is -42.11333736882669\n",
      "Iteration 4283, the loss is 4.442405843607436, parameters k is 10.30807123272768 and b is -42.11333341625752\n",
      "Iteration 4284, the loss is 4.442405827833056, parameters k is 10.308070843399618 and b is -42.113329463688345\n",
      "Iteration 4285, the loss is 4.442405812058675, parameters k is 10.308070454071554 and b is -42.11332551111917\n",
      "Iteration 4286, the loss is 4.442405796284297, parameters k is 10.308070064743491 and b is -42.11332155855\n",
      "Iteration 4287, the loss is 4.442405780509917, parameters k is 10.308069675415428 and b is -42.113317605980825\n",
      "Iteration 4288, the loss is 4.442405764735538, parameters k is 10.308069286087365 and b is -42.11331365341165\n",
      "Iteration 4289, the loss is 4.442405748961159, parameters k is 10.308068896759302 and b is -42.11330970084248\n",
      "Iteration 4290, the loss is 4.44240573318678, parameters k is 10.308068507431239 and b is -42.113305748273305\n",
      "Iteration 4291, the loss is 4.442405717412401, parameters k is 10.308068118103176 and b is -42.11330179570413\n",
      "Iteration 4292, the loss is 4.442405701638022, parameters k is 10.308067728775113 and b is -42.11329784313496\n",
      "Iteration 4293, the loss is 4.44240568586364, parameters k is 10.30806733944705 and b is -42.113293890565785\n",
      "Iteration 4294, the loss is 4.442405670089265, parameters k is 10.308066950118986 and b is -42.11328993799661\n",
      "Iteration 4295, the loss is 4.442405654314883, parameters k is 10.308066560790923 and b is -42.11328598542744\n",
      "Iteration 4296, the loss is 4.4424056385405, parameters k is 10.30806617146286 and b is -42.113282032858265\n",
      "Iteration 4297, the loss is 4.442405622766122, parameters k is 10.308065782134797 and b is -42.11327808028909\n",
      "Iteration 4298, the loss is 4.442405606991744, parameters k is 10.308065392806734 and b is -42.11327412771992\n",
      "Iteration 4299, the loss is 4.442405591217366, parameters k is 10.30806500347867 and b is -42.113270175150745\n",
      "Iteration 4300, the loss is 4.4424055754429865, parameters k is 10.308064614150608 and b is -42.11326622258157\n",
      "Iteration 4301, the loss is 4.4424055596686065, parameters k is 10.308064224822544 and b is -42.1132622700124\n",
      "Iteration 4302, the loss is 4.442405543894224, parameters k is 10.308063835494481 and b is -42.113258317443226\n",
      "Iteration 4303, the loss is 4.442405528119846, parameters k is 10.308063446166418 and b is -42.11325436487405\n",
      "Iteration 4304, the loss is 4.44240551234547, parameters k is 10.308063056838355 and b is -42.11325041230488\n",
      "Iteration 4305, the loss is 4.442405496571092, parameters k is 10.308062667510292 and b is -42.113246459735706\n",
      "Iteration 4306, the loss is 4.442405480796711, parameters k is 10.308062278182229 and b is -42.11324250716653\n",
      "Iteration 4307, the loss is 4.44240546502233, parameters k is 10.308061888854166 and b is -42.11323855459736\n",
      "Iteration 4308, the loss is 4.442405449247952, parameters k is 10.308061499526103 and b is -42.113234602028186\n",
      "Iteration 4309, the loss is 4.442405433473571, parameters k is 10.30806111019804 and b is -42.11323064945901\n",
      "Iteration 4310, the loss is 4.442405417699192, parameters k is 10.308060720869976 and b is -42.11322669688984\n",
      "Iteration 4311, the loss is 4.442405401924813, parameters k is 10.308060331541913 and b is -42.113222744320666\n",
      "Iteration 4312, the loss is 4.442405386150435, parameters k is 10.30805994221385 and b is -42.11321879175149\n",
      "Iteration 4313, the loss is 4.442405370376054, parameters k is 10.308059552885787 and b is -42.11321483918232\n",
      "Iteration 4314, the loss is 4.442405354601674, parameters k is 10.308059163557724 and b is -42.113210886613146\n",
      "Iteration 4315, the loss is 4.442405338827298, parameters k is 10.30805877422966 and b is -42.11320693404397\n",
      "Iteration 4316, the loss is 4.442405323052915, parameters k is 10.308058384901598 and b is -42.1132029814748\n",
      "Iteration 4317, the loss is 4.442405307278535, parameters k is 10.308057995573535 and b is -42.113199028905626\n",
      "Iteration 4318, the loss is 4.442405291504157, parameters k is 10.308057606245471 and b is -42.11319507633645\n",
      "Iteration 4319, the loss is 4.442405275729778, parameters k is 10.308057216917408 and b is -42.11319112376728\n",
      "Iteration 4320, the loss is 4.442405259955399, parameters k is 10.308056827589345 and b is -42.113187171198106\n",
      "Iteration 4321, the loss is 4.44240524418102, parameters k is 10.308056438261282 and b is -42.11318321862893\n",
      "Iteration 4322, the loss is 4.442405228406639, parameters k is 10.308056048933219 and b is -42.11317926605976\n",
      "Iteration 4323, the loss is 4.44240521263226, parameters k is 10.308055659605156 and b is -42.113175313490586\n",
      "Iteration 4324, the loss is 4.442405196857881, parameters k is 10.308055270277093 and b is -42.11317136092141\n",
      "Iteration 4325, the loss is 4.442405181083501, parameters k is 10.30805488094903 and b is -42.11316740835224\n",
      "Iteration 4326, the loss is 4.442405165309118, parameters k is 10.308054491620966 and b is -42.11316345578307\n",
      "Iteration 4327, the loss is 4.442405149534742, parameters k is 10.308054102292903 and b is -42.11315950321389\n",
      "Iteration 4328, the loss is 4.442405133760363, parameters k is 10.30805371296484 and b is -42.11315555064472\n",
      "Iteration 4329, the loss is 4.442405117985982, parameters k is 10.308053323636777 and b is -42.11315159807555\n",
      "Iteration 4330, the loss is 4.442405102211605, parameters k is 10.308052934308714 and b is -42.11314764550637\n",
      "Iteration 4331, the loss is 4.442405086437224, parameters k is 10.30805254498065 and b is -42.1131436929372\n",
      "Iteration 4332, the loss is 4.442405070662845, parameters k is 10.308052155652588 and b is -42.11313974036803\n",
      "Iteration 4333, the loss is 4.4424050548884635, parameters k is 10.308051766324525 and b is -42.11313578779885\n",
      "Iteration 4334, the loss is 4.442405039114086, parameters k is 10.308051376996461 and b is -42.11313183522968\n",
      "Iteration 4335, the loss is 4.442405023339707, parameters k is 10.308050987668398 and b is -42.11312788266051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4336, the loss is 4.442405007565328, parameters k is 10.308050598340335 and b is -42.113123930091334\n",
      "Iteration 4337, the loss is 4.442404991790948, parameters k is 10.308050209012272 and b is -42.11311997752216\n",
      "Iteration 4338, the loss is 4.442404976016572, parameters k is 10.308049819684209 and b is -42.11311602495299\n",
      "Iteration 4339, the loss is 4.4424049602421904, parameters k is 10.308049430356146 and b is -42.113112072383814\n",
      "Iteration 4340, the loss is 4.4424049444678095, parameters k is 10.308049041028083 and b is -42.11310811981464\n",
      "Iteration 4341, the loss is 4.442404928693431, parameters k is 10.30804865170002 and b is -42.11310416724547\n",
      "Iteration 4342, the loss is 4.442404912919051, parameters k is 10.308048262371956 and b is -42.113100214676294\n",
      "Iteration 4343, the loss is 4.442404897144672, parameters k is 10.308047873043893 and b is -42.11309626210712\n",
      "Iteration 4344, the loss is 4.442404881370292, parameters k is 10.30804748371583 and b is -42.11309230953795\n",
      "Iteration 4345, the loss is 4.442404865595914, parameters k is 10.308047094387767 and b is -42.113088356968774\n",
      "Iteration 4346, the loss is 4.442404849821531, parameters k is 10.308046705059704 and b is -42.1130844043996\n",
      "Iteration 4347, the loss is 4.442404834047155, parameters k is 10.30804631573164 and b is -42.11308045183043\n",
      "Iteration 4348, the loss is 4.442404818272775, parameters k is 10.308045926403578 and b is -42.113076499261254\n",
      "Iteration 4349, the loss is 4.442404803505282, parameters k is 10.308045537075515 and b is -42.11307254669208\n",
      "Iteration 4350, the loss is 4.442404791641067, parameters k is 10.308017649723736 and b is -42.11307254669208\n",
      "Iteration 4351, the loss is 4.442404775866684, parameters k is 10.308017260395673 and b is -42.11306859412291\n",
      "Iteration 4352, the loss is 4.442404760092306, parameters k is 10.30801687106761 and b is -42.113064641553734\n",
      "Iteration 4353, the loss is 4.442404744317928, parameters k is 10.308016481739546 and b is -42.11306068898456\n",
      "Iteration 4354, the loss is 4.442404728543548, parameters k is 10.308016092411483 and b is -42.11305673641539\n",
      "Iteration 4355, the loss is 4.442404712769172, parameters k is 10.30801570308342 and b is -42.113052783846214\n",
      "Iteration 4356, the loss is 4.442404696994791, parameters k is 10.308015313755357 and b is -42.11304883127704\n",
      "Iteration 4357, the loss is 4.442404681220413, parameters k is 10.308014924427294 and b is -42.11304487870787\n",
      "Iteration 4358, the loss is 4.442404665446033, parameters k is 10.30801453509923 and b is -42.113040926138694\n",
      "Iteration 4359, the loss is 4.44240464967165, parameters k is 10.308014145771168 and b is -42.11303697356952\n",
      "Iteration 4360, the loss is 4.442404633897272, parameters k is 10.308013756443104 and b is -42.11303302100035\n",
      "Iteration 4361, the loss is 4.442404618122892, parameters k is 10.308013367115041 and b is -42.113029068431175\n",
      "Iteration 4362, the loss is 4.442404602348513, parameters k is 10.308012977786978 and b is -42.113025115862\n",
      "Iteration 4363, the loss is 4.442404586574135, parameters k is 10.308012588458915 and b is -42.11302116329283\n",
      "Iteration 4364, the loss is 4.442404570799755, parameters k is 10.308012199130852 and b is -42.113017210723655\n",
      "Iteration 4365, the loss is 4.442404555025376, parameters k is 10.308011809802789 and b is -42.11301325815448\n",
      "Iteration 4366, the loss is 4.442404539250997, parameters k is 10.308011420474726 and b is -42.11300930558531\n",
      "Iteration 4367, the loss is 4.442404523476619, parameters k is 10.308011031146663 and b is -42.113005353016135\n",
      "Iteration 4368, the loss is 4.44240450770224, parameters k is 10.3080106418186 and b is -42.11300140044696\n",
      "Iteration 4369, the loss is 4.442404491927858, parameters k is 10.308010252490536 and b is -42.11299744787779\n",
      "Iteration 4370, the loss is 4.44240447615348, parameters k is 10.308009863162473 and b is -42.112993495308615\n",
      "Iteration 4371, the loss is 4.442404460379097, parameters k is 10.30800947383441 and b is -42.11298954273944\n",
      "Iteration 4372, the loss is 4.442404444604718, parameters k is 10.308009084506347 and b is -42.11298559017027\n",
      "Iteration 4373, the loss is 4.442404428830341, parameters k is 10.308008695178284 and b is -42.112981637601095\n",
      "Iteration 4374, the loss is 4.44240441305596, parameters k is 10.30800830585022 and b is -42.11297768503192\n",
      "Iteration 4375, the loss is 4.442404397281582, parameters k is 10.308007916522158 and b is -42.11297373246275\n",
      "Iteration 4376, the loss is 4.4424043815072025, parameters k is 10.308007527194095 and b is -42.112969779893575\n",
      "Iteration 4377, the loss is 4.4424043657328225, parameters k is 10.308007137866031 and b is -42.1129658273244\n",
      "Iteration 4378, the loss is 4.442404349958443, parameters k is 10.308006748537968 and b is -42.11296187475523\n",
      "Iteration 4379, the loss is 4.442404334184066, parameters k is 10.308006359209905 and b is -42.112957922186055\n",
      "Iteration 4380, the loss is 4.442404318409684, parameters k is 10.308005969881842 and b is -42.11295396961688\n",
      "Iteration 4381, the loss is 4.442404302635303, parameters k is 10.308005580553779 and b is -42.11295001704771\n",
      "Iteration 4382, the loss is 4.442404286860924, parameters k is 10.308005191225716 and b is -42.112946064478535\n",
      "Iteration 4383, the loss is 4.442404271086547, parameters k is 10.308004801897653 and b is -42.11294211190936\n",
      "Iteration 4384, the loss is 4.442404255312166, parameters k is 10.30800441256959 and b is -42.11293815934019\n",
      "Iteration 4385, the loss is 4.442404239537788, parameters k is 10.308004023241526 and b is -42.112934206771016\n",
      "Iteration 4386, the loss is 4.4424042237634085, parameters k is 10.308003633913463 and b is -42.11293025420184\n",
      "Iteration 4387, the loss is 4.44240420798903, parameters k is 10.3080032445854 and b is -42.11292630163267\n",
      "Iteration 4388, the loss is 4.442404192214649, parameters k is 10.308002855257337 and b is -42.112922349063496\n",
      "Iteration 4389, the loss is 4.442404176440269, parameters k is 10.308002465929274 and b is -42.11291839649432\n",
      "Iteration 4390, the loss is 4.442404160665892, parameters k is 10.30800207660121 and b is -42.11291444392515\n",
      "Iteration 4391, the loss is 4.44240414489151, parameters k is 10.308001687273148 and b is -42.112910491355976\n",
      "Iteration 4392, the loss is 4.442404129117132, parameters k is 10.308001297945085 and b is -42.1129065387868\n",
      "Iteration 4393, the loss is 4.442404113342751, parameters k is 10.308000908617021 and b is -42.11290258621763\n",
      "Iteration 4394, the loss is 4.442404097568373, parameters k is 10.308000519288958 and b is -42.112898633648456\n",
      "Iteration 4395, the loss is 4.4424040817939945, parameters k is 10.308000129960895 and b is -42.11289468107928\n",
      "Iteration 4396, the loss is 4.442404066019615, parameters k is 10.307999740632832 and b is -42.11289072851011\n",
      "Iteration 4397, the loss is 4.442404050245233, parameters k is 10.307999351304769 and b is -42.112886775940936\n",
      "Iteration 4398, the loss is 4.4424040344708535, parameters k is 10.307998961976706 and b is -42.11288282337176\n",
      "Iteration 4399, the loss is 4.442404018696479, parameters k is 10.307998572648643 and b is -42.11287887080259\n",
      "Iteration 4400, the loss is 4.442404002922097, parameters k is 10.30799818332058 and b is -42.112874918233416\n",
      "Iteration 4401, the loss is 4.442403987147717, parameters k is 10.307997793992516 and b is -42.11287096566424\n",
      "Iteration 4402, the loss is 4.442403971373338, parameters k is 10.307997404664453 and b is -42.11286701309507\n",
      "Iteration 4403, the loss is 4.44240395559896, parameters k is 10.30799701533639 and b is -42.112863060525896\n",
      "Iteration 4404, the loss is 4.442403939824576, parameters k is 10.307996626008327 and b is -42.11285910795672\n",
      "Iteration 4405, the loss is 4.4424039240502005, parameters k is 10.307996236680264 and b is -42.11285515538755\n",
      "Iteration 4406, the loss is 4.442403908275821, parameters k is 10.3079958473522 and b is -42.112851202818376\n",
      "Iteration 4407, the loss is 4.44240389250144, parameters k is 10.307995458024138 and b is -42.1128472502492\n",
      "Iteration 4408, the loss is 4.442403876727062, parameters k is 10.307995068696075 and b is -42.11284329768003\n",
      "Iteration 4409, the loss is 4.442403860952682, parameters k is 10.307994679368012 and b is -42.11283934511086\n",
      "Iteration 4410, the loss is 4.442403845178301, parameters k is 10.307994290039948 and b is -42.11283539254168\n",
      "Iteration 4411, the loss is 4.442403829403921, parameters k is 10.307993900711885 and b is -42.11283143997251\n",
      "Iteration 4412, the loss is 4.442403813629545, parameters k is 10.307993511383822 and b is -42.11282748740334\n",
      "Iteration 4413, the loss is 4.442403797855166, parameters k is 10.307993122055759 and b is -42.11282353483416\n",
      "Iteration 4414, the loss is 4.442403782080786, parameters k is 10.307992732727696 and b is -42.11281958226499\n",
      "Iteration 4415, the loss is 4.442403766306406, parameters k is 10.307992343399633 and b is -42.11281562969582\n",
      "Iteration 4416, the loss is 4.442403750532025, parameters k is 10.30799195407157 and b is -42.11281167712664\n",
      "Iteration 4417, the loss is 4.442403734757648, parameters k is 10.307991564743507 and b is -42.11280772455747\n",
      "Iteration 4418, the loss is 4.4424037189832655, parameters k is 10.307991175415443 and b is -42.1128037719883\n",
      "Iteration 4419, the loss is 4.442403703208891, parameters k is 10.30799078608738 and b is -42.11279981941912\n",
      "Iteration 4420, the loss is 4.442403687434508, parameters k is 10.307990396759317 and b is -42.11279586684995\n",
      "Iteration 4421, the loss is 4.442403671660132, parameters k is 10.307990007431254 and b is -42.11279191428078\n",
      "Iteration 4422, the loss is 4.442403655885752, parameters k is 10.307989618103191 and b is -42.112787961711604\n",
      "Iteration 4423, the loss is 4.44240364011137, parameters k is 10.307989228775128 and b is -42.11278400914243\n",
      "Iteration 4424, the loss is 4.442403624336992, parameters k is 10.307988839447065 and b is -42.11278005657326\n",
      "Iteration 4425, the loss is 4.442403608562612, parameters k is 10.307988450119002 and b is -42.112776104004084\n",
      "Iteration 4426, the loss is 4.4424035927882315, parameters k is 10.307988060790938 and b is -42.11277215143491\n",
      "Iteration 4427, the loss is 4.442403577013852, parameters k is 10.307987671462875 and b is -42.11276819886574\n",
      "Iteration 4428, the loss is 4.442403561239473, parameters k is 10.307987282134812 and b is -42.112764246296564\n",
      "Iteration 4429, the loss is 4.442403545465096, parameters k is 10.307986892806749 and b is -42.11276029372739\n",
      "Iteration 4430, the loss is 4.442403529690713, parameters k is 10.307986503478686 and b is -42.11275634115822\n",
      "Iteration 4431, the loss is 4.442403513916336, parameters k is 10.307986114150623 and b is -42.112752388589044\n",
      "Iteration 4432, the loss is 4.442403498141957, parameters k is 10.30798572482256 and b is -42.11274843601987\n",
      "Iteration 4433, the loss is 4.442403482367576, parameters k is 10.307985335494497 and b is -42.1127444834507\n",
      "Iteration 4434, the loss is 4.442403466593198, parameters k is 10.307984946166433 and b is -42.112740530881524\n",
      "Iteration 4435, the loss is 4.442403450818818, parameters k is 10.30798455683837 and b is -42.11273657831235\n",
      "Iteration 4436, the loss is 4.4424034350444375, parameters k is 10.307984167510307 and b is -42.11273262574318\n",
      "Iteration 4437, the loss is 4.442403419270057, parameters k is 10.307983778182244 and b is -42.112728673174004\n",
      "Iteration 4438, the loss is 4.442403403495681, parameters k is 10.307983388854181 and b is -42.11272472060483\n",
      "Iteration 4439, the loss is 4.442403387721301, parameters k is 10.307982999526118 and b is -42.11272076803566\n",
      "Iteration 4440, the loss is 4.44240337194692, parameters k is 10.307982610198055 and b is -42.112716815466484\n",
      "Iteration 4441, the loss is 4.442403356172544, parameters k is 10.307982220869992 and b is -42.11271286289731\n",
      "Iteration 4442, the loss is 4.442403340398163, parameters k is 10.307981831541928 and b is -42.11270891032814\n",
      "Iteration 4443, the loss is 4.4424033246237835, parameters k is 10.307981442213865 and b is -42.112704957758964\n",
      "Iteration 4444, the loss is 4.442403308849402, parameters k is 10.307981052885802 and b is -42.11270100518979\n",
      "Iteration 4445, the loss is 4.442403293075026, parameters k is 10.30798066355774 and b is -42.11269705262062\n",
      "Iteration 4446, the loss is 4.4424032773006426, parameters k is 10.307980274229676 and b is -42.112693100051445\n",
      "Iteration 4447, the loss is 4.442403261526266, parameters k is 10.307979884901613 and b is -42.11268914748227\n",
      "Iteration 4448, the loss is 4.442403245751885, parameters k is 10.30797949557355 and b is -42.1126851949131\n",
      "Iteration 4449, the loss is 4.442403229977507, parameters k is 10.307979106245487 and b is -42.112681242343925\n",
      "Iteration 4450, the loss is 4.44240321420313, parameters k is 10.307978716917424 and b is -42.11267728977475\n",
      "Iteration 4451, the loss is 4.442403198428748, parameters k is 10.30797832758936 and b is -42.11267333720558\n",
      "Iteration 4452, the loss is 4.4424031826543695, parameters k is 10.307977938261297 and b is -42.112669384636405\n",
      "Iteration 4453, the loss is 4.442403166879988, parameters k is 10.307977548933234 and b is -42.11266543206723\n",
      "Iteration 4454, the loss is 4.4424031511056095, parameters k is 10.307977159605171 and b is -42.11266147949806\n",
      "Iteration 4455, the loss is 4.44240313533123, parameters k is 10.307976770277108 and b is -42.112657526928885\n",
      "Iteration 4456, the loss is 4.442403119556851, parameters k is 10.307976380949045 and b is -42.11265357435971\n",
      "Iteration 4457, the loss is 4.442403103782471, parameters k is 10.307975991620982 and b is -42.11264962179054\n",
      "Iteration 4458, the loss is 4.442403088008091, parameters k is 10.307975602292919 and b is -42.112645669221365\n",
      "Iteration 4459, the loss is 4.442403072233715, parameters k is 10.307975212964855 and b is -42.11264171665219\n",
      "Iteration 4460, the loss is 4.442403056459332, parameters k is 10.307974823636792 and b is -42.11263776408302\n",
      "Iteration 4461, the loss is 4.44240304068495, parameters k is 10.30797443430873 and b is -42.112633811513845\n",
      "Iteration 4462, the loss is 4.442403024910573, parameters k is 10.307974044980666 and b is -42.11262985894467\n",
      "Iteration 4463, the loss is 4.4424030091361955, parameters k is 10.307973655652603 and b is -42.1126259063755\n",
      "Iteration 4464, the loss is 4.4424029933618145, parameters k is 10.30797326632454 and b is -42.112621953806325\n",
      "Iteration 4465, the loss is 4.4424029775874345, parameters k is 10.307972876996477 and b is -42.11261800123715\n",
      "Iteration 4466, the loss is 4.442402961813057, parameters k is 10.307972487668414 and b is -42.11261404866798\n",
      "Iteration 4467, the loss is 4.442402946038681, parameters k is 10.30797209834035 and b is -42.112610096098805\n",
      "Iteration 4468, the loss is 4.442402930264296, parameters k is 10.307971709012287 and b is -42.11260614352963\n",
      "Iteration 4469, the loss is 4.442402914489918, parameters k is 10.307971319684224 and b is -42.11260219096046\n",
      "Iteration 4470, the loss is 4.442402898715537, parameters k is 10.307970930356161 and b is -42.112598238391286\n",
      "Iteration 4471, the loss is 4.442402882941159, parameters k is 10.307970541028098 and b is -42.11259428582211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4472, the loss is 4.442402867166781, parameters k is 10.307970151700035 and b is -42.11259033325294\n",
      "Iteration 4473, the loss is 4.4424028513924005, parameters k is 10.307969762371972 and b is -42.112586380683766\n",
      "Iteration 4474, the loss is 4.442402835618021, parameters k is 10.307969373043909 and b is -42.11258242811459\n",
      "Iteration 4475, the loss is 4.442402819843645, parameters k is 10.307968983715845 and b is -42.11257847554542\n",
      "Iteration 4476, the loss is 4.442402804069262, parameters k is 10.307968594387782 and b is -42.112574522976246\n",
      "Iteration 4477, the loss is 4.442402788294882, parameters k is 10.30796820505972 and b is -42.11257057040707\n",
      "Iteration 4478, the loss is 4.442402772520506, parameters k is 10.307967815731656 and b is -42.1125666178379\n",
      "Iteration 4479, the loss is 4.442402756746126, parameters k is 10.307967426403593 and b is -42.112562665268726\n",
      "Iteration 4480, the loss is 4.442402740971747, parameters k is 10.30796703707553 and b is -42.11255871269955\n",
      "Iteration 4481, the loss is 4.442402725197367, parameters k is 10.307966647747467 and b is -42.11255476013038\n",
      "Iteration 4482, the loss is 4.442402709422986, parameters k is 10.307966258419404 and b is -42.112550807561206\n",
      "Iteration 4483, the loss is 4.442402693648606, parameters k is 10.30796586909134 and b is -42.11254685499203\n",
      "Iteration 4484, the loss is 4.442402677874229, parameters k is 10.307965479763277 and b is -42.11254290242286\n",
      "Iteration 4485, the loss is 4.442402662099848, parameters k is 10.307965090435214 and b is -42.112538949853686\n",
      "Iteration 4486, the loss is 4.44240264632547, parameters k is 10.307964701107151 and b is -42.11253499728451\n",
      "Iteration 4487, the loss is 4.442402630551091, parameters k is 10.307964311779088 and b is -42.11253104471534\n",
      "Iteration 4488, the loss is 4.44240261477671, parameters k is 10.307963922451025 and b is -42.112527092146166\n",
      "Iteration 4489, the loss is 4.44240259900233, parameters k is 10.307963533122962 and b is -42.11252313957699\n",
      "Iteration 4490, the loss is 4.44240258322795, parameters k is 10.307963143794899 and b is -42.11251918700782\n",
      "Iteration 4491, the loss is 4.442402567453572, parameters k is 10.307962754466836 and b is -42.112515234438646\n",
      "Iteration 4492, the loss is 4.442402551679189, parameters k is 10.307962365138772 and b is -42.11251128186947\n",
      "Iteration 4493, the loss is 4.442402535904812, parameters k is 10.30796197581071 and b is -42.1125073293003\n",
      "Iteration 4494, the loss is 4.442402520130434, parameters k is 10.307961586482646 and b is -42.11250337673113\n",
      "Iteration 4495, the loss is 4.442402504356053, parameters k is 10.307961197154583 and b is -42.11249942416195\n",
      "Iteration 4496, the loss is 4.442402488581675, parameters k is 10.30796080782652 and b is -42.11249547159278\n",
      "Iteration 4497, the loss is 4.442402472807298, parameters k is 10.307960418498457 and b is -42.11249151902361\n",
      "Iteration 4498, the loss is 4.442402457032916, parameters k is 10.307960029170394 and b is -42.11248756645443\n",
      "Iteration 4499, the loss is 4.442402441258537, parameters k is 10.30795963984233 and b is -42.11248361388526\n",
      "Iteration 4500, the loss is 4.442402425484157, parameters k is 10.307959250514267 and b is -42.11247966131609\n",
      "Iteration 4501, the loss is 4.442402409709778, parameters k is 10.307958861186204 and b is -42.11247570874691\n",
      "Iteration 4502, the loss is 4.442402393935397, parameters k is 10.307958471858141 and b is -42.11247175617774\n",
      "Iteration 4503, the loss is 4.44240237816102, parameters k is 10.307958082530078 and b is -42.11246780360857\n",
      "Iteration 4504, the loss is 4.442402362386637, parameters k is 10.307957693202015 and b is -42.112463851039394\n",
      "Iteration 4505, the loss is 4.442402346612259, parameters k is 10.307957303873952 and b is -42.11245989847022\n",
      "Iteration 4506, the loss is 4.442402332057626, parameters k is 10.307956914545889 and b is -42.11245594590105\n",
      "Iteration 4507, the loss is 4.442402319980552, parameters k is 10.30792902719411 and b is -42.11245594590105\n",
      "Iteration 4508, the loss is 4.442402304206172, parameters k is 10.307928637866047 and b is -42.112451993331874\n",
      "Iteration 4509, the loss is 4.4424022884317935, parameters k is 10.307928248537984 and b is -42.1124480407627\n",
      "Iteration 4510, the loss is 4.442402272657413, parameters k is 10.30792785920992 and b is -42.11244408819353\n",
      "Iteration 4511, the loss is 4.442402256883033, parameters k is 10.307927469881857 and b is -42.112440135624354\n",
      "Iteration 4512, the loss is 4.442402241108654, parameters k is 10.307927080553794 and b is -42.11243618305518\n",
      "Iteration 4513, the loss is 4.442402225334276, parameters k is 10.307926691225731 and b is -42.11243223048601\n",
      "Iteration 4514, the loss is 4.442402209559895, parameters k is 10.307926301897668 and b is -42.112428277916834\n",
      "Iteration 4515, the loss is 4.442402193785515, parameters k is 10.307925912569605 and b is -42.11242432534766\n",
      "Iteration 4516, the loss is 4.442402178011138, parameters k is 10.307925523241542 and b is -42.11242037277849\n",
      "Iteration 4517, the loss is 4.442402162236756, parameters k is 10.307925133913479 and b is -42.112416420209314\n",
      "Iteration 4518, the loss is 4.442402146462378, parameters k is 10.307924744585415 and b is -42.11241246764014\n",
      "Iteration 4519, the loss is 4.442402130687999, parameters k is 10.307924355257352 and b is -42.11240851507097\n",
      "Iteration 4520, the loss is 4.442402114913617, parameters k is 10.30792396592929 and b is -42.112404562501794\n",
      "Iteration 4521, the loss is 4.4424020991392394, parameters k is 10.307923576601226 and b is -42.11240060993262\n",
      "Iteration 4522, the loss is 4.442402083364864, parameters k is 10.307923187273163 and b is -42.11239665736345\n",
      "Iteration 4523, the loss is 4.442402067590479, parameters k is 10.3079227979451 and b is -42.112392704794274\n",
      "Iteration 4524, the loss is 4.4424020518161, parameters k is 10.307922408617037 and b is -42.1123887522251\n",
      "Iteration 4525, the loss is 4.442402036041722, parameters k is 10.307922019288974 and b is -42.11238479965593\n",
      "Iteration 4526, the loss is 4.4424020202673455, parameters k is 10.30792162996091 and b is -42.112380847086754\n",
      "Iteration 4527, the loss is 4.442402004492964, parameters k is 10.307921240632847 and b is -42.11237689451758\n",
      "Iteration 4528, the loss is 4.442401988718585, parameters k is 10.307920851304784 and b is -42.11237294194841\n",
      "Iteration 4529, the loss is 4.4424019729442055, parameters k is 10.307920461976721 and b is -42.112368989379235\n",
      "Iteration 4530, the loss is 4.442401957169826, parameters k is 10.307920072648658 and b is -42.11236503681006\n",
      "Iteration 4531, the loss is 4.442401941395446, parameters k is 10.307919683320595 and b is -42.11236108424089\n",
      "Iteration 4532, the loss is 4.4424019256210645, parameters k is 10.307919293992532 and b is -42.112357131671715\n",
      "Iteration 4533, the loss is 4.442401909846686, parameters k is 10.307918904664469 and b is -42.11235317910254\n",
      "Iteration 4534, the loss is 4.442401894072308, parameters k is 10.307918515336405 and b is -42.11234922653337\n",
      "Iteration 4535, the loss is 4.442401878297931, parameters k is 10.307918126008342 and b is -42.112345273964195\n",
      "Iteration 4536, the loss is 4.442401862523551, parameters k is 10.30791773668028 and b is -42.11234132139502\n",
      "Iteration 4537, the loss is 4.442401846749167, parameters k is 10.307917347352216 and b is -42.11233736882585\n",
      "Iteration 4538, the loss is 4.442401830974791, parameters k is 10.307916958024153 and b is -42.112333416256675\n",
      "Iteration 4539, the loss is 4.44240181520041, parameters k is 10.30791656869609 and b is -42.1123294636875\n",
      "Iteration 4540, the loss is 4.442401799426031, parameters k is 10.307916179368027 and b is -42.11232551111833\n",
      "Iteration 4541, the loss is 4.442401783651652, parameters k is 10.307915790039964 and b is -42.112321558549155\n",
      "Iteration 4542, the loss is 4.442401767877272, parameters k is 10.3079154007119 and b is -42.11231760597998\n",
      "Iteration 4543, the loss is 4.442401752102895, parameters k is 10.307915011383837 and b is -42.11231365341081\n",
      "Iteration 4544, the loss is 4.442401736328515, parameters k is 10.307914622055774 and b is -42.112309700841635\n",
      "Iteration 4545, the loss is 4.442401720554135, parameters k is 10.307914232727711 and b is -42.11230574827246\n",
      "Iteration 4546, the loss is 4.442401704779756, parameters k is 10.307913843399648 and b is -42.11230179570329\n",
      "Iteration 4547, the loss is 4.442401689005378, parameters k is 10.307913454071585 and b is -42.112297843134115\n",
      "Iteration 4548, the loss is 4.4424016732309966, parameters k is 10.307913064743522 and b is -42.11229389056494\n",
      "Iteration 4549, the loss is 4.442401657456618, parameters k is 10.307912675415459 and b is -42.11228993799577\n",
      "Iteration 4550, the loss is 4.442401641682237, parameters k is 10.307912286087396 and b is -42.112285985426595\n",
      "Iteration 4551, the loss is 4.442401625907857, parameters k is 10.307911896759332 and b is -42.11228203285742\n",
      "Iteration 4552, the loss is 4.44240161013348, parameters k is 10.30791150743127 and b is -42.11227808028825\n",
      "Iteration 4553, the loss is 4.442401594359099, parameters k is 10.307911118103206 and b is -42.112274127719076\n",
      "Iteration 4554, the loss is 4.442401578584722, parameters k is 10.307910728775143 and b is -42.1122701751499\n",
      "Iteration 4555, the loss is 4.442401562810341, parameters k is 10.30791033944708 and b is -42.11226622258073\n",
      "Iteration 4556, the loss is 4.442401547035962, parameters k is 10.307909950119017 and b is -42.112262270011556\n",
      "Iteration 4557, the loss is 4.4424015312615825, parameters k is 10.307909560790954 and b is -42.11225831744238\n",
      "Iteration 4558, the loss is 4.442401515487202, parameters k is 10.30790917146289 and b is -42.11225436487321\n",
      "Iteration 4559, the loss is 4.442401499712821, parameters k is 10.307908782134827 and b is -42.112250412304036\n",
      "Iteration 4560, the loss is 4.442401483938443, parameters k is 10.307908392806764 and b is -42.11224645973486\n",
      "Iteration 4561, the loss is 4.442401468164065, parameters k is 10.307908003478701 and b is -42.11224250716569\n",
      "Iteration 4562, the loss is 4.442401452389682, parameters k is 10.307907614150638 and b is -42.112238554596516\n",
      "Iteration 4563, the loss is 4.442401436615305, parameters k is 10.307907224822575 and b is -42.11223460202734\n",
      "Iteration 4564, the loss is 4.442401420840928, parameters k is 10.307906835494512 and b is -42.11223064945817\n",
      "Iteration 4565, the loss is 4.442401405066547, parameters k is 10.307906446166449 and b is -42.112226696888996\n",
      "Iteration 4566, the loss is 4.4424013892921685, parameters k is 10.307906056838386 and b is -42.11222274431982\n",
      "Iteration 4567, the loss is 4.4424013735177885, parameters k is 10.307905667510322 and b is -42.11221879175065\n",
      "Iteration 4568, the loss is 4.442401357743409, parameters k is 10.30790527818226 and b is -42.112214839181476\n",
      "Iteration 4569, the loss is 4.442401341969029, parameters k is 10.307904888854196 and b is -42.1122108866123\n",
      "Iteration 4570, the loss is 4.4424013261946484, parameters k is 10.307904499526133 and b is -42.11220693404313\n",
      "Iteration 4571, the loss is 4.44240131042027, parameters k is 10.30790411019807 and b is -42.112202981473956\n",
      "Iteration 4572, the loss is 4.442401294645887, parameters k is 10.307903720870007 and b is -42.11219902890478\n",
      "Iteration 4573, the loss is 4.442401278871512, parameters k is 10.307903331541944 and b is -42.11219507633561\n",
      "Iteration 4574, the loss is 4.442401263097135, parameters k is 10.30790294221388 and b is -42.112191123766436\n",
      "Iteration 4575, the loss is 4.442401247322753, parameters k is 10.307902552885817 and b is -42.11218717119726\n",
      "Iteration 4576, the loss is 4.442401231548374, parameters k is 10.307902163557754 and b is -42.11218321862809\n",
      "Iteration 4577, the loss is 4.442401215773994, parameters k is 10.307901774229691 and b is -42.11217926605892\n",
      "Iteration 4578, the loss is 4.442401199999614, parameters k is 10.307901384901628 and b is -42.11217531348974\n",
      "Iteration 4579, the loss is 4.442401184225234, parameters k is 10.307900995573565 and b is -42.11217136092057\n",
      "Iteration 4580, the loss is 4.442401168450856, parameters k is 10.307900606245502 and b is -42.1121674083514\n",
      "Iteration 4581, the loss is 4.442401152676478, parameters k is 10.307900216917439 and b is -42.11216345578222\n",
      "Iteration 4582, the loss is 4.442401136902099, parameters k is 10.307899827589376 and b is -42.11215950321305\n",
      "Iteration 4583, the loss is 4.442401121127719, parameters k is 10.307899438261312 and b is -42.11215555064388\n",
      "Iteration 4584, the loss is 4.442401105353338, parameters k is 10.30789904893325 and b is -42.1121515980747\n",
      "Iteration 4585, the loss is 4.44240108957896, parameters k is 10.307898659605186 and b is -42.11214764550553\n",
      "Iteration 4586, the loss is 4.442401073804581, parameters k is 10.307898270277123 and b is -42.11214369293636\n",
      "Iteration 4587, the loss is 4.442401058030202, parameters k is 10.30789788094906 and b is -42.11213974036718\n",
      "Iteration 4588, the loss is 4.442401042255822, parameters k is 10.307897491620997 and b is -42.11213578779801\n",
      "Iteration 4589, the loss is 4.44240102648144, parameters k is 10.307897102292934 and b is -42.11213183522884\n",
      "Iteration 4590, the loss is 4.442401010707061, parameters k is 10.30789671296487 and b is -42.112127882659664\n",
      "Iteration 4591, the loss is 4.442400994932685, parameters k is 10.307896323636808 and b is -42.11212393009049\n",
      "Iteration 4592, the loss is 4.442400979158302, parameters k is 10.307895934308744 and b is -42.11211997752132\n",
      "Iteration 4593, the loss is 4.442400963383924, parameters k is 10.307895544980681 and b is -42.112116024952144\n",
      "Iteration 4594, the loss is 4.442400947609544, parameters k is 10.307895155652618 and b is -42.11211207238297\n",
      "Iteration 4595, the loss is 4.442400931835165, parameters k is 10.307894766324555 and b is -42.1121081198138\n",
      "Iteration 4596, the loss is 4.442400916060788, parameters k is 10.307894376996492 and b is -42.112104167244624\n",
      "Iteration 4597, the loss is 4.442400900286406, parameters k is 10.307893987668429 and b is -42.11210021467545\n",
      "Iteration 4598, the loss is 4.442400884512027, parameters k is 10.307893598340366 and b is -42.11209626210628\n",
      "Iteration 4599, the loss is 4.442400868737648, parameters k is 10.307893209012303 and b is -42.112092309537104\n",
      "Iteration 4600, the loss is 4.442400852963268, parameters k is 10.30789281968424 and b is -42.11208835696793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4601, the loss is 4.442400837188888, parameters k is 10.307892430356176 and b is -42.11208440439876\n",
      "Iteration 4602, the loss is 4.44240082141451, parameters k is 10.307892041028113 and b is -42.112080451829584\n",
      "Iteration 4603, the loss is 4.44240080564013, parameters k is 10.30789165170005 and b is -42.11207649926041\n",
      "Iteration 4604, the loss is 4.442400789865751, parameters k is 10.307891262371987 and b is -42.11207254669124\n",
      "Iteration 4605, the loss is 4.442400774091371, parameters k is 10.307890873043924 and b is -42.112068594122064\n",
      "Iteration 4606, the loss is 4.442400758316991, parameters k is 10.30789048371586 and b is -42.11206464155289\n",
      "Iteration 4607, the loss is 4.4424007425426115, parameters k is 10.307890094387798 and b is -42.11206068898372\n",
      "Iteration 4608, the loss is 4.442400726768235, parameters k is 10.307889705059734 and b is -42.112056736414544\n",
      "Iteration 4609, the loss is 4.442400710993852, parameters k is 10.307889315731671 and b is -42.11205278384537\n",
      "Iteration 4610, the loss is 4.442400695219476, parameters k is 10.307888926403608 and b is -42.1120488312762\n",
      "Iteration 4611, the loss is 4.442400679445094, parameters k is 10.307888537075545 and b is -42.112044878707025\n",
      "Iteration 4612, the loss is 4.442400663670718, parameters k is 10.307888147747482 and b is -42.11204092613785\n",
      "Iteration 4613, the loss is 4.442400647896336, parameters k is 10.307887758419419 and b is -42.11203697356868\n",
      "Iteration 4614, the loss is 4.442400632121954, parameters k is 10.307887369091356 and b is -42.112033020999505\n",
      "Iteration 4615, the loss is 4.442400616347578, parameters k is 10.307886979763293 and b is -42.11202906843033\n",
      "Iteration 4616, the loss is 4.442400600573199, parameters k is 10.30788659043523 and b is -42.11202511586116\n",
      "Iteration 4617, the loss is 4.442400584798818, parameters k is 10.307886201107166 and b is -42.112021163291985\n",
      "Iteration 4618, the loss is 4.442400569024439, parameters k is 10.307885811779103 and b is -42.11201721072281\n",
      "Iteration 4619, the loss is 4.442400553250059, parameters k is 10.30788542245104 and b is -42.11201325815364\n",
      "Iteration 4620, the loss is 4.442400537475681, parameters k is 10.307885033122977 and b is -42.112009305584465\n",
      "Iteration 4621, the loss is 4.442400521701301, parameters k is 10.307884643794914 and b is -42.11200535301529\n",
      "Iteration 4622, the loss is 4.442400505926923, parameters k is 10.30788425446685 and b is -42.11200140044612\n",
      "Iteration 4623, the loss is 4.442400490152542, parameters k is 10.307883865138788 and b is -42.111997447876945\n",
      "Iteration 4624, the loss is 4.442400474378165, parameters k is 10.307883475810725 and b is -42.11199349530777\n",
      "Iteration 4625, the loss is 4.4424004586037835, parameters k is 10.307883086482661 and b is -42.1119895427386\n",
      "Iteration 4626, the loss is 4.442400442829403, parameters k is 10.307882697154598 and b is -42.111985590169425\n",
      "Iteration 4627, the loss is 4.442400427055026, parameters k is 10.307882307826535 and b is -42.11198163760025\n",
      "Iteration 4628, the loss is 4.442400411280643, parameters k is 10.307881918498472 and b is -42.11197768503108\n",
      "Iteration 4629, the loss is 4.442400395506266, parameters k is 10.307881529170409 and b is -42.111973732461905\n",
      "Iteration 4630, the loss is 4.442400379731889, parameters k is 10.307881139842346 and b is -42.11196977989273\n",
      "Iteration 4631, the loss is 4.442400363957506, parameters k is 10.307880750514283 and b is -42.11196582732356\n",
      "Iteration 4632, the loss is 4.442400348183127, parameters k is 10.30788036118622 and b is -42.111961874754385\n",
      "Iteration 4633, the loss is 4.4424003324087495, parameters k is 10.307879971858156 and b is -42.11195792218521\n",
      "Iteration 4634, the loss is 4.442400316634368, parameters k is 10.307879582530093 and b is -42.11195396961604\n",
      "Iteration 4635, the loss is 4.442400300859987, parameters k is 10.30787919320203 and b is -42.111950017046865\n",
      "Iteration 4636, the loss is 4.442400285085612, parameters k is 10.307878803873967 and b is -42.11194606447769\n",
      "Iteration 4637, the loss is 4.442400269311231, parameters k is 10.307878414545904 and b is -42.11194211190852\n",
      "Iteration 4638, the loss is 4.442400253536849, parameters k is 10.30787802521784 and b is -42.111938159339346\n",
      "Iteration 4639, the loss is 4.442400237762469, parameters k is 10.307877635889778 and b is -42.11193420677017\n",
      "Iteration 4640, the loss is 4.44240022198809, parameters k is 10.307877246561715 and b is -42.111930254201\n",
      "Iteration 4641, the loss is 4.442400206213712, parameters k is 10.307876857233651 and b is -42.111926301631826\n",
      "Iteration 4642, the loss is 4.442400190439335, parameters k is 10.307876467905588 and b is -42.11192234906265\n",
      "Iteration 4643, the loss is 4.442400174664956, parameters k is 10.307876078577525 and b is -42.11191839649348\n",
      "Iteration 4644, the loss is 4.442400158890575, parameters k is 10.307875689249462 and b is -42.111914443924306\n",
      "Iteration 4645, the loss is 4.4424001431161955, parameters k is 10.307875299921399 and b is -42.11191049135513\n",
      "Iteration 4646, the loss is 4.442400127341815, parameters k is 10.307874910593336 and b is -42.11190653878596\n",
      "Iteration 4647, the loss is 4.442400111567436, parameters k is 10.307874521265273 and b is -42.111902586216786\n",
      "Iteration 4648, the loss is 4.442400095793057, parameters k is 10.30787413193721 and b is -42.11189863364761\n",
      "Iteration 4649, the loss is 4.442400080018678, parameters k is 10.307873742609146 and b is -42.11189468107844\n",
      "Iteration 4650, the loss is 4.442400064244298, parameters k is 10.307873353281083 and b is -42.111890728509266\n",
      "Iteration 4651, the loss is 4.442400048469919, parameters k is 10.30787296395302 and b is -42.11188677594009\n",
      "Iteration 4652, the loss is 4.442400032695541, parameters k is 10.307872574624957 and b is -42.11188282337092\n",
      "Iteration 4653, the loss is 4.44240001692116, parameters k is 10.307872185296894 and b is -42.111878870801746\n",
      "Iteration 4654, the loss is 4.442400001146781, parameters k is 10.30787179596883 and b is -42.11187491823257\n",
      "Iteration 4655, the loss is 4.442399985372402, parameters k is 10.307871406640768 and b is -42.1118709656634\n",
      "Iteration 4656, the loss is 4.442399969598023, parameters k is 10.307871017312705 and b is -42.111867013094226\n",
      "Iteration 4657, the loss is 4.442399953823644, parameters k is 10.307870627984641 and b is -42.11186306052505\n",
      "Iteration 4658, the loss is 4.442399938049262, parameters k is 10.307870238656578 and b is -42.11185910795588\n",
      "Iteration 4659, the loss is 4.442399922274884, parameters k is 10.307869849328515 and b is -42.111855155386706\n",
      "Iteration 4660, the loss is 4.442399906500501, parameters k is 10.307869460000452 and b is -42.11185120281753\n",
      "Iteration 4661, the loss is 4.442399890726122, parameters k is 10.307869070672389 and b is -42.11184725024836\n",
      "Iteration 4662, the loss is 4.442399874951747, parameters k is 10.307868681344326 and b is -42.11184329767919\n",
      "Iteration 4663, the loss is 4.442399860609963, parameters k is 10.307868292016263 and b is -42.11183934511001\n",
      "Iteration 4664, the loss is 4.442399848320037, parameters k is 10.307840404664484 and b is -42.11183934511001\n",
      "Iteration 4665, the loss is 4.442399832545658, parameters k is 10.30784001533642 and b is -42.11183539254084\n",
      "Iteration 4666, the loss is 4.442399816771278, parameters k is 10.307839626008358 and b is -42.11183143997167\n",
      "Iteration 4667, the loss is 4.4423998009969, parameters k is 10.307839236680294 and b is -42.11182748740249\n",
      "Iteration 4668, the loss is 4.442399785222519, parameters k is 10.307838847352231 and b is -42.11182353483332\n",
      "Iteration 4669, the loss is 4.4423997694481425, parameters k is 10.307838458024168 and b is -42.11181958226415\n",
      "Iteration 4670, the loss is 4.442399753673761, parameters k is 10.307838068696105 and b is -42.11181562969497\n",
      "Iteration 4671, the loss is 4.442399737899382, parameters k is 10.307837679368042 and b is -42.1118116771258\n",
      "Iteration 4672, the loss is 4.442399722125002, parameters k is 10.307837290039979 and b is -42.11180772455663\n",
      "Iteration 4673, the loss is 4.442399706350624, parameters k is 10.307836900711916 and b is -42.111803771987454\n",
      "Iteration 4674, the loss is 4.442399690576244, parameters k is 10.307836511383853 and b is -42.11179981941828\n",
      "Iteration 4675, the loss is 4.442399674801864, parameters k is 10.30783612205579 and b is -42.11179586684911\n",
      "Iteration 4676, the loss is 4.442399659027485, parameters k is 10.307835732727726 and b is -42.111791914279934\n",
      "Iteration 4677, the loss is 4.442399643253107, parameters k is 10.307835343399663 and b is -42.11178796171076\n",
      "Iteration 4678, the loss is 4.442399627478727, parameters k is 10.3078349540716 and b is -42.11178400914159\n",
      "Iteration 4679, the loss is 4.442399611704348, parameters k is 10.307834564743537 and b is -42.111780056572414\n",
      "Iteration 4680, the loss is 4.442399595929966, parameters k is 10.307834175415474 and b is -42.11177610400324\n",
      "Iteration 4681, the loss is 4.442399580155585, parameters k is 10.30783378608741 and b is -42.11177215143407\n",
      "Iteration 4682, the loss is 4.442399564381208, parameters k is 10.307833396759348 and b is -42.111768198864894\n",
      "Iteration 4683, the loss is 4.442399548606828, parameters k is 10.307833007431284 and b is -42.11176424629572\n",
      "Iteration 4684, the loss is 4.442399532832449, parameters k is 10.307832618103221 and b is -42.11176029372655\n",
      "Iteration 4685, the loss is 4.442399517058069, parameters k is 10.307832228775158 and b is -42.111756341157374\n",
      "Iteration 4686, the loss is 4.442399501283689, parameters k is 10.307831839447095 and b is -42.1117523885882\n",
      "Iteration 4687, the loss is 4.44239948550931, parameters k is 10.307831450119032 and b is -42.11174843601903\n",
      "Iteration 4688, the loss is 4.44239946973493, parameters k is 10.307831060790969 and b is -42.111744483449854\n",
      "Iteration 4689, the loss is 4.442399453960552, parameters k is 10.307830671462906 and b is -42.11174053088068\n",
      "Iteration 4690, the loss is 4.442399438186171, parameters k is 10.307830282134843 and b is -42.11173657831151\n",
      "Iteration 4691, the loss is 4.4423994224117935, parameters k is 10.30782989280678 and b is -42.111732625742334\n",
      "Iteration 4692, the loss is 4.44239940663741, parameters k is 10.307829503478716 and b is -42.11172867317316\n",
      "Iteration 4693, the loss is 4.442399390863034, parameters k is 10.307829114150653 and b is -42.11172472060399\n",
      "Iteration 4694, the loss is 4.442399375088657, parameters k is 10.30782872482259 and b is -42.111720768034814\n",
      "Iteration 4695, the loss is 4.442399359314275, parameters k is 10.307828335494527 and b is -42.11171681546564\n",
      "Iteration 4696, the loss is 4.442399343539896, parameters k is 10.307827946166464 and b is -42.11171286289647\n",
      "Iteration 4697, the loss is 4.442399327765518, parameters k is 10.3078275568384 and b is -42.111708910327295\n",
      "Iteration 4698, the loss is 4.442399311991139, parameters k is 10.307827167510338 and b is -42.11170495775812\n",
      "Iteration 4699, the loss is 4.44239929621676, parameters k is 10.307826778182275 and b is -42.11170100518895\n",
      "Iteration 4700, the loss is 4.44239928044238, parameters k is 10.307826388854211 and b is -42.111697052619775\n",
      "Iteration 4701, the loss is 4.442399264667997, parameters k is 10.307825999526148 and b is -42.1116931000506\n",
      "Iteration 4702, the loss is 4.44239924889362, parameters k is 10.307825610198085 and b is -42.11168914748143\n",
      "Iteration 4703, the loss is 4.442399233119243, parameters k is 10.307825220870022 and b is -42.111685194912255\n",
      "Iteration 4704, the loss is 4.442399217344862, parameters k is 10.307824831541959 and b is -42.11168124234308\n",
      "Iteration 4705, the loss is 4.442399201570484, parameters k is 10.307824442213896 and b is -42.11167728977391\n",
      "Iteration 4706, the loss is 4.442399185796101, parameters k is 10.307824052885833 and b is -42.111673337204735\n",
      "Iteration 4707, the loss is 4.442399170021724, parameters k is 10.30782366355777 and b is -42.11166938463556\n",
      "Iteration 4708, the loss is 4.442399154247344, parameters k is 10.307823274229706 and b is -42.11166543206639\n",
      "Iteration 4709, the loss is 4.442399138472964, parameters k is 10.307822884901643 and b is -42.111661479497215\n",
      "Iteration 4710, the loss is 4.4423991226985855, parameters k is 10.30782249557358 and b is -42.11165752692804\n",
      "Iteration 4711, the loss is 4.442399106924206, parameters k is 10.307822106245517 and b is -42.11165357435887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4712, the loss is 4.442399091149826, parameters k is 10.307821716917454 and b is -42.111649621789695\n",
      "Iteration 4713, the loss is 4.442399075375443, parameters k is 10.30782132758939 and b is -42.11164566922052\n",
      "Iteration 4714, the loss is 4.442399059601067, parameters k is 10.307820938261328 and b is -42.11164171665135\n",
      "Iteration 4715, the loss is 4.442399043826689, parameters k is 10.307820548933265 and b is -42.111637764082175\n",
      "Iteration 4716, the loss is 4.442399028052307, parameters k is 10.307820159605201 and b is -42.111633811513\n",
      "Iteration 4717, the loss is 4.4423990122779315, parameters k is 10.307819770277138 and b is -42.11162985894383\n",
      "Iteration 4718, the loss is 4.442398996503549, parameters k is 10.307819380949075 and b is -42.111625906374655\n",
      "Iteration 4719, the loss is 4.442398980729171, parameters k is 10.307818991621012 and b is -42.11162195380548\n",
      "Iteration 4720, the loss is 4.44239896495479, parameters k is 10.307818602292949 and b is -42.11161800123631\n",
      "Iteration 4721, the loss is 4.442398949180413, parameters k is 10.307818212964886 and b is -42.111614048667136\n",
      "Iteration 4722, the loss is 4.442398933406032, parameters k is 10.307817823636823 and b is -42.11161009609796\n",
      "Iteration 4723, the loss is 4.442398917631651, parameters k is 10.30781743430876 and b is -42.11160614352879\n",
      "Iteration 4724, the loss is 4.442398901857275, parameters k is 10.307817044980697 and b is -42.111602190959616\n",
      "Iteration 4725, the loss is 4.442398886082895, parameters k is 10.307816655652633 and b is -42.11159823839044\n",
      "Iteration 4726, the loss is 4.442398870308514, parameters k is 10.30781626632457 and b is -42.11159428582127\n",
      "Iteration 4727, the loss is 4.442398854534136, parameters k is 10.307815876996507 and b is -42.111590333252096\n",
      "Iteration 4728, the loss is 4.442398838759755, parameters k is 10.307815487668444 and b is -42.11158638068292\n",
      "Iteration 4729, the loss is 4.442398822985378, parameters k is 10.307815098340381 and b is -42.11158242811375\n",
      "Iteration 4730, the loss is 4.442398807210998, parameters k is 10.307814709012318 and b is -42.111578475544576\n",
      "Iteration 4731, the loss is 4.442398791436619, parameters k is 10.307814319684255 and b is -42.1115745229754\n",
      "Iteration 4732, the loss is 4.442398775662239, parameters k is 10.307813930356192 and b is -42.11157057040623\n",
      "Iteration 4733, the loss is 4.442398759887858, parameters k is 10.307813541028128 and b is -42.111566617837056\n",
      "Iteration 4734, the loss is 4.442398744113479, parameters k is 10.307813151700065 and b is -42.11156266526788\n",
      "Iteration 4735, the loss is 4.4423987283391, parameters k is 10.307812762372002 and b is -42.11155871269871\n",
      "Iteration 4736, the loss is 4.442398712564717, parameters k is 10.307812373043939 and b is -42.111554760129536\n",
      "Iteration 4737, the loss is 4.442398696790341, parameters k is 10.307811983715876 and b is -42.11155080756036\n",
      "Iteration 4738, the loss is 4.442398681015963, parameters k is 10.307811594387813 and b is -42.11154685499119\n",
      "Iteration 4739, the loss is 4.442398665241582, parameters k is 10.30781120505975 and b is -42.111542902422016\n",
      "Iteration 4740, the loss is 4.442398649467202, parameters k is 10.307810815731687 and b is -42.11153894985284\n",
      "Iteration 4741, the loss is 4.442398633692822, parameters k is 10.307810426403623 and b is -42.11153499728367\n",
      "Iteration 4742, the loss is 4.442398617918444, parameters k is 10.30781003707556 and b is -42.111531044714496\n",
      "Iteration 4743, the loss is 4.442398602144064, parameters k is 10.307809647747497 and b is -42.11152709214532\n",
      "Iteration 4744, the loss is 4.442398586369686, parameters k is 10.307809258419434 and b is -42.11152313957615\n",
      "Iteration 4745, the loss is 4.442398570595305, parameters k is 10.307808869091371 and b is -42.11151918700698\n",
      "Iteration 4746, the loss is 4.442398554820925, parameters k is 10.307808479763308 and b is -42.1115152344378\n",
      "Iteration 4747, the loss is 4.44239853904655, parameters k is 10.307808090435245 and b is -42.11151128186863\n",
      "Iteration 4748, the loss is 4.442398523272167, parameters k is 10.307807701107182 and b is -42.11150732929946\n",
      "Iteration 4749, the loss is 4.4423985074977885, parameters k is 10.307807311779118 and b is -42.11150337673028\n",
      "Iteration 4750, the loss is 4.442398491723407, parameters k is 10.307806922451055 and b is -42.11149942416111\n",
      "Iteration 4751, the loss is 4.4423984759490285, parameters k is 10.307806533122992 and b is -42.11149547159194\n",
      "Iteration 4752, the loss is 4.4423984601746485, parameters k is 10.307806143794929 and b is -42.11149151902276\n",
      "Iteration 4753, the loss is 4.442398444400271, parameters k is 10.307805754466866 and b is -42.11148756645359\n",
      "Iteration 4754, the loss is 4.442398428625891, parameters k is 10.307805365138803 and b is -42.11148361388442\n",
      "Iteration 4755, the loss is 4.44239841285151, parameters k is 10.30780497581074 and b is -42.111479661315244\n",
      "Iteration 4756, the loss is 4.44239839707713, parameters k is 10.307804586482677 and b is -42.11147570874607\n",
      "Iteration 4757, the loss is 4.442398381302754, parameters k is 10.307804197154613 and b is -42.1114717561769\n",
      "Iteration 4758, the loss is 4.442398365528374, parameters k is 10.30780380782655 and b is -42.111467803607724\n",
      "Iteration 4759, the loss is 4.442398349753994, parameters k is 10.307803418498487 and b is -42.11146385103855\n",
      "Iteration 4760, the loss is 4.4423983339796145, parameters k is 10.307803029170424 and b is -42.11145989846938\n",
      "Iteration 4761, the loss is 4.442398318205235, parameters k is 10.307802639842361 and b is -42.111455945900204\n",
      "Iteration 4762, the loss is 4.442398302430858, parameters k is 10.307802250514298 and b is -42.11145199333103\n",
      "Iteration 4763, the loss is 4.442398286656479, parameters k is 10.307801861186235 and b is -42.11144804076186\n",
      "Iteration 4764, the loss is 4.442398270882097, parameters k is 10.307801471858172 and b is -42.111444088192684\n",
      "Iteration 4765, the loss is 4.442398255107716, parameters k is 10.307801082530109 and b is -42.11144013562351\n",
      "Iteration 4766, the loss is 4.442398239333337, parameters k is 10.307800693202045 and b is -42.11143618305434\n",
      "Iteration 4767, the loss is 4.442398223558958, parameters k is 10.307800303873982 and b is -42.111432230485164\n",
      "Iteration 4768, the loss is 4.4423982077845805, parameters k is 10.30779991454592 and b is -42.11142827791599\n",
      "Iteration 4769, the loss is 4.4423981920102005, parameters k is 10.307799525217856 and b is -42.11142432534682\n",
      "Iteration 4770, the loss is 4.442398176235819, parameters k is 10.307799135889793 and b is -42.111420372777644\n",
      "Iteration 4771, the loss is 4.442398160461439, parameters k is 10.30779874656173 and b is -42.11141642020847\n",
      "Iteration 4772, the loss is 4.442398144687064, parameters k is 10.307798357233667 and b is -42.1114124676393\n",
      "Iteration 4773, the loss is 4.442398128912684, parameters k is 10.307797967905604 and b is -42.111408515070124\n",
      "Iteration 4774, the loss is 4.442398113138304, parameters k is 10.30779757857754 and b is -42.11140456250095\n",
      "Iteration 4775, the loss is 4.442398097363923, parameters k is 10.307797189249477 and b is -42.11140060993178\n",
      "Iteration 4776, the loss is 4.442398081589545, parameters k is 10.307796799921414 and b is -42.111396657362604\n",
      "Iteration 4777, the loss is 4.442398065815167, parameters k is 10.307796410593351 and b is -42.11139270479343\n",
      "Iteration 4778, the loss is 4.442398050040786, parameters k is 10.307796021265288 and b is -42.11138875222426\n",
      "Iteration 4779, the loss is 4.442398034266406, parameters k is 10.307795631937225 and b is -42.111384799655085\n",
      "Iteration 4780, the loss is 4.442398018492028, parameters k is 10.307795242609162 and b is -42.11138084708591\n",
      "Iteration 4781, the loss is 4.442398002717647, parameters k is 10.307794853281099 and b is -42.11137689451674\n",
      "Iteration 4782, the loss is 4.442397986943268, parameters k is 10.307794463953035 and b is -42.111372941947565\n",
      "Iteration 4783, the loss is 4.442397971168889, parameters k is 10.307794074624972 and b is -42.11136898937839\n",
      "Iteration 4784, the loss is 4.44239795539451, parameters k is 10.30779368529691 and b is -42.11136503680922\n",
      "Iteration 4785, the loss is 4.44239793962013, parameters k is 10.307793295968846 and b is -42.111361084240045\n",
      "Iteration 4786, the loss is 4.442397923845751, parameters k is 10.307792906640783 and b is -42.11135713167087\n",
      "Iteration 4787, the loss is 4.442397908071372, parameters k is 10.30779251731272 and b is -42.1113531791017\n",
      "Iteration 4788, the loss is 4.4423978922969924, parameters k is 10.307792127984657 and b is -42.111349226532525\n",
      "Iteration 4789, the loss is 4.442397876522612, parameters k is 10.307791738656594 and b is -42.11134527396335\n",
      "Iteration 4790, the loss is 4.442397860748236, parameters k is 10.30779134932853 and b is -42.11134132139418\n",
      "Iteration 4791, the loss is 4.442397844973855, parameters k is 10.307790960000467 and b is -42.111337368825005\n",
      "Iteration 4792, the loss is 4.442397829199475, parameters k is 10.307790570672404 and b is -42.11133341625583\n",
      "Iteration 4793, the loss is 4.442397813425097, parameters k is 10.307790181344341 and b is -42.11132946368666\n",
      "Iteration 4794, the loss is 4.442397797650714, parameters k is 10.307789792016278 and b is -42.111325511117485\n",
      "Iteration 4795, the loss is 4.442397781876338, parameters k is 10.307789402688215 and b is -42.11132155854831\n",
      "Iteration 4796, the loss is 4.442397766101958, parameters k is 10.307789013360152 and b is -42.11131760597914\n",
      "Iteration 4797, the loss is 4.442397750327577, parameters k is 10.307788624032089 and b is -42.111313653409965\n",
      "Iteration 4798, the loss is 4.442397734553197, parameters k is 10.307788234704025 and b is -42.11130970084079\n",
      "Iteration 4799, the loss is 4.442397718778818, parameters k is 10.307787845375962 and b is -42.11130574827162\n",
      "Iteration 4800, the loss is 4.442397703004437, parameters k is 10.3077874560479 and b is -42.111301795702445\n",
      "Iteration 4801, the loss is 4.4423976872300575, parameters k is 10.307787066719836 and b is -42.11129784313327\n",
      "Iteration 4802, the loss is 4.442397671455681, parameters k is 10.307786677391773 and b is -42.1112938905641\n",
      "Iteration 4803, the loss is 4.442397655681302, parameters k is 10.30778628806371 and b is -42.111289937994925\n",
      "Iteration 4804, the loss is 4.44239763990692, parameters k is 10.307785898735647 and b is -42.11128598542575\n",
      "Iteration 4805, the loss is 4.442397624132543, parameters k is 10.307785509407584 and b is -42.11128203285658\n",
      "Iteration 4806, the loss is 4.442397608358163, parameters k is 10.30778512007952 and b is -42.111278080287406\n",
      "Iteration 4807, the loss is 4.442397592583783, parameters k is 10.307784730751457 and b is -42.11127412771823\n",
      "Iteration 4808, the loss is 4.4423975768094035, parameters k is 10.307784341423394 and b is -42.11127017514906\n",
      "Iteration 4809, the loss is 4.4423975610350235, parameters k is 10.307783952095331 and b is -42.111266222579886\n",
      "Iteration 4810, the loss is 4.442397545260645, parameters k is 10.307783562767268 and b is -42.11126227001071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4811, the loss is 4.442397529486268, parameters k is 10.307783173439205 and b is -42.11125831744154\n",
      "Iteration 4812, the loss is 4.442397513711886, parameters k is 10.307782784111142 and b is -42.111254364872366\n",
      "Iteration 4813, the loss is 4.442397497937507, parameters k is 10.307782394783079 and b is -42.11125041230319\n",
      "Iteration 4814, the loss is 4.442397482163127, parameters k is 10.307782005455016 and b is -42.11124645973402\n",
      "Iteration 4815, the loss is 4.442397466388748, parameters k is 10.307781616126952 and b is -42.111242507164846\n",
      "Iteration 4816, the loss is 4.44239745061437, parameters k is 10.30778122679889 and b is -42.11123855459567\n",
      "Iteration 4817, the loss is 4.4423974348399895, parameters k is 10.307780837470826 and b is -42.1112346020265\n",
      "Iteration 4818, the loss is 4.4423974190656095, parameters k is 10.307780448142763 and b is -42.111230649457326\n",
      "Iteration 4819, the loss is 4.442397403291229, parameters k is 10.3077800588147 and b is -42.11122669688815\n",
      "Iteration 4820, the loss is 4.442397389162304, parameters k is 10.307779669486637 and b is -42.11122274431898\n",
      "Iteration 4821, the loss is 4.442397376659522, parameters k is 10.307751782134858 and b is -42.11122274431898\n",
      "Iteration 4822, the loss is 4.442397360885144, parameters k is 10.307751392806795 and b is -42.111218791749806\n",
      "Iteration 4823, the loss is 4.442397345110764, parameters k is 10.307751003478732 and b is -42.11121483918063\n",
      "Iteration 4824, the loss is 4.442397329336382, parameters k is 10.307750614150669 and b is -42.11121088661146\n",
      "Iteration 4825, the loss is 4.442397313562008, parameters k is 10.307750224822605 and b is -42.111206934042286\n",
      "Iteration 4826, the loss is 4.442397297787625, parameters k is 10.307749835494542 and b is -42.11120298147311\n",
      "Iteration 4827, the loss is 4.442397282013247, parameters k is 10.30774944616648 and b is -42.11119902890394\n",
      "Iteration 4828, the loss is 4.442397266238866, parameters k is 10.307749056838416 and b is -42.111195076334766\n",
      "Iteration 4829, the loss is 4.442397250464489, parameters k is 10.307748667510353 and b is -42.11119112376559\n",
      "Iteration 4830, the loss is 4.44239723469011, parameters k is 10.30774827818229 and b is -42.11118717119642\n",
      "Iteration 4831, the loss is 4.442397218915727, parameters k is 10.307747888854227 and b is -42.11118321862725\n",
      "Iteration 4832, the loss is 4.442397203141351, parameters k is 10.307747499526164 and b is -42.11117926605807\n",
      "Iteration 4833, the loss is 4.442397187366969, parameters k is 10.3077471101981 and b is -42.1111753134889\n",
      "Iteration 4834, the loss is 4.44239717159259, parameters k is 10.307746720870037 and b is -42.11117136091973\n",
      "Iteration 4835, the loss is 4.442397155818213, parameters k is 10.307746331541974 and b is -42.11116740835055\n",
      "Iteration 4836, the loss is 4.442397140043831, parameters k is 10.307745942213911 and b is -42.11116345578138\n",
      "Iteration 4837, the loss is 4.442397124269453, parameters k is 10.307745552885848 and b is -42.11115950321221\n",
      "Iteration 4838, the loss is 4.442397108495075, parameters k is 10.307745163557785 and b is -42.11115555064303\n",
      "Iteration 4839, the loss is 4.442397092720694, parameters k is 10.307744774229722 and b is -42.11115159807386\n",
      "Iteration 4840, the loss is 4.442397076946316, parameters k is 10.307744384901659 and b is -42.11114764550469\n",
      "Iteration 4841, the loss is 4.442397061171936, parameters k is 10.307743995573595 and b is -42.111143692935514\n",
      "Iteration 4842, the loss is 4.442397045397556, parameters k is 10.307743606245532 and b is -42.11113974036634\n",
      "Iteration 4843, the loss is 4.442397029623176, parameters k is 10.30774321691747 and b is -42.11113578779717\n",
      "Iteration 4844, the loss is 4.442397013848796, parameters k is 10.307742827589406 and b is -42.111131835227994\n",
      "Iteration 4845, the loss is 4.442396998074419, parameters k is 10.307742438261343 and b is -42.11112788265882\n",
      "Iteration 4846, the loss is 4.442396982300038, parameters k is 10.30774204893328 and b is -42.11112393008965\n",
      "Iteration 4847, the loss is 4.442396966525656, parameters k is 10.307741659605217 and b is -42.111119977520474\n",
      "Iteration 4848, the loss is 4.442396950751279, parameters k is 10.307741270277154 and b is -42.1111160249513\n",
      "Iteration 4849, the loss is 4.442396934976898, parameters k is 10.30774088094909 and b is -42.11111207238213\n",
      "Iteration 4850, the loss is 4.442396919202522, parameters k is 10.307740491621027 and b is -42.111108119812954\n",
      "Iteration 4851, the loss is 4.442396903428138, parameters k is 10.307740102292964 and b is -42.11110416724378\n",
      "Iteration 4852, the loss is 4.4423968876537625, parameters k is 10.307739712964901 and b is -42.11110021467461\n",
      "Iteration 4853, the loss is 4.4423968718793825, parameters k is 10.307739323636838 and b is -42.111096262105434\n",
      "Iteration 4854, the loss is 4.442396856105001, parameters k is 10.307738934308775 and b is -42.11109230953626\n",
      "Iteration 4855, the loss is 4.442396840330624, parameters k is 10.307738544980712 and b is -42.11108835696709\n",
      "Iteration 4856, the loss is 4.4423968245562415, parameters k is 10.307738155652649 and b is -42.111084404397914\n",
      "Iteration 4857, the loss is 4.442396808781865, parameters k is 10.307737766324585 and b is -42.11108045182874\n",
      "Iteration 4858, the loss is 4.442396793007487, parameters k is 10.307737376996522 and b is -42.11107649925957\n",
      "Iteration 4859, the loss is 4.442396777233104, parameters k is 10.30773698766846 and b is -42.111072546690394\n",
      "Iteration 4860, the loss is 4.442396761458727, parameters k is 10.307736598340396 and b is -42.11106859412122\n",
      "Iteration 4861, the loss is 4.442396745684347, parameters k is 10.307736209012333 and b is -42.11106464155205\n",
      "Iteration 4862, the loss is 4.442396729909968, parameters k is 10.30773581968427 and b is -42.111060688982874\n",
      "Iteration 4863, the loss is 4.4423967141355885, parameters k is 10.307735430356207 and b is -42.1110567364137\n",
      "Iteration 4864, the loss is 4.442396698361209, parameters k is 10.307735041028144 and b is -42.11105278384453\n",
      "Iteration 4865, the loss is 4.442396682586831, parameters k is 10.30773465170008 and b is -42.111048831275355\n",
      "Iteration 4866, the loss is 4.442396666812451, parameters k is 10.307734262372017 and b is -42.11104487870618\n",
      "Iteration 4867, the loss is 4.44239665103807, parameters k is 10.307733873043954 and b is -42.11104092613701\n",
      "Iteration 4868, the loss is 4.44239663526369, parameters k is 10.307733483715891 and b is -42.111036973567835\n",
      "Iteration 4869, the loss is 4.442396619489309, parameters k is 10.307733094387828 and b is -42.11103302099866\n",
      "Iteration 4870, the loss is 4.442396603714931, parameters k is 10.307732705059765 and b is -42.11102906842949\n",
      "Iteration 4871, the loss is 4.442396587940554, parameters k is 10.307732315731702 and b is -42.111025115860315\n",
      "Iteration 4872, the loss is 4.442396572166173, parameters k is 10.307731926403639 and b is -42.11102116329114\n",
      "Iteration 4873, the loss is 4.442396556391794, parameters k is 10.307731537075576 and b is -42.11101721072197\n",
      "Iteration 4874, the loss is 4.442396540617415, parameters k is 10.307731147747512 and b is -42.111013258152795\n",
      "Iteration 4875, the loss is 4.442396524843035, parameters k is 10.30773075841945 and b is -42.11100930558362\n",
      "Iteration 4876, the loss is 4.442396509068653, parameters k is 10.307730369091386 and b is -42.11100535301445\n",
      "Iteration 4877, the loss is 4.442396493294278, parameters k is 10.307729979763323 and b is -42.111001400445275\n",
      "Iteration 4878, the loss is 4.442396477519895, parameters k is 10.30772959043526 and b is -42.1109974478761\n",
      "Iteration 4879, the loss is 4.442396461745519, parameters k is 10.307729201107197 and b is -42.11099349530693\n",
      "Iteration 4880, the loss is 4.4423964459711405, parameters k is 10.307728811779134 and b is -42.110989542737755\n",
      "Iteration 4881, the loss is 4.442396430196758, parameters k is 10.30772842245107 and b is -42.11098559016858\n",
      "Iteration 4882, the loss is 4.4423964144223795, parameters k is 10.307728033123007 and b is -42.11098163759941\n",
      "Iteration 4883, the loss is 4.442396398648, parameters k is 10.307727643794944 and b is -42.110977685030235\n",
      "Iteration 4884, the loss is 4.442396382873622, parameters k is 10.307727254466881 and b is -42.11097373246106\n",
      "Iteration 4885, the loss is 4.44239636709924, parameters k is 10.307726865138818 and b is -42.11096977989189\n",
      "Iteration 4886, the loss is 4.442396351324863, parameters k is 10.307726475810755 and b is -42.110965827322715\n",
      "Iteration 4887, the loss is 4.442396335550483, parameters k is 10.307726086482692 and b is -42.11096187475354\n",
      "Iteration 4888, the loss is 4.442396319776106, parameters k is 10.307725697154629 and b is -42.11095792218437\n",
      "Iteration 4889, the loss is 4.442396304001722, parameters k is 10.307725307826566 and b is -42.110953969615196\n",
      "Iteration 4890, the loss is 4.442396288227346, parameters k is 10.307724918498502 and b is -42.11095001704602\n",
      "Iteration 4891, the loss is 4.442396272452968, parameters k is 10.30772452917044 and b is -42.11094606447685\n",
      "Iteration 4892, the loss is 4.442396256678585, parameters k is 10.307724139842376 and b is -42.110942111907676\n",
      "Iteration 4893, the loss is 4.442396240904208, parameters k is 10.307723750514313 and b is -42.1109381593385\n",
      "Iteration 4894, the loss is 4.442396225129827, parameters k is 10.30772336118625 and b is -42.11093420676933\n",
      "Iteration 4895, the loss is 4.442396209355445, parameters k is 10.307722971858187 and b is -42.110930254200156\n",
      "Iteration 4896, the loss is 4.442396193581069, parameters k is 10.307722582530124 and b is -42.11092630163098\n",
      "Iteration 4897, the loss is 4.442396177806686, parameters k is 10.30772219320206 and b is -42.11092234906181\n",
      "Iteration 4898, the loss is 4.442396162032307, parameters k is 10.307721803873998 and b is -42.110918396492636\n",
      "Iteration 4899, the loss is 4.442396146257929, parameters k is 10.307721414545934 and b is -42.11091444392346\n",
      "Iteration 4900, the loss is 4.442396130483551, parameters k is 10.307721025217871 and b is -42.11091049135429\n",
      "Iteration 4901, the loss is 4.442396114709169, parameters k is 10.307720635889808 and b is -42.110906538785116\n",
      "Iteration 4902, the loss is 4.442396098934791, parameters k is 10.307720246561745 and b is -42.11090258621594\n",
      "Iteration 4903, the loss is 4.442396083160413, parameters k is 10.307719857233682 and b is -42.11089863364677\n",
      "Iteration 4904, the loss is 4.442396067386035, parameters k is 10.307719467905619 and b is -42.110894681077596\n",
      "Iteration 4905, the loss is 4.442396051611652, parameters k is 10.307719078577556 and b is -42.11089072850842\n",
      "Iteration 4906, the loss is 4.442396035837274, parameters k is 10.307718689249493 and b is -42.11088677593925\n",
      "Iteration 4907, the loss is 4.442396020062895, parameters k is 10.30771829992143 and b is -42.110882823370076\n",
      "Iteration 4908, the loss is 4.442396004288513, parameters k is 10.307717910593366 and b is -42.1108788708009\n",
      "Iteration 4909, the loss is 4.442395988514137, parameters k is 10.307717521265303 and b is -42.11087491823173\n",
      "Iteration 4910, the loss is 4.442395972739757, parameters k is 10.30771713193724 and b is -42.110870965662556\n",
      "Iteration 4911, the loss is 4.442395956965374, parameters k is 10.307716742609177 and b is -42.11086701309338\n",
      "Iteration 4912, the loss is 4.442395941190996, parameters k is 10.307716353281114 and b is -42.11086306052421\n",
      "Iteration 4913, the loss is 4.442395925416619, parameters k is 10.30771596395305 and b is -42.11085910795504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4914, the loss is 4.442395909642239, parameters k is 10.307715574624988 and b is -42.11085515538586\n",
      "Iteration 4915, the loss is 4.442395893867857, parameters k is 10.307715185296924 and b is -42.11085120281669\n",
      "Iteration 4916, the loss is 4.442395878093477, parameters k is 10.307714795968861 and b is -42.11084725024752\n",
      "Iteration 4917, the loss is 4.442395862319103, parameters k is 10.307714406640798 and b is -42.11084329767834\n",
      "Iteration 4918, the loss is 4.442395846544719, parameters k is 10.307714017312735 and b is -42.11083934510917\n",
      "Iteration 4919, the loss is 4.442395830770342, parameters k is 10.307713627984672 and b is -42.11083539254\n",
      "Iteration 4920, the loss is 4.4423958149959635, parameters k is 10.307713238656609 and b is -42.11083143997082\n",
      "Iteration 4921, the loss is 4.4423957992215835, parameters k is 10.307712849328546 and b is -42.11082748740165\n",
      "Iteration 4922, the loss is 4.442395783447202, parameters k is 10.307712460000483 and b is -42.11082353483248\n",
      "Iteration 4923, the loss is 4.442395767672825, parameters k is 10.30771207067242 and b is -42.110819582263304\n",
      "Iteration 4924, the loss is 4.442395751898443, parameters k is 10.307711681344356 and b is -42.11081562969413\n",
      "Iteration 4925, the loss is 4.442395736124064, parameters k is 10.307711292016293 and b is -42.11081167712496\n",
      "Iteration 4926, the loss is 4.442395720349688, parameters k is 10.30771090268823 and b is -42.110807724555784\n",
      "Iteration 4927, the loss is 4.442395704575304, parameters k is 10.307710513360167 and b is -42.11080377198661\n",
      "Iteration 4928, the loss is 4.442395688800926, parameters k is 10.307710124032104 and b is -42.11079981941744\n",
      "Iteration 4929, the loss is 4.442395673026549, parameters k is 10.30770973470404 and b is -42.110795866848264\n",
      "Iteration 4930, the loss is 4.442395657252169, parameters k is 10.307709345375978 and b is -42.11079191427909\n",
      "Iteration 4931, the loss is 4.44239564147779, parameters k is 10.307708956047914 and b is -42.11078796170992\n",
      "Iteration 4932, the loss is 4.442395625703409, parameters k is 10.307708566719851 and b is -42.110784009140744\n",
      "Iteration 4933, the loss is 4.442395609929031, parameters k is 10.307708177391788 and b is -42.11078005657157\n",
      "Iteration 4934, the loss is 4.442395594154649, parameters k is 10.307707788063725 and b is -42.1107761040024\n",
      "Iteration 4935, the loss is 4.442395578380271, parameters k is 10.307707398735662 and b is -42.110772151433224\n",
      "Iteration 4936, the loss is 4.442395562605892, parameters k is 10.307707009407599 and b is -42.11076819886405\n",
      "Iteration 4937, the loss is 4.442395546831513, parameters k is 10.307706620079536 and b is -42.11076424629488\n",
      "Iteration 4938, the loss is 4.442395531057133, parameters k is 10.307706230751473 and b is -42.110760293725704\n",
      "Iteration 4939, the loss is 4.442395515282753, parameters k is 10.30770584142341 and b is -42.11075634115653\n",
      "Iteration 4940, the loss is 4.442395499508376, parameters k is 10.307705452095346 and b is -42.11075238858736\n",
      "Iteration 4941, the loss is 4.442395483733994, parameters k is 10.307705062767283 and b is -42.110748436018184\n",
      "Iteration 4942, the loss is 4.442395467959615, parameters k is 10.30770467343922 and b is -42.11074448344901\n",
      "Iteration 4943, the loss is 4.442395452185237, parameters k is 10.307704284111157 and b is -42.11074053087984\n",
      "Iteration 4944, the loss is 4.442395436410855, parameters k is 10.307703894783094 and b is -42.110736578310664\n",
      "Iteration 4945, the loss is 4.442395420636478, parameters k is 10.30770350545503 and b is -42.11073262574149\n",
      "Iteration 4946, the loss is 4.442395404862098, parameters k is 10.307703116126968 and b is -42.11072867317232\n",
      "Iteration 4947, the loss is 4.442395389087717, parameters k is 10.307702726798905 and b is -42.110724720603145\n",
      "Iteration 4948, the loss is 4.442395373313341, parameters k is 10.307702337470841 and b is -42.11072076803397\n",
      "Iteration 4949, the loss is 4.442395357538962, parameters k is 10.307701948142778 and b is -42.1107168154648\n",
      "Iteration 4950, the loss is 4.4423953417645805, parameters k is 10.307701558814715 and b is -42.110712862895625\n",
      "Iteration 4951, the loss is 4.4423953259902, parameters k is 10.307701169486652 and b is -42.11070891032645\n",
      "Iteration 4952, the loss is 4.442395310215822, parameters k is 10.307700780158589 and b is -42.11070495775728\n",
      "Iteration 4953, the loss is 4.44239529444144, parameters k is 10.307700390830526 and b is -42.110701005188105\n",
      "Iteration 4954, the loss is 4.442395278667064, parameters k is 10.307700001502463 and b is -42.11069705261893\n",
      "Iteration 4955, the loss is 4.442395262892683, parameters k is 10.3076996121744 and b is -42.11069310004976\n",
      "Iteration 4956, the loss is 4.442395247118302, parameters k is 10.307699222846336 and b is -42.110689147480585\n",
      "Iteration 4957, the loss is 4.442395231343925, parameters k is 10.307698833518273 and b is -42.11068519491141\n",
      "Iteration 4958, the loss is 4.442395215569545, parameters k is 10.30769844419021 and b is -42.11068124234224\n",
      "Iteration 4959, the loss is 4.442395199795166, parameters k is 10.307698054862147 and b is -42.110677289773065\n",
      "Iteration 4960, the loss is 4.442395184020787, parameters k is 10.307697665534084 and b is -42.11067333720389\n",
      "Iteration 4961, the loss is 4.4423951682464065, parameters k is 10.30769727620602 and b is -42.11066938463472\n",
      "Iteration 4962, the loss is 4.442395152472026, parameters k is 10.307696886877958 and b is -42.110665432065545\n",
      "Iteration 4963, the loss is 4.442395136697647, parameters k is 10.307696497549895 and b is -42.11066147949637\n",
      "Iteration 4964, the loss is 4.442395120923269, parameters k is 10.307696108221831 and b is -42.1106575269272\n",
      "Iteration 4965, the loss is 4.442395105148893, parameters k is 10.307695718893768 and b is -42.110653574358025\n",
      "Iteration 4966, the loss is 4.442395089374508, parameters k is 10.307695329565705 and b is -42.11064962178885\n",
      "Iteration 4967, the loss is 4.44239507360013, parameters k is 10.307694940237642 and b is -42.11064566921968\n",
      "Iteration 4968, the loss is 4.442395057825753, parameters k is 10.307694550909579 and b is -42.110641716650505\n",
      "Iteration 4969, the loss is 4.442395042051371, parameters k is 10.307694161581516 and b is -42.11063776408133\n",
      "Iteration 4970, the loss is 4.442395026276993, parameters k is 10.307693772253453 and b is -42.11063381151216\n",
      "Iteration 4971, the loss is 4.442395010502614, parameters k is 10.30769338292539 and b is -42.110629858942985\n",
      "Iteration 4972, the loss is 4.442394994728233, parameters k is 10.307692993597326 and b is -42.11062590637381\n",
      "Iteration 4973, the loss is 4.4423949789538515, parameters k is 10.307692604269263 and b is -42.11062195380464\n",
      "Iteration 4974, the loss is 4.442394963179478, parameters k is 10.3076922149412 and b is -42.110618001235466\n",
      "Iteration 4975, the loss is 4.442394947405097, parameters k is 10.307691825613137 and b is -42.11061404866629\n",
      "Iteration 4976, the loss is 4.442394931630716, parameters k is 10.307691436285074 and b is -42.11061009609712\n",
      "Iteration 4977, the loss is 4.442394917714647, parameters k is 10.30769104695701 and b is -42.110606143527946\n",
      "Iteration 4978, the loss is 4.4423949049990075, parameters k is 10.307663159605232 and b is -42.110606143527946\n",
      "Iteration 4979, the loss is 4.44239488922463, parameters k is 10.307662770277169 and b is -42.11060219095877\n",
      "Iteration 4980, the loss is 4.442394873450246, parameters k is 10.307662380949106 and b is -42.1105982383896\n",
      "Iteration 4981, the loss is 4.442394857675871, parameters k is 10.307661991621043 and b is -42.110594285820426\n",
      "Iteration 4982, the loss is 4.442394841901492, parameters k is 10.30766160229298 and b is -42.11059033325125\n",
      "Iteration 4983, the loss is 4.442394826127109, parameters k is 10.307661212964916 and b is -42.11058638068208\n",
      "Iteration 4984, the loss is 4.442394810352732, parameters k is 10.307660823636853 and b is -42.110582428112906\n",
      "Iteration 4985, the loss is 4.442394794578353, parameters k is 10.30766043430879 and b is -42.11057847554373\n",
      "Iteration 4986, the loss is 4.442394778803974, parameters k is 10.307660044980727 and b is -42.11057452297456\n",
      "Iteration 4987, the loss is 4.442394763029593, parameters k is 10.307659655652664 and b is -42.110570570405386\n",
      "Iteration 4988, the loss is 4.442394747255215, parameters k is 10.3076592663246 and b is -42.11056661783621\n",
      "Iteration 4989, the loss is 4.442394731480833, parameters k is 10.307658876996538 and b is -42.11056266526704\n",
      "Iteration 4990, the loss is 4.442394715706455, parameters k is 10.307658487668474 and b is -42.110558712697866\n",
      "Iteration 4991, the loss is 4.442394699932074, parameters k is 10.307658098340411 and b is -42.11055476012869\n",
      "Iteration 4992, the loss is 4.442394684157695, parameters k is 10.307657709012348 and b is -42.11055080755952\n",
      "Iteration 4993, the loss is 4.442394668383317, parameters k is 10.307657319684285 and b is -42.110546854990346\n",
      "Iteration 4994, the loss is 4.442394652608939, parameters k is 10.307656930356222 and b is -42.11054290242117\n",
      "Iteration 4995, the loss is 4.442394636834558, parameters k is 10.307656541028159 and b is -42.110538949852\n",
      "Iteration 4996, the loss is 4.442394621060179, parameters k is 10.307656151700096 and b is -42.11053499728283\n",
      "Iteration 4997, the loss is 4.442394605285801, parameters k is 10.307655762372033 and b is -42.11053104471365\n",
      "Iteration 4998, the loss is 4.442394589511421, parameters k is 10.30765537304397 and b is -42.11052709214448\n",
      "Iteration 4999, the loss is 4.442394573737042, parameters k is 10.307654983715906 and b is -42.11052313957531\n",
      "Iteration 5000, the loss is 4.442394557962661, parameters k is 10.307654594387843 and b is -42.11051918700613\n",
      "Iteration 5001, the loss is 4.442394542188282, parameters k is 10.30765420505978 and b is -42.11051523443696\n",
      "Iteration 5002, the loss is 4.442394526413901, parameters k is 10.307653815731717 and b is -42.11051128186779\n",
      "Iteration 5003, the loss is 4.442394510639526, parameters k is 10.307653426403654 and b is -42.11050732929861\n",
      "Iteration 5004, the loss is 4.442394494865146, parameters k is 10.30765303707559 and b is -42.11050337672944\n",
      "Iteration 5005, the loss is 4.44239447909076, parameters k is 10.307652647747528 and b is -42.11049942416027\n",
      "Iteration 5006, the loss is 4.442394463316384, parameters k is 10.307652258419465 and b is -42.11049547159109\n",
      "Iteration 5007, the loss is 4.442394447542008, parameters k is 10.307651869091401 and b is -42.11049151902192\n",
      "Iteration 5008, the loss is 4.442394431767627, parameters k is 10.307651479763338 and b is -42.11048756645275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5009, the loss is 4.442394415993248, parameters k is 10.307651090435275 and b is -42.110483613883574\n",
      "Iteration 5010, the loss is 4.442394400218866, parameters k is 10.307650701107212 and b is -42.1104796613144\n",
      "Iteration 5011, the loss is 4.442394384444488, parameters k is 10.307650311779149 and b is -42.11047570874523\n",
      "Iteration 5012, the loss is 4.442394368670109, parameters k is 10.307649922451086 and b is -42.110471756176054\n",
      "Iteration 5013, the loss is 4.442394352895731, parameters k is 10.307649533123023 and b is -42.11046780360688\n",
      "Iteration 5014, the loss is 4.442394337121351, parameters k is 10.30764914379496 and b is -42.11046385103771\n",
      "Iteration 5015, the loss is 4.442394321346971, parameters k is 10.307648754466896 and b is -42.110459898468534\n",
      "Iteration 5016, the loss is 4.4423943055725905, parameters k is 10.307648365138833 and b is -42.11045594589936\n",
      "Iteration 5017, the loss is 4.442394289798214, parameters k is 10.30764797581077 and b is -42.11045199333019\n",
      "Iteration 5018, the loss is 4.442394274023833, parameters k is 10.307647586482707 and b is -42.110448040761014\n",
      "Iteration 5019, the loss is 4.442394258249451, parameters k is 10.307647197154644 and b is -42.11044408819184\n",
      "Iteration 5020, the loss is 4.442394242475073, parameters k is 10.30764680782658 and b is -42.11044013562267\n",
      "Iteration 5021, the loss is 4.442394226700695, parameters k is 10.307646418498518 and b is -42.110436183053494\n",
      "Iteration 5022, the loss is 4.442394210926312, parameters k is 10.307646029170455 and b is -42.11043223048432\n",
      "Iteration 5023, the loss is 4.442394195151937, parameters k is 10.307645639842391 and b is -42.11042827791515\n",
      "Iteration 5024, the loss is 4.442394179377553, parameters k is 10.307645250514328 and b is -42.110424325345974\n",
      "Iteration 5025, the loss is 4.442394163603175, parameters k is 10.307644861186265 and b is -42.1104203727768\n",
      "Iteration 5026, the loss is 4.442394147828799, parameters k is 10.307644471858202 and b is -42.11041642020763\n",
      "Iteration 5027, the loss is 4.442394132054417, parameters k is 10.307644082530139 and b is -42.110412467638454\n",
      "Iteration 5028, the loss is 4.442394116280039, parameters k is 10.307643693202076 and b is -42.11040851506928\n",
      "Iteration 5029, the loss is 4.442394100505659, parameters k is 10.307643303874013 and b is -42.11040456250011\n",
      "Iteration 5030, the loss is 4.442394084731278, parameters k is 10.30764291454595 and b is -42.110400609930934\n",
      "Iteration 5031, the loss is 4.442394068956899, parameters k is 10.307642525217886 and b is -42.11039665736176\n",
      "Iteration 5032, the loss is 4.442394053182522, parameters k is 10.307642135889823 and b is -42.11039270479259\n",
      "Iteration 5033, the loss is 4.4423940374081425, parameters k is 10.30764174656176 and b is -42.110388752223415\n",
      "Iteration 5034, the loss is 4.442394021633761, parameters k is 10.307641357233697 and b is -42.11038479965424\n",
      "Iteration 5035, the loss is 4.442394005859384, parameters k is 10.307640967905634 and b is -42.11038084708507\n",
      "Iteration 5036, the loss is 4.442393990085005, parameters k is 10.30764057857757 and b is -42.110376894515895\n",
      "Iteration 5037, the loss is 4.442393974310627, parameters k is 10.307640189249508 and b is -42.11037294194672\n",
      "Iteration 5038, the loss is 4.4423939585362415, parameters k is 10.307639799921445 and b is -42.11036898937755\n",
      "Iteration 5039, the loss is 4.442393942761864, parameters k is 10.307639410593382 and b is -42.110365036808375\n",
      "Iteration 5040, the loss is 4.442393926987488, parameters k is 10.307639021265318 and b is -42.1103610842392\n",
      "Iteration 5041, the loss is 4.442393911213103, parameters k is 10.307638631937255 and b is -42.11035713167003\n",
      "Iteration 5042, the loss is 4.442393895438725, parameters k is 10.307638242609192 and b is -42.110353179100855\n",
      "Iteration 5043, the loss is 4.442393879664347, parameters k is 10.307637853281129 and b is -42.11034922653168\n",
      "Iteration 5044, the loss is 4.442393863889968, parameters k is 10.307637463953066 and b is -42.11034527396251\n",
      "Iteration 5045, the loss is 4.442393848115588, parameters k is 10.307637074625003 and b is -42.110341321393335\n",
      "Iteration 5046, the loss is 4.442393832341212, parameters k is 10.30763668529694 and b is -42.11033736882416\n",
      "Iteration 5047, the loss is 4.442393816566828, parameters k is 10.307636295968877 and b is -42.11033341625499\n",
      "Iteration 5048, the loss is 4.442393800792449, parameters k is 10.307635906640813 and b is -42.110329463685815\n",
      "Iteration 5049, the loss is 4.44239378501807, parameters k is 10.30763551731275 and b is -42.11032551111664\n",
      "Iteration 5050, the loss is 4.442393769243691, parameters k is 10.307635127984687 and b is -42.11032155854747\n",
      "Iteration 5051, the loss is 4.442393753469314, parameters k is 10.307634738656624 and b is -42.110317605978295\n",
      "Iteration 5052, the loss is 4.442393737694932, parameters k is 10.307634349328561 and b is -42.11031365340912\n",
      "Iteration 5053, the loss is 4.442393721920554, parameters k is 10.307633960000498 and b is -42.11030970083995\n",
      "Iteration 5054, the loss is 4.442393706146175, parameters k is 10.307633570672435 and b is -42.110305748270775\n",
      "Iteration 5055, the loss is 4.442393690371793, parameters k is 10.307633181344372 and b is -42.1103017957016\n",
      "Iteration 5056, the loss is 4.442393674597416, parameters k is 10.307632792016308 and b is -42.11029784313243\n",
      "Iteration 5057, the loss is 4.442393658823034, parameters k is 10.307632402688245 and b is -42.110293890563256\n",
      "Iteration 5058, the loss is 4.442393643048655, parameters k is 10.307632013360182 and b is -42.11028993799408\n",
      "Iteration 5059, the loss is 4.44239362727428, parameters k is 10.307631624032119 and b is -42.11028598542491\n",
      "Iteration 5060, the loss is 4.4423936114999005, parameters k is 10.307631234704056 and b is -42.110282032855736\n",
      "Iteration 5061, the loss is 4.442393595725518, parameters k is 10.307630845375993 and b is -42.11027808028656\n",
      "Iteration 5062, the loss is 4.442393579951139, parameters k is 10.30763045604793 and b is -42.11027412771739\n",
      "Iteration 5063, the loss is 4.4423935641767605, parameters k is 10.307630066719867 and b is -42.110270175148216\n",
      "Iteration 5064, the loss is 4.442393548402381, parameters k is 10.307629677391803 and b is -42.11026622257904\n",
      "Iteration 5065, the loss is 4.442393532628001, parameters k is 10.30762928806374 and b is -42.11026227000987\n",
      "Iteration 5066, the loss is 4.442393516853622, parameters k is 10.307628898735677 and b is -42.110258317440696\n",
      "Iteration 5067, the loss is 4.442393501079243, parameters k is 10.307628509407614 and b is -42.11025436487152\n",
      "Iteration 5068, the loss is 4.442393485304863, parameters k is 10.307628120079551 and b is -42.11025041230235\n",
      "Iteration 5069, the loss is 4.442393469530484, parameters k is 10.307627730751488 and b is -42.110246459733176\n",
      "Iteration 5070, the loss is 4.442393453756104, parameters k is 10.307627341423425 and b is -42.110242507164\n",
      "Iteration 5071, the loss is 4.442393437981722, parameters k is 10.307626952095362 and b is -42.11023855459483\n",
      "Iteration 5072, the loss is 4.442393422207344, parameters k is 10.307626562767298 and b is -42.110234602025656\n",
      "Iteration 5073, the loss is 4.442393406432965, parameters k is 10.307626173439235 and b is -42.11023064945648\n",
      "Iteration 5074, the loss is 4.4423933906585855, parameters k is 10.307625784111172 and b is -42.11022669688731\n",
      "Iteration 5075, the loss is 4.442393374884206, parameters k is 10.30762539478311 and b is -42.110222744318136\n",
      "Iteration 5076, the loss is 4.442393359109826, parameters k is 10.307625005455046 and b is -42.11021879174896\n",
      "Iteration 5077, the loss is 4.442393343335449, parameters k is 10.307624616126983 and b is -42.11021483917979\n",
      "Iteration 5078, the loss is 4.44239332756107, parameters k is 10.30762422679892 and b is -42.110210886610616\n",
      "Iteration 5079, the loss is 4.44239331178669, parameters k is 10.307623837470857 and b is -42.11020693404144\n",
      "Iteration 5080, the loss is 4.442393296012311, parameters k is 10.307623448142794 and b is -42.11020298147227\n",
      "Iteration 5081, the loss is 4.442393280237931, parameters k is 10.30762305881473 and b is -42.1101990289031\n",
      "Iteration 5082, the loss is 4.442393264463548, parameters k is 10.307622669486667 and b is -42.11019507633392\n",
      "Iteration 5083, the loss is 4.442393248689173, parameters k is 10.307622280158604 and b is -42.11019112376475\n",
      "Iteration 5084, the loss is 4.4423932329147915, parameters k is 10.307621890830541 and b is -42.11018717119558\n",
      "Iteration 5085, the loss is 4.442393217140412, parameters k is 10.307621501502478 and b is -42.1101832186264\n",
      "Iteration 5086, the loss is 4.442393201366032, parameters k is 10.307621112174415 and b is -42.11017926605723\n",
      "Iteration 5087, the loss is 4.442393185591655, parameters k is 10.307620722846352 and b is -42.11017531348806\n",
      "Iteration 5088, the loss is 4.442393169817274, parameters k is 10.307620333518289 and b is -42.11017136091888\n",
      "Iteration 5089, the loss is 4.442393154042892, parameters k is 10.307619944190225 and b is -42.11016740834971\n",
      "Iteration 5090, the loss is 4.442393138268515, parameters k is 10.307619554862162 and b is -42.11016345578054\n",
      "Iteration 5091, the loss is 4.442393122494135, parameters k is 10.3076191655341 and b is -42.110159503211364\n",
      "Iteration 5092, the loss is 4.442393106719758, parameters k is 10.307618776206036 and b is -42.11015555064219\n",
      "Iteration 5093, the loss is 4.442393090945379, parameters k is 10.307618386877973 and b is -42.11015159807302\n",
      "Iteration 5094, the loss is 4.4423930751709975, parameters k is 10.30761799754991 and b is -42.110147645503844\n",
      "Iteration 5095, the loss is 4.442393059396618, parameters k is 10.307617608221847 and b is -42.11014369293467\n",
      "Iteration 5096, the loss is 4.442393043622237, parameters k is 10.307617218893784 and b is -42.1101397403655\n",
      "Iteration 5097, the loss is 4.442393027847859, parameters k is 10.30761682956572 and b is -42.110135787796324\n",
      "Iteration 5098, the loss is 4.442393012073479, parameters k is 10.307616440237657 and b is -42.11013183522715\n",
      "Iteration 5099, the loss is 4.4423929962991, parameters k is 10.307616050909594 and b is -42.11012788265798\n",
      "Iteration 5100, the loss is 4.44239298052472, parameters k is 10.307615661581531 and b is -42.110123930088804\n",
      "Iteration 5101, the loss is 4.442392964750343, parameters k is 10.307615272253468 and b is -42.11011997751963\n",
      "Iteration 5102, the loss is 4.442392948975963, parameters k is 10.307614882925405 and b is -42.11011602495046\n",
      "Iteration 5103, the loss is 4.4423929332015835, parameters k is 10.307614493597342 and b is -42.110112072381284\n",
      "Iteration 5104, the loss is 4.442392917427204, parameters k is 10.307614104269279 and b is -42.11010811981211\n",
      "Iteration 5105, the loss is 4.4423929016528225, parameters k is 10.307613714941215 and b is -42.11010416724294\n",
      "Iteration 5106, the loss is 4.442392885878445, parameters k is 10.307613325613152 and b is -42.110100214673764\n",
      "Iteration 5107, the loss is 4.442392870104064, parameters k is 10.30761293628509 and b is -42.11009626210459\n",
      "Iteration 5108, the loss is 4.442392854329686, parameters k is 10.307612546957026 and b is -42.11009230953542\n",
      "Iteration 5109, the loss is 4.442392838555304, parameters k is 10.307612157628963 and b is -42.110088356966244\n",
      "Iteration 5110, the loss is 4.442392822780928, parameters k is 10.3076117683009 and b is -42.11008440439707\n",
      "Iteration 5111, the loss is 4.442392807006549, parameters k is 10.307611378972837 and b is -42.1100804518279\n",
      "Iteration 5112, the loss is 4.44239279123217, parameters k is 10.307610989644774 and b is -42.110076499258724\n",
      "Iteration 5113, the loss is 4.442392775457789, parameters k is 10.30761060031671 and b is -42.11007254668955\n",
      "Iteration 5114, the loss is 4.442392759683411, parameters k is 10.307610210988647 and b is -42.11006859412038\n",
      "Iteration 5115, the loss is 4.44239274390903, parameters k is 10.307609821660584 and b is -42.110064641551205\n",
      "Iteration 5116, the loss is 4.44239272813465, parameters k is 10.307609432332521 and b is -42.11006068898203\n",
      "Iteration 5117, the loss is 4.442392712360272, parameters k is 10.307609043004458 and b is -42.11005673641286\n",
      "Iteration 5118, the loss is 4.442392696585892, parameters k is 10.307608653676395 and b is -42.110052783843685\n",
      "Iteration 5119, the loss is 4.442392680811514, parameters k is 10.307608264348332 and b is -42.11004883127451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5120, the loss is 4.442392665037135, parameters k is 10.307607875020269 and b is -42.11004487870534\n",
      "Iteration 5121, the loss is 4.442392649262754, parameters k is 10.307607485692206 and b is -42.110040926136165\n",
      "Iteration 5122, the loss is 4.442392633488379, parameters k is 10.307607096364142 and b is -42.11003697356699\n",
      "Iteration 5123, the loss is 4.442392617713994, parameters k is 10.30760670703608 and b is -42.11003302099782\n",
      "Iteration 5124, the loss is 4.442392601939616, parameters k is 10.307606317708016 and b is -42.110029068428645\n",
      "Iteration 5125, the loss is 4.442392586165236, parameters k is 10.307605928379953 and b is -42.11002511585947\n",
      "Iteration 5126, the loss is 4.442392570390857, parameters k is 10.30760553905189 and b is -42.1100211632903\n",
      "Iteration 5127, the loss is 4.442392554616478, parameters k is 10.307605149723827 and b is -42.110017210721125\n",
      "Iteration 5128, the loss is 4.442392538842098, parameters k is 10.307604760395764 and b is -42.11001325815195\n",
      "Iteration 5129, the loss is 4.44239252306772, parameters k is 10.3076043710677 and b is -42.11000930558278\n",
      "Iteration 5130, the loss is 4.44239250729334, parameters k is 10.307603981739637 and b is -42.110005353013605\n",
      "Iteration 5131, the loss is 4.44239249151896, parameters k is 10.307603592411574 and b is -42.11000140044443\n",
      "Iteration 5132, the loss is 4.44239247574458, parameters k is 10.307603203083511 and b is -42.10999744787526\n",
      "Iteration 5133, the loss is 4.4423924599702005, parameters k is 10.307602813755448 and b is -42.109993495306085\n",
      "Iteration 5134, the loss is 4.442392446266986, parameters k is 10.307602424427385 and b is -42.10998954273691\n",
      "Iteration 5135, the loss is 4.442392433338494, parameters k is 10.307574537075606 and b is -42.10998954273691\n",
      "Iteration 5136, the loss is 4.4423924175641165, parameters k is 10.307574147747543 and b is -42.10998559016774\n",
      "Iteration 5137, the loss is 4.442392401789735, parameters k is 10.30757375841948 and b is -42.109981637598565\n",
      "Iteration 5138, the loss is 4.442392386015356, parameters k is 10.307573369091417 and b is -42.10997768502939\n",
      "Iteration 5139, the loss is 4.442392370240977, parameters k is 10.307572979763354 and b is -42.10997373246022\n",
      "Iteration 5140, the loss is 4.442392354466599, parameters k is 10.30757259043529 and b is -42.109969779891046\n",
      "Iteration 5141, the loss is 4.442392338692218, parameters k is 10.307572201107227 and b is -42.10996582732187\n",
      "Iteration 5142, the loss is 4.442392322917838, parameters k is 10.307571811779164 and b is -42.1099618747527\n",
      "Iteration 5143, the loss is 4.442392307143459, parameters k is 10.307571422451101 and b is -42.109957922183526\n",
      "Iteration 5144, the loss is 4.442392291369081, parameters k is 10.307571033123038 and b is -42.10995396961435\n",
      "Iteration 5145, the loss is 4.442392275594698, parameters k is 10.307570643794975 and b is -42.10995001704518\n",
      "Iteration 5146, the loss is 4.442392259820318, parameters k is 10.307570254466912 and b is -42.109946064476006\n",
      "Iteration 5147, the loss is 4.442392244045939, parameters k is 10.307569865138849 and b is -42.10994211190683\n",
      "Iteration 5148, the loss is 4.4423922282715615, parameters k is 10.307569475810785 and b is -42.10993815933766\n",
      "Iteration 5149, the loss is 4.442392212497181, parameters k is 10.307569086482722 and b is -42.109934206768486\n",
      "Iteration 5150, the loss is 4.442392196722804, parameters k is 10.30756869715466 and b is -42.10993025419931\n",
      "Iteration 5151, the loss is 4.442392180948421, parameters k is 10.307568307826596 and b is -42.10992630163014\n",
      "Iteration 5152, the loss is 4.4423921651740415, parameters k is 10.307567918498533 and b is -42.109922349060966\n",
      "Iteration 5153, the loss is 4.442392149399662, parameters k is 10.30756752917047 and b is -42.10991839649179\n",
      "Iteration 5154, the loss is 4.442392133625285, parameters k is 10.307567139842407 and b is -42.10991444392262\n",
      "Iteration 5155, the loss is 4.442392117850902, parameters k is 10.307566750514344 and b is -42.109910491353446\n",
      "Iteration 5156, the loss is 4.442392102076525, parameters k is 10.30756636118628 and b is -42.10990653878427\n",
      "Iteration 5157, the loss is 4.442392086302149, parameters k is 10.307565971858217 and b is -42.1099025862151\n",
      "Iteration 5158, the loss is 4.442392070527767, parameters k is 10.307565582530154 and b is -42.109898633645926\n",
      "Iteration 5159, the loss is 4.442392054753388, parameters k is 10.307565193202091 and b is -42.10989468107675\n",
      "Iteration 5160, the loss is 4.442392038979007, parameters k is 10.307564803874028 and b is -42.10989072850758\n",
      "Iteration 5161, the loss is 4.4423920232046274, parameters k is 10.307564414545965 and b is -42.109886775938406\n",
      "Iteration 5162, the loss is 4.442392007430249, parameters k is 10.307564025217902 and b is -42.10988282336923\n",
      "Iteration 5163, the loss is 4.44239199165587, parameters k is 10.307563635889839 and b is -42.10987887080006\n",
      "Iteration 5164, the loss is 4.44239197588149, parameters k is 10.307563246561775 and b is -42.10987491823089\n",
      "Iteration 5165, the loss is 4.442391960107114, parameters k is 10.307562857233712 and b is -42.10987096566171\n",
      "Iteration 5166, the loss is 4.442391944332733, parameters k is 10.30756246790565 and b is -42.10986701309254\n",
      "Iteration 5167, the loss is 4.442391928558354, parameters k is 10.307562078577586 and b is -42.10986306052337\n",
      "Iteration 5168, the loss is 4.4423919127839735, parameters k is 10.307561689249523 and b is -42.10985910795419\n",
      "Iteration 5169, the loss is 4.442391897009595, parameters k is 10.30756129992146 and b is -42.10985515538502\n",
      "Iteration 5170, the loss is 4.442391881235215, parameters k is 10.307560910593397 and b is -42.10985120281585\n",
      "Iteration 5171, the loss is 4.4423918654608325, parameters k is 10.307560521265334 and b is -42.10984725024667\n",
      "Iteration 5172, the loss is 4.442391849686457, parameters k is 10.30756013193727 and b is -42.1098432976775\n",
      "Iteration 5173, the loss is 4.442391833912076, parameters k is 10.307559742609207 and b is -42.10983934510833\n",
      "Iteration 5174, the loss is 4.442391818137695, parameters k is 10.307559353281144 and b is -42.10983539253915\n",
      "Iteration 5175, the loss is 4.442391802363317, parameters k is 10.307558963953081 and b is -42.10983143996998\n",
      "Iteration 5176, the loss is 4.442391786588939, parameters k is 10.307558574625018 and b is -42.10982748740081\n",
      "Iteration 5177, the loss is 4.4423917708145595, parameters k is 10.307558185296955 and b is -42.109823534831634\n",
      "Iteration 5178, the loss is 4.4423917550401795, parameters k is 10.307557795968892 and b is -42.10981958226246\n",
      "Iteration 5179, the loss is 4.442391739265799, parameters k is 10.307557406640829 and b is -42.10981562969329\n",
      "Iteration 5180, the loss is 4.442391723491422, parameters k is 10.307557017312766 and b is -42.109811677124114\n",
      "Iteration 5181, the loss is 4.442391707717042, parameters k is 10.307556627984702 and b is -42.10980772455494\n",
      "Iteration 5182, the loss is 4.442391691942663, parameters k is 10.30755623865664 and b is -42.10980377198577\n",
      "Iteration 5183, the loss is 4.442391676168281, parameters k is 10.307555849328576 and b is -42.109799819416594\n",
      "Iteration 5184, the loss is 4.442391660393903, parameters k is 10.307555460000513 and b is -42.10979586684742\n",
      "Iteration 5185, the loss is 4.442391644619525, parameters k is 10.30755507067245 and b is -42.10979191427825\n",
      "Iteration 5186, the loss is 4.442391628845144, parameters k is 10.307554681344387 and b is -42.109787961709074\n",
      "Iteration 5187, the loss is 4.4423916130707655, parameters k is 10.307554292016324 and b is -42.1097840091399\n",
      "Iteration 5188, the loss is 4.4423915972963846, parameters k is 10.30755390268826 and b is -42.10978005657073\n",
      "Iteration 5189, the loss is 4.442391581522008, parameters k is 10.307553513360197 and b is -42.109776104001554\n",
      "Iteration 5190, the loss is 4.442391565747626, parameters k is 10.307553124032134 and b is -42.10977215143238\n",
      "Iteration 5191, the loss is 4.442391549973247, parameters k is 10.307552734704071 and b is -42.10976819886321\n",
      "Iteration 5192, the loss is 4.442391534198867, parameters k is 10.307552345376008 and b is -42.109764246294034\n",
      "Iteration 5193, the loss is 4.442391518424488, parameters k is 10.307551956047945 and b is -42.10976029372486\n",
      "Iteration 5194, the loss is 4.44239150265011, parameters k is 10.307551566719882 and b is -42.10975634115569\n",
      "Iteration 5195, the loss is 4.4423914868757315, parameters k is 10.307551177391819 and b is -42.109752388586514\n",
      "Iteration 5196, the loss is 4.44239147110135, parameters k is 10.307550788063756 and b is -42.10974843601734\n",
      "Iteration 5197, the loss is 4.4423914553269706, parameters k is 10.307550398735692 and b is -42.10974448344817\n",
      "Iteration 5198, the loss is 4.442391439552591, parameters k is 10.30755000940763 and b is -42.109740530878994\n",
      "Iteration 5199, the loss is 4.442391423778212, parameters k is 10.307549620079566 and b is -42.10973657830982\n",
      "Iteration 5200, the loss is 4.442391408003836, parameters k is 10.307549230751503 and b is -42.10973262574065\n",
      "Iteration 5201, the loss is 4.442391392229454, parameters k is 10.30754884142344 and b is -42.109728673171475\n",
      "Iteration 5202, the loss is 4.442391376455074, parameters k is 10.307548452095377 and b is -42.1097247206023\n",
      "Iteration 5203, the loss is 4.442391360680694, parameters k is 10.307548062767314 and b is -42.10972076803313\n",
      "Iteration 5204, the loss is 4.442391344906312, parameters k is 10.30754767343925 and b is -42.109716815463955\n",
      "Iteration 5205, the loss is 4.442391329131937, parameters k is 10.307547284111187 and b is -42.10971286289478\n",
      "Iteration 5206, the loss is 4.4423913133575565, parameters k is 10.307546894783124 and b is -42.10970891032561\n",
      "Iteration 5207, the loss is 4.442391297583179, parameters k is 10.307546505455061 and b is -42.109704957756435\n",
      "Iteration 5208, the loss is 4.442391281808797, parameters k is 10.307546116126998 and b is -42.10970100518726\n",
      "Iteration 5209, the loss is 4.442391266034421, parameters k is 10.307545726798935 and b is -42.10969705261809\n",
      "Iteration 5210, the loss is 4.442391250260039, parameters k is 10.307545337470872 and b is -42.109693100048915\n",
      "Iteration 5211, the loss is 4.442391234485658, parameters k is 10.307544948142809 and b is -42.10968914747974\n",
      "Iteration 5212, the loss is 4.442391218711278, parameters k is 10.307544558814746 and b is -42.10968519491057\n",
      "Iteration 5213, the loss is 4.442391202936899, parameters k is 10.307544169486683 and b is -42.109681242341395\n",
      "Iteration 5214, the loss is 4.442391187162521, parameters k is 10.30754378015862 and b is -42.10967728977222\n",
      "Iteration 5215, the loss is 4.442391171388142, parameters k is 10.307543390830556 and b is -42.10967333720305\n",
      "Iteration 5216, the loss is 4.442391155613763, parameters k is 10.307543001502493 and b is -42.109669384633875\n",
      "Iteration 5217, the loss is 4.442391139839382, parameters k is 10.30754261217443 and b is -42.1096654320647\n",
      "Iteration 5218, the loss is 4.4423911240650025, parameters k is 10.307542222846367 and b is -42.10966147949553\n",
      "Iteration 5219, the loss is 4.442391108290624, parameters k is 10.307541833518304 and b is -42.109657526926355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5220, the loss is 4.442391092516244, parameters k is 10.30754144419024 and b is -42.10965357435718\n",
      "Iteration 5221, the loss is 4.442391076741865, parameters k is 10.307541054862178 and b is -42.10964962178801\n",
      "Iteration 5222, the loss is 4.442391060967487, parameters k is 10.307540665534114 and b is -42.109645669218835\n",
      "Iteration 5223, the loss is 4.442391045193108, parameters k is 10.307540276206051 and b is -42.10964171664966\n",
      "Iteration 5224, the loss is 4.442391029418728, parameters k is 10.307539886877988 and b is -42.10963776408049\n",
      "Iteration 5225, the loss is 4.442391013644349, parameters k is 10.307539497549925 and b is -42.109633811511316\n",
      "Iteration 5226, the loss is 4.442390997869967, parameters k is 10.307539108221862 and b is -42.10962985894214\n",
      "Iteration 5227, the loss is 4.442390982095589, parameters k is 10.307538718893799 and b is -42.10962590637297\n",
      "Iteration 5228, the loss is 4.442390966321209, parameters k is 10.307538329565736 and b is -42.109621953803796\n",
      "Iteration 5229, the loss is 4.442390950546828, parameters k is 10.307537940237673 and b is -42.10961800123462\n",
      "Iteration 5230, the loss is 4.442390934772452, parameters k is 10.30753755090961 and b is -42.10961404866545\n",
      "Iteration 5231, the loss is 4.442390918998071, parameters k is 10.307537161581546 and b is -42.109610096096276\n",
      "Iteration 5232, the loss is 4.442390903223692, parameters k is 10.307536772253483 and b is -42.1096061435271\n",
      "Iteration 5233, the loss is 4.44239088744931, parameters k is 10.30753638292542 and b is -42.10960219095793\n",
      "Iteration 5234, the loss is 4.442390871674933, parameters k is 10.307535993597357 and b is -42.109598238388756\n",
      "Iteration 5235, the loss is 4.4423908559005545, parameters k is 10.307535604269294 and b is -42.10959428581958\n",
      "Iteration 5236, the loss is 4.4423908401261745, parameters k is 10.30753521494123 and b is -42.10959033325041\n",
      "Iteration 5237, the loss is 4.442390824351796, parameters k is 10.307534825613168 and b is -42.109586380681236\n",
      "Iteration 5238, the loss is 4.442390808577417, parameters k is 10.307534436285104 and b is -42.10958242811206\n",
      "Iteration 5239, the loss is 4.442390792803035, parameters k is 10.307534046957041 and b is -42.10957847554289\n",
      "Iteration 5240, the loss is 4.442390777028655, parameters k is 10.307533657628978 and b is -42.109574522973716\n",
      "Iteration 5241, the loss is 4.442390761254278, parameters k is 10.307533268300915 and b is -42.10957057040454\n",
      "Iteration 5242, the loss is 4.4423907454799, parameters k is 10.307532878972852 and b is -42.10956661783537\n",
      "Iteration 5243, the loss is 4.442390729705519, parameters k is 10.307532489644789 and b is -42.109562665266196\n",
      "Iteration 5244, the loss is 4.4423907139311405, parameters k is 10.307532100316726 and b is -42.10955871269702\n",
      "Iteration 5245, the loss is 4.442390698156759, parameters k is 10.307531710988663 and b is -42.10955476012785\n",
      "Iteration 5246, the loss is 4.442390682382379, parameters k is 10.3075313216606 and b is -42.109550807558676\n",
      "Iteration 5247, the loss is 4.442390666608003, parameters k is 10.307530932332536 and b is -42.1095468549895\n",
      "Iteration 5248, the loss is 4.442390650833623, parameters k is 10.307530543004473 and b is -42.10954290242033\n",
      "Iteration 5249, the loss is 4.442390635059245, parameters k is 10.30753015367641 and b is -42.10953894985116\n",
      "Iteration 5250, the loss is 4.442390619284864, parameters k is 10.307529764348347 and b is -42.10953499728198\n",
      "Iteration 5251, the loss is 4.442390603510485, parameters k is 10.307529375020284 and b is -42.10953104471281\n",
      "Iteration 5252, the loss is 4.442390587736103, parameters k is 10.30752898569222 and b is -42.10952709214364\n",
      "Iteration 5253, the loss is 4.442390571961725, parameters k is 10.307528596364158 and b is -42.10952313957446\n",
      "Iteration 5254, the loss is 4.442390556187345, parameters k is 10.307528207036095 and b is -42.10951918700529\n",
      "Iteration 5255, the loss is 4.442390540412967, parameters k is 10.307527817708031 and b is -42.10951523443612\n",
      "Iteration 5256, the loss is 4.442390524638587, parameters k is 10.307527428379968 and b is -42.10951128186694\n",
      "Iteration 5257, the loss is 4.44239050886421, parameters k is 10.307527039051905 and b is -42.10950732929777\n",
      "Iteration 5258, the loss is 4.442390493089828, parameters k is 10.307526649723842 and b is -42.1095033767286\n",
      "Iteration 5259, the loss is 4.442390477315448, parameters k is 10.307526260395779 and b is -42.109499424159424\n",
      "Iteration 5260, the loss is 4.442390461541069, parameters k is 10.307525871067716 and b is -42.10949547159025\n",
      "Iteration 5261, the loss is 4.442390445766692, parameters k is 10.307525481739653 and b is -42.10949151902108\n",
      "Iteration 5262, the loss is 4.44239042999231, parameters k is 10.30752509241159 and b is -42.109487566451904\n",
      "Iteration 5263, the loss is 4.442390414217929, parameters k is 10.307524703083526 and b is -42.10948361388273\n",
      "Iteration 5264, the loss is 4.442390398443552, parameters k is 10.307524313755463 and b is -42.10947966131356\n",
      "Iteration 5265, the loss is 4.442390382669173, parameters k is 10.3075239244274 and b is -42.109475708744384\n",
      "Iteration 5266, the loss is 4.442390366894792, parameters k is 10.307523535099337 and b is -42.10947175617521\n",
      "Iteration 5267, the loss is 4.442390351120412, parameters k is 10.307523145771274 and b is -42.10946780360604\n",
      "Iteration 5268, the loss is 4.442390335346035, parameters k is 10.30752275644321 and b is -42.109463851036864\n",
      "Iteration 5269, the loss is 4.442390319571655, parameters k is 10.307522367115148 and b is -42.10945989846769\n",
      "Iteration 5270, the loss is 4.442390303797275, parameters k is 10.307521977787085 and b is -42.10945594589852\n",
      "Iteration 5271, the loss is 4.442390288022895, parameters k is 10.307521588459021 and b is -42.109451993329344\n",
      "Iteration 5272, the loss is 4.442390272248517, parameters k is 10.307521199130958 and b is -42.10944804076017\n",
      "Iteration 5273, the loss is 4.442390256474137, parameters k is 10.307520809802895 and b is -42.109444088191\n",
      "Iteration 5274, the loss is 4.4423902406997575, parameters k is 10.307520420474832 and b is -42.109440135621824\n",
      "Iteration 5275, the loss is 4.442390224925378, parameters k is 10.307520031146769 and b is -42.10943618305265\n",
      "Iteration 5276, the loss is 4.442390209150997, parameters k is 10.307519641818706 and b is -42.10943223048348\n",
      "Iteration 5277, the loss is 4.442390193376619, parameters k is 10.307519252490643 and b is -42.109428277914304\n",
      "Iteration 5278, the loss is 4.442390177602241, parameters k is 10.30751886316258 and b is -42.10942432534513\n",
      "Iteration 5279, the loss is 4.442390161827858, parameters k is 10.307518473834516 and b is -42.10942037277596\n",
      "Iteration 5280, the loss is 4.442390146053482, parameters k is 10.307518084506453 and b is -42.109416420206784\n",
      "Iteration 5281, the loss is 4.442390130279101, parameters k is 10.30751769517839 and b is -42.10941246763761\n",
      "Iteration 5282, the loss is 4.442390114504722, parameters k is 10.307517305850327 and b is -42.10940851506844\n",
      "Iteration 5283, the loss is 4.442390098730346, parameters k is 10.307516916522264 and b is -42.109404562499265\n",
      "Iteration 5284, the loss is 4.442390082955962, parameters k is 10.3075165271942 and b is -42.10940060993009\n",
      "Iteration 5285, the loss is 4.4423900671815835, parameters k is 10.307516137866138 and b is -42.10939665736092\n",
      "Iteration 5286, the loss is 4.442390051407206, parameters k is 10.307515748538075 and b is -42.109392704791745\n",
      "Iteration 5287, the loss is 4.442390035632824, parameters k is 10.307515359210011 and b is -42.10938875222257\n",
      "Iteration 5288, the loss is 4.442390019858444, parameters k is 10.307514969881948 and b is -42.1093847996534\n",
      "Iteration 5289, the loss is 4.442390004084066, parameters k is 10.307514580553885 and b is -42.109380847084225\n",
      "Iteration 5290, the loss is 4.442389988309687, parameters k is 10.307514191225822 and b is -42.10937689451505\n",
      "Iteration 5291, the loss is 4.442389974819325, parameters k is 10.307513801897759 and b is -42.10937294194588\n",
      "Iteration 5292, the loss is 4.4423899616779785, parameters k is 10.30748591454598 and b is -42.10937294194588\n",
      "Iteration 5293, the loss is 4.442389945903599, parameters k is 10.307485525217917 and b is -42.109368989376705\n",
      "Iteration 5294, the loss is 4.442389930129218, parameters k is 10.307485135889854 and b is -42.10936503680753\n",
      "Iteration 5295, the loss is 4.442389914354839, parameters k is 10.30748474656179 and b is -42.10936108423836\n",
      "Iteration 5296, the loss is 4.44238989858046, parameters k is 10.307484357233728 and b is -42.109357131669185\n",
      "Iteration 5297, the loss is 4.442389882806078, parameters k is 10.307483967905664 and b is -42.10935317910001\n",
      "Iteration 5298, the loss is 4.442389867031703, parameters k is 10.307483578577601 and b is -42.10934922653084\n",
      "Iteration 5299, the loss is 4.442389851257323, parameters k is 10.307483189249538 and b is -42.109345273961665\n",
      "Iteration 5300, the loss is 4.442389835482945, parameters k is 10.307482799921475 and b is -42.10934132139249\n",
      "Iteration 5301, the loss is 4.442389819708563, parameters k is 10.307482410593412 and b is -42.10933736882332\n",
      "Iteration 5302, the loss is 4.442389803934186, parameters k is 10.307482021265349 and b is -42.109333416254145\n",
      "Iteration 5303, the loss is 4.442389788159807, parameters k is 10.307481631937286 and b is -42.10932946368497\n",
      "Iteration 5304, the loss is 4.442389772385428, parameters k is 10.307481242609223 and b is -42.1093255111158\n",
      "Iteration 5305, the loss is 4.442389756611046, parameters k is 10.30748085328116 and b is -42.109321558546625\n",
      "Iteration 5306, the loss is 4.442389740836668, parameters k is 10.307480463953096 and b is -42.10931760597745\n",
      "Iteration 5307, the loss is 4.442389725062287, parameters k is 10.307480074625033 and b is -42.10931365340828\n",
      "Iteration 5308, the loss is 4.44238970928791, parameters k is 10.30747968529697 and b is -42.109309700839106\n",
      "Iteration 5309, the loss is 4.442389693513532, parameters k is 10.307479295968907 and b is -42.10930574826993\n",
      "Iteration 5310, the loss is 4.44238967773915, parameters k is 10.307478906640844 and b is -42.10930179570076\n",
      "Iteration 5311, the loss is 4.44238966196477, parameters k is 10.30747851731278 and b is -42.109297843131586\n",
      "Iteration 5312, the loss is 4.442389646190393, parameters k is 10.307478127984718 and b is -42.10929389056241\n",
      "Iteration 5313, the loss is 4.442389630416009, parameters k is 10.307477738656655 and b is -42.10928993799324\n",
      "Iteration 5314, the loss is 4.442389614641632, parameters k is 10.307477349328591 and b is -42.109285985424066\n",
      "Iteration 5315, the loss is 4.442389598867255, parameters k is 10.307476960000528 and b is -42.10928203285489\n",
      "Iteration 5316, the loss is 4.442389583092871, parameters k is 10.307476570672465 and b is -42.10927808028572\n",
      "Iteration 5317, the loss is 4.442389567318495, parameters k is 10.307476181344402 and b is -42.109274127716546\n",
      "Iteration 5318, the loss is 4.442389551544115, parameters k is 10.307475792016339 and b is -42.10927017514737\n",
      "Iteration 5319, the loss is 4.442389535769734, parameters k is 10.307475402688276 and b is -42.1092662225782\n",
      "Iteration 5320, the loss is 4.442389519995356, parameters k is 10.307475013360213 and b is -42.109262270009026\n",
      "Iteration 5321, the loss is 4.442389504220976, parameters k is 10.30747462403215 and b is -42.10925831743985\n",
      "Iteration 5322, the loss is 4.442389488446595, parameters k is 10.307474234704086 and b is -42.10925436487068\n",
      "Iteration 5323, the loss is 4.442389472672217, parameters k is 10.307473845376023 and b is -42.109250412301506\n",
      "Iteration 5324, the loss is 4.442389456897839, parameters k is 10.30747345604796 and b is -42.10924645973233\n",
      "Iteration 5325, the loss is 4.442389441123457, parameters k is 10.307473066719897 and b is -42.10924250716316\n",
      "Iteration 5326, the loss is 4.442389425349076, parameters k is 10.307472677391834 and b is -42.109238554593986\n",
      "Iteration 5327, the loss is 4.442389409574701, parameters k is 10.30747228806377 and b is -42.10923460202481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5328, the loss is 4.44238939380032, parameters k is 10.307471898735708 and b is -42.10923064945564\n",
      "Iteration 5329, the loss is 4.4423893780259425, parameters k is 10.307471509407645 and b is -42.109226696886466\n",
      "Iteration 5330, the loss is 4.442389362251562, parameters k is 10.307471120079581 and b is -42.10922274431729\n",
      "Iteration 5331, the loss is 4.4423893464771815, parameters k is 10.307470730751518 and b is -42.10921879174812\n",
      "Iteration 5332, the loss is 4.4423893307028015, parameters k is 10.307470341423455 and b is -42.10921483917895\n",
      "Iteration 5333, the loss is 4.4423893149284215, parameters k is 10.307469952095392 and b is -42.10921088660977\n",
      "Iteration 5334, the loss is 4.442389299154043, parameters k is 10.307469562767329 and b is -42.1092069340406\n",
      "Iteration 5335, the loss is 4.442389283379666, parameters k is 10.307469173439266 and b is -42.10920298147143\n",
      "Iteration 5336, the loss is 4.442389267605284, parameters k is 10.307468784111203 and b is -42.10919902890225\n",
      "Iteration 5337, the loss is 4.442389251830904, parameters k is 10.30746839478314 and b is -42.10919507633308\n",
      "Iteration 5338, the loss is 4.442389236056527, parameters k is 10.307468005455076 and b is -42.10919112376391\n",
      "Iteration 5339, the loss is 4.442389220282147, parameters k is 10.307467616127013 and b is -42.10918717119473\n",
      "Iteration 5340, the loss is 4.4423892045077675, parameters k is 10.30746722679895 and b is -42.10918321862556\n",
      "Iteration 5341, the loss is 4.4423891887333875, parameters k is 10.307466837470887 and b is -42.10917926605639\n",
      "Iteration 5342, the loss is 4.442389172959009, parameters k is 10.307466448142824 and b is -42.10917531348721\n",
      "Iteration 5343, the loss is 4.442389157184628, parameters k is 10.30746605881476 and b is -42.10917136091804\n",
      "Iteration 5344, the loss is 4.44238914141025, parameters k is 10.307465669486698 and b is -42.10916740834887\n",
      "Iteration 5345, the loss is 4.44238912563587, parameters k is 10.307465280158635 and b is -42.109163455779694\n",
      "Iteration 5346, the loss is 4.442389109861491, parameters k is 10.307464890830571 and b is -42.10915950321052\n",
      "Iteration 5347, the loss is 4.442389094087113, parameters k is 10.307464501502508 and b is -42.10915555064135\n",
      "Iteration 5348, the loss is 4.442389078312732, parameters k is 10.307464112174445 and b is -42.109151598072174\n",
      "Iteration 5349, the loss is 4.4423890625383535, parameters k is 10.307463722846382 and b is -42.109147645503\n",
      "Iteration 5350, the loss is 4.4423890467639735, parameters k is 10.307463333518319 and b is -42.10914369293383\n",
      "Iteration 5351, the loss is 4.442389030989591, parameters k is 10.307462944190256 and b is -42.109139740364654\n",
      "Iteration 5352, the loss is 4.442389015215216, parameters k is 10.307462554862193 and b is -42.10913578779548\n",
      "Iteration 5353, the loss is 4.442388999440836, parameters k is 10.30746216553413 and b is -42.10913183522631\n",
      "Iteration 5354, the loss is 4.442388983666455, parameters k is 10.307461776206067 and b is -42.109127882657134\n",
      "Iteration 5355, the loss is 4.442388967892077, parameters k is 10.307461386878003 and b is -42.10912393008796\n",
      "Iteration 5356, the loss is 4.4423889521177005, parameters k is 10.30746099754994 and b is -42.10911997751879\n",
      "Iteration 5357, the loss is 4.442388936343318, parameters k is 10.307460608221877 and b is -42.109116024949614\n",
      "Iteration 5358, the loss is 4.44238892056894, parameters k is 10.307460218893814 and b is -42.10911207238044\n",
      "Iteration 5359, the loss is 4.442388904794563, parameters k is 10.307459829565751 and b is -42.10910811981127\n",
      "Iteration 5360, the loss is 4.442388889020181, parameters k is 10.307459440237688 and b is -42.109104167242094\n",
      "Iteration 5361, the loss is 4.442388873245799, parameters k is 10.307459050909625 and b is -42.10910021467292\n",
      "Iteration 5362, the loss is 4.442388857471423, parameters k is 10.307458661581562 and b is -42.10909626210375\n",
      "Iteration 5363, the loss is 4.442388841697041, parameters k is 10.307458272253498 and b is -42.109092309534574\n",
      "Iteration 5364, the loss is 4.442388825922661, parameters k is 10.307457882925435 and b is -42.1090883569654\n",
      "Iteration 5365, the loss is 4.442388810148284, parameters k is 10.307457493597372 and b is -42.10908440439623\n",
      "Iteration 5366, the loss is 4.4423887943739055, parameters k is 10.307457104269309 and b is -42.109080451827055\n",
      "Iteration 5367, the loss is 4.4423887785995255, parameters k is 10.307456714941246 and b is -42.10907649925788\n",
      "Iteration 5368, the loss is 4.442388762825146, parameters k is 10.307456325613183 and b is -42.10907254668871\n",
      "Iteration 5369, the loss is 4.442388747050767, parameters k is 10.30745593628512 and b is -42.109068594119535\n",
      "Iteration 5370, the loss is 4.442388731276384, parameters k is 10.307455546957057 and b is -42.10906464155036\n",
      "Iteration 5371, the loss is 4.4423887155020045, parameters k is 10.307455157628993 and b is -42.10906068898119\n",
      "Iteration 5372, the loss is 4.442388699727628, parameters k is 10.30745476830093 and b is -42.109056736412015\n",
      "Iteration 5373, the loss is 4.442388683953248, parameters k is 10.307454378972867 and b is -42.10905278384284\n",
      "Iteration 5374, the loss is 4.442388668178869, parameters k is 10.307453989644804 and b is -42.10904883127367\n",
      "Iteration 5375, the loss is 4.4423886524044915, parameters k is 10.307453600316741 and b is -42.109044878704495\n",
      "Iteration 5376, the loss is 4.442388636630107, parameters k is 10.307453210988678 and b is -42.10904092613532\n",
      "Iteration 5377, the loss is 4.44238862085573, parameters k is 10.307452821660615 and b is -42.10903697356615\n",
      "Iteration 5378, the loss is 4.442388605081352, parameters k is 10.307452432332552 and b is -42.109033020996975\n",
      "Iteration 5379, the loss is 4.4423885893069714, parameters k is 10.307452043004488 and b is -42.1090290684278\n",
      "Iteration 5380, the loss is 4.4423885735325905, parameters k is 10.307451653676425 and b is -42.10902511585863\n",
      "Iteration 5381, the loss is 4.442388557758212, parameters k is 10.307451264348362 and b is -42.109021163289455\n",
      "Iteration 5382, the loss is 4.442388541983832, parameters k is 10.307450875020299 and b is -42.10901721072028\n",
      "Iteration 5383, the loss is 4.442388526209451, parameters k is 10.307450485692236 and b is -42.10901325815111\n",
      "Iteration 5384, the loss is 4.442388510435073, parameters k is 10.307450096364173 and b is -42.109009305581935\n",
      "Iteration 5385, the loss is 4.442388494660697, parameters k is 10.30744970703611 and b is -42.10900535301276\n",
      "Iteration 5386, the loss is 4.4423884788863175, parameters k is 10.307449317708047 and b is -42.10900140044359\n",
      "Iteration 5387, the loss is 4.4423884631119375, parameters k is 10.307448928379983 and b is -42.108997447874415\n",
      "Iteration 5388, the loss is 4.4423884473375574, parameters k is 10.30744853905192 and b is -42.10899349530524\n",
      "Iteration 5389, the loss is 4.4423884315631765, parameters k is 10.307448149723857 and b is -42.10898954273607\n",
      "Iteration 5390, the loss is 4.442388415788796, parameters k is 10.307447760395794 and b is -42.108985590166895\n",
      "Iteration 5391, the loss is 4.442388400014419, parameters k is 10.307447371067731 and b is -42.10898163759772\n",
      "Iteration 5392, the loss is 4.44238838424004, parameters k is 10.307446981739668 and b is -42.10897768502855\n",
      "Iteration 5393, the loss is 4.442388368465659, parameters k is 10.307446592411605 and b is -42.108973732459376\n",
      "Iteration 5394, the loss is 4.442388352691281, parameters k is 10.307446203083542 and b is -42.1089697798902\n",
      "Iteration 5395, the loss is 4.442388336916901, parameters k is 10.307445813755479 and b is -42.10896582732103\n",
      "Iteration 5396, the loss is 4.4423883211425235, parameters k is 10.307445424427415 and b is -42.108961874751856\n",
      "Iteration 5397, the loss is 4.44238830536814, parameters k is 10.307445035099352 and b is -42.10895792218268\n",
      "Iteration 5398, the loss is 4.4423882895937625, parameters k is 10.30744464577129 and b is -42.10895396961351\n",
      "Iteration 5399, the loss is 4.442388273819384, parameters k is 10.307444256443226 and b is -42.108950017044336\n",
      "Iteration 5400, the loss is 4.442388258045004, parameters k is 10.307443867115163 and b is -42.10894606447516\n",
      "Iteration 5401, the loss is 4.442388242270624, parameters k is 10.3074434777871 and b is -42.10894211190599\n",
      "Iteration 5402, the loss is 4.442388226496245, parameters k is 10.307443088459037 and b is -42.108938159336816\n",
      "Iteration 5403, the loss is 4.442388210721867, parameters k is 10.307442699130974 and b is -42.10893420676764\n",
      "Iteration 5404, the loss is 4.442388194947484, parameters k is 10.30744230980291 and b is -42.10893025419847\n",
      "Iteration 5405, the loss is 4.442388179173109, parameters k is 10.307441920474847 and b is -42.108926301629296\n",
      "Iteration 5406, the loss is 4.442388163398727, parameters k is 10.307441531146784 and b is -42.10892234906012\n",
      "Iteration 5407, the loss is 4.4423881476243485, parameters k is 10.307441141818721 and b is -42.10891839649095\n",
      "Iteration 5408, the loss is 4.4423881318499685, parameters k is 10.307440752490658 and b is -42.108914443921776\n",
      "Iteration 5409, the loss is 4.442388116075588, parameters k is 10.307440363162595 and b is -42.1089104913526\n",
      "Iteration 5410, the loss is 4.442388100301209, parameters k is 10.307439973834532 and b is -42.10890653878343\n",
      "Iteration 5411, the loss is 4.44238808452683, parameters k is 10.307439584506469 and b is -42.108902586214256\n",
      "Iteration 5412, the loss is 4.442388068752449, parameters k is 10.307439195178405 and b is -42.10889863364508\n",
      "Iteration 5413, the loss is 4.442388052978072, parameters k is 10.307438805850342 and b is -42.10889468107591\n",
      "Iteration 5414, the loss is 4.442388037203694, parameters k is 10.30743841652228 and b is -42.108890728506736\n",
      "Iteration 5415, the loss is 4.442388021429313, parameters k is 10.307438027194216 and b is -42.10888677593756\n",
      "Iteration 5416, the loss is 4.4423880056549345, parameters k is 10.307437637866153 and b is -42.10888282336839\n",
      "Iteration 5417, the loss is 4.442387989880555, parameters k is 10.30743724853809 and b is -42.10887887079922\n",
      "Iteration 5418, the loss is 4.442387974106175, parameters k is 10.307436859210027 and b is -42.10887491823004\n",
      "Iteration 5419, the loss is 4.442387958331795, parameters k is 10.307436469881964 and b is -42.10887096566087\n",
      "Iteration 5420, the loss is 4.442387942557416, parameters k is 10.3074360805539 and b is -42.1088670130917\n",
      "Iteration 5421, the loss is 4.442387926783038, parameters k is 10.307435691225837 and b is -42.10886306052252\n",
      "Iteration 5422, the loss is 4.442387911008658, parameters k is 10.307435301897774 and b is -42.10885910795335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5423, the loss is 4.442387895234277, parameters k is 10.307434912569711 and b is -42.10885515538418\n",
      "Iteration 5424, the loss is 4.442387879459901, parameters k is 10.307434523241648 and b is -42.108851202815\n",
      "Iteration 5425, the loss is 4.442387863685519, parameters k is 10.307434133913585 and b is -42.10884725024583\n",
      "Iteration 5426, the loss is 4.442387847911139, parameters k is 10.307433744585522 and b is -42.10884329767666\n",
      "Iteration 5427, the loss is 4.442387832136761, parameters k is 10.307433355257459 and b is -42.108839345107484\n",
      "Iteration 5428, the loss is 4.442387816362377, parameters k is 10.307432965929396 and b is -42.10883539253831\n",
      "Iteration 5429, the loss is 4.442387800588002, parameters k is 10.307432576601332 and b is -42.10883143996914\n",
      "Iteration 5430, the loss is 4.442387784813626, parameters k is 10.30743218727327 and b is -42.108827487399964\n",
      "Iteration 5431, the loss is 4.442387769039242, parameters k is 10.307431797945206 and b is -42.10882353483079\n",
      "Iteration 5432, the loss is 4.442387753264863, parameters k is 10.307431408617143 and b is -42.10881958226162\n",
      "Iteration 5433, the loss is 4.442387737490485, parameters k is 10.30743101928908 and b is -42.108815629692444\n",
      "Iteration 5434, the loss is 4.442387721716105, parameters k is 10.307430629961017 and b is -42.10881167712327\n",
      "Iteration 5435, the loss is 4.442387705941725, parameters k is 10.307430240632954 and b is -42.1088077245541\n",
      "Iteration 5436, the loss is 4.442387690167347, parameters k is 10.30742985130489 and b is -42.108803771984924\n",
      "Iteration 5437, the loss is 4.4423876743929664, parameters k is 10.307429461976827 and b is -42.10879981941575\n",
      "Iteration 5438, the loss is 4.442387658618585, parameters k is 10.307429072648764 and b is -42.10879586684658\n",
      "Iteration 5439, the loss is 4.442387642844206, parameters k is 10.307428683320701 and b is -42.108791914277404\n",
      "Iteration 5440, the loss is 4.442387627069828, parameters k is 10.307428293992638 and b is -42.10878796170823\n",
      "Iteration 5441, the loss is 4.442387611295449, parameters k is 10.307427904664575 and b is -42.10878400913906\n",
      "Iteration 5442, the loss is 4.44238759552107, parameters k is 10.307427515336512 and b is -42.108780056569884\n",
      "Iteration 5443, the loss is 4.442387579746692, parameters k is 10.307427126008449 and b is -42.10877610400071\n",
      "Iteration 5444, the loss is 4.442387563972312, parameters k is 10.307426736680386 and b is -42.10877215143154\n",
      "Iteration 5445, the loss is 4.442387548197929, parameters k is 10.307426347352322 and b is -42.108768198862364\n",
      "Iteration 5446, the loss is 4.442387532423551, parameters k is 10.30742595802426 and b is -42.10876424629319\n",
      "Iteration 5447, the loss is 4.442387516649174, parameters k is 10.307425568696196 and b is -42.10876029372402\n",
      "Iteration 5448, the loss is 4.442387503371665, parameters k is 10.307425179368133 and b is -42.108756341154844\n",
      "Iteration 5449, the loss is 4.442387490017461, parameters k is 10.307397292016354 and b is -42.108756341154844\n",
      "Iteration 5450, the loss is 4.442387474243085, parameters k is 10.307396902688291 and b is -42.10875238858567\n",
      "Iteration 5451, the loss is 4.442387458468704, parameters k is 10.307396513360228 and b is -42.1087484360165\n",
      "Iteration 5452, the loss is 4.442387442694323, parameters k is 10.307396124032165 and b is -42.108744483447325\n",
      "Iteration 5453, the loss is 4.4423874269199475, parameters k is 10.307395734704102 and b is -42.10874053087815\n",
      "Iteration 5454, the loss is 4.442387411145567, parameters k is 10.307395345376039 and b is -42.10873657830898\n",
      "Iteration 5455, the loss is 4.442387395371187, parameters k is 10.307394956047975 and b is -42.108732625739805\n",
      "Iteration 5456, the loss is 4.442387379596809, parameters k is 10.307394566719912 and b is -42.10872867317063\n",
      "Iteration 5457, the loss is 4.442387363822428, parameters k is 10.30739417739185 and b is -42.10872472060146\n",
      "Iteration 5458, the loss is 4.442387348048051, parameters k is 10.307393788063786 and b is -42.108720768032285\n",
      "Iteration 5459, the loss is 4.442387332273668, parameters k is 10.307393398735723 and b is -42.10871681546311\n",
      "Iteration 5460, the loss is 4.44238731649929, parameters k is 10.30739300940766 and b is -42.10871286289394\n",
      "Iteration 5461, the loss is 4.442387300724912, parameters k is 10.307392620079597 and b is -42.108708910324765\n",
      "Iteration 5462, the loss is 4.442387284950531, parameters k is 10.307392230751534 and b is -42.10870495775559\n",
      "Iteration 5463, the loss is 4.442387269176151, parameters k is 10.30739184142347 and b is -42.10870100518642\n",
      "Iteration 5464, the loss is 4.442387253401774, parameters k is 10.307391452095407 and b is -42.108697052617245\n",
      "Iteration 5465, the loss is 4.442387237627392, parameters k is 10.307391062767344 and b is -42.10869310004807\n",
      "Iteration 5466, the loss is 4.442387221853015, parameters k is 10.307390673439281 and b is -42.1086891474789\n",
      "Iteration 5467, the loss is 4.442387206078635, parameters k is 10.307390284111218 and b is -42.108685194909725\n",
      "Iteration 5468, the loss is 4.442387190304254, parameters k is 10.307389894783155 and b is -42.10868124234055\n",
      "Iteration 5469, the loss is 4.442387174529877, parameters k is 10.307389505455092 and b is -42.10867728977138\n",
      "Iteration 5470, the loss is 4.442387158755496, parameters k is 10.307389116127029 and b is -42.108673337202205\n",
      "Iteration 5471, the loss is 4.4423871429811195, parameters k is 10.307388726798965 and b is -42.10866938463303\n",
      "Iteration 5472, the loss is 4.442387127206739, parameters k is 10.307388337470902 and b is -42.10866543206386\n",
      "Iteration 5473, the loss is 4.4423871114323585, parameters k is 10.30738794814284 and b is -42.108661479494685\n",
      "Iteration 5474, the loss is 4.4423870956579785, parameters k is 10.307387558814776 and b is -42.10865752692551\n",
      "Iteration 5475, the loss is 4.442387079883601, parameters k is 10.307387169486713 and b is -42.10865357435634\n",
      "Iteration 5476, the loss is 4.442387064109222, parameters k is 10.30738678015865 and b is -42.108649621787166\n",
      "Iteration 5477, the loss is 4.44238704833484, parameters k is 10.307386390830587 and b is -42.10864566921799\n",
      "Iteration 5478, the loss is 4.442387032560463, parameters k is 10.307386001502524 and b is -42.10864171664882\n",
      "Iteration 5479, the loss is 4.442387016786083, parameters k is 10.30738561217446 and b is -42.108637764079646\n",
      "Iteration 5480, the loss is 4.442387001011703, parameters k is 10.307385222846397 and b is -42.10863381151047\n",
      "Iteration 5481, the loss is 4.442386985237321, parameters k is 10.307384833518334 and b is -42.1086298589413\n",
      "Iteration 5482, the loss is 4.442386969462945, parameters k is 10.307384444190271 and b is -42.108625906372126\n",
      "Iteration 5483, the loss is 4.442386953688565, parameters k is 10.307384054862208 and b is -42.10862195380295\n",
      "Iteration 5484, the loss is 4.4423869379141845, parameters k is 10.307383665534145 and b is -42.10861800123378\n",
      "Iteration 5485, the loss is 4.442386922139806, parameters k is 10.307383276206082 and b is -42.108614048664606\n",
      "Iteration 5486, the loss is 4.442386906365428, parameters k is 10.307382886878019 and b is -42.10861009609543\n",
      "Iteration 5487, the loss is 4.442386890591048, parameters k is 10.307382497549956 and b is -42.10860614352626\n",
      "Iteration 5488, the loss is 4.442386874816667, parameters k is 10.307382108221892 and b is -42.108602190957086\n",
      "Iteration 5489, the loss is 4.442386859042289, parameters k is 10.30738171889383 and b is -42.10859823838791\n",
      "Iteration 5490, the loss is 4.442386843267908, parameters k is 10.307381329565766 and b is -42.10859428581874\n",
      "Iteration 5491, the loss is 4.44238682749353, parameters k is 10.307380940237703 and b is -42.108590333249566\n",
      "Iteration 5492, the loss is 4.442386811719153, parameters k is 10.30738055090964 and b is -42.10858638068039\n",
      "Iteration 5493, the loss is 4.442386795944769, parameters k is 10.307380161581577 and b is -42.10858242811122\n",
      "Iteration 5494, the loss is 4.4423867801703905, parameters k is 10.307379772253514 and b is -42.108578475542046\n",
      "Iteration 5495, the loss is 4.442386764396011, parameters k is 10.30737938292545 and b is -42.10857452297287\n",
      "Iteration 5496, the loss is 4.442386748621635, parameters k is 10.307378993597387 and b is -42.1085705704037\n",
      "Iteration 5497, the loss is 4.442386732847253, parameters k is 10.307378604269324 and b is -42.108566617834526\n",
      "Iteration 5498, the loss is 4.442386717072873, parameters k is 10.307378214941261 and b is -42.10856266526535\n",
      "Iteration 5499, the loss is 4.442386701298494, parameters k is 10.307377825613198 and b is -42.10855871269618\n",
      "Iteration 5500, the loss is 4.442386685524117, parameters k is 10.307377436285135 and b is -42.10855476012701\n",
      "Iteration 5501, the loss is 4.4423866697497365, parameters k is 10.307377046957072 and b is -42.10855080755783\n",
      "Iteration 5502, the loss is 4.442386653975355, parameters k is 10.307376657629009 and b is -42.10854685498866\n",
      "Iteration 5503, the loss is 4.442386638200977, parameters k is 10.307376268300946 and b is -42.10854290241949\n",
      "Iteration 5504, the loss is 4.442386622426599, parameters k is 10.307375878972882 and b is -42.10853894985031\n",
      "Iteration 5505, the loss is 4.44238660665222, parameters k is 10.30737548964482 and b is -42.10853499728114\n",
      "Iteration 5506, the loss is 4.442386590877837, parameters k is 10.307375100316756 and b is -42.10853104471197\n",
      "Iteration 5507, the loss is 4.44238657510346, parameters k is 10.307374710988693 and b is -42.10852709214279\n",
      "Iteration 5508, the loss is 4.442386559329078, parameters k is 10.30737432166063 and b is -42.10852313957362\n",
      "Iteration 5509, the loss is 4.442386543554702, parameters k is 10.307373932332567 and b is -42.10851918700445\n",
      "Iteration 5510, the loss is 4.44238652778032, parameters k is 10.307373543004504 and b is -42.108515234435274\n",
      "Iteration 5511, the loss is 4.442386512005943, parameters k is 10.30737315367644 and b is -42.1085112818661\n",
      "Iteration 5512, the loss is 4.44238649623156, parameters k is 10.307372764348377 and b is -42.10850732929693\n",
      "Iteration 5513, the loss is 4.4423864804571815, parameters k is 10.307372375020314 and b is -42.108503376727754\n",
      "Iteration 5514, the loss is 4.442386464682805, parameters k is 10.307371985692251 and b is -42.10849942415858\n",
      "Iteration 5515, the loss is 4.442386448908424, parameters k is 10.307371596364188 and b is -42.10849547158941\n",
      "Iteration 5516, the loss is 4.442386433134045, parameters k is 10.307371207036125 and b is -42.108491519020234\n",
      "Iteration 5517, the loss is 4.442386417359664, parameters k is 10.307370817708062 and b is -42.10848756645106\n",
      "Iteration 5518, the loss is 4.442386401585287, parameters k is 10.307370428379999 and b is -42.10848361388189\n",
      "Iteration 5519, the loss is 4.442386385810905, parameters k is 10.307370039051936 and b is -42.108479661312714\n",
      "Iteration 5520, the loss is 4.442386370036526, parameters k is 10.307369649723872 and b is -42.10847570874354\n",
      "Iteration 5521, the loss is 4.442386354262149, parameters k is 10.30736926039581 and b is -42.10847175617437\n",
      "Iteration 5522, the loss is 4.442386338487768, parameters k is 10.307368871067746 and b is -42.108467803605194\n",
      "Iteration 5523, the loss is 4.442386322713387, parameters k is 10.307368481739683 and b is -42.10846385103602\n",
      "Iteration 5524, the loss is 4.442386306939008, parameters k is 10.30736809241162 and b is -42.10845989846685\n",
      "Iteration 5525, the loss is 4.442386291164629, parameters k is 10.307367703083557 and b is -42.108455945897674\n",
      "Iteration 5526, the loss is 4.44238627539025, parameters k is 10.307367313755494 and b is -42.1084519933285\n",
      "Iteration 5527, the loss is 4.442386259615871, parameters k is 10.30736692442743 and b is -42.10844804075933\n",
      "Iteration 5528, the loss is 4.442386243841492, parameters k is 10.307366535099368 and b is -42.108444088190154\n",
      "Iteration 5529, the loss is 4.442386228067114, parameters k is 10.307366145771304 and b is -42.10844013562098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5530, the loss is 4.442386212292732, parameters k is 10.307365756443241 and b is -42.10843618305181\n",
      "Iteration 5531, the loss is 4.442386196518354, parameters k is 10.307365367115178 and b is -42.108432230482634\n",
      "Iteration 5532, the loss is 4.442386180743974, parameters k is 10.307364977787115 and b is -42.10842827791346\n",
      "Iteration 5533, the loss is 4.442386164969594, parameters k is 10.307364588459052 and b is -42.10842432534429\n",
      "Iteration 5534, the loss is 4.442386149195215, parameters k is 10.307364199130989 and b is -42.108420372775115\n",
      "Iteration 5535, the loss is 4.442386133420837, parameters k is 10.307363809802926 and b is -42.10841642020594\n",
      "Iteration 5536, the loss is 4.442386117646457, parameters k is 10.307363420474863 and b is -42.10841246763677\n",
      "Iteration 5537, the loss is 4.442386101872078, parameters k is 10.3073630311468 and b is -42.108408515067595\n",
      "Iteration 5538, the loss is 4.442386086097698, parameters k is 10.307362641818736 and b is -42.10840456249842\n",
      "Iteration 5539, the loss is 4.44238607032332, parameters k is 10.307362252490673 and b is -42.10840060992925\n",
      "Iteration 5540, the loss is 4.442386054548939, parameters k is 10.30736186316261 and b is -42.108396657360075\n",
      "Iteration 5541, the loss is 4.44238603877456, parameters k is 10.307361473834547 and b is -42.1083927047909\n",
      "Iteration 5542, the loss is 4.442386023000179, parameters k is 10.307361084506484 and b is -42.10838875222173\n",
      "Iteration 5543, the loss is 4.442386007225801, parameters k is 10.30736069517842 and b is -42.108384799652555\n",
      "Iteration 5544, the loss is 4.442385991451423, parameters k is 10.307360305850358 and b is -42.10838084708338\n",
      "Iteration 5545, the loss is 4.44238597567704, parameters k is 10.307359916522294 and b is -42.10837689451421\n",
      "Iteration 5546, the loss is 4.442385959902664, parameters k is 10.307359527194231 and b is -42.108372941945035\n",
      "Iteration 5547, the loss is 4.442385944128284, parameters k is 10.307359137866168 and b is -42.10836898937586\n",
      "Iteration 5548, the loss is 4.442385928353903, parameters k is 10.307358748538105 and b is -42.10836503680669\n",
      "Iteration 5549, the loss is 4.4423859125795255, parameters k is 10.307358359210042 and b is -42.108361084237515\n",
      "Iteration 5550, the loss is 4.442385896805147, parameters k is 10.307357969881979 and b is -42.10835713166834\n",
      "Iteration 5551, the loss is 4.442385881030766, parameters k is 10.307357580553916 and b is -42.10835317909917\n",
      "Iteration 5552, the loss is 4.4423858652563855, parameters k is 10.307357191225853 and b is -42.108349226529995\n",
      "Iteration 5553, the loss is 4.442385849482006, parameters k is 10.30735680189779 and b is -42.10834527396082\n",
      "Iteration 5554, the loss is 4.442385833707628, parameters k is 10.307356412569726 and b is -42.10834132139165\n",
      "Iteration 5555, the loss is 4.442385817933249, parameters k is 10.307356023241663 and b is -42.108337368822475\n",
      "Iteration 5556, the loss is 4.442385802158867, parameters k is 10.3073556339136 and b is -42.1083334162533\n",
      "Iteration 5557, the loss is 4.442385786384491, parameters k is 10.307355244585537 and b is -42.10832946368413\n",
      "Iteration 5558, the loss is 4.442385770610109, parameters k is 10.307354855257474 and b is -42.108325511114955\n",
      "Iteration 5559, the loss is 4.442385754835728, parameters k is 10.30735446592941 and b is -42.10832155854578\n",
      "Iteration 5560, the loss is 4.442385739061353, parameters k is 10.307354076601348 and b is -42.10831760597661\n",
      "Iteration 5561, the loss is 4.442385723286969, parameters k is 10.307353687273284 and b is -42.108313653407436\n",
      "Iteration 5562, the loss is 4.442385707512594, parameters k is 10.307353297945221 and b is -42.10830970083826\n",
      "Iteration 5563, the loss is 4.4423856917382105, parameters k is 10.307352908617158 and b is -42.10830574826909\n",
      "Iteration 5564, the loss is 4.442385675963835, parameters k is 10.307352519289095 and b is -42.108301795699916\n",
      "Iteration 5565, the loss is 4.442385660189453, parameters k is 10.307352129961032 and b is -42.10829784313074\n",
      "Iteration 5566, the loss is 4.442385644415073, parameters k is 10.307351740632969 and b is -42.10829389056157\n",
      "Iteration 5567, the loss is 4.442385628640694, parameters k is 10.307351351304906 and b is -42.108289937992396\n",
      "Iteration 5568, the loss is 4.442385612866314, parameters k is 10.307350961976843 and b is -42.10828598542322\n",
      "Iteration 5569, the loss is 4.4423855970919375, parameters k is 10.30735057264878 and b is -42.10828203285405\n",
      "Iteration 5570, the loss is 4.4423855813175575, parameters k is 10.307350183320716 and b is -42.108278080284876\n",
      "Iteration 5571, the loss is 4.442385565543178, parameters k is 10.307349793992653 and b is -42.1082741277157\n",
      "Iteration 5572, the loss is 4.442385549768797, parameters k is 10.30734940466459 and b is -42.10827017514653\n",
      "Iteration 5573, the loss is 4.442385533994418, parameters k is 10.307349015336527 and b is -42.108266222577356\n",
      "Iteration 5574, the loss is 4.442385518220037, parameters k is 10.307348626008464 and b is -42.10826227000818\n",
      "Iteration 5575, the loss is 4.442385502445658, parameters k is 10.3073482366804 and b is -42.10825831743901\n",
      "Iteration 5576, the loss is 4.44238548667128, parameters k is 10.307347847352338 and b is -42.108254364869836\n",
      "Iteration 5577, the loss is 4.442385470896903, parameters k is 10.307347458024275 and b is -42.10825041230066\n",
      "Iteration 5578, the loss is 4.442385455122521, parameters k is 10.307347068696211 and b is -42.10824645973149\n",
      "Iteration 5579, the loss is 4.442385439348143, parameters k is 10.307346679368148 and b is -42.108242507162316\n",
      "Iteration 5580, the loss is 4.4423854235737625, parameters k is 10.307346290040085 and b is -42.10823855459314\n",
      "Iteration 5581, the loss is 4.442385407799383, parameters k is 10.307345900712022 and b is -42.10823460202397\n",
      "Iteration 5582, the loss is 4.442385392025005, parameters k is 10.307345511383959 and b is -42.108230649454796\n",
      "Iteration 5583, the loss is 4.442385376250626, parameters k is 10.307345122055896 and b is -42.10822669688562\n",
      "Iteration 5584, the loss is 4.442385360476247, parameters k is 10.307344732727833 and b is -42.10822274431645\n",
      "Iteration 5585, the loss is 4.442385344701868, parameters k is 10.30734434339977 and b is -42.10821879174728\n",
      "Iteration 5586, the loss is 4.442385328927485, parameters k is 10.307343954071706 and b is -42.1082148391781\n",
      "Iteration 5587, the loss is 4.442385313153107, parameters k is 10.307343564743643 and b is -42.10821088660893\n",
      "Iteration 5588, the loss is 4.442385297378728, parameters k is 10.30734317541558 and b is -42.10820693403976\n",
      "Iteration 5589, the loss is 4.442385281604349, parameters k is 10.307342786087517 and b is -42.10820298147058\n",
      "Iteration 5590, the loss is 4.442385265829969, parameters k is 10.307342396759454 and b is -42.10819902890141\n",
      "Iteration 5591, the loss is 4.442385250055589, parameters k is 10.30734200743139 and b is -42.10819507633224\n",
      "Iteration 5592, the loss is 4.44238523428121, parameters k is 10.307341618103328 and b is -42.10819112376306\n",
      "Iteration 5593, the loss is 4.442385218506832, parameters k is 10.307341228775265 and b is -42.10818717119389\n",
      "Iteration 5594, the loss is 4.442385202732449, parameters k is 10.307340839447201 and b is -42.10818321862472\n",
      "Iteration 5595, the loss is 4.442385186958072, parameters k is 10.307340450119138 and b is -42.108179266055544\n",
      "Iteration 5596, the loss is 4.442385171183691, parameters k is 10.307340060791075 and b is -42.10817531348637\n",
      "Iteration 5597, the loss is 4.442385155409314, parameters k is 10.307339671463012 and b is -42.1081713609172\n",
      "Iteration 5598, the loss is 4.442385139634934, parameters k is 10.307339282134949 and b is -42.108167408348024\n",
      "Iteration 5599, the loss is 4.442385123860555, parameters k is 10.307338892806886 and b is -42.10816345577885\n",
      "Iteration 5600, the loss is 4.4423851080861745, parameters k is 10.307338503478823 and b is -42.10815950320968\n",
      "Iteration 5601, the loss is 4.442385092311796, parameters k is 10.30733811415076 and b is -42.108155550640504\n",
      "Iteration 5602, the loss is 4.442385076537417, parameters k is 10.307337724822697 and b is -42.10815159807133\n",
      "Iteration 5603, the loss is 4.442385060763039, parameters k is 10.307337335494633 and b is -42.10814764550216\n",
      "Iteration 5604, the loss is 4.44238504498866, parameters k is 10.30733694616657 and b is -42.108143692932984\n",
      "Iteration 5605, the loss is 4.442385031924008, parameters k is 10.307336556838507 and b is -42.10813974036381\n",
      "Iteration 5606, the loss is 4.4423850183569495, parameters k is 10.307308669486728 and b is -42.10813974036381\n",
      "Iteration 5607, the loss is 4.442385002582568, parameters k is 10.307308280158665 and b is -42.10813578779464\n",
      "Iteration 5608, the loss is 4.442384986808192, parameters k is 10.307307890830602 and b is -42.108131835225464\n",
      "Iteration 5609, the loss is 4.442384971033813, parameters k is 10.307307501502539 and b is -42.10812788265629\n",
      "Iteration 5610, the loss is 4.442384955259434, parameters k is 10.307307112174476 and b is -42.10812393008712\n",
      "Iteration 5611, the loss is 4.442384939485054, parameters k is 10.307306722846413 and b is -42.108119977517944\n",
      "Iteration 5612, the loss is 4.442384923710675, parameters k is 10.30730633351835 and b is -42.10811602494877\n",
      "Iteration 5613, the loss is 4.442384907936295, parameters k is 10.307305944190286 and b is -42.1081120723796\n",
      "Iteration 5614, the loss is 4.442384892161915, parameters k is 10.307305554862223 and b is -42.108108119810424\n",
      "Iteration 5615, the loss is 4.442384876387535, parameters k is 10.30730516553416 and b is -42.10810416724125\n",
      "Iteration 5616, the loss is 4.442384860613157, parameters k is 10.307304776206097 and b is -42.10810021467208\n",
      "Iteration 5617, the loss is 4.442384844838776, parameters k is 10.307304386878034 and b is -42.108096262102904\n",
      "Iteration 5618, the loss is 4.442384829064396, parameters k is 10.30730399754997 and b is -42.10809230953373\n",
      "Iteration 5619, the loss is 4.442384813290019, parameters k is 10.307303608221908 and b is -42.10808835696456\n",
      "Iteration 5620, the loss is 4.442384797515637, parameters k is 10.307303218893844 and b is -42.108084404395385\n",
      "Iteration 5621, the loss is 4.442384781741259, parameters k is 10.307302829565781 and b is -42.10808045182621\n",
      "Iteration 5622, the loss is 4.442384765966882, parameters k is 10.307302440237718 and b is -42.10807649925704\n",
      "Iteration 5623, the loss is 4.4423847501925, parameters k is 10.307302050909655 and b is -42.108072546687865\n",
      "Iteration 5624, the loss is 4.4423847344181215, parameters k is 10.307301661581592 and b is -42.10806859411869\n",
      "Iteration 5625, the loss is 4.442384718643742, parameters k is 10.307301272253529 and b is -42.10806464154952\n",
      "Iteration 5626, the loss is 4.44238470286936, parameters k is 10.307300882925466 and b is -42.108060688980345\n",
      "Iteration 5627, the loss is 4.442384687094984, parameters k is 10.307300493597403 and b is -42.10805673641117\n",
      "Iteration 5628, the loss is 4.442384671320604, parameters k is 10.30730010426934 and b is -42.108052783842\n",
      "Iteration 5629, the loss is 4.442384655546221, parameters k is 10.307299714941276 and b is -42.108048831272825\n",
      "Iteration 5630, the loss is 4.442384639771845, parameters k is 10.307299325613213 and b is -42.10804487870365\n",
      "Iteration 5631, the loss is 4.442384623997466, parameters k is 10.30729893628515 and b is -42.10804092613448\n",
      "Iteration 5632, the loss is 4.442384608223086, parameters k is 10.307298546957087 and b is -42.108036973565305\n",
      "Iteration 5633, the loss is 4.442384592448705, parameters k is 10.307298157629024 and b is -42.10803302099613\n",
      "Iteration 5634, the loss is 4.442384576674325, parameters k is 10.30729776830096 and b is -42.10802906842696\n",
      "Iteration 5635, the loss is 4.442384560899947, parameters k is 10.307297378972898 and b is -42.108025115857785\n",
      "Iteration 5636, the loss is 4.442384545125566, parameters k is 10.307296989644835 and b is -42.10802116328861\n",
      "Iteration 5637, the loss is 4.442384529351186, parameters k is 10.307296600316771 and b is -42.10801721071944\n",
      "Iteration 5638, the loss is 4.442384513576808, parameters k is 10.307296210988708 and b is -42.108013258150265\n",
      "Iteration 5639, the loss is 4.442384497802427, parameters k is 10.307295821660645 and b is -42.10800930558109\n",
      "Iteration 5640, the loss is 4.44238448202805, parameters k is 10.307295432332582 and b is -42.10800535301192\n",
      "Iteration 5641, the loss is 4.44238446625367, parameters k is 10.307295043004519 and b is -42.108001400442745\n",
      "Iteration 5642, the loss is 4.442384450479291, parameters k is 10.307294653676456 and b is -42.10799744787357\n",
      "Iteration 5643, the loss is 4.442384434704909, parameters k is 10.307294264348393 and b is -42.1079934953044\n",
      "Iteration 5644, the loss is 4.442384418930536, parameters k is 10.30729387502033 and b is -42.107989542735226\n",
      "Iteration 5645, the loss is 4.442384403156153, parameters k is 10.307293485692266 and b is -42.10798559016605\n",
      "Iteration 5646, the loss is 4.442384387381772, parameters k is 10.307293096364203 and b is -42.10798163759688\n",
      "Iteration 5647, the loss is 4.442384371607394, parameters k is 10.30729270703614 and b is -42.107977685027706\n",
      "Iteration 5648, the loss is 4.442384355833016, parameters k is 10.307292317708077 and b is -42.10797373245853\n",
      "Iteration 5649, the loss is 4.442384340058635, parameters k is 10.307291928380014 and b is -42.10796977988936\n",
      "Iteration 5650, the loss is 4.442384324284257, parameters k is 10.30729153905195 and b is -42.107965827320186\n",
      "Iteration 5651, the loss is 4.442384308509879, parameters k is 10.307291149723888 and b is -42.10796187475101\n",
      "Iteration 5652, the loss is 4.442384292735499, parameters k is 10.307290760395825 and b is -42.10795792218184\n",
      "Iteration 5653, the loss is 4.442384276961118, parameters k is 10.307290371067761 and b is -42.107953969612666\n",
      "Iteration 5654, the loss is 4.442384261186737, parameters k is 10.307289981739698 and b is -42.10795001704349\n",
      "Iteration 5655, the loss is 4.442384245412358, parameters k is 10.307289592411635 and b is -42.10794606447432\n",
      "Iteration 5656, the loss is 4.44238422963798, parameters k is 10.307289203083572 and b is -42.107942111905146\n",
      "Iteration 5657, the loss is 4.4423842138636, parameters k is 10.307288813755509 and b is -42.10793815933597\n",
      "Iteration 5658, the loss is 4.44238419808922, parameters k is 10.307288424427446 and b is -42.1079342067668\n",
      "Iteration 5659, the loss is 4.442384182314842, parameters k is 10.307288035099383 and b is -42.107930254197626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5660, the loss is 4.442384166540463, parameters k is 10.30728764577132 and b is -42.10792630162845\n",
      "Iteration 5661, the loss is 4.442384150766082, parameters k is 10.307287256443256 and b is -42.10792234905928\n",
      "Iteration 5662, the loss is 4.442384134991704, parameters k is 10.307286867115193 and b is -42.107918396490106\n",
      "Iteration 5663, the loss is 4.442384119217324, parameters k is 10.30728647778713 and b is -42.10791444392093\n",
      "Iteration 5664, the loss is 4.4423841034429445, parameters k is 10.307286088459067 and b is -42.10791049135176\n",
      "Iteration 5665, the loss is 4.442384087668568, parameters k is 10.307285699131004 and b is -42.107906538782586\n",
      "Iteration 5666, the loss is 4.442384071894188, parameters k is 10.30728530980294 and b is -42.10790258621341\n",
      "Iteration 5667, the loss is 4.442384056119805, parameters k is 10.307284920474878 and b is -42.10789863364424\n",
      "Iteration 5668, the loss is 4.442384040345428, parameters k is 10.307284531146815 and b is -42.10789468107507\n",
      "Iteration 5669, the loss is 4.442384024571049, parameters k is 10.307284141818752 and b is -42.10789072850589\n",
      "Iteration 5670, the loss is 4.442384008796669, parameters k is 10.307283752490688 and b is -42.10788677593672\n",
      "Iteration 5671, the loss is 4.442383993022288, parameters k is 10.307283363162625 and b is -42.10788282336755\n",
      "Iteration 5672, the loss is 4.442383977247909, parameters k is 10.307282973834562 and b is -42.10787887079837\n",
      "Iteration 5673, the loss is 4.442383961473529, parameters k is 10.307282584506499 and b is -42.1078749182292\n",
      "Iteration 5674, the loss is 4.4423839456991505, parameters k is 10.307282195178436 and b is -42.10787096566003\n",
      "Iteration 5675, the loss is 4.44238392992477, parameters k is 10.307281805850373 and b is -42.10786701309085\n",
      "Iteration 5676, the loss is 4.442383914150392, parameters k is 10.30728141652231 and b is -42.10786306052168\n",
      "Iteration 5677, the loss is 4.442383898376015, parameters k is 10.307281027194247 and b is -42.10785910795251\n",
      "Iteration 5678, the loss is 4.442383882601634, parameters k is 10.307280637866183 and b is -42.107855155383334\n",
      "Iteration 5679, the loss is 4.442383866827252, parameters k is 10.30728024853812 and b is -42.10785120281416\n",
      "Iteration 5680, the loss is 4.442383851052874, parameters k is 10.307279859210057 and b is -42.10784725024499\n",
      "Iteration 5681, the loss is 4.442383835278495, parameters k is 10.307279469881994 and b is -42.107843297675814\n",
      "Iteration 5682, the loss is 4.442383819504114, parameters k is 10.307279080553931 and b is -42.10783934510664\n",
      "Iteration 5683, the loss is 4.442383803729734, parameters k is 10.307278691225868 and b is -42.10783539253747\n",
      "Iteration 5684, the loss is 4.442383787955357, parameters k is 10.307278301897805 and b is -42.107831439968294\n",
      "Iteration 5685, the loss is 4.442383772180976, parameters k is 10.307277912569742 and b is -42.10782748739912\n",
      "Iteration 5686, the loss is 4.442383756406598, parameters k is 10.307277523241678 and b is -42.10782353482995\n",
      "Iteration 5687, the loss is 4.442383740632218, parameters k is 10.307277133913615 and b is -42.107819582260774\n",
      "Iteration 5688, the loss is 4.442383724857836, parameters k is 10.307276744585552 and b is -42.1078156296916\n",
      "Iteration 5689, the loss is 4.442383709083457, parameters k is 10.307276355257489 and b is -42.10781167712243\n",
      "Iteration 5690, the loss is 4.442383693309083, parameters k is 10.307275965929426 and b is -42.107807724553254\n",
      "Iteration 5691, the loss is 4.4423836775347025, parameters k is 10.307275576601363 and b is -42.10780377198408\n",
      "Iteration 5692, the loss is 4.442383661760322, parameters k is 10.3072751872733 and b is -42.10779981941491\n",
      "Iteration 5693, the loss is 4.44238364598594, parameters k is 10.307274797945237 and b is -42.107795866845734\n",
      "Iteration 5694, the loss is 4.442383630211561, parameters k is 10.307274408617173 and b is -42.10779191427656\n",
      "Iteration 5695, the loss is 4.442383614437185, parameters k is 10.30727401928911 and b is -42.10778796170739\n",
      "Iteration 5696, the loss is 4.442383598662804, parameters k is 10.307273629961047 and b is -42.107784009138214\n",
      "Iteration 5697, the loss is 4.442383582888425, parameters k is 10.307273240632984 and b is -42.10778005656904\n",
      "Iteration 5698, the loss is 4.442383567114043, parameters k is 10.307272851304921 and b is -42.10777610399987\n",
      "Iteration 5699, the loss is 4.442383551339667, parameters k is 10.307272461976858 and b is -42.107772151430694\n",
      "Iteration 5700, the loss is 4.442383535565286, parameters k is 10.307272072648795 and b is -42.10776819886152\n",
      "Iteration 5701, the loss is 4.442383519790908, parameters k is 10.307271683320732 and b is -42.10776424629235\n",
      "Iteration 5702, the loss is 4.442383504016528, parameters k is 10.307271293992669 and b is -42.107760293723175\n",
      "Iteration 5703, the loss is 4.442383488242149, parameters k is 10.307270904664605 and b is -42.107756341154\n",
      "Iteration 5704, the loss is 4.442383472467769, parameters k is 10.307270515336542 and b is -42.10775238858483\n",
      "Iteration 5705, the loss is 4.442383456693389, parameters k is 10.30727012600848 and b is -42.107748436015655\n",
      "Iteration 5706, the loss is 4.442383440919009, parameters k is 10.307269736680416 and b is -42.10774448344648\n",
      "Iteration 5707, the loss is 4.442383425144631, parameters k is 10.307269347352353 and b is -42.10774053087731\n",
      "Iteration 5708, the loss is 4.44238340937025, parameters k is 10.30726895802429 and b is -42.107736578308135\n",
      "Iteration 5709, the loss is 4.442383393595871, parameters k is 10.307268568696227 and b is -42.10773262573896\n",
      "Iteration 5710, the loss is 4.442383377821493, parameters k is 10.307268179368164 and b is -42.10772867316979\n",
      "Iteration 5711, the loss is 4.442383362047113, parameters k is 10.3072677900401 and b is -42.107724720600615\n",
      "Iteration 5712, the loss is 4.4423833462727345, parameters k is 10.307267400712037 and b is -42.10772076803144\n",
      "Iteration 5713, the loss is 4.442383330498356, parameters k is 10.307267011383974 and b is -42.10771681546227\n",
      "Iteration 5714, the loss is 4.4423833147239735, parameters k is 10.307266622055911 and b is -42.107712862893095\n",
      "Iteration 5715, the loss is 4.4423832989495935, parameters k is 10.307266232727848 and b is -42.10770891032392\n",
      "Iteration 5716, the loss is 4.442383283175214, parameters k is 10.307265843399785 and b is -42.10770495775475\n",
      "Iteration 5717, the loss is 4.442383267400837, parameters k is 10.307265454071722 and b is -42.107701005185575\n",
      "Iteration 5718, the loss is 4.442383251626458, parameters k is 10.307265064743659 and b is -42.1076970526164\n",
      "Iteration 5719, the loss is 4.442383235852079, parameters k is 10.307264675415595 and b is -42.10769310004723\n",
      "Iteration 5720, the loss is 4.442383220077699, parameters k is 10.307264286087532 and b is -42.107689147478055\n",
      "Iteration 5721, the loss is 4.442383204303319, parameters k is 10.30726389675947 and b is -42.10768519490888\n",
      "Iteration 5722, the loss is 4.4423831885289395, parameters k is 10.307263507431406 and b is -42.10768124233971\n",
      "Iteration 5723, the loss is 4.44238317275456, parameters k is 10.307263118103343 and b is -42.107677289770535\n",
      "Iteration 5724, the loss is 4.442383156980183, parameters k is 10.30726272877528 and b is -42.10767333720136\n",
      "Iteration 5725, the loss is 4.4423831412058, parameters k is 10.307262339447217 and b is -42.10766938463219\n",
      "Iteration 5726, the loss is 4.44238312543142, parameters k is 10.307261950119154 and b is -42.107665432063015\n",
      "Iteration 5727, the loss is 4.442383109657042, parameters k is 10.30726156079109 and b is -42.10766147949384\n",
      "Iteration 5728, the loss is 4.442383093882661, parameters k is 10.307261171463027 and b is -42.10765752692467\n",
      "Iteration 5729, the loss is 4.4423830781082865, parameters k is 10.307260782134964 and b is -42.107653574355496\n",
      "Iteration 5730, the loss is 4.442383062333906, parameters k is 10.307260392806901 and b is -42.10764962178632\n",
      "Iteration 5731, the loss is 4.442383046559524, parameters k is 10.307260003478838 and b is -42.10764566921715\n",
      "Iteration 5732, the loss is 4.442383030785147, parameters k is 10.307259614150775 and b is -42.107641716647976\n",
      "Iteration 5733, the loss is 4.442383015010766, parameters k is 10.307259224822712 and b is -42.1076377640788\n",
      "Iteration 5734, the loss is 4.442382999236386, parameters k is 10.307258835494649 and b is -42.10763381150963\n",
      "Iteration 5735, the loss is 4.442382983462007, parameters k is 10.307258446166585 and b is -42.107629858940456\n",
      "Iteration 5736, the loss is 4.442382967687629, parameters k is 10.307258056838522 and b is -42.10762590637128\n",
      "Iteration 5737, the loss is 4.442382951913247, parameters k is 10.30725766751046 and b is -42.10762195380211\n",
      "Iteration 5738, the loss is 4.442382936138871, parameters k is 10.307257278182396 and b is -42.107618001232936\n",
      "Iteration 5739, the loss is 4.44238292036449, parameters k is 10.307256888854333 and b is -42.10761404866376\n",
      "Iteration 5740, the loss is 4.44238290459011, parameters k is 10.30725649952627 and b is -42.10761009609459\n",
      "Iteration 5741, the loss is 4.442382888815731, parameters k is 10.307256110198207 and b is -42.107606143525416\n",
      "Iteration 5742, the loss is 4.44238287304135, parameters k is 10.307255720870144 and b is -42.10760219095624\n",
      "Iteration 5743, the loss is 4.442382857266973, parameters k is 10.30725533154208 and b is -42.10759823838707\n",
      "Iteration 5744, the loss is 4.4423828414925906, parameters k is 10.307254942214017 and b is -42.107594285817896\n",
      "Iteration 5745, the loss is 4.4423828257182105, parameters k is 10.307254552885954 and b is -42.10759033324872\n",
      "Iteration 5746, the loss is 4.442382809943836, parameters k is 10.307254163557891 and b is -42.10758638067955\n",
      "Iteration 5747, the loss is 4.442382794169457, parameters k is 10.307253774229828 and b is -42.107582428110376\n",
      "Iteration 5748, the loss is 4.442382778395074, parameters k is 10.307253384901765 and b is -42.1075784755412\n",
      "Iteration 5749, the loss is 4.442382762620697, parameters k is 10.307252995573702 and b is -42.10757452297203\n",
      "Iteration 5750, the loss is 4.442382746846317, parameters k is 10.307252606245639 and b is -42.107570570402856\n",
      "Iteration 5751, the loss is 4.442382731071938, parameters k is 10.307252216917576 and b is -42.10756661783368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5752, the loss is 4.4423827152975575, parameters k is 10.307251827589512 and b is -42.10756266526451\n",
      "Iteration 5753, the loss is 4.442382699523175, parameters k is 10.30725143826145 and b is -42.10755871269534\n",
      "Iteration 5754, the loss is 4.442382683748797, parameters k is 10.307251048933386 and b is -42.10755476012616\n",
      "Iteration 5755, the loss is 4.442382667974419, parameters k is 10.307250659605323 and b is -42.10755080755699\n",
      "Iteration 5756, the loss is 4.44238265220004, parameters k is 10.30725027027726 and b is -42.10754685498782\n",
      "Iteration 5757, the loss is 4.44238263642566, parameters k is 10.307249880949197 and b is -42.10754290241864\n",
      "Iteration 5758, the loss is 4.442382620651281, parameters k is 10.307249491621134 and b is -42.10753894984947\n",
      "Iteration 5759, the loss is 4.442382604876903, parameters k is 10.30724910229307 and b is -42.1075349972803\n",
      "Iteration 5760, the loss is 4.442382589102523, parameters k is 10.307248712965007 and b is -42.10753104471112\n",
      "Iteration 5761, the loss is 4.442382573328143, parameters k is 10.307248323636944 and b is -42.10752709214195\n",
      "Iteration 5762, the loss is 4.442382560476348, parameters k is 10.307247934308881 and b is -42.10752313957278\n",
      "Iteration 5763, the loss is 4.442382546696437, parameters k is 10.307220046957102 and b is -42.10752313957278\n",
      "Iteration 5764, the loss is 4.442382530922053, parameters k is 10.30721965762904 and b is -42.107519187003604\n",
      "Iteration 5765, the loss is 4.442382515147677, parameters k is 10.307219268300976 and b is -42.10751523443443\n",
      "Iteration 5766, the loss is 4.4423824993732985, parameters k is 10.307218878972913 and b is -42.10751128186526\n",
      "Iteration 5767, the loss is 4.442382483598918, parameters k is 10.30721848964485 and b is -42.107507329296084\n",
      "Iteration 5768, the loss is 4.44238246782454, parameters k is 10.307218100316787 and b is -42.10750337672691\n",
      "Iteration 5769, the loss is 4.44238245205016, parameters k is 10.307217710988724 and b is -42.10749942415774\n",
      "Iteration 5770, the loss is 4.44238243627578, parameters k is 10.30721732166066 and b is -42.107495471588564\n",
      "Iteration 5771, the loss is 4.442382420501401, parameters k is 10.307216932332597 and b is -42.10749151901939\n",
      "Iteration 5772, the loss is 4.442382404727018, parameters k is 10.307216543004534 and b is -42.10748756645022\n",
      "Iteration 5773, the loss is 4.442382388952642, parameters k is 10.307216153676471 and b is -42.107483613881044\n",
      "Iteration 5774, the loss is 4.442382373178261, parameters k is 10.307215764348408 and b is -42.10747966131187\n",
      "Iteration 5775, the loss is 4.442382357403881, parameters k is 10.307215375020345 and b is -42.1074757087427\n",
      "Iteration 5776, the loss is 4.442382341629503, parameters k is 10.307214985692282 and b is -42.107471756173524\n",
      "Iteration 5777, the loss is 4.442382325855126, parameters k is 10.307214596364219 and b is -42.10746780360435\n",
      "Iteration 5778, the loss is 4.4423823100807445, parameters k is 10.307214207036155 and b is -42.10746385103518\n",
      "Iteration 5779, the loss is 4.442382294306366, parameters k is 10.307213817708092 and b is -42.107459898466004\n",
      "Iteration 5780, the loss is 4.442382278531987, parameters k is 10.30721342838003 and b is -42.10745594589683\n",
      "Iteration 5781, the loss is 4.442382262757604, parameters k is 10.307213039051966 and b is -42.10745199332766\n",
      "Iteration 5782, the loss is 4.442382246983226, parameters k is 10.307212649723903 and b is -42.107448040758484\n",
      "Iteration 5783, the loss is 4.442382231208848, parameters k is 10.30721226039584 and b is -42.10744408818931\n",
      "Iteration 5784, the loss is 4.442382215434465, parameters k is 10.307211871067777 and b is -42.10744013562014\n",
      "Iteration 5785, the loss is 4.44238219966009, parameters k is 10.307211481739714 and b is -42.107436183050964\n",
      "Iteration 5786, the loss is 4.442382183885709, parameters k is 10.30721109241165 and b is -42.10743223048179\n",
      "Iteration 5787, the loss is 4.442382168111329, parameters k is 10.307210703083587 and b is -42.10742827791262\n",
      "Iteration 5788, the loss is 4.442382152336951, parameters k is 10.307210313755524 and b is -42.107424325343445\n",
      "Iteration 5789, the loss is 4.442382136562572, parameters k is 10.307209924427461 and b is -42.10742037277427\n",
      "Iteration 5790, the loss is 4.44238212078819, parameters k is 10.307209535099398 and b is -42.1074164202051\n",
      "Iteration 5791, the loss is 4.442382105013809, parameters k is 10.307209145771335 and b is -42.107412467635925\n",
      "Iteration 5792, the loss is 4.442382089239435, parameters k is 10.307208756443272 and b is -42.10740851506675\n",
      "Iteration 5793, the loss is 4.442382073465053, parameters k is 10.307208367115209 and b is -42.10740456249758\n",
      "Iteration 5794, the loss is 4.442382057690673, parameters k is 10.307207977787145 and b is -42.107400609928405\n",
      "Iteration 5795, the loss is 4.442382041916292, parameters k is 10.307207588459082 and b is -42.10739665735923\n",
      "Iteration 5796, the loss is 4.442382026141917, parameters k is 10.30720719913102 and b is -42.10739270479006\n",
      "Iteration 5797, the loss is 4.442382010367535, parameters k is 10.307206809802956 and b is -42.107388752220885\n",
      "Iteration 5798, the loss is 4.442381994593157, parameters k is 10.307206420474893 and b is -42.10738479965171\n",
      "Iteration 5799, the loss is 4.4423819788187755, parameters k is 10.30720603114683 and b is -42.10738084708254\n",
      "Iteration 5800, the loss is 4.442381963044397, parameters k is 10.307205641818767 and b is -42.107376894513365\n",
      "Iteration 5801, the loss is 4.442381947270018, parameters k is 10.307205252490704 and b is -42.10737294194419\n",
      "Iteration 5802, the loss is 4.442381931495637, parameters k is 10.30720486316264 and b is -42.10736898937502\n",
      "Iteration 5803, the loss is 4.442381915721262, parameters k is 10.307204473834577 and b is -42.107365036805845\n",
      "Iteration 5804, the loss is 4.442381899946878, parameters k is 10.307204084506514 and b is -42.10736108423667\n",
      "Iteration 5805, the loss is 4.442381884172498, parameters k is 10.307203695178451 and b is -42.1073571316675\n",
      "Iteration 5806, the loss is 4.442381868398122, parameters k is 10.307203305850388 and b is -42.107353179098325\n",
      "Iteration 5807, the loss is 4.442381852623743, parameters k is 10.307202916522325 and b is -42.10734922652915\n",
      "Iteration 5808, the loss is 4.442381836849362, parameters k is 10.307202527194262 and b is -42.10734527395998\n",
      "Iteration 5809, the loss is 4.442381821074983, parameters k is 10.307202137866199 and b is -42.107341321390805\n",
      "Iteration 5810, the loss is 4.442381805300605, parameters k is 10.307201748538136 and b is -42.10733736882163\n",
      "Iteration 5811, the loss is 4.442381789526222, parameters k is 10.307201359210072 and b is -42.10733341625246\n",
      "Iteration 5812, the loss is 4.442381773751842, parameters k is 10.30720096988201 and b is -42.107329463683286\n",
      "Iteration 5813, the loss is 4.442381757977468, parameters k is 10.307200580553946 and b is -42.10732551111411\n",
      "Iteration 5814, the loss is 4.442381742203087, parameters k is 10.307200191225883 and b is -42.10732155854494\n",
      "Iteration 5815, the loss is 4.442381726428707, parameters k is 10.30719980189782 and b is -42.107317605975766\n",
      "Iteration 5816, the loss is 4.442381710654326, parameters k is 10.307199412569757 and b is -42.10731365340659\n",
      "Iteration 5817, the loss is 4.4423816948799475, parameters k is 10.307199023241694 and b is -42.10730970083742\n",
      "Iteration 5818, the loss is 4.4423816791055675, parameters k is 10.30719863391363 and b is -42.107305748268246\n",
      "Iteration 5819, the loss is 4.442381663331188, parameters k is 10.307198244585567 and b is -42.10730179569907\n",
      "Iteration 5820, the loss is 4.4423816475568065, parameters k is 10.307197855257504 and b is -42.1072978431299\n",
      "Iteration 5821, the loss is 4.442381631782428, parameters k is 10.307197465929441 and b is -42.107293890560726\n",
      "Iteration 5822, the loss is 4.44238161600805, parameters k is 10.307197076601378 and b is -42.10728993799155\n",
      "Iteration 5823, the loss is 4.442381600233673, parameters k is 10.307196687273315 and b is -42.10728598542238\n",
      "Iteration 5824, the loss is 4.442381584459291, parameters k is 10.307196297945252 and b is -42.107282032853206\n",
      "Iteration 5825, the loss is 4.44238156868491, parameters k is 10.307195908617189 and b is -42.10727808028403\n",
      "Iteration 5826, the loss is 4.442381552910535, parameters k is 10.307195519289126 and b is -42.10727412771486\n",
      "Iteration 5827, the loss is 4.442381537136153, parameters k is 10.307195129961062 and b is -42.107270175145686\n",
      "Iteration 5828, the loss is 4.442381521361774, parameters k is 10.307194740633 and b is -42.10726622257651\n",
      "Iteration 5829, the loss is 4.442381505587396, parameters k is 10.307194351304936 and b is -42.10726227000734\n",
      "Iteration 5830, the loss is 4.442381489813016, parameters k is 10.307193961976873 and b is -42.107258317438166\n",
      "Iteration 5831, the loss is 4.442381474038639, parameters k is 10.30719357264881 and b is -42.10725436486899\n",
      "Iteration 5832, the loss is 4.442381458264256, parameters k is 10.307193183320747 and b is -42.10725041229982\n",
      "Iteration 5833, the loss is 4.442381442489876, parameters k is 10.307192793992684 and b is -42.107246459730646\n",
      "Iteration 5834, the loss is 4.442381426715498, parameters k is 10.30719240466462 and b is -42.10724250716147\n",
      "Iteration 5835, the loss is 4.4423814109411195, parameters k is 10.307192015336557 and b is -42.1072385545923\n",
      "Iteration 5836, the loss is 4.44238139516674, parameters k is 10.307191626008494 and b is -42.10723460202313\n",
      "Iteration 5837, the loss is 4.44238137939236, parameters k is 10.307191236680431 and b is -42.10723064945395\n",
      "Iteration 5838, the loss is 4.442381363617979, parameters k is 10.307190847352368 and b is -42.10722669688478\n",
      "Iteration 5839, the loss is 4.4423813478436, parameters k is 10.307190458024305 and b is -42.10722274431561\n",
      "Iteration 5840, the loss is 4.442381332069223, parameters k is 10.307190068696242 and b is -42.10721879174643\n",
      "Iteration 5841, the loss is 4.442381316294843, parameters k is 10.307189679368179 and b is -42.10721483917726\n",
      "Iteration 5842, the loss is 4.442381300520462, parameters k is 10.307189290040116 and b is -42.10721088660809\n",
      "Iteration 5843, the loss is 4.442381284746084, parameters k is 10.307188900712053 and b is -42.10720693403891\n",
      "Iteration 5844, the loss is 4.442381268971701, parameters k is 10.30718851138399 and b is -42.10720298146974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5845, the loss is 4.442381253197325, parameters k is 10.307188122055926 and b is -42.10719902890057\n",
      "Iteration 5846, the loss is 4.442381237422945, parameters k is 10.307187732727863 and b is -42.107195076331394\n",
      "Iteration 5847, the loss is 4.442381221648567, parameters k is 10.3071873433998 and b is -42.10719112376222\n",
      "Iteration 5848, the loss is 4.442381205874186, parameters k is 10.307186954071737 and b is -42.10718717119305\n",
      "Iteration 5849, the loss is 4.4423811900998045, parameters k is 10.307186564743674 and b is -42.107183218623874\n",
      "Iteration 5850, the loss is 4.442381174325428, parameters k is 10.30718617541561 and b is -42.1071792660547\n",
      "Iteration 5851, the loss is 4.442381158551046, parameters k is 10.307185786087548 and b is -42.10717531348553\n",
      "Iteration 5852, the loss is 4.442381142776667, parameters k is 10.307185396759484 and b is -42.107171360916354\n",
      "Iteration 5853, the loss is 4.442381127002289, parameters k is 10.307185007431421 and b is -42.10716740834718\n",
      "Iteration 5854, the loss is 4.442381111227909, parameters k is 10.307184618103358 and b is -42.10716345577801\n",
      "Iteration 5855, the loss is 4.44238109545353, parameters k is 10.307184228775295 and b is -42.107159503208834\n",
      "Iteration 5856, the loss is 4.442381079679151, parameters k is 10.307183839447232 and b is -42.10715555063966\n",
      "Iteration 5857, the loss is 4.4423810639047705, parameters k is 10.307183450119169 and b is -42.10715159807049\n",
      "Iteration 5858, the loss is 4.442381048130391, parameters k is 10.307183060791106 and b is -42.107147645501314\n",
      "Iteration 5859, the loss is 4.442381032356012, parameters k is 10.307182671463043 and b is -42.10714369293214\n",
      "Iteration 5860, the loss is 4.442381016581633, parameters k is 10.30718228213498 and b is -42.10713974036297\n",
      "Iteration 5861, the loss is 4.442381000807254, parameters k is 10.307181892806916 and b is -42.107135787793794\n",
      "Iteration 5862, the loss is 4.442380985032874, parameters k is 10.307181503478853 and b is -42.10713183522462\n",
      "Iteration 5863, the loss is 4.442380969258494, parameters k is 10.30718111415079 and b is -42.10712788265545\n",
      "Iteration 5864, the loss is 4.442380953484116, parameters k is 10.307180724822727 and b is -42.107123930086274\n",
      "Iteration 5865, the loss is 4.4423809377097365, parameters k is 10.307180335494664 and b is -42.1071199775171\n",
      "Iteration 5866, the loss is 4.442380921935356, parameters k is 10.3071799461666 and b is -42.10711602494793\n",
      "Iteration 5867, the loss is 4.442380906160975, parameters k is 10.307179556838538 and b is -42.107112072378754\n",
      "Iteration 5868, the loss is 4.4423808903866, parameters k is 10.307179167510474 and b is -42.10710811980958\n",
      "Iteration 5869, the loss is 4.442380874612217, parameters k is 10.307178778182411 and b is -42.10710416724041\n",
      "Iteration 5870, the loss is 4.442380858837839, parameters k is 10.307178388854348 and b is -42.107100214671235\n",
      "Iteration 5871, the loss is 4.442380843063457, parameters k is 10.307177999526285 and b is -42.10709626210206\n",
      "Iteration 5872, the loss is 4.442380827289079, parameters k is 10.307177610198222 and b is -42.10709230953289\n",
      "Iteration 5873, the loss is 4.4423808115147025, parameters k is 10.307177220870159 and b is -42.107088356963715\n",
      "Iteration 5874, the loss is 4.442380795740321, parameters k is 10.307176831542096 and b is -42.10708440439454\n",
      "Iteration 5875, the loss is 4.442380779965941, parameters k is 10.307176442214033 and b is -42.10708045182537\n",
      "Iteration 5876, the loss is 4.4423807641915625, parameters k is 10.30717605288597 and b is -42.107076499256195\n",
      "Iteration 5877, the loss is 4.442380748417183, parameters k is 10.307175663557906 and b is -42.10707254668702\n",
      "Iteration 5878, the loss is 4.442380732642805, parameters k is 10.307175274229843 and b is -42.10706859411785\n",
      "Iteration 5879, the loss is 4.442380716868425, parameters k is 10.30717488490178 and b is -42.107064641548675\n",
      "Iteration 5880, the loss is 4.442380701094046, parameters k is 10.307174495573717 and b is -42.1070606889795\n",
      "Iteration 5881, the loss is 4.442380685319664, parameters k is 10.307174106245654 and b is -42.10705673641033\n",
      "Iteration 5882, the loss is 4.442380669545286, parameters k is 10.30717371691759 and b is -42.107052783841155\n",
      "Iteration 5883, the loss is 4.442380653770905, parameters k is 10.307173327589528 and b is -42.10704883127198\n",
      "Iteration 5884, the loss is 4.442380637996528, parameters k is 10.307172938261465 and b is -42.10704487870281\n",
      "Iteration 5885, the loss is 4.4423806222221485, parameters k is 10.307172548933401 and b is -42.107040926133635\n",
      "Iteration 5886, the loss is 4.442380606447769, parameters k is 10.307172159605338 and b is -42.10703697356446\n",
      "Iteration 5887, the loss is 4.442380590673392, parameters k is 10.307171770277275 and b is -42.10703302099529\n",
      "Iteration 5888, the loss is 4.442380574899011, parameters k is 10.307171380949212 and b is -42.107029068426115\n",
      "Iteration 5889, the loss is 4.442380559124632, parameters k is 10.307170991621149 and b is -42.10702511585694\n",
      "Iteration 5890, the loss is 4.442380543350252, parameters k is 10.307170602293086 and b is -42.10702116328777\n",
      "Iteration 5891, the loss is 4.442380527575871, parameters k is 10.307170212965023 and b is -42.107017210718595\n",
      "Iteration 5892, the loss is 4.4423805118014945, parameters k is 10.30716982363696 and b is -42.10701325814942\n",
      "Iteration 5893, the loss is 4.442380496027114, parameters k is 10.307169434308896 and b is -42.10700930558025\n",
      "Iteration 5894, the loss is 4.442380480252735, parameters k is 10.307169044980833 and b is -42.107005353011075\n",
      "Iteration 5895, the loss is 4.4423804644783536, parameters k is 10.30716865565277 and b is -42.1070014004419\n",
      "Iteration 5896, the loss is 4.442380448703975, parameters k is 10.307168266324707 and b is -42.10699744787273\n",
      "Iteration 5897, the loss is 4.442380432929594, parameters k is 10.307167876996644 and b is -42.106993495303556\n",
      "Iteration 5898, the loss is 4.442380417155218, parameters k is 10.30716748766858 and b is -42.10698954273438\n",
      "Iteration 5899, the loss is 4.442380401380836, parameters k is 10.307167098340518 and b is -42.10698559016521\n",
      "Iteration 5900, the loss is 4.442380385606457, parameters k is 10.307166709012455 and b is -42.106981637596036\n",
      "Iteration 5901, the loss is 4.442380369832077, parameters k is 10.307166319684391 and b is -42.10697768502686\n",
      "Iteration 5902, the loss is 4.442380354057696, parameters k is 10.307165930356328 and b is -42.10697373245769\n",
      "Iteration 5903, the loss is 4.4423803382833205, parameters k is 10.307165541028265 and b is -42.106969779888516\n",
      "Iteration 5904, the loss is 4.4423803225089395, parameters k is 10.307165151700202 and b is -42.10696582731934\n",
      "Iteration 5905, the loss is 4.442380306734562, parameters k is 10.307164762372139 and b is -42.10696187475017\n",
      "Iteration 5906, the loss is 4.442380290960182, parameters k is 10.307164373044076 and b is -42.106957922180996\n",
      "Iteration 5907, the loss is 4.4423802751857995, parameters k is 10.307163983716013 and b is -42.10695396961182\n",
      "Iteration 5908, the loss is 4.442380259411422, parameters k is 10.30716359438795 and b is -42.10695001704265\n",
      "Iteration 5909, the loss is 4.442380243637043, parameters k is 10.307163205059886 and b is -42.106946064473476\n",
      "Iteration 5910, the loss is 4.442380227862661, parameters k is 10.307162815731823 and b is -42.1069421119043\n",
      "Iteration 5911, the loss is 4.442380212088285, parameters k is 10.30716242640376 and b is -42.10693815933513\n",
      "Iteration 5912, the loss is 4.442380196313907, parameters k is 10.307162037075697 and b is -42.106934206765956\n",
      "Iteration 5913, the loss is 4.442380180539523, parameters k is 10.307161647747634 and b is -42.10693025419678\n",
      "Iteration 5914, the loss is 4.442380164765145, parameters k is 10.30716125841957 and b is -42.10692630162761\n",
      "Iteration 5915, the loss is 4.442380148990766, parameters k is 10.307160869091508 and b is -42.106922349058436\n",
      "Iteration 5916, the loss is 4.442380133216386, parameters k is 10.307160479763445 and b is -42.10691839648926\n",
      "Iteration 5917, the loss is 4.442380117442007, parameters k is 10.307160090435382 and b is -42.10691444392009\n",
      "Iteration 5918, the loss is 4.442380101667628, parameters k is 10.307159701107318 and b is -42.10691049135092\n",
      "Iteration 5919, the loss is 4.44238008902869, parameters k is 10.307159311779255 and b is -42.10690653878174\n",
      "Iteration 5920, the loss is 4.44238007503592, parameters k is 10.307131424427476 and b is -42.10690653878174\n",
      "Iteration 5921, the loss is 4.442380059261543, parameters k is 10.307131035099413 and b is -42.10690258621257\n",
      "Iteration 5922, the loss is 4.442380043487162, parameters k is 10.30713064577135 and b is -42.1068986336434\n",
      "Iteration 5923, the loss is 4.442380027712781, parameters k is 10.307130256443287 and b is -42.10689468107422\n",
      "Iteration 5924, the loss is 4.442380011938402, parameters k is 10.307129867115224 and b is -42.10689072850505\n",
      "Iteration 5925, the loss is 4.442379996164024, parameters k is 10.30712947778716 and b is -42.10688677593588\n",
      "Iteration 5926, the loss is 4.442379980389644, parameters k is 10.307129088459098 and b is -42.1068828233667\n",
      "Iteration 5927, the loss is 4.442379964615263, parameters k is 10.307128699131034 and b is -42.10687887079753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5928, the loss is 4.442379948840886, parameters k is 10.307128309802971 and b is -42.10687491822836\n",
      "Iteration 5929, the loss is 4.442379933066506, parameters k is 10.307127920474908 and b is -42.10687096565918\n",
      "Iteration 5930, the loss is 4.442379917292125, parameters k is 10.307127531146845 and b is -42.10686701309001\n",
      "Iteration 5931, the loss is 4.442379901517745, parameters k is 10.307127141818782 and b is -42.10686306052084\n",
      "Iteration 5932, the loss is 4.442379885743368, parameters k is 10.307126752490719 and b is -42.106859107951664\n",
      "Iteration 5933, the loss is 4.4423798699689865, parameters k is 10.307126363162656 and b is -42.10685515538249\n",
      "Iteration 5934, the loss is 4.442379854194608, parameters k is 10.307125973834593 and b is -42.10685120281332\n",
      "Iteration 5935, the loss is 4.442379838420228, parameters k is 10.30712558450653 and b is -42.106847250244144\n",
      "Iteration 5936, the loss is 4.442379822645852, parameters k is 10.307125195178466 and b is -42.10684329767497\n",
      "Iteration 5937, the loss is 4.442379806871471, parameters k is 10.307124805850403 and b is -42.1068393451058\n",
      "Iteration 5938, the loss is 4.442379791097091, parameters k is 10.30712441652234 and b is -42.106835392536624\n",
      "Iteration 5939, the loss is 4.442379775322711, parameters k is 10.307124027194277 and b is -42.10683143996745\n",
      "Iteration 5940, the loss is 4.4423797595483325, parameters k is 10.307123637866214 and b is -42.10682748739828\n",
      "Iteration 5941, the loss is 4.442379743773953, parameters k is 10.30712324853815 and b is -42.106823534829104\n",
      "Iteration 5942, the loss is 4.442379727999573, parameters k is 10.307122859210088 and b is -42.10681958225993\n",
      "Iteration 5943, the loss is 4.442379712225195, parameters k is 10.307122469882025 and b is -42.10681562969076\n",
      "Iteration 5944, the loss is 4.442379696450817, parameters k is 10.307122080553961 and b is -42.106811677121584\n",
      "Iteration 5945, the loss is 4.442379680676434, parameters k is 10.307121691225898 and b is -42.10680772455241\n",
      "Iteration 5946, the loss is 4.442379664902056, parameters k is 10.307121301897835 and b is -42.10680377198324\n",
      "Iteration 5947, the loss is 4.442379649127677, parameters k is 10.307120912569772 and b is -42.106799819414064\n",
      "Iteration 5948, the loss is 4.442379633353296, parameters k is 10.307120523241709 and b is -42.10679586684489\n",
      "Iteration 5949, the loss is 4.442379617578919, parameters k is 10.307120133913646 and b is -42.10679191427572\n",
      "Iteration 5950, the loss is 4.442379601804539, parameters k is 10.307119744585583 and b is -42.106787961706544\n",
      "Iteration 5951, the loss is 4.442379586030161, parameters k is 10.30711935525752 and b is -42.10678400913737\n",
      "Iteration 5952, the loss is 4.4423795702557785, parameters k is 10.307118965929456 and b is -42.1067800565682\n",
      "Iteration 5953, the loss is 4.442379554481399, parameters k is 10.307118576601393 and b is -42.106776103999024\n",
      "Iteration 5954, the loss is 4.442379538707025, parameters k is 10.30711818727333 and b is -42.10677215142985\n",
      "Iteration 5955, the loss is 4.442379522932643, parameters k is 10.307117797945267 and b is -42.10676819886068\n",
      "Iteration 5956, the loss is 4.442379507158263, parameters k is 10.307117408617204 and b is -42.106764246291505\n",
      "Iteration 5957, the loss is 4.442379491383883, parameters k is 10.30711701928914 and b is -42.10676029372233\n",
      "Iteration 5958, the loss is 4.442379475609503, parameters k is 10.307116629961078 and b is -42.10675634115316\n",
      "Iteration 5959, the loss is 4.442379459835125, parameters k is 10.307116240633015 and b is -42.106752388583985\n",
      "Iteration 5960, the loss is 4.4423794440607445, parameters k is 10.307115851304951 and b is -42.10674843601481\n",
      "Iteration 5961, the loss is 4.4423794282863645, parameters k is 10.307115461976888 and b is -42.10674448344564\n",
      "Iteration 5962, the loss is 4.442379412511984, parameters k is 10.307115072648825 and b is -42.106740530876465\n",
      "Iteration 5963, the loss is 4.442379396737605, parameters k is 10.307114683320762 and b is -42.10673657830729\n",
      "Iteration 5964, the loss is 4.442379380963228, parameters k is 10.307114293992699 and b is -42.10673262573812\n",
      "Iteration 5965, the loss is 4.442379365188847, parameters k is 10.307113904664636 and b is -42.106728673168945\n",
      "Iteration 5966, the loss is 4.442379349414468, parameters k is 10.307113515336573 and b is -42.10672472059977\n",
      "Iteration 5967, the loss is 4.44237933364009, parameters k is 10.30711312600851 and b is -42.1067207680306\n",
      "Iteration 5968, the loss is 4.44237931786571, parameters k is 10.307112736680446 and b is -42.106716815461425\n",
      "Iteration 5969, the loss is 4.442379302091332, parameters k is 10.307112347352383 and b is -42.10671286289225\n",
      "Iteration 5970, the loss is 4.44237928631695, parameters k is 10.30711195802432 and b is -42.10670891032308\n",
      "Iteration 5971, the loss is 4.442379270542571, parameters k is 10.307111568696257 and b is -42.106704957753905\n",
      "Iteration 5972, the loss is 4.442379254768191, parameters k is 10.307111179368194 and b is -42.10670100518473\n",
      "Iteration 5973, the loss is 4.442379238993811, parameters k is 10.30711079004013 and b is -42.10669705261556\n",
      "Iteration 5974, the loss is 4.442379223219434, parameters k is 10.307110400712068 and b is -42.106693100046385\n",
      "Iteration 5975, the loss is 4.442379207445053, parameters k is 10.307110011384005 and b is -42.10668914747721\n",
      "Iteration 5976, the loss is 4.442379191670672, parameters k is 10.307109622055942 and b is -42.10668519490804\n",
      "Iteration 5977, the loss is 4.442379175896295, parameters k is 10.307109232727878 and b is -42.106681242338865\n",
      "Iteration 5978, the loss is 4.4423791601219165, parameters k is 10.307108843399815 and b is -42.10667728976969\n",
      "Iteration 5979, the loss is 4.442379144347536, parameters k is 10.307108454071752 and b is -42.10667333720052\n",
      "Iteration 5980, the loss is 4.442379128573154, parameters k is 10.307108064743689 and b is -42.106669384631346\n",
      "Iteration 5981, the loss is 4.442379112798777, parameters k is 10.307107675415626 and b is -42.10666543206217\n",
      "Iteration 5982, the loss is 4.442379097024398, parameters k is 10.307107286087563 and b is -42.106661479493\n",
      "Iteration 5983, the loss is 4.442379081250018, parameters k is 10.3071068967595 and b is -42.106657526923826\n",
      "Iteration 5984, the loss is 4.44237906547564, parameters k is 10.307106507431437 and b is -42.10665357435465\n",
      "Iteration 5985, the loss is 4.442379049701257, parameters k is 10.307106118103373 and b is -42.10664962178548\n",
      "Iteration 5986, the loss is 4.442379033926881, parameters k is 10.30710572877531 and b is -42.106645669216306\n",
      "Iteration 5987, the loss is 4.442379018152503, parameters k is 10.307105339447247 and b is -42.10664171664713\n",
      "Iteration 5988, the loss is 4.4423790023781216, parameters k is 10.307104950119184 and b is -42.10663776407796\n",
      "Iteration 5989, the loss is 4.442378986603741, parameters k is 10.307104560791121 and b is -42.106633811508786\n",
      "Iteration 5990, the loss is 4.4423789708293615, parameters k is 10.307104171463058 and b is -42.10662985893961\n",
      "Iteration 5991, the loss is 4.442378955054982, parameters k is 10.307103782134995 and b is -42.10662590637044\n",
      "Iteration 5992, the loss is 4.442378939280601, parameters k is 10.307103392806932 and b is -42.106621953801266\n",
      "Iteration 5993, the loss is 4.442378923506224, parameters k is 10.307103003478868 and b is -42.10661800123209\n",
      "Iteration 5994, the loss is 4.442378907731844, parameters k is 10.307102614150805 and b is -42.10661404866292\n",
      "Iteration 5995, the loss is 4.442378891957467, parameters k is 10.307102224822742 and b is -42.106610096093746\n",
      "Iteration 5996, the loss is 4.442378876183088, parameters k is 10.307101835494679 and b is -42.10660614352457\n",
      "Iteration 5997, the loss is 4.442378860408707, parameters k is 10.307101446166616 and b is -42.1066021909554\n",
      "Iteration 5998, the loss is 4.442378844634327, parameters k is 10.307101056838553 and b is -42.106598238386226\n",
      "Iteration 5999, the loss is 4.442378828859948, parameters k is 10.30710066751049 and b is -42.10659428581705\n",
      "Iteration 6000, the loss is 4.4423788130855675, parameters k is 10.307100278182427 and b is -42.10659033324788\n",
      "Iteration 6001, the loss is 4.44237879731119, parameters k is 10.307099888854363 and b is -42.106586380678706\n",
      "Iteration 6002, the loss is 4.442378781536807, parameters k is 10.3070994995263 and b is -42.10658242810953\n",
      "Iteration 6003, the loss is 4.442378765762429, parameters k is 10.307099110198237 and b is -42.10657847554036\n",
      "Iteration 6004, the loss is 4.44237874998805, parameters k is 10.307098720870174 and b is -42.10657452297119\n",
      "Iteration 6005, the loss is 4.44237873421367, parameters k is 10.307098331542111 and b is -42.10657057040201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6006, the loss is 4.442378718439293, parameters k is 10.307097942214048 and b is -42.10656661783284\n",
      "Iteration 6007, the loss is 4.442378702664913, parameters k is 10.307097552885985 and b is -42.10656266526367\n",
      "Iteration 6008, the loss is 4.4423786868905335, parameters k is 10.307097163557922 and b is -42.10655871269449\n",
      "Iteration 6009, the loss is 4.442378671116154, parameters k is 10.307096774229858 and b is -42.10655476012532\n",
      "Iteration 6010, the loss is 4.4423786553417735, parameters k is 10.307096384901795 and b is -42.10655080755615\n",
      "Iteration 6011, the loss is 4.442378639567394, parameters k is 10.307095995573732 and b is -42.10654685498697\n",
      "Iteration 6012, the loss is 4.442378623793018, parameters k is 10.30709560624567 and b is -42.1065429024178\n",
      "Iteration 6013, the loss is 4.442378608018638, parameters k is 10.307095216917606 and b is -42.10653894984863\n",
      "Iteration 6014, the loss is 4.442378592244256, parameters k is 10.307094827589543 and b is -42.106534997279454\n",
      "Iteration 6015, the loss is 4.4423785764698795, parameters k is 10.30709443826148 and b is -42.10653104471028\n",
      "Iteration 6016, the loss is 4.4423785606955, parameters k is 10.307094048933417 and b is -42.10652709214111\n",
      "Iteration 6017, the loss is 4.442378544921119, parameters k is 10.307093659605354 and b is -42.106523139571934\n",
      "Iteration 6018, the loss is 4.4423785291467395, parameters k is 10.30709327027729 and b is -42.10651918700276\n",
      "Iteration 6019, the loss is 4.442378513372358, parameters k is 10.307092880949227 and b is -42.10651523443359\n",
      "Iteration 6020, the loss is 4.442378497597979, parameters k is 10.307092491621164 and b is -42.106511281864414\n",
      "Iteration 6021, the loss is 4.442378481823603, parameters k is 10.307092102293101 and b is -42.10650732929524\n",
      "Iteration 6022, the loss is 4.442378466049222, parameters k is 10.307091712965038 and b is -42.10650337672607\n",
      "Iteration 6023, the loss is 4.442378450274844, parameters k is 10.307091323636975 and b is -42.106499424156894\n",
      "Iteration 6024, the loss is 4.442378434500463, parameters k is 10.307090934308912 and b is -42.10649547158772\n",
      "Iteration 6025, the loss is 4.442378418726085, parameters k is 10.307090544980849 and b is -42.10649151901855\n",
      "Iteration 6026, the loss is 4.442378402951705, parameters k is 10.307090155652785 and b is -42.106487566449374\n",
      "Iteration 6027, the loss is 4.442378387177327, parameters k is 10.307089766324722 and b is -42.1064836138802\n",
      "Iteration 6028, the loss is 4.442378371402944, parameters k is 10.30708937699666 and b is -42.10647966131103\n",
      "Iteration 6029, the loss is 4.442378355628568, parameters k is 10.307088987668596 and b is -42.106475708741854\n",
      "Iteration 6030, the loss is 4.442378339854184, parameters k is 10.307088598340533 and b is -42.10647175617268\n",
      "Iteration 6031, the loss is 4.442378324079806, parameters k is 10.30708820901247 and b is -42.10646780360351\n",
      "Iteration 6032, the loss is 4.442378308305429, parameters k is 10.307087819684407 and b is -42.106463851034334\n",
      "Iteration 6033, the loss is 4.442378292531049, parameters k is 10.307087430356344 and b is -42.10645989846516\n",
      "Iteration 6034, the loss is 4.4423782767566715, parameters k is 10.30708704102828 and b is -42.10645594589599\n",
      "Iteration 6035, the loss is 4.442378260982291, parameters k is 10.307086651700217 and b is -42.106451993326814\n",
      "Iteration 6036, the loss is 4.4423782452079115, parameters k is 10.307086262372154 and b is -42.10644804075764\n",
      "Iteration 6037, the loss is 4.4423782294335314, parameters k is 10.307085873044091 and b is -42.10644408818847\n",
      "Iteration 6038, the loss is 4.442378213659152, parameters k is 10.307085483716028 and b is -42.106440135619295\n",
      "Iteration 6039, the loss is 4.442378197884772, parameters k is 10.307085094387965 and b is -42.10643618305012\n",
      "Iteration 6040, the loss is 4.442378182110391, parameters k is 10.307084705059902 and b is -42.10643223048095\n",
      "Iteration 6041, the loss is 4.442378166336015, parameters k is 10.307084315731839 and b is -42.106428277911775\n",
      "Iteration 6042, the loss is 4.442378150561635, parameters k is 10.307083926403775 and b is -42.1064243253426\n",
      "Iteration 6043, the loss is 4.442378134787255, parameters k is 10.307083537075712 and b is -42.10642037277343\n",
      "Iteration 6044, the loss is 4.442378119012874, parameters k is 10.30708314774765 and b is -42.106416420204255\n",
      "Iteration 6045, the loss is 4.442378103238496, parameters k is 10.307082758419586 and b is -42.10641246763508\n",
      "Iteration 6046, the loss is 4.4423780874641166, parameters k is 10.307082369091523 and b is -42.10640851506591\n",
      "Iteration 6047, the loss is 4.442378071689736, parameters k is 10.30708197976346 and b is -42.106404562496735\n",
      "Iteration 6048, the loss is 4.4423780559153565, parameters k is 10.307081590435397 and b is -42.10640060992756\n",
      "Iteration 6049, the loss is 4.442378040140977, parameters k is 10.307081201107334 and b is -42.10639665735839\n",
      "Iteration 6050, the loss is 4.442378024366597, parameters k is 10.30708081177927 and b is -42.106392704789215\n",
      "Iteration 6051, the loss is 4.442378008592218, parameters k is 10.307080422451207 and b is -42.10638875222004\n",
      "Iteration 6052, the loss is 4.44237799281784, parameters k is 10.307080033123144 and b is -42.10638479965087\n",
      "Iteration 6053, the loss is 4.44237797704346, parameters k is 10.307079643795081 and b is -42.106380847081695\n",
      "Iteration 6054, the loss is 4.442377961269083, parameters k is 10.307079254467018 and b is -42.10637689451252\n",
      "Iteration 6055, the loss is 4.442377945494701, parameters k is 10.307078865138955 and b is -42.10637294194335\n",
      "Iteration 6056, the loss is 4.442377929720321, parameters k is 10.307078475810892 and b is -42.106368989374175\n",
      "Iteration 6057, the loss is 4.442377913945944, parameters k is 10.307078086482829 and b is -42.106365036805\n",
      "Iteration 6058, the loss is 4.442377898171563, parameters k is 10.307077697154766 and b is -42.10636108423583\n",
      "Iteration 6059, the loss is 4.442377882397183, parameters k is 10.307077307826702 and b is -42.106357131666655\n",
      "Iteration 6060, the loss is 4.442377866622802, parameters k is 10.30707691849864 and b is -42.10635317909748\n",
      "Iteration 6061, the loss is 4.442377850848426, parameters k is 10.307076529170576 and b is -42.10634922652831\n",
      "Iteration 6062, the loss is 4.442377835074045, parameters k is 10.307076139842513 and b is -42.106345273959136\n",
      "Iteration 6063, the loss is 4.442377819299667, parameters k is 10.30707575051445 and b is -42.10634132138996\n",
      "Iteration 6064, the loss is 4.442377803525288, parameters k is 10.307075361186387 and b is -42.10633736882079\n",
      "Iteration 6065, the loss is 4.442377787750908, parameters k is 10.307074971858324 and b is -42.106333416251616\n",
      "Iteration 6066, the loss is 4.442377771976528, parameters k is 10.30707458253026 and b is -42.10632946368244\n",
      "Iteration 6067, the loss is 4.442377756202149, parameters k is 10.307074193202197 and b is -42.10632551111327\n",
      "Iteration 6068, the loss is 4.44237774042777, parameters k is 10.307073803874134 and b is -42.106321558544096\n",
      "Iteration 6069, the loss is 4.442377724653394, parameters k is 10.307073414546071 and b is -42.10631760597492\n",
      "Iteration 6070, the loss is 4.442377708879007, parameters k is 10.307073025218008 and b is -42.10631365340575\n",
      "Iteration 6071, the loss is 4.442377693104632, parameters k is 10.307072635889945 and b is -42.106309700836576\n",
      "Iteration 6072, the loss is 4.442377677330253, parameters k is 10.307072246561882 and b is -42.1063057482674\n",
      "Iteration 6073, the loss is 4.44237766155587, parameters k is 10.307071857233819 and b is -42.10630179569823\n",
      "Iteration 6074, the loss is 4.442377645781494, parameters k is 10.307071467905756 and b is -42.106297843129056\n",
      "Iteration 6075, the loss is 4.4423776300071145, parameters k is 10.307071078577692 and b is -42.10629389055988\n",
      "Iteration 6076, the loss is 4.44237761758103, parameters k is 10.30707068924963 and b is -42.10628993799071\n",
      "Iteration 6077, the loss is 4.442377603375404, parameters k is 10.30704280189785 and b is -42.10628993799071\n",
      "Iteration 6078, the loss is 4.442377587601026, parameters k is 10.307042412569787 and b is -42.106285985421536\n",
      "Iteration 6079, the loss is 4.442377571826648, parameters k is 10.307042023241724 and b is -42.10628203285236\n",
      "Iteration 6080, the loss is 4.442377556052265, parameters k is 10.307041633913661 and b is -42.10627808028319\n",
      "Iteration 6081, the loss is 4.442377540277888, parameters k is 10.307041244585598 and b is -42.106274127714016\n",
      "Iteration 6082, the loss is 4.4423775245035095, parameters k is 10.307040855257535 and b is -42.10627017514484\n",
      "Iteration 6083, the loss is 4.442377508729132, parameters k is 10.307040465929472 and b is -42.10626622257567\n",
      "Iteration 6084, the loss is 4.442377492954751, parameters k is 10.307040076601409 and b is -42.106262270006496\n",
      "Iteration 6085, the loss is 4.4423774771803695, parameters k is 10.307039687273345 and b is -42.10625831743732\n",
      "Iteration 6086, the loss is 4.442377461405994, parameters k is 10.307039297945282 and b is -42.10625436486815\n",
      "Iteration 6087, the loss is 4.442377445631612, parameters k is 10.30703890861722 and b is -42.10625041229898\n",
      "Iteration 6088, the loss is 4.442377429857231, parameters k is 10.307038519289156 and b is -42.1062464597298\n",
      "Iteration 6089, the loss is 4.442377414082851, parameters k is 10.307038129961093 and b is -42.10624250716063\n",
      "Iteration 6090, the loss is 4.442377398308475, parameters k is 10.30703774063303 and b is -42.10623855459146\n",
      "Iteration 6091, the loss is 4.442377382534094, parameters k is 10.307037351304967 and b is -42.10623460202228\n",
      "Iteration 6092, the loss is 4.442377366759714, parameters k is 10.307036961976904 and b is -42.10623064945311\n",
      "Iteration 6093, the loss is 4.442377350985335, parameters k is 10.30703657264884 and b is -42.10622669688394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6094, the loss is 4.442377335210956, parameters k is 10.307036183320777 and b is -42.10622274431476\n",
      "Iteration 6095, the loss is 4.4423773194365745, parameters k is 10.307035793992714 and b is -42.10621879174559\n",
      "Iteration 6096, the loss is 4.442377303662197, parameters k is 10.307035404664651 and b is -42.10621483917642\n",
      "Iteration 6097, the loss is 4.442377287887814, parameters k is 10.307035015336588 and b is -42.10621088660724\n",
      "Iteration 6098, the loss is 4.442377272113439, parameters k is 10.307034626008525 and b is -42.10620693403807\n",
      "Iteration 6099, the loss is 4.442377256339056, parameters k is 10.307034236680462 and b is -42.1062029814689\n",
      "Iteration 6100, the loss is 4.44237724056468, parameters k is 10.307033847352399 and b is -42.106199028899724\n",
      "Iteration 6101, the loss is 4.4423772247903, parameters k is 10.307033458024335 and b is -42.10619507633055\n",
      "Iteration 6102, the loss is 4.442377209015921, parameters k is 10.307033068696272 and b is -42.10619112376138\n",
      "Iteration 6103, the loss is 4.442377193241542, parameters k is 10.30703267936821 and b is -42.106187171192204\n",
      "Iteration 6104, the loss is 4.44237717746716, parameters k is 10.307032290040146 and b is -42.10618321862303\n",
      "Iteration 6105, the loss is 4.442377161692781, parameters k is 10.307031900712083 and b is -42.10617926605386\n",
      "Iteration 6106, the loss is 4.442377145918403, parameters k is 10.30703151138402 and b is -42.106175313484684\n",
      "Iteration 6107, the loss is 4.442377130144023, parameters k is 10.307031122055957 and b is -42.10617136091551\n",
      "Iteration 6108, the loss is 4.442377114369642, parameters k is 10.307030732727894 and b is -42.10616740834634\n",
      "Iteration 6109, the loss is 4.442377098595266, parameters k is 10.30703034339983 and b is -42.106163455777164\n",
      "Iteration 6110, the loss is 4.442377082820885, parameters k is 10.307029954071767 and b is -42.10615950320799\n",
      "Iteration 6111, the loss is 4.442377067046506, parameters k is 10.307029564743704 and b is -42.10615555063882\n",
      "Iteration 6112, the loss is 4.442377051272127, parameters k is 10.307029175415641 and b is -42.106151598069644\n",
      "Iteration 6113, the loss is 4.442377035497749, parameters k is 10.307028786087578 and b is -42.10614764550047\n",
      "Iteration 6114, the loss is 4.442377019723367, parameters k is 10.307028396759515 and b is -42.1061436929313\n",
      "Iteration 6115, the loss is 4.442377003948987, parameters k is 10.307028007431452 and b is -42.106139740362124\n",
      "Iteration 6116, the loss is 4.442376988174612, parameters k is 10.307027618103389 and b is -42.10613578779295\n",
      "Iteration 6117, the loss is 4.442376972400231, parameters k is 10.307027228775326 and b is -42.10613183522378\n",
      "Iteration 6118, the loss is 4.442376956625851, parameters k is 10.307026839447262 and b is -42.106127882654604\n",
      "Iteration 6119, the loss is 4.442376940851471, parameters k is 10.3070264501192 and b is -42.10612393008543\n",
      "Iteration 6120, the loss is 4.442376925077093, parameters k is 10.307026060791136 and b is -42.10611997751626\n",
      "Iteration 6121, the loss is 4.442376909302712, parameters k is 10.307025671463073 and b is -42.106116024947084\n",
      "Iteration 6122, the loss is 4.442376893528332, parameters k is 10.30702528213501 and b is -42.10611207237791\n",
      "Iteration 6123, the loss is 4.442376877753953, parameters k is 10.307024892806947 and b is -42.10610811980874\n",
      "Iteration 6124, the loss is 4.4423768619795725, parameters k is 10.307024503478884 and b is -42.106104167239565\n",
      "Iteration 6125, the loss is 4.442376846205194, parameters k is 10.30702411415082 and b is -42.10610021467039\n",
      "Iteration 6126, the loss is 4.442376830430814, parameters k is 10.307023724822757 and b is -42.10609626210122\n",
      "Iteration 6127, the loss is 4.442376814656438, parameters k is 10.307023335494694 and b is -42.106092309532045\n",
      "Iteration 6128, the loss is 4.442376798882057, parameters k is 10.307022946166631 and b is -42.10608835696287\n",
      "Iteration 6129, the loss is 4.442376783107677, parameters k is 10.307022556838568 and b is -42.1060844043937\n",
      "Iteration 6130, the loss is 4.4423767673332994, parameters k is 10.307022167510505 and b is -42.106080451824525\n",
      "Iteration 6131, the loss is 4.4423767515589185, parameters k is 10.307021778182442 and b is -42.10607649925535\n",
      "Iteration 6132, the loss is 4.4423767357845385, parameters k is 10.307021388854379 and b is -42.10607254668618\n",
      "Iteration 6133, the loss is 4.44237672001016, parameters k is 10.307020999526316 and b is -42.106068594117005\n",
      "Iteration 6134, the loss is 4.442376704235782, parameters k is 10.307020610198252 and b is -42.10606464154783\n",
      "Iteration 6135, the loss is 4.4423766884614, parameters k is 10.30702022087019 and b is -42.10606068897866\n",
      "Iteration 6136, the loss is 4.442376672687021, parameters k is 10.307019831542126 and b is -42.106056736409485\n",
      "Iteration 6137, the loss is 4.442376656912642, parameters k is 10.307019442214063 and b is -42.10605278384031\n",
      "Iteration 6138, the loss is 4.442376641138264, parameters k is 10.307019052886 and b is -42.10604883127114\n",
      "Iteration 6139, the loss is 4.442376625363883, parameters k is 10.307018663557937 and b is -42.106044878701965\n",
      "Iteration 6140, the loss is 4.4423766095895045, parameters k is 10.307018274229874 and b is -42.10604092613279\n",
      "Iteration 6141, the loss is 4.4423765938151245, parameters k is 10.30701788490181 and b is -42.10603697356362\n",
      "Iteration 6142, the loss is 4.442376578040745, parameters k is 10.307017495573747 and b is -42.106033020994445\n",
      "Iteration 6143, the loss is 4.442376562266365, parameters k is 10.307017106245684 and b is -42.10602906842527\n",
      "Iteration 6144, the loss is 4.442376546491985, parameters k is 10.307016716917621 and b is -42.1060251158561\n",
      "Iteration 6145, the loss is 4.442376530717609, parameters k is 10.307016327589558 and b is -42.106021163286925\n",
      "Iteration 6146, the loss is 4.442376514943228, parameters k is 10.307015938261495 and b is -42.10601721071775\n",
      "Iteration 6147, the loss is 4.442376499168848, parameters k is 10.307015548933432 and b is -42.10601325814858\n",
      "Iteration 6148, the loss is 4.442376483394467, parameters k is 10.307015159605369 and b is -42.106009305579406\n",
      "Iteration 6149, the loss is 4.4423764676200905, parameters k is 10.307014770277306 and b is -42.10600535301023\n",
      "Iteration 6150, the loss is 4.442376451845709, parameters k is 10.307014380949242 and b is -42.10600140044106\n",
      "Iteration 6151, the loss is 4.442376436071331, parameters k is 10.30701399162118 and b is -42.105997447871886\n",
      "Iteration 6152, the loss is 4.4423764202969505, parameters k is 10.307013602293116 and b is -42.10599349530271\n",
      "Iteration 6153, the loss is 4.442376404522572, parameters k is 10.307013212965053 and b is -42.10598954273354\n",
      "Iteration 6154, the loss is 4.442376388748192, parameters k is 10.30701282363699 and b is -42.105985590164366\n",
      "Iteration 6155, the loss is 4.442376372973811, parameters k is 10.307012434308927 and b is -42.10598163759519\n",
      "Iteration 6156, the loss is 4.442376357199434, parameters k is 10.307012044980864 and b is -42.10597768502602\n",
      "Iteration 6157, the loss is 4.442376341425053, parameters k is 10.3070116556528 and b is -42.105973732456846\n",
      "Iteration 6158, the loss is 4.442376325650674, parameters k is 10.307011266324738 and b is -42.10596977988767\n",
      "Iteration 6159, the loss is 4.4423763098762965, parameters k is 10.307010876996674 and b is -42.1059658273185\n",
      "Iteration 6160, the loss is 4.442376294101917, parameters k is 10.307010487668611 and b is -42.105961874749326\n",
      "Iteration 6161, the loss is 4.442376278327534, parameters k is 10.307010098340548 and b is -42.10595792218015\n",
      "Iteration 6162, the loss is 4.442376262553158, parameters k is 10.307009709012485 and b is -42.10595396961098\n",
      "Iteration 6163, the loss is 4.4423762467787755, parameters k is 10.307009319684422 and b is -42.105950017041806\n",
      "Iteration 6164, the loss is 4.442376231004398, parameters k is 10.307008930356359 and b is -42.10594606447263\n",
      "Iteration 6165, the loss is 4.442376215230019, parameters k is 10.307008541028296 and b is -42.10594211190346\n",
      "Iteration 6166, the loss is 4.442376199455637, parameters k is 10.307008151700233 and b is -42.105938159334286\n",
      "Iteration 6167, the loss is 4.442376183681261, parameters k is 10.30700776237217 and b is -42.10593420676511\n",
      "Iteration 6168, the loss is 4.44237616790688, parameters k is 10.307007373044106 and b is -42.10593025419594\n",
      "Iteration 6169, the loss is 4.442376152132502, parameters k is 10.307006983716043 and b is -42.105926301626766\n",
      "Iteration 6170, the loss is 4.442376136358123, parameters k is 10.30700659438798 and b is -42.10592234905759\n",
      "Iteration 6171, the loss is 4.44237612058374, parameters k is 10.307006205059917 and b is -42.10591839648842\n",
      "Iteration 6172, the loss is 4.442376104809364, parameters k is 10.307005815731854 and b is -42.10591444391925\n",
      "Iteration 6173, the loss is 4.442376089034983, parameters k is 10.30700542640379 and b is -42.10591049135007\n",
      "Iteration 6174, the loss is 4.4423760732606015, parameters k is 10.307005037075728 and b is -42.1059065387809\n",
      "Iteration 6175, the loss is 4.442376057486223, parameters k is 10.307004647747664 and b is -42.10590258621173\n",
      "Iteration 6176, the loss is 4.442376041711848, parameters k is 10.307004258419601 and b is -42.10589863364255\n",
      "Iteration 6177, the loss is 4.442376025937466, parameters k is 10.307003869091538 and b is -42.10589468107338\n",
      "Iteration 6178, the loss is 4.442376010163086, parameters k is 10.307003479763475 and b is -42.10589072850421\n",
      "Iteration 6179, the loss is 4.442375994388707, parameters k is 10.307003090435412 and b is -42.10588677593503\n",
      "Iteration 6180, the loss is 4.442375978614329, parameters k is 10.307002701107349 and b is -42.10588282336586\n",
      "Iteration 6181, the loss is 4.4423759628399475, parameters k is 10.307002311779286 and b is -42.10587887079669\n",
      "Iteration 6182, the loss is 4.442375947065568, parameters k is 10.307001922451223 and b is -42.105874918227514\n",
      "Iteration 6183, the loss is 4.442375931291189, parameters k is 10.30700153312316 and b is -42.10587096565834\n",
      "Iteration 6184, the loss is 4.442375915516811, parameters k is 10.307001143795096 and b is -42.10586701308917\n",
      "Iteration 6185, the loss is 4.442375899742433, parameters k is 10.307000754467033 and b is -42.105863060519994\n",
      "Iteration 6186, the loss is 4.442375883968049, parameters k is 10.30700036513897 and b is -42.10585910795082\n",
      "Iteration 6187, the loss is 4.442375868193674, parameters k is 10.306999975810907 and b is -42.10585515538165\n",
      "Iteration 6188, the loss is 4.44237585241929, parameters k is 10.306999586482844 and b is -42.105851202812474\n",
      "Iteration 6189, the loss is 4.442375836644915, parameters k is 10.30699919715478 and b is -42.1058472502433\n",
      "Iteration 6190, the loss is 4.442375820870537, parameters k is 10.306998807826718 and b is -42.10584329767413\n",
      "Iteration 6191, the loss is 4.4423758050961535, parameters k is 10.306998418498655 and b is -42.105839345104954\n",
      "Iteration 6192, the loss is 4.442375789321775, parameters k is 10.306998029170591 and b is -42.10583539253578\n",
      "Iteration 6193, the loss is 4.442375773547395, parameters k is 10.306997639842528 and b is -42.10583143996661\n",
      "Iteration 6194, the loss is 4.442375757773015, parameters k is 10.306997250514465 and b is -42.105827487397434\n",
      "Iteration 6195, the loss is 4.442375741998637, parameters k is 10.306996861186402 and b is -42.10582353482826\n",
      "Iteration 6196, the loss is 4.442375726224258, parameters k is 10.306996471858339 and b is -42.10581958225909\n",
      "Iteration 6197, the loss is 4.4423757104498796, parameters k is 10.306996082530276 and b is -42.105815629689914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6198, the loss is 4.4423756946754995, parameters k is 10.306995693202213 and b is -42.10581167712074\n",
      "Iteration 6199, the loss is 4.4423756789011195, parameters k is 10.30699530387415 and b is -42.10580772455157\n",
      "Iteration 6200, the loss is 4.4423756631267395, parameters k is 10.306994914546086 and b is -42.105803771982394\n",
      "Iteration 6201, the loss is 4.442375647352361, parameters k is 10.306994525218023 and b is -42.10579981941322\n",
      "Iteration 6202, the loss is 4.44237563157798, parameters k is 10.30699413588996 and b is -42.10579586684405\n",
      "Iteration 6203, the loss is 4.442375615803602, parameters k is 10.306993746561897 and b is -42.105791914274874\n",
      "Iteration 6204, the loss is 4.442375600029223, parameters k is 10.306993357233834 and b is -42.1057879617057\n",
      "Iteration 6205, the loss is 4.442375584254843, parameters k is 10.30699296790577 and b is -42.10578400913653\n",
      "Iteration 6206, the loss is 4.442375568480462, parameters k is 10.306992578577708 and b is -42.105780056567355\n",
      "Iteration 6207, the loss is 4.442375552706084, parameters k is 10.306992189249645 and b is -42.10577610399818\n",
      "Iteration 6208, the loss is 4.4423755369317055, parameters k is 10.306991799921581 and b is -42.10577215142901\n",
      "Iteration 6209, the loss is 4.442375521157325, parameters k is 10.306991410593518 and b is -42.105768198859835\n",
      "Iteration 6210, the loss is 4.442375505382946, parameters k is 10.306991021265455 and b is -42.10576424629066\n",
      "Iteration 6211, the loss is 4.442375489608568, parameters k is 10.306990631937392 and b is -42.10576029372149\n",
      "Iteration 6212, the loss is 4.442375473834187, parameters k is 10.306990242609329 and b is -42.105756341152315\n",
      "Iteration 6213, the loss is 4.442375458059807, parameters k is 10.306989853281266 and b is -42.10575238858314\n",
      "Iteration 6214, the loss is 4.442375442285427, parameters k is 10.306989463953203 and b is -42.10574843601397\n",
      "Iteration 6215, the loss is 4.44237542651105, parameters k is 10.30698907462514 and b is -42.105744483444795\n",
      "Iteration 6216, the loss is 4.44237541073667, parameters k is 10.306988685297076 and b is -42.10574053087562\n",
      "Iteration 6217, the loss is 4.442375394962289, parameters k is 10.306988295969013 and b is -42.10573657830645\n",
      "Iteration 6218, the loss is 4.442375379187912, parameters k is 10.30698790664095 and b is -42.105732625737275\n",
      "Iteration 6219, the loss is 4.442375363413531, parameters k is 10.306987517312887 and b is -42.1057286731681\n",
      "Iteration 6220, the loss is 4.4423753476391505, parameters k is 10.306987127984824 and b is -42.10572472059893\n",
      "Iteration 6221, the loss is 4.442375331864771, parameters k is 10.30698673865676 and b is -42.105720768029755\n",
      "Iteration 6222, the loss is 4.442375316090395, parameters k is 10.306986349328698 and b is -42.10571681546058\n",
      "Iteration 6223, the loss is 4.442375300316014, parameters k is 10.306985960000635 and b is -42.10571286289141\n",
      "Iteration 6224, the loss is 4.442375284541636, parameters k is 10.306985570672571 and b is -42.105708910322235\n",
      "Iteration 6225, the loss is 4.442375268767258, parameters k is 10.306985181344508 and b is -42.10570495775306\n",
      "Iteration 6226, the loss is 4.442375252992874, parameters k is 10.306984792016445 and b is -42.10570100518389\n",
      "Iteration 6227, the loss is 4.442375237218497, parameters k is 10.306984402688382 and b is -42.105697052614715\n",
      "Iteration 6228, the loss is 4.4423752214441175, parameters k is 10.306984013360319 and b is -42.10569310004554\n",
      "Iteration 6229, the loss is 4.442375205669737, parameters k is 10.306983624032256 and b is -42.10568914747637\n",
      "Iteration 6230, the loss is 4.442375189895359, parameters k is 10.306983234704193 and b is -42.105685194907196\n",
      "Iteration 6231, the loss is 4.4423751741209765, parameters k is 10.30698284537613 and b is -42.10568124233802\n",
      "Iteration 6232, the loss is 4.442375158346598, parameters k is 10.306982456048067 and b is -42.10567728976885\n",
      "Iteration 6233, the loss is 4.442375146133371, parameters k is 10.306982066720003 and b is -42.105673337199676\n",
      "Iteration 6234, the loss is 4.442375131714892, parameters k is 10.306954179368224 and b is -42.105673337199676\n",
      "Iteration 6235, the loss is 4.442375115940511, parameters k is 10.306953790040161 and b is -42.1056693846305\n",
      "Iteration 6236, the loss is 4.442375100166131, parameters k is 10.306953400712098 and b is -42.10566543206133\n",
      "Iteration 6237, the loss is 4.442375084391751, parameters k is 10.306953011384035 and b is -42.105661479492156\n",
      "Iteration 6238, the loss is 4.442375068617373, parameters k is 10.306952622055972 and b is -42.10565752692298\n",
      "Iteration 6239, the loss is 4.442375052842995, parameters k is 10.306952232727909 and b is -42.10565357435381\n",
      "Iteration 6240, the loss is 4.442375037068614, parameters k is 10.306951843399846 and b is -42.105649621784636\n",
      "Iteration 6241, the loss is 4.442375021294234, parameters k is 10.306951454071783 and b is -42.10564566921546\n",
      "Iteration 6242, the loss is 4.442375005519854, parameters k is 10.30695106474372 and b is -42.10564171664629\n",
      "Iteration 6243, the loss is 4.442374989745475, parameters k is 10.306950675415656 and b is -42.105637764077116\n",
      "Iteration 6244, the loss is 4.4423749739710985, parameters k is 10.306950286087593 and b is -42.10563381150794\n",
      "Iteration 6245, the loss is 4.442374958196717, parameters k is 10.30694989675953 and b is -42.10562985893877\n",
      "Iteration 6246, the loss is 4.442374942422336, parameters k is 10.306949507431467 and b is -42.105625906369596\n",
      "Iteration 6247, the loss is 4.442374926647961, parameters k is 10.306949118103404 and b is -42.10562195380042\n",
      "Iteration 6248, the loss is 4.442374910873578, parameters k is 10.30694872877534 and b is -42.10561800123125\n",
      "Iteration 6249, the loss is 4.442374895099201, parameters k is 10.306948339447278 and b is -42.105614048662076\n",
      "Iteration 6250, the loss is 4.442374879324821, parameters k is 10.306947950119214 and b is -42.1056100960929\n",
      "Iteration 6251, the loss is 4.442374863550441, parameters k is 10.306947560791151 and b is -42.10560614352373\n",
      "Iteration 6252, the loss is 4.442374847776063, parameters k is 10.306947171463088 and b is -42.105602190954556\n",
      "Iteration 6253, the loss is 4.4423748320016845, parameters k is 10.306946782135025 and b is -42.10559823838538\n",
      "Iteration 6254, the loss is 4.442374816227303, parameters k is 10.306946392806962 and b is -42.10559428581621\n",
      "Iteration 6255, the loss is 4.442374800452921, parameters k is 10.306946003478899 and b is -42.10559033324704\n",
      "Iteration 6256, the loss is 4.4423747846785435, parameters k is 10.306945614150836 and b is -42.10558638067786\n",
      "Iteration 6257, the loss is 4.442374768904164, parameters k is 10.306945224822773 and b is -42.10558242810869\n",
      "Iteration 6258, the loss is 4.442374753129785, parameters k is 10.30694483549471 and b is -42.10557847553952\n",
      "Iteration 6259, the loss is 4.442374737355406, parameters k is 10.306944446166646 and b is -42.10557452297034\n",
      "Iteration 6260, the loss is 4.442374721581027, parameters k is 10.306944056838583 and b is -42.10557057040117\n",
      "Iteration 6261, the loss is 4.442374705806647, parameters k is 10.30694366751052 and b is -42.105566617832\n",
      "Iteration 6262, the loss is 4.442374690032268, parameters k is 10.306943278182457 and b is -42.10556266526282\n",
      "Iteration 6263, the loss is 4.442374674257888, parameters k is 10.306942888854394 and b is -42.10555871269365\n",
      "Iteration 6264, the loss is 4.44237465848351, parameters k is 10.30694249952633 and b is -42.10555476012448\n",
      "Iteration 6265, the loss is 4.44237464270913, parameters k is 10.306942110198268 and b is -42.1055508075553\n",
      "Iteration 6266, the loss is 4.44237462693475, parameters k is 10.306941720870205 and b is -42.10554685498613\n",
      "Iteration 6267, the loss is 4.44237461116037, parameters k is 10.306941331542141 and b is -42.10554290241696\n",
      "Iteration 6268, the loss is 4.442374595385992, parameters k is 10.306940942214078 and b is -42.105538949847784\n",
      "Iteration 6269, the loss is 4.442374579611612, parameters k is 10.306940552886015 and b is -42.10553499727861\n",
      "Iteration 6270, the loss is 4.44237456383723, parameters k is 10.306940163557952 and b is -42.10553104470944\n",
      "Iteration 6271, the loss is 4.442374548062854, parameters k is 10.306939774229889 and b is -42.105527092140264\n",
      "Iteration 6272, the loss is 4.442374532288476, parameters k is 10.306939384901826 and b is -42.10552313957109\n",
      "Iteration 6273, the loss is 4.442374516514096, parameters k is 10.306938995573763 and b is -42.10551918700192\n",
      "Iteration 6274, the loss is 4.442374500739714, parameters k is 10.3069386062457 and b is -42.105515234432744\n",
      "Iteration 6275, the loss is 4.442374484965336, parameters k is 10.306938216917636 and b is -42.10551128186357\n",
      "Iteration 6276, the loss is 4.442374469190955, parameters k is 10.306937827589573 and b is -42.1055073292944\n",
      "Iteration 6277, the loss is 4.442374453416578, parameters k is 10.30693743826151 and b is -42.105503376725224\n",
      "Iteration 6278, the loss is 4.442374437642201, parameters k is 10.306937048933447 and b is -42.10549942415605\n",
      "Iteration 6279, the loss is 4.442374421867818, parameters k is 10.306936659605384 and b is -42.10549547158688\n",
      "Iteration 6280, the loss is 4.442374406093436, parameters k is 10.30693627027732 and b is -42.105491519017704\n",
      "Iteration 6281, the loss is 4.442374390319059, parameters k is 10.306935880949258 and b is -42.10548756644853\n",
      "Iteration 6282, the loss is 4.442374374544684, parameters k is 10.306935491621195 and b is -42.10548361387936\n",
      "Iteration 6283, the loss is 4.4423743587703, parameters k is 10.306935102293131 and b is -42.105479661310184\n",
      "Iteration 6284, the loss is 4.44237434299592, parameters k is 10.306934712965068 and b is -42.10547570874101\n",
      "Iteration 6285, the loss is 4.442374327221541, parameters k is 10.306934323637005 and b is -42.10547175617184\n",
      "Iteration 6286, the loss is 4.442374311447162, parameters k is 10.306933934308942 and b is -42.105467803602664\n",
      "Iteration 6287, the loss is 4.442374295672782, parameters k is 10.306933544980879 and b is -42.10546385103349\n",
      "Iteration 6288, the loss is 4.442374279898403, parameters k is 10.306933155652816 and b is -42.10545989846432\n",
      "Iteration 6289, the loss is 4.442374264124028, parameters k is 10.306932766324753 and b is -42.105455945895145\n",
      "Iteration 6290, the loss is 4.442374248349643, parameters k is 10.30693237699669 and b is -42.10545199332597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6291, the loss is 4.442374232575268, parameters k is 10.306931987668627 and b is -42.1054480407568\n",
      "Iteration 6292, the loss is 4.442374216800884, parameters k is 10.306931598340563 and b is -42.105444088187625\n",
      "Iteration 6293, the loss is 4.4423742010265075, parameters k is 10.3069312090125 and b is -42.10544013561845\n",
      "Iteration 6294, the loss is 4.4423741852521275, parameters k is 10.306930819684437 and b is -42.10543618304928\n",
      "Iteration 6295, the loss is 4.4423741694777465, parameters k is 10.306930430356374 and b is -42.105432230480105\n",
      "Iteration 6296, the loss is 4.442374153703369, parameters k is 10.306930041028311 and b is -42.10542827791093\n",
      "Iteration 6297, the loss is 4.44237413792899, parameters k is 10.306929651700248 and b is -42.10542432534176\n",
      "Iteration 6298, the loss is 4.442374122154609, parameters k is 10.306929262372185 and b is -42.105420372772585\n",
      "Iteration 6299, the loss is 4.44237410638023, parameters k is 10.306928873044122 and b is -42.10541642020341\n",
      "Iteration 6300, the loss is 4.442374090605851, parameters k is 10.306928483716058 and b is -42.10541246763424\n",
      "Iteration 6301, the loss is 4.4423740748314735, parameters k is 10.306928094387995 and b is -42.105408515065065\n",
      "Iteration 6302, the loss is 4.442374059057092, parameters k is 10.306927705059932 and b is -42.10540456249589\n",
      "Iteration 6303, the loss is 4.442374043282715, parameters k is 10.306927315731869 and b is -42.10540060992672\n",
      "Iteration 6304, the loss is 4.442374027508333, parameters k is 10.306926926403806 and b is -42.105396657357545\n",
      "Iteration 6305, the loss is 4.442374011733953, parameters k is 10.306926537075743 and b is -42.10539270478837\n",
      "Iteration 6306, the loss is 4.442373995959574, parameters k is 10.30692614774768 and b is -42.1053887522192\n",
      "Iteration 6307, the loss is 4.442373980185193, parameters k is 10.306925758419617 and b is -42.105384799650025\n",
      "Iteration 6308, the loss is 4.442373964410816, parameters k is 10.306925369091553 and b is -42.10538084708085\n",
      "Iteration 6309, the loss is 4.442373948636436, parameters k is 10.30692497976349 and b is -42.10537689451168\n",
      "Iteration 6310, the loss is 4.442373932862058, parameters k is 10.306924590435427 and b is -42.105372941942505\n",
      "Iteration 6311, the loss is 4.442373917087679, parameters k is 10.306924201107364 and b is -42.10536898937333\n",
      "Iteration 6312, the loss is 4.442373901313299, parameters k is 10.306923811779301 and b is -42.10536503680416\n",
      "Iteration 6313, the loss is 4.442373885538919, parameters k is 10.306923422451238 and b is -42.105361084234985\n",
      "Iteration 6314, the loss is 4.442373869764537, parameters k is 10.306923033123175 and b is -42.10535713166581\n",
      "Iteration 6315, the loss is 4.442373853990159, parameters k is 10.306922643795112 and b is -42.10535317909664\n",
      "Iteration 6316, the loss is 4.442373838215781, parameters k is 10.306922254467048 and b is -42.105349226527466\n",
      "Iteration 6317, the loss is 4.442373822441402, parameters k is 10.306921865138985 and b is -42.10534527395829\n",
      "Iteration 6318, the loss is 4.442373806667021, parameters k is 10.306921475810922 and b is -42.10534132138912\n",
      "Iteration 6319, the loss is 4.442373790892644, parameters k is 10.306921086482859 and b is -42.105337368819946\n",
      "Iteration 6320, the loss is 4.442373775118263, parameters k is 10.306920697154796 and b is -42.10533341625077\n",
      "Iteration 6321, the loss is 4.442373759343885, parameters k is 10.306920307826733 and b is -42.1053294636816\n",
      "Iteration 6322, the loss is 4.442373743569506, parameters k is 10.30691991849867 and b is -42.105325511112426\n",
      "Iteration 6323, the loss is 4.4423737277951245, parameters k is 10.306919529170607 and b is -42.10532155854325\n",
      "Iteration 6324, the loss is 4.442373712020745, parameters k is 10.306919139842543 and b is -42.10531760597408\n",
      "Iteration 6325, the loss is 4.442373696246367, parameters k is 10.30691875051448 and b is -42.105313653404906\n",
      "Iteration 6326, the loss is 4.442373680471988, parameters k is 10.306918361186417 and b is -42.10530970083573\n",
      "Iteration 6327, the loss is 4.442373664697605, parameters k is 10.306917971858354 and b is -42.10530574826656\n",
      "Iteration 6328, the loss is 4.442373648923227, parameters k is 10.306917582530291 and b is -42.105301795697386\n",
      "Iteration 6329, the loss is 4.44237363314885, parameters k is 10.306917193202228 and b is -42.10529784312821\n",
      "Iteration 6330, the loss is 4.442373617374469, parameters k is 10.306916803874165 and b is -42.10529389055904\n",
      "Iteration 6331, the loss is 4.44237360160009, parameters k is 10.306916414546102 and b is -42.105289937989866\n",
      "Iteration 6332, the loss is 4.44237358582571, parameters k is 10.306916025218039 and b is -42.10528598542069\n",
      "Iteration 6333, the loss is 4.442373570051331, parameters k is 10.306915635889975 and b is -42.10528203285152\n",
      "Iteration 6334, the loss is 4.4423735542769505, parameters k is 10.306915246561912 and b is -42.105278080282346\n",
      "Iteration 6335, the loss is 4.442373538502571, parameters k is 10.30691485723385 and b is -42.10527412771317\n",
      "Iteration 6336, the loss is 4.442373522728192, parameters k is 10.306914467905786 and b is -42.105270175144\n",
      "Iteration 6337, the loss is 4.442373506953814, parameters k is 10.306914078577723 and b is -42.105266222574826\n",
      "Iteration 6338, the loss is 4.442373491179435, parameters k is 10.30691368924966 and b is -42.10526227000565\n",
      "Iteration 6339, the loss is 4.442373475405055, parameters k is 10.306913299921597 and b is -42.10525831743648\n",
      "Iteration 6340, the loss is 4.442373459630676, parameters k is 10.306912910593534 and b is -42.10525436486731\n",
      "Iteration 6341, the loss is 4.4423734438562965, parameters k is 10.30691252126547 and b is -42.10525041229813\n",
      "Iteration 6342, the loss is 4.442373428081914, parameters k is 10.306912131937407 and b is -42.10524645972896\n",
      "Iteration 6343, the loss is 4.4423734123075365, parameters k is 10.306911742609344 and b is -42.10524250715979\n",
      "Iteration 6344, the loss is 4.442373396533156, parameters k is 10.306911353281281 and b is -42.10523855459061\n",
      "Iteration 6345, the loss is 4.4423733807587755, parameters k is 10.306910963953218 and b is -42.10523460202144\n",
      "Iteration 6346, the loss is 4.442373364984397, parameters k is 10.306910574625155 and b is -42.10523064945227\n",
      "Iteration 6347, the loss is 4.442373349210021, parameters k is 10.306910185297092 and b is -42.10522669688309\n",
      "Iteration 6348, the loss is 4.442373333435641, parameters k is 10.306909795969029 and b is -42.10522274431392\n",
      "Iteration 6349, the loss is 4.44237331766126, parameters k is 10.306909406640965 and b is -42.10521879174475\n",
      "Iteration 6350, the loss is 4.442373301886881, parameters k is 10.306909017312902 and b is -42.105214839175574\n",
      "Iteration 6351, the loss is 4.442373286112502, parameters k is 10.30690862798484 and b is -42.1052108866064\n",
      "Iteration 6352, the loss is 4.4423732703381225, parameters k is 10.306908238656776 and b is -42.10520693403723\n",
      "Iteration 6353, the loss is 4.44237325456374, parameters k is 10.306907849328713 and b is -42.105202981468054\n",
      "Iteration 6354, the loss is 4.442373238789362, parameters k is 10.30690746000065 and b is -42.10519902889888\n",
      "Iteration 6355, the loss is 4.442373223014987, parameters k is 10.306907070672587 and b is -42.10519507632971\n",
      "Iteration 6356, the loss is 4.442373207240605, parameters k is 10.306906681344524 and b is -42.105191123760534\n",
      "Iteration 6357, the loss is 4.442373191466228, parameters k is 10.30690629201646 and b is -42.10518717119136\n",
      "Iteration 6358, the loss is 4.442373175691846, parameters k is 10.306905902688397 and b is -42.10518321862219\n",
      "Iteration 6359, the loss is 4.442373159917469, parameters k is 10.306905513360334 and b is -42.105179266053014\n",
      "Iteration 6360, the loss is 4.442373144143087, parameters k is 10.306905124032271 and b is -42.10517531348384\n",
      "Iteration 6361, the loss is 4.442373128368707, parameters k is 10.306904734704208 and b is -42.10517136091467\n",
      "Iteration 6362, the loss is 4.442373112594326, parameters k is 10.306904345376145 and b is -42.105167408345494\n",
      "Iteration 6363, the loss is 4.442373096819949, parameters k is 10.306903956048082 and b is -42.10516345577632\n",
      "Iteration 6364, the loss is 4.44237308104557, parameters k is 10.306903566720019 and b is -42.10515950320715\n",
      "Iteration 6365, the loss is 4.442373065271189, parameters k is 10.306903177391955 and b is -42.105155550637974\n",
      "Iteration 6366, the loss is 4.44237304949681, parameters k is 10.306902788063892 and b is -42.1051515980688\n",
      "Iteration 6367, the loss is 4.442373033722431, parameters k is 10.30690239873583 and b is -42.10514764549963\n",
      "Iteration 6368, the loss is 4.442373017948053, parameters k is 10.306902009407766 and b is -42.105143692930454\n",
      "Iteration 6369, the loss is 4.442373002173671, parameters k is 10.306901620079703 and b is -42.10513974036128\n",
      "Iteration 6370, the loss is 4.442372986399295, parameters k is 10.30690123075164 and b is -42.10513578779211\n",
      "Iteration 6371, the loss is 4.442372970624911, parameters k is 10.306900841423577 and b is -42.105131835222934\n",
      "Iteration 6372, the loss is 4.442372954850531, parameters k is 10.306900452095514 and b is -42.10512788265376\n",
      "Iteration 6373, the loss is 4.442372939076156, parameters k is 10.30690006276745 and b is -42.10512393008459\n",
      "Iteration 6374, the loss is 4.442372923301777, parameters k is 10.306899673439387 and b is -42.105119977515415\n",
      "Iteration 6375, the loss is 4.442372907527395, parameters k is 10.306899284111324 and b is -42.10511602494624\n",
      "Iteration 6376, the loss is 4.442372891753017, parameters k is 10.306898894783261 and b is -42.10511207237707\n",
      "Iteration 6377, the loss is 4.442372875978639, parameters k is 10.306898505455198 and b is -42.105108119807895\n",
      "Iteration 6378, the loss is 4.442372860204257, parameters k is 10.306898116127135 and b is -42.10510416723872\n",
      "Iteration 6379, the loss is 4.44237284442988, parameters k is 10.306897726799072 and b is -42.10510021466955\n",
      "Iteration 6380, the loss is 4.4423728286554995, parameters k is 10.306897337471009 and b is -42.105096262100375\n",
      "Iteration 6381, the loss is 4.442372812881119, parameters k is 10.306896948142946 and b is -42.1050923095312\n",
      "Iteration 6382, the loss is 4.44237279710674, parameters k is 10.306896558814882 and b is -42.10508835696203\n",
      "Iteration 6383, the loss is 4.4423727813323595, parameters k is 10.30689616948682 and b is -42.105084404392855\n",
      "Iteration 6384, the loss is 4.442372765557981, parameters k is 10.306895780158756 and b is -42.10508045182368\n",
      "Iteration 6385, the loss is 4.442372749783601, parameters k is 10.306895390830693 and b is -42.10507649925451\n",
      "Iteration 6386, the loss is 4.442372734009225, parameters k is 10.30689500150263 and b is -42.105072546685335\n",
      "Iteration 6387, the loss is 4.442372718234846, parameters k is 10.306894612174567 and b is -42.10506859411616\n",
      "Iteration 6388, the loss is 4.442372702460466, parameters k is 10.306894222846504 and b is -42.10506464154699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6389, the loss is 4.442372686686085, parameters k is 10.30689383351844 and b is -42.105060688977815\n",
      "Iteration 6390, the loss is 4.442372674685711, parameters k is 10.306893444190377 and b is -42.10505673640864\n",
      "Iteration 6391, the loss is 4.442372660054378, parameters k is 10.306865556838599 and b is -42.10505673640864\n",
      "Iteration 6392, the loss is 4.442372644279995, parameters k is 10.306865167510535 and b is -42.10505278383947\n",
      "Iteration 6393, the loss is 4.442372628505619, parameters k is 10.306864778182472 and b is -42.105048831270295\n",
      "Iteration 6394, the loss is 4.442372612731239, parameters k is 10.30686438885441 and b is -42.10504487870112\n",
      "Iteration 6395, the loss is 4.442372596956859, parameters k is 10.306863999526346 and b is -42.10504092613195\n",
      "Iteration 6396, the loss is 4.44237258118248, parameters k is 10.306863610198283 and b is -42.105036973562775\n",
      "Iteration 6397, the loss is 4.4423725654081, parameters k is 10.30686322087022 and b is -42.1050330209936\n",
      "Iteration 6398, the loss is 4.442372549633719, parameters k is 10.306862831542157 and b is -42.10502906842443\n",
      "Iteration 6399, the loss is 4.442372533859338, parameters k is 10.306862442214094 and b is -42.105025115855256\n",
      "Iteration 6400, the loss is 4.442372518084959, parameters k is 10.30686205288603 and b is -42.10502116328608\n",
      "Iteration 6401, the loss is 4.442372502310582, parameters k is 10.306861663557967 and b is -42.10501721071691\n",
      "Iteration 6402, the loss is 4.442372486536203, parameters k is 10.306861274229904 and b is -42.105013258147736\n",
      "Iteration 6403, the loss is 4.442372470761822, parameters k is 10.306860884901841 and b is -42.10500930557856\n",
      "Iteration 6404, the loss is 4.442372454987444, parameters k is 10.306860495573778 and b is -42.10500535300939\n",
      "Iteration 6405, the loss is 4.442372439213066, parameters k is 10.306860106245715 and b is -42.105001400440216\n",
      "Iteration 6406, the loss is 4.442372423438685, parameters k is 10.306859716917652 and b is -42.10499744787104\n",
      "Iteration 6407, the loss is 4.4423724076643065, parameters k is 10.306859327589589 and b is -42.10499349530187\n",
      "Iteration 6408, the loss is 4.4423723918899265, parameters k is 10.306858938261525 and b is -42.104989542732696\n",
      "Iteration 6409, the loss is 4.442372376115546, parameters k is 10.306858548933462 and b is -42.10498559016352\n",
      "Iteration 6410, the loss is 4.442372360341167, parameters k is 10.3068581596054 and b is -42.10498163759435\n",
      "Iteration 6411, the loss is 4.442372344566788, parameters k is 10.306857770277336 and b is -42.104977685025176\n",
      "Iteration 6412, the loss is 4.442372328792408, parameters k is 10.306857380949273 and b is -42.104973732456\n",
      "Iteration 6413, the loss is 4.442372313018028, parameters k is 10.30685699162121 and b is -42.10496977988683\n",
      "Iteration 6414, the loss is 4.44237229724365, parameters k is 10.306856602293147 and b is -42.104965827317656\n",
      "Iteration 6415, the loss is 4.4423722814692725, parameters k is 10.306856212965084 and b is -42.10496187474848\n",
      "Iteration 6416, the loss is 4.4423722656948925, parameters k is 10.30685582363702 and b is -42.10495792217931\n",
      "Iteration 6417, the loss is 4.442372249920512, parameters k is 10.306855434308957 and b is -42.104953969610136\n",
      "Iteration 6418, the loss is 4.442372234146133, parameters k is 10.306855044980894 and b is -42.10495001704096\n",
      "Iteration 6419, the loss is 4.442372218371753, parameters k is 10.306854655652831 and b is -42.10494606447179\n",
      "Iteration 6420, the loss is 4.442372202597371, parameters k is 10.306854266324768 and b is -42.104942111902616\n",
      "Iteration 6421, the loss is 4.442372186822996, parameters k is 10.306853876996705 and b is -42.10493815933344\n",
      "Iteration 6422, the loss is 4.442372171048614, parameters k is 10.306853487668642 and b is -42.10493420676427\n",
      "Iteration 6423, the loss is 4.442372155274232, parameters k is 10.306853098340579 and b is -42.1049302541951\n",
      "Iteration 6424, the loss is 4.442372139499855, parameters k is 10.306852709012515 and b is -42.10492630162592\n",
      "Iteration 6425, the loss is 4.4423721237254785, parameters k is 10.306852319684452 and b is -42.10492234905675\n",
      "Iteration 6426, the loss is 4.442372107951096, parameters k is 10.30685193035639 and b is -42.10491839648758\n",
      "Iteration 6427, the loss is 4.442372092176716, parameters k is 10.306851541028326 and b is -42.1049144439184\n",
      "Iteration 6428, the loss is 4.442372076402338, parameters k is 10.306851151700263 and b is -42.10491049134923\n",
      "Iteration 6429, the loss is 4.442372060627959, parameters k is 10.3068507623722 and b is -42.10490653878006\n",
      "Iteration 6430, the loss is 4.442372044853578, parameters k is 10.306850373044137 and b is -42.10490258621088\n",
      "Iteration 6431, the loss is 4.442372029079201, parameters k is 10.306849983716074 and b is -42.10489863364171\n",
      "Iteration 6432, the loss is 4.442372013304822, parameters k is 10.30684959438801 and b is -42.10489468107254\n",
      "Iteration 6433, the loss is 4.442371997530441, parameters k is 10.306849205059947 and b is -42.104890728503364\n",
      "Iteration 6434, the loss is 4.442371981756064, parameters k is 10.306848815731884 and b is -42.10488677593419\n",
      "Iteration 6435, the loss is 4.442371965981683, parameters k is 10.306848426403821 and b is -42.10488282336502\n",
      "Iteration 6436, the loss is 4.4423719502073045, parameters k is 10.306848037075758 and b is -42.104878870795844\n",
      "Iteration 6437, the loss is 4.442371934432924, parameters k is 10.306847647747695 and b is -42.10487491822667\n",
      "Iteration 6438, the loss is 4.442371918658543, parameters k is 10.306847258419632 and b is -42.1048709656575\n",
      "Iteration 6439, the loss is 4.442371902884166, parameters k is 10.306846869091569 and b is -42.104867013088324\n",
      "Iteration 6440, the loss is 4.442371887109787, parameters k is 10.306846479763506 and b is -42.10486306051915\n",
      "Iteration 6441, the loss is 4.442371871335409, parameters k is 10.306846090435442 and b is -42.10485910794998\n",
      "Iteration 6442, the loss is 4.442371855561028, parameters k is 10.30684570110738 and b is -42.104855155380804\n",
      "Iteration 6443, the loss is 4.442371839786648, parameters k is 10.306845311779316 and b is -42.10485120281163\n",
      "Iteration 6444, the loss is 4.44237182401227, parameters k is 10.306844922451253 and b is -42.10484725024246\n",
      "Iteration 6445, the loss is 4.442371808237889, parameters k is 10.30684453312319 and b is -42.104843297673284\n",
      "Iteration 6446, the loss is 4.44237179246351, parameters k is 10.306844143795127 and b is -42.10483934510411\n",
      "Iteration 6447, the loss is 4.4423717766891295, parameters k is 10.306843754467064 and b is -42.10483539253494\n",
      "Iteration 6448, the loss is 4.442371760914751, parameters k is 10.306843365139 and b is -42.104831439965764\n",
      "Iteration 6449, the loss is 4.442371745140371, parameters k is 10.306842975810937 and b is -42.10482748739659\n",
      "Iteration 6450, the loss is 4.442371729365994, parameters k is 10.306842586482874 and b is -42.10482353482742\n",
      "Iteration 6451, the loss is 4.442371713591613, parameters k is 10.306842197154811 and b is -42.104819582258244\n",
      "Iteration 6452, the loss is 4.442371697817232, parameters k is 10.306841807826748 and b is -42.10481562968907\n",
      "Iteration 6453, the loss is 4.442371682042852, parameters k is 10.306841418498685 and b is -42.1048116771199\n",
      "Iteration 6454, the loss is 4.442371666268473, parameters k is 10.306841029170622 and b is -42.104807724550724\n",
      "Iteration 6455, the loss is 4.442371650494095, parameters k is 10.306840639842559 and b is -42.10480377198155\n",
      "Iteration 6456, the loss is 4.4423716347197155, parameters k is 10.306840250514496 and b is -42.10479981941238\n",
      "Iteration 6457, the loss is 4.442371618945334, parameters k is 10.306839861186432 and b is -42.104795866843205\n",
      "Iteration 6458, the loss is 4.442371603170957, parameters k is 10.30683947185837 and b is -42.10479191427403\n",
      "Iteration 6459, the loss is 4.442371587396578, parameters k is 10.306839082530306 and b is -42.10478796170486\n",
      "Iteration 6460, the loss is 4.442371571622198, parameters k is 10.306838693202243 and b is -42.104784009135685\n",
      "Iteration 6461, the loss is 4.442371555847818, parameters k is 10.30683830387418 and b is -42.10478005656651\n",
      "Iteration 6462, the loss is 4.442371540073439, parameters k is 10.306837914546117 and b is -42.10477610399734\n",
      "Iteration 6463, the loss is 4.442371524299059, parameters k is 10.306837525218054 and b is -42.104772151428165\n",
      "Iteration 6464, the loss is 4.44237150852468, parameters k is 10.30683713588999 and b is -42.10476819885899\n",
      "Iteration 6465, the loss is 4.4423714927503015, parameters k is 10.306836746561927 and b is -42.10476424628982\n",
      "Iteration 6466, the loss is 4.4423714769759215, parameters k is 10.306836357233864 and b is -42.104760293720645\n",
      "Iteration 6467, the loss is 4.442371461201542, parameters k is 10.306835967905801 and b is -42.10475634115147\n",
      "Iteration 6468, the loss is 4.442371445427165, parameters k is 10.306835578577738 and b is -42.1047523885823\n",
      "Iteration 6469, the loss is 4.442371429652782, parameters k is 10.306835189249675 and b is -42.104748436013125\n",
      "Iteration 6470, the loss is 4.442371413878405, parameters k is 10.306834799921612 and b is -42.10474448344395\n",
      "Iteration 6471, the loss is 4.442371398104025, parameters k is 10.306834410593549 and b is -42.10474053087478\n",
      "Iteration 6472, the loss is 4.442371382329645, parameters k is 10.306834021265486 and b is -42.104736578305605\n",
      "Iteration 6473, the loss is 4.442371366555267, parameters k is 10.306833631937423 and b is -42.10473262573643\n",
      "Iteration 6474, the loss is 4.442371350780887, parameters k is 10.30683324260936 and b is -42.10472867316726\n",
      "Iteration 6475, the loss is 4.442371335006507, parameters k is 10.306832853281296 and b is -42.104724720598085\n",
      "Iteration 6476, the loss is 4.44237131923213, parameters k is 10.306832463953233 and b is -42.10472076802891\n",
      "Iteration 6477, the loss is 4.44237130345775, parameters k is 10.30683207462517 and b is -42.10471681545974\n",
      "Iteration 6478, the loss is 4.442371287683368, parameters k is 10.306831685297107 and b is -42.104712862890565\n",
      "Iteration 6479, the loss is 4.442371271908989, parameters k is 10.306831295969044 and b is -42.10470891032139\n",
      "Iteration 6480, the loss is 4.442371256134609, parameters k is 10.30683090664098 and b is -42.10470495775222\n",
      "Iteration 6481, the loss is 4.442371240360232, parameters k is 10.306830517312918 and b is -42.104701005183045\n",
      "Iteration 6482, the loss is 4.442371224585851, parameters k is 10.306830127984854 and b is -42.10469705261387\n",
      "Iteration 6483, the loss is 4.442371208811471, parameters k is 10.306829738656791 and b is -42.1046931000447\n",
      "Iteration 6484, the loss is 4.442371193037092, parameters k is 10.306829349328728 and b is -42.104689147475526\n",
      "Iteration 6485, the loss is 4.442371177262714, parameters k is 10.306828960000665 and b is -42.10468519490635\n",
      "Iteration 6486, the loss is 4.442371161488333, parameters k is 10.306828570672602 and b is -42.10468124233718\n",
      "Iteration 6487, the loss is 4.442371145713955, parameters k is 10.306828181344539 and b is -42.104677289768006\n",
      "Iteration 6488, the loss is 4.442371129939575, parameters k is 10.306827792016476 and b is -42.10467333719883\n",
      "Iteration 6489, the loss is 4.442371114165196, parameters k is 10.306827402688413 and b is -42.10466938462966\n",
      "Iteration 6490, the loss is 4.442371098390814, parameters k is 10.30682701336035 and b is -42.104665432060486\n",
      "Iteration 6491, the loss is 4.442371082616438, parameters k is 10.306826624032286 and b is -42.10466147949131\n",
      "Iteration 6492, the loss is 4.442371066842057, parameters k is 10.306826234704223 and b is -42.10465752692214\n",
      "Iteration 6493, the loss is 4.442371051067677, parameters k is 10.30682584537616 and b is -42.104653574352966\n",
      "Iteration 6494, the loss is 4.442371035293298, parameters k is 10.306825456048097 and b is -42.10464962178379\n",
      "Iteration 6495, the loss is 4.442371019518919, parameters k is 10.306825066720034 and b is -42.10464566921462\n",
      "Iteration 6496, the loss is 4.442371003744541, parameters k is 10.30682467739197 and b is -42.104641716645446\n",
      "Iteration 6497, the loss is 4.44237098797016, parameters k is 10.306824288063908 and b is -42.10463776407627\n",
      "Iteration 6498, the loss is 4.44237097219578, parameters k is 10.306823898735844 and b is -42.1046338115071\n",
      "Iteration 6499, the loss is 4.442370956421401, parameters k is 10.306823509407781 and b is -42.104629858937926\n",
      "Iteration 6500, the loss is 4.442370940647021, parameters k is 10.306823120079718 and b is -42.10462590636875\n",
      "Iteration 6501, the loss is 4.442370924872645, parameters k is 10.306822730751655 and b is -42.10462195379958\n",
      "Iteration 6502, the loss is 4.442370909098261, parameters k is 10.306822341423592 and b is -42.104618001230406\n",
      "Iteration 6503, the loss is 4.442370893323884, parameters k is 10.306821952095529 and b is -42.10461404866123\n",
      "Iteration 6504, the loss is 4.4423708775495045, parameters k is 10.306821562767466 and b is -42.10461009609206\n",
      "Iteration 6505, the loss is 4.442370861775126, parameters k is 10.306821173439403 and b is -42.104606143522886\n",
      "Iteration 6506, the loss is 4.442370846000747, parameters k is 10.30682078411134 and b is -42.10460219095371\n",
      "Iteration 6507, the loss is 4.442370830226367, parameters k is 10.306820394783276 and b is -42.10459823838454\n",
      "Iteration 6508, the loss is 4.442370814451985, parameters k is 10.306820005455213 and b is -42.10459428581537\n",
      "Iteration 6509, the loss is 4.442370798677607, parameters k is 10.30681961612715 and b is -42.10459033324619\n",
      "Iteration 6510, the loss is 4.442370782903227, parameters k is 10.306819226799087 and b is -42.10458638067702\n",
      "Iteration 6511, the loss is 4.44237076712885, parameters k is 10.306818837471024 and b is -42.10458242810785\n",
      "Iteration 6512, the loss is 4.442370751354469, parameters k is 10.30681844814296 and b is -42.10457847553867\n",
      "Iteration 6513, the loss is 4.44237073558009, parameters k is 10.306818058814898 and b is -42.1045745229695\n",
      "Iteration 6514, the loss is 4.442370719805709, parameters k is 10.306817669486835 and b is -42.10457057040033\n",
      "Iteration 6515, the loss is 4.442370704031332, parameters k is 10.306817280158771 and b is -42.10456661783115\n",
      "Iteration 6516, the loss is 4.442370688256952, parameters k is 10.306816890830708 and b is -42.10456266526198\n",
      "Iteration 6517, the loss is 4.442370672482573, parameters k is 10.306816501502645 and b is -42.10455871269281\n",
      "Iteration 6518, the loss is 4.442370656708191, parameters k is 10.306816112174582 and b is -42.104554760123634\n",
      "Iteration 6519, the loss is 4.442370640933814, parameters k is 10.306815722846519 and b is -42.10455080755446\n",
      "Iteration 6520, the loss is 4.442370625159434, parameters k is 10.306815333518456 and b is -42.10454685498529\n",
      "Iteration 6521, the loss is 4.442370609385054, parameters k is 10.306814944190393 and b is -42.104542902416114\n",
      "Iteration 6522, the loss is 4.442370593610674, parameters k is 10.30681455486233 and b is -42.10453894984694\n",
      "Iteration 6523, the loss is 4.442370577836293, parameters k is 10.306814165534266 and b is -42.10453499727777\n",
      "Iteration 6524, the loss is 4.442370562061918, parameters k is 10.306813776206203 and b is -42.104531044708594\n",
      "Iteration 6525, the loss is 4.442370546287539, parameters k is 10.30681338687814 and b is -42.10452709213942\n",
      "Iteration 6526, the loss is 4.442370530513158, parameters k is 10.306812997550077 and b is -42.10452313957025\n",
      "Iteration 6527, the loss is 4.442370514738778, parameters k is 10.306812608222014 and b is -42.104519187001074\n",
      "Iteration 6528, the loss is 4.442370498964398, parameters k is 10.30681221889395 and b is -42.1045152344319\n",
      "Iteration 6529, the loss is 4.44237048319002, parameters k is 10.306811829565888 and b is -42.10451128186273\n",
      "Iteration 6530, the loss is 4.442370467415637, parameters k is 10.306811440237825 and b is -42.104507329293554\n",
      "Iteration 6531, the loss is 4.442370451641261, parameters k is 10.306811050909761 and b is -42.10450337672438\n",
      "Iteration 6532, the loss is 4.442370435866882, parameters k is 10.306810661581698 and b is -42.10449942415521\n",
      "Iteration 6533, the loss is 4.442370420092502, parameters k is 10.306810272253635 and b is -42.104495471586034\n",
      "Iteration 6534, the loss is 4.442370404318123, parameters k is 10.306809882925572 and b is -42.10449151901686\n",
      "Iteration 6535, the loss is 4.442370388543742, parameters k is 10.306809493597509 and b is -42.10448756644769\n",
      "Iteration 6536, the loss is 4.442370372769363, parameters k is 10.306809104269446 and b is -42.104483613878514\n",
      "Iteration 6537, the loss is 4.442370356994984, parameters k is 10.306808714941383 and b is -42.10447966130934\n",
      "Iteration 6538, the loss is 4.442370341220603, parameters k is 10.30680832561332 and b is -42.10447570874017\n",
      "Iteration 6539, the loss is 4.442370325446226, parameters k is 10.306807936285256 and b is -42.104471756170994\n",
      "Iteration 6540, the loss is 4.442370309671846, parameters k is 10.306807546957193 and b is -42.10446780360182\n",
      "Iteration 6541, the loss is 4.442370293897466, parameters k is 10.30680715762913 and b is -42.10446385103265\n",
      "Iteration 6542, the loss is 4.442370278123084, parameters k is 10.306806768301067 and b is -42.104459898463475\n",
      "Iteration 6543, the loss is 4.442370262348708, parameters k is 10.306806378973004 and b is -42.1044559458943\n",
      "Iteration 6544, the loss is 4.442370246574328, parameters k is 10.30680598964494 and b is -42.10445199332513\n",
      "Iteration 6545, the loss is 4.442370230799949, parameters k is 10.306805600316878 and b is -42.104448040755955\n",
      "Iteration 6546, the loss is 4.442370215025572, parameters k is 10.306805210988815 and b is -42.10444408818678\n",
      "Iteration 6547, the loss is 4.4423702032380525, parameters k is 10.306804821660752 and b is -42.10444013561761\n",
      "Iteration 6548, the loss is 4.442370188393863, parameters k is 10.306776934308973 and b is -42.10444013561761\n",
      "Iteration 6549, the loss is 4.442370172619484, parameters k is 10.30677654498091 and b is -42.104436183048435\n",
      "Iteration 6550, the loss is 4.4423701568451035, parameters k is 10.306776155652846 and b is -42.10443223047926\n",
      "Iteration 6551, the loss is 4.442370141070727, parameters k is 10.306775766324783 and b is -42.10442827791009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6552, the loss is 4.4423701252963435, parameters k is 10.30677537699672 and b is -42.104424325340915\n",
      "Iteration 6553, the loss is 4.442370109521963, parameters k is 10.306774987668657 and b is -42.10442037277174\n",
      "Iteration 6554, the loss is 4.442370093747585, parameters k is 10.306774598340594 and b is -42.10441642020257\n",
      "Iteration 6555, the loss is 4.442370077973204, parameters k is 10.30677420901253 and b is -42.104412467633395\n",
      "Iteration 6556, the loss is 4.442370062198827, parameters k is 10.306773819684468 and b is -42.10440851506422\n",
      "Iteration 6557, the loss is 4.442370046424448, parameters k is 10.306773430356404 and b is -42.10440456249505\n",
      "Iteration 6558, the loss is 4.44237003065007, parameters k is 10.306773041028341 and b is -42.104400609925875\n",
      "Iteration 6559, the loss is 4.442370014875688, parameters k is 10.306772651700278 and b is -42.1043966573567\n",
      "Iteration 6560, the loss is 4.44236999910131, parameters k is 10.306772262372215 and b is -42.10439270478753\n",
      "Iteration 6561, the loss is 4.44236998332693, parameters k is 10.306771873044152 and b is -42.104388752218355\n",
      "Iteration 6562, the loss is 4.442369967552551, parameters k is 10.306771483716089 and b is -42.10438479964918\n",
      "Iteration 6563, the loss is 4.442369951778172, parameters k is 10.306771094388026 and b is -42.10438084708001\n",
      "Iteration 6564, the loss is 4.442369936003791, parameters k is 10.306770705059963 and b is -42.104376894510835\n",
      "Iteration 6565, the loss is 4.442369920229413, parameters k is 10.3067703157319 and b is -42.10437294194166\n",
      "Iteration 6566, the loss is 4.442369904455033, parameters k is 10.306769926403836 and b is -42.10436898937249\n",
      "Iteration 6567, the loss is 4.442369888680653, parameters k is 10.306769537075773 and b is -42.104365036803316\n",
      "Iteration 6568, the loss is 4.442369872906275, parameters k is 10.30676914774771 and b is -42.10436108423414\n",
      "Iteration 6569, the loss is 4.442369857131897, parameters k is 10.306768758419647 and b is -42.10435713166497\n",
      "Iteration 6570, the loss is 4.442369841357514, parameters k is 10.306768369091584 and b is -42.104353179095796\n",
      "Iteration 6571, the loss is 4.4423698255831345, parameters k is 10.30676797976352 and b is -42.10434922652662\n",
      "Iteration 6572, the loss is 4.442369809808755, parameters k is 10.306767590435458 and b is -42.10434527395745\n",
      "Iteration 6573, the loss is 4.442369794034375, parameters k is 10.306767201107395 and b is -42.104341321388276\n",
      "Iteration 6574, the loss is 4.442369778259997, parameters k is 10.306766811779331 and b is -42.1043373688191\n",
      "Iteration 6575, the loss is 4.442369762485618, parameters k is 10.306766422451268 and b is -42.10433341624993\n",
      "Iteration 6576, the loss is 4.44236974671124, parameters k is 10.306766033123205 and b is -42.104329463680756\n",
      "Iteration 6577, the loss is 4.442369730936859, parameters k is 10.306765643795142 and b is -42.10432551111158\n",
      "Iteration 6578, the loss is 4.442369715162479, parameters k is 10.306765254467079 and b is -42.10432155854241\n",
      "Iteration 6579, the loss is 4.442369699388101, parameters k is 10.306764865139016 and b is -42.104317605973236\n",
      "Iteration 6580, the loss is 4.442369683613719, parameters k is 10.306764475810953 and b is -42.10431365340406\n",
      "Iteration 6581, the loss is 4.442369667839341, parameters k is 10.30676408648289 and b is -42.10430970083489\n",
      "Iteration 6582, the loss is 4.442369652064964, parameters k is 10.306763697154826 and b is -42.104305748265716\n",
      "Iteration 6583, the loss is 4.442369636290584, parameters k is 10.306763307826763 and b is -42.10430179569654\n",
      "Iteration 6584, the loss is 4.442369620516203, parameters k is 10.3067629184987 and b is -42.10429784312737\n",
      "Iteration 6585, the loss is 4.442369604741826, parameters k is 10.306762529170637 and b is -42.104293890558196\n",
      "Iteration 6586, the loss is 4.442369588967443, parameters k is 10.306762139842574 and b is -42.10428993798902\n",
      "Iteration 6587, the loss is 4.442369573193065, parameters k is 10.30676175051451 and b is -42.10428598541985\n",
      "Iteration 6588, the loss is 4.4423695574186866, parameters k is 10.306761361186448 and b is -42.104282032850676\n",
      "Iteration 6589, the loss is 4.442369541644307, parameters k is 10.306760971858385 and b is -42.1042780802815\n",
      "Iteration 6590, the loss is 4.4423695258699265, parameters k is 10.306760582530321 and b is -42.10427412771233\n",
      "Iteration 6591, the loss is 4.442369510095547, parameters k is 10.306760193202258 and b is -42.10427017514316\n",
      "Iteration 6592, the loss is 4.4423694943211665, parameters k is 10.306759803874195 and b is -42.10426622257398\n",
      "Iteration 6593, the loss is 4.442369478546786, parameters k is 10.306759414546132 and b is -42.10426227000481\n",
      "Iteration 6594, the loss is 4.442369462772407, parameters k is 10.306759025218069 and b is -42.10425831743564\n",
      "Iteration 6595, the loss is 4.442369446998032, parameters k is 10.306758635890006 and b is -42.10425436486646\n",
      "Iteration 6596, the loss is 4.442369431223651, parameters k is 10.306758246561943 and b is -42.10425041229729\n",
      "Iteration 6597, the loss is 4.442369415449272, parameters k is 10.30675785723388 and b is -42.10424645972812\n",
      "Iteration 6598, the loss is 4.442369399674892, parameters k is 10.306757467905816 and b is -42.10424250715894\n",
      "Iteration 6599, the loss is 4.442369383900513, parameters k is 10.306757078577753 and b is -42.10423855458977\n",
      "Iteration 6600, the loss is 4.4423693681261325, parameters k is 10.30675668924969 and b is -42.1042346020206\n",
      "Iteration 6601, the loss is 4.442369352351753, parameters k is 10.306756299921627 and b is -42.104230649451424\n",
      "Iteration 6602, the loss is 4.442369336577376, parameters k is 10.306755910593564 and b is -42.10422669688225\n",
      "Iteration 6603, the loss is 4.442369320802997, parameters k is 10.3067555212655 and b is -42.10422274431308\n",
      "Iteration 6604, the loss is 4.442369305028616, parameters k is 10.306755131937438 and b is -42.104218791743904\n",
      "Iteration 6605, the loss is 4.442369289254236, parameters k is 10.306754742609375 and b is -42.10421483917473\n",
      "Iteration 6606, the loss is 4.442369273479854, parameters k is 10.306754353281312 and b is -42.10421088660556\n",
      "Iteration 6607, the loss is 4.442369257705478, parameters k is 10.306753963953248 and b is -42.104206934036384\n",
      "Iteration 6608, the loss is 4.4423692419310985, parameters k is 10.306753574625185 and b is -42.10420298146721\n",
      "Iteration 6609, the loss is 4.4423692261567185, parameters k is 10.306753185297122 and b is -42.10419902889804\n",
      "Iteration 6610, the loss is 4.442369210382338, parameters k is 10.306752795969059 and b is -42.104195076328864\n",
      "Iteration 6611, the loss is 4.4423691946079575, parameters k is 10.306752406640996 and b is -42.10419112375969\n",
      "Iteration 6612, the loss is 4.44236917883358, parameters k is 10.306752017312933 and b is -42.10418717119052\n",
      "Iteration 6613, the loss is 4.442369163059202, parameters k is 10.30675162798487 and b is -42.104183218621344\n",
      "Iteration 6614, the loss is 4.442369147284823, parameters k is 10.306751238656807 and b is -42.10417926605217\n",
      "Iteration 6615, the loss is 4.44236913151044, parameters k is 10.306750849328743 and b is -42.104175313483\n",
      "Iteration 6616, the loss is 4.442369115736063, parameters k is 10.30675046000068 and b is -42.104171360913824\n",
      "Iteration 6617, the loss is 4.442369099961683, parameters k is 10.306750070672617 and b is -42.10416740834465\n",
      "Iteration 6618, the loss is 4.442369084187303, parameters k is 10.306749681344554 and b is -42.10416345577548\n",
      "Iteration 6619, the loss is 4.4423690684129244, parameters k is 10.306749292016491 and b is -42.104159503206304\n",
      "Iteration 6620, the loss is 4.442369052638545, parameters k is 10.306748902688428 and b is -42.10415555063713\n",
      "Iteration 6621, the loss is 4.442369036864167, parameters k is 10.306748513360365 and b is -42.10415159806796\n",
      "Iteration 6622, the loss is 4.442369021089786, parameters k is 10.306748124032302 and b is -42.104147645498784\n",
      "Iteration 6623, the loss is 4.442369005315408, parameters k is 10.306747734704238 and b is -42.10414369292961\n",
      "Iteration 6624, the loss is 4.442368989541028, parameters k is 10.306747345376175 and b is -42.10413974036044\n",
      "Iteration 6625, the loss is 4.442368973766647, parameters k is 10.306746956048112 and b is -42.104135787791265\n",
      "Iteration 6626, the loss is 4.442368957992267, parameters k is 10.306746566720049 and b is -42.10413183522209\n",
      "Iteration 6627, the loss is 4.442368942217889, parameters k is 10.306746177391986 and b is -42.10412788265292\n",
      "Iteration 6628, the loss is 4.442368926443511, parameters k is 10.306745788063923 and b is -42.104123930083745\n",
      "Iteration 6629, the loss is 4.4423689106691295, parameters k is 10.30674539873586 and b is -42.10411997751457\n",
      "Iteration 6630, the loss is 4.44236889489475, parameters k is 10.306745009407797 and b is -42.1041160249454\n",
      "Iteration 6631, the loss is 4.442368879120371, parameters k is 10.306744620079733 and b is -42.104112072376225\n",
      "Iteration 6632, the loss is 4.44236886334599, parameters k is 10.30674423075167 and b is -42.10410811980705\n",
      "Iteration 6633, the loss is 4.442368847571613, parameters k is 10.306743841423607 and b is -42.10410416723788\n",
      "Iteration 6634, the loss is 4.442368831797233, parameters k is 10.306743452095544 and b is -42.104100214668705\n",
      "Iteration 6635, the loss is 4.442368816022853, parameters k is 10.306743062767481 and b is -42.10409626209953\n",
      "Iteration 6636, the loss is 4.442368800248476, parameters k is 10.306742673439418 and b is -42.10409230953036\n",
      "Iteration 6637, the loss is 4.4423687844740956, parameters k is 10.306742284111355 and b is -42.104088356961185\n",
      "Iteration 6638, the loss is 4.442368768699715, parameters k is 10.306741894783292 and b is -42.10408440439201\n",
      "Iteration 6639, the loss is 4.442368752925336, parameters k is 10.306741505455228 and b is -42.10408045182284\n",
      "Iteration 6640, the loss is 4.442368737150956, parameters k is 10.306741116127165 and b is -42.104076499253665\n",
      "Iteration 6641, the loss is 4.4423687213765755, parameters k is 10.306740726799102 and b is -42.10407254668449\n",
      "Iteration 6642, the loss is 4.442368705602197, parameters k is 10.30674033747104 and b is -42.10406859411532\n",
      "Iteration 6643, the loss is 4.442368689827818, parameters k is 10.306739948142976 and b is -42.104064641546145\n",
      "Iteration 6644, the loss is 4.44236867405344, parameters k is 10.306739558814913 and b is -42.10406068897697\n",
      "Iteration 6645, the loss is 4.442368658279058, parameters k is 10.30673916948685 and b is -42.1040567364078\n",
      "Iteration 6646, the loss is 4.44236864250468, parameters k is 10.306738780158787 and b is -42.104052783838625\n",
      "Iteration 6647, the loss is 4.442368626730301, parameters k is 10.306738390830724 and b is -42.10404883126945\n",
      "Iteration 6648, the loss is 4.442368610955922, parameters k is 10.30673800150266 and b is -42.10404487870028\n",
      "Iteration 6649, the loss is 4.442368595181541, parameters k is 10.306737612174597 and b is -42.104040926131105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6650, the loss is 4.442368579407163, parameters k is 10.306737222846534 and b is -42.10403697356193\n",
      "Iteration 6651, the loss is 4.442368563632785, parameters k is 10.306736833518471 and b is -42.10403302099276\n",
      "Iteration 6652, the loss is 4.442368547858406, parameters k is 10.306736444190408 and b is -42.104029068423586\n",
      "Iteration 6653, the loss is 4.442368532084026, parameters k is 10.306736054862345 and b is -42.10402511585441\n",
      "Iteration 6654, the loss is 4.442368516309645, parameters k is 10.306735665534282 and b is -42.10402116328524\n",
      "Iteration 6655, the loss is 4.442368500535263, parameters k is 10.306735276206219 and b is -42.104017210716066\n",
      "Iteration 6656, the loss is 4.442368484760887, parameters k is 10.306734886878155 and b is -42.10401325814689\n",
      "Iteration 6657, the loss is 4.4423684689865075, parameters k is 10.306734497550092 and b is -42.10400930557772\n",
      "Iteration 6658, the loss is 4.4423684532121275, parameters k is 10.30673410822203 and b is -42.104005353008546\n",
      "Iteration 6659, the loss is 4.442368437437749, parameters k is 10.306733718893966 and b is -42.10400140043937\n",
      "Iteration 6660, the loss is 4.442368421663368, parameters k is 10.306733329565903 and b is -42.1039974478702\n",
      "Iteration 6661, the loss is 4.442368405888989, parameters k is 10.30673294023784 and b is -42.103993495301026\n",
      "Iteration 6662, the loss is 4.442368390114611, parameters k is 10.306732550909777 and b is -42.10398954273185\n",
      "Iteration 6663, the loss is 4.442368374340231, parameters k is 10.306732161581714 and b is -42.10398559016268\n",
      "Iteration 6664, the loss is 4.442368358565849, parameters k is 10.30673177225365 and b is -42.103981637593506\n",
      "Iteration 6665, the loss is 4.442368342791474, parameters k is 10.306731382925587 and b is -42.10397768502433\n",
      "Iteration 6666, the loss is 4.4423683270170935, parameters k is 10.306730993597524 and b is -42.10397373245516\n",
      "Iteration 6667, the loss is 4.442368311242713, parameters k is 10.306730604269461 and b is -42.103969779885986\n",
      "Iteration 6668, the loss is 4.442368295468335, parameters k is 10.306730214941398 and b is -42.10396582731681\n",
      "Iteration 6669, the loss is 4.4423682796939525, parameters k is 10.306729825613335 and b is -42.10396187474764\n",
      "Iteration 6670, the loss is 4.442368263919575, parameters k is 10.306729436285272 and b is -42.103957922178466\n",
      "Iteration 6671, the loss is 4.442368248145198, parameters k is 10.306729046957209 and b is -42.10395396960929\n",
      "Iteration 6672, the loss is 4.442368232370817, parameters k is 10.306728657629145 and b is -42.10395001704012\n",
      "Iteration 6673, the loss is 4.442368216596439, parameters k is 10.306728268301082 and b is -42.10394606447095\n",
      "Iteration 6674, the loss is 4.442368200822059, parameters k is 10.30672787897302 and b is -42.10394211190177\n",
      "Iteration 6675, the loss is 4.442368185047678, parameters k is 10.306727489644956 and b is -42.1039381593326\n",
      "Iteration 6676, the loss is 4.442368169273301, parameters k is 10.306727100316893 and b is -42.10393420676343\n",
      "Iteration 6677, the loss is 4.442368153498919, parameters k is 10.30672671098883 and b is -42.10393025419425\n",
      "Iteration 6678, the loss is 4.44236813772454, parameters k is 10.306726321660767 and b is -42.10392630162508\n",
      "Iteration 6679, the loss is 4.442368121950162, parameters k is 10.306725932332704 and b is -42.10392234905591\n",
      "Iteration 6680, the loss is 4.442368106175783, parameters k is 10.30672554300464 and b is -42.10391839648673\n",
      "Iteration 6681, the loss is 4.4423680904014, parameters k is 10.306725153676577 and b is -42.10391444391756\n",
      "Iteration 6682, the loss is 4.442368074627023, parameters k is 10.306724764348514 and b is -42.10391049134839\n",
      "Iteration 6683, the loss is 4.442368058852642, parameters k is 10.306724375020451 and b is -42.10390653877921\n",
      "Iteration 6684, the loss is 4.442368043078264, parameters k is 10.306723985692388 and b is -42.10390258621004\n",
      "Iteration 6685, the loss is 4.442368027303886, parameters k is 10.306723596364325 and b is -42.10389863364087\n",
      "Iteration 6686, the loss is 4.442368011529505, parameters k is 10.306723207036262 and b is -42.103894681071694\n",
      "Iteration 6687, the loss is 4.442367995755126, parameters k is 10.306722817708199 and b is -42.10389072850252\n",
      "Iteration 6688, the loss is 4.442367979980745, parameters k is 10.306722428380136 and b is -42.10388677593335\n",
      "Iteration 6689, the loss is 4.442367964206365, parameters k is 10.306722039052072 and b is -42.103882823364174\n",
      "Iteration 6690, the loss is 4.442367948431988, parameters k is 10.30672164972401 and b is -42.103878870795\n",
      "Iteration 6691, the loss is 4.442367932657607, parameters k is 10.306721260395946 and b is -42.10387491822583\n",
      "Iteration 6692, the loss is 4.44236791688323, parameters k is 10.306720871067883 and b is -42.103870965656654\n",
      "Iteration 6693, the loss is 4.4423679011088515, parameters k is 10.30672048173982 and b is -42.10386701308748\n",
      "Iteration 6694, the loss is 4.442367885334471, parameters k is 10.306720092411757 and b is -42.10386306051831\n",
      "Iteration 6695, the loss is 4.442367869560088, parameters k is 10.306719703083694 and b is -42.103859107949134\n",
      "Iteration 6696, the loss is 4.442367853785711, parameters k is 10.30671931375563 and b is -42.10385515537996\n",
      "Iteration 6697, the loss is 4.442367838011333, parameters k is 10.306718924427567 and b is -42.10385120281079\n",
      "Iteration 6698, the loss is 4.442367822236951, parameters k is 10.306718535099504 and b is -42.103847250241614\n",
      "Iteration 6699, the loss is 4.442367806462572, parameters k is 10.306718145771441 and b is -42.10384329767244\n",
      "Iteration 6700, the loss is 4.442367790688193, parameters k is 10.306717756443378 and b is -42.10383934510327\n",
      "Iteration 6701, the loss is 4.442367774913812, parameters k is 10.306717367115315 and b is -42.103835392534094\n",
      "Iteration 6702, the loss is 4.442367759139433, parameters k is 10.306716977787252 and b is -42.10383143996492\n",
      "Iteration 6703, the loss is 4.442367743365055, parameters k is 10.306716588459189 and b is -42.10382748739575\n",
      "Iteration 6704, the loss is 4.442367731790395, parameters k is 10.306716199131126 and b is -42.103823534826574\n",
      "Iteration 6705, the loss is 4.442367716733346, parameters k is 10.306688311779347 and b is -42.103823534826574\n",
      "Iteration 6706, the loss is 4.442367700958969, parameters k is 10.306687922451284 and b is -42.1038195822574\n",
      "Iteration 6707, the loss is 4.442367685184587, parameters k is 10.30668753312322 and b is -42.10381562968823\n",
      "Iteration 6708, the loss is 4.442367669410209, parameters k is 10.306687143795157 and b is -42.103811677119054\n",
      "Iteration 6709, the loss is 4.44236765363583, parameters k is 10.306686754467094 and b is -42.10380772454988\n",
      "Iteration 6710, the loss is 4.44236763786145, parameters k is 10.306686365139031 and b is -42.10380377198071\n",
      "Iteration 6711, the loss is 4.44236762208707, parameters k is 10.306685975810968 and b is -42.103799819411535\n",
      "Iteration 6712, the loss is 4.442367606312694, parameters k is 10.306685586482905 and b is -42.10379586684236\n",
      "Iteration 6713, the loss is 4.442367590538312, parameters k is 10.306685197154842 and b is -42.10379191427319\n",
      "Iteration 6714, the loss is 4.442367574763935, parameters k is 10.306684807826779 and b is -42.103787961704015\n",
      "Iteration 6715, the loss is 4.442367558989557, parameters k is 10.306684418498715 and b is -42.10378400913484\n",
      "Iteration 6716, the loss is 4.442367543215172, parameters k is 10.306684029170652 and b is -42.10378005656567\n",
      "Iteration 6717, the loss is 4.442367527440794, parameters k is 10.30668363984259 and b is -42.103776103996495\n",
      "Iteration 6718, the loss is 4.442367511666416, parameters k is 10.306683250514526 and b is -42.10377215142732\n",
      "Iteration 6719, the loss is 4.442367495892035, parameters k is 10.306682861186463 and b is -42.10376819885815\n",
      "Iteration 6720, the loss is 4.442367480117655, parameters k is 10.3066824718584 and b is -42.103764246288975\n",
      "Iteration 6721, the loss is 4.442367464343277, parameters k is 10.306682082530337 and b is -42.1037602937198\n",
      "Iteration 6722, the loss is 4.4423674485688975, parameters k is 10.306681693202274 and b is -42.10375634115063\n",
      "Iteration 6723, the loss is 4.4423674327945175, parameters k is 10.30668130387421 and b is -42.103752388581455\n",
      "Iteration 6724, the loss is 4.442367417020139, parameters k is 10.306680914546147 and b is -42.10374843601228\n",
      "Iteration 6725, the loss is 4.442367401245759, parameters k is 10.306680525218084 and b is -42.10374448344311\n",
      "Iteration 6726, the loss is 4.442367385471378, parameters k is 10.306680135890021 and b is -42.103740530873935\n",
      "Iteration 6727, the loss is 4.442367369697001, parameters k is 10.306679746561958 and b is -42.10373657830476\n",
      "Iteration 6728, the loss is 4.442367353922619, parameters k is 10.306679357233895 and b is -42.10373262573559\n",
      "Iteration 6729, the loss is 4.442367338148243, parameters k is 10.306678967905832 and b is -42.103728673166415\n",
      "Iteration 6730, the loss is 4.44236732237386, parameters k is 10.306678578577769 and b is -42.10372472059724\n",
      "Iteration 6731, the loss is 4.4423673065994835, parameters k is 10.306678189249705 and b is -42.10372076802807\n",
      "Iteration 6732, the loss is 4.4423672908251035, parameters k is 10.306677799921642 and b is -42.103716815458895\n",
      "Iteration 6733, the loss is 4.442367275050723, parameters k is 10.30667741059358 and b is -42.10371286288972\n",
      "Iteration 6734, the loss is 4.442367259276344, parameters k is 10.306677021265516 and b is -42.10370891032055\n",
      "Iteration 6735, the loss is 4.442367243501963, parameters k is 10.306676631937453 and b is -42.103704957751376\n",
      "Iteration 6736, the loss is 4.442367227727585, parameters k is 10.30667624260939 and b is -42.1037010051822\n",
      "Iteration 6737, the loss is 4.442367211953209, parameters k is 10.306675853281327 and b is -42.10369705261303\n",
      "Iteration 6738, the loss is 4.442367196178827, parameters k is 10.306675463953264 and b is -42.103693100043856\n",
      "Iteration 6739, the loss is 4.442367180404448, parameters k is 10.3066750746252 and b is -42.10368914747468\n",
      "Iteration 6740, the loss is 4.442367164630068, parameters k is 10.306674685297137 and b is -42.10368519490551\n",
      "Iteration 6741, the loss is 4.442367148855687, parameters k is 10.306674295969074 and b is -42.103681242336336\n",
      "Iteration 6742, the loss is 4.442367133081311, parameters k is 10.306673906641011 and b is -42.10367728976716\n",
      "Iteration 6743, the loss is 4.442367117306931, parameters k is 10.306673517312948 and b is -42.10367333719799\n",
      "Iteration 6744, the loss is 4.442367101532549, parameters k is 10.306673127984885 and b is -42.103669384628816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6745, the loss is 4.442367085758171, parameters k is 10.306672738656822 and b is -42.10366543205964\n",
      "Iteration 6746, the loss is 4.442367069983791, parameters k is 10.306672349328759 and b is -42.10366147949047\n",
      "Iteration 6747, the loss is 4.442367054209415, parameters k is 10.306671960000696 and b is -42.103657526921296\n",
      "Iteration 6748, the loss is 4.442367038435034, parameters k is 10.306671570672632 and b is -42.10365357435212\n",
      "Iteration 6749, the loss is 4.442367022660653, parameters k is 10.30667118134457 and b is -42.10364962178295\n",
      "Iteration 6750, the loss is 4.442367006886273, parameters k is 10.306670792016506 and b is -42.103645669213776\n",
      "Iteration 6751, the loss is 4.442366991111897, parameters k is 10.306670402688443 and b is -42.1036417166446\n",
      "Iteration 6752, the loss is 4.4423669753375155, parameters k is 10.30667001336038 and b is -42.10363776407543\n",
      "Iteration 6753, the loss is 4.442366959563135, parameters k is 10.306669624032317 and b is -42.103633811506256\n",
      "Iteration 6754, the loss is 4.442366943788757, parameters k is 10.306669234704254 and b is -42.10362985893708\n",
      "Iteration 6755, the loss is 4.442366928014375, parameters k is 10.30666884537619 and b is -42.10362590636791\n",
      "Iteration 6756, the loss is 4.442366912239998, parameters k is 10.306668456048127 and b is -42.103621953798736\n",
      "Iteration 6757, the loss is 4.442366896465618, parameters k is 10.306668066720064 and b is -42.10361800122956\n",
      "Iteration 6758, the loss is 4.442366880691237, parameters k is 10.306667677392001 and b is -42.10361404866039\n",
      "Iteration 6759, the loss is 4.442366864916862, parameters k is 10.306667288063938 and b is -42.10361009609122\n",
      "Iteration 6760, the loss is 4.44236684914248, parameters k is 10.306666898735875 and b is -42.10360614352204\n",
      "Iteration 6761, the loss is 4.4423668333681015, parameters k is 10.306666509407812 and b is -42.10360219095287\n",
      "Iteration 6762, the loss is 4.44236681759372, parameters k is 10.306666120079749 and b is -42.1035982383837\n",
      "Iteration 6763, the loss is 4.442366801819341, parameters k is 10.306665730751686 and b is -42.10359428581452\n",
      "Iteration 6764, the loss is 4.442366786044964, parameters k is 10.306665341423622 and b is -42.10359033324535\n",
      "Iteration 6765, the loss is 4.442366770270584, parameters k is 10.30666495209556 and b is -42.10358638067618\n",
      "Iteration 6766, the loss is 4.442366754496205, parameters k is 10.306664562767496 and b is -42.103582428107\n",
      "Iteration 6767, the loss is 4.442366738721824, parameters k is 10.306664173439433 and b is -42.10357847553783\n",
      "Iteration 6768, the loss is 4.442366722947447, parameters k is 10.30666378411137 and b is -42.10357452296866\n",
      "Iteration 6769, the loss is 4.442366707173064, parameters k is 10.306663394783307 and b is -42.103570570399484\n",
      "Iteration 6770, the loss is 4.4423666913986875, parameters k is 10.306663005455244 and b is -42.10356661783031\n",
      "Iteration 6771, the loss is 4.442366675624308, parameters k is 10.30666261612718 and b is -42.10356266526114\n",
      "Iteration 6772, the loss is 4.442366659849928, parameters k is 10.306662226799117 and b is -42.103558712691964\n",
      "Iteration 6773, the loss is 4.44236664407555, parameters k is 10.306661837471054 and b is -42.10355476012279\n",
      "Iteration 6774, the loss is 4.442366628301168, parameters k is 10.306661448142991 and b is -42.10355080755362\n",
      "Iteration 6775, the loss is 4.442366612526789, parameters k is 10.306661058814928 and b is -42.103546854984444\n",
      "Iteration 6776, the loss is 4.442366596752409, parameters k is 10.306660669486865 and b is -42.10354290241527\n",
      "Iteration 6777, the loss is 4.442366580978032, parameters k is 10.306660280158802 and b is -42.1035389498461\n",
      "Iteration 6778, the loss is 4.442366565203652, parameters k is 10.306659890830739 and b is -42.103534997276924\n",
      "Iteration 6779, the loss is 4.442366549429272, parameters k is 10.306659501502676 and b is -42.10353104470775\n",
      "Iteration 6780, the loss is 4.442366533654896, parameters k is 10.306659112174613 and b is -42.10352709213858\n",
      "Iteration 6781, the loss is 4.442366517880513, parameters k is 10.30665872284655 and b is -42.103523139569404\n",
      "Iteration 6782, the loss is 4.442366502106132, parameters k is 10.306658333518486 and b is -42.10351918700023\n",
      "Iteration 6783, the loss is 4.442366486331752, parameters k is 10.306657944190423 and b is -42.10351523443106\n",
      "Iteration 6784, the loss is 4.442366470557373, parameters k is 10.30665755486236 and b is -42.103511281861884\n",
      "Iteration 6785, the loss is 4.442366454782996, parameters k is 10.306657165534297 and b is -42.10350732929271\n",
      "Iteration 6786, the loss is 4.442366439008614, parameters k is 10.306656776206234 and b is -42.10350337672354\n",
      "Iteration 6787, the loss is 4.442366423234236, parameters k is 10.30665638687817 and b is -42.103499424154364\n",
      "Iteration 6788, the loss is 4.442366407459857, parameters k is 10.306655997550108 and b is -42.10349547158519\n",
      "Iteration 6789, the loss is 4.4423663916854785, parameters k is 10.306655608222044 and b is -42.10349151901602\n",
      "Iteration 6790, the loss is 4.442366375911098, parameters k is 10.306655218893981 and b is -42.103487566446844\n",
      "Iteration 6791, the loss is 4.442366360136719, parameters k is 10.306654829565918 and b is -42.10348361387767\n",
      "Iteration 6792, the loss is 4.442366344362339, parameters k is 10.306654440237855 and b is -42.1034796613085\n",
      "Iteration 6793, the loss is 4.4423663285879575, parameters k is 10.306654050909792 and b is -42.103475708739325\n",
      "Iteration 6794, the loss is 4.442366312813581, parameters k is 10.306653661581729 and b is -42.10347175617015\n",
      "Iteration 6795, the loss is 4.442366297039202, parameters k is 10.306653272253666 and b is -42.10346780360098\n",
      "Iteration 6796, the loss is 4.442366281264821, parameters k is 10.306652882925603 and b is -42.103463851031805\n",
      "Iteration 6797, the loss is 4.442366265490443, parameters k is 10.30665249359754 and b is -42.10345989846263\n",
      "Iteration 6798, the loss is 4.4423662497160645, parameters k is 10.306652104269476 and b is -42.10345594589346\n",
      "Iteration 6799, the loss is 4.442366233941684, parameters k is 10.306651714941413 and b is -42.103451993324285\n",
      "Iteration 6800, the loss is 4.442366218167305, parameters k is 10.30665132561335 and b is -42.10344804075511\n",
      "Iteration 6801, the loss is 4.442366202392925, parameters k is 10.306650936285287 and b is -42.10344408818594\n",
      "Iteration 6802, the loss is 4.442366186618545, parameters k is 10.306650546957224 and b is -42.103440135616765\n",
      "Iteration 6803, the loss is 4.4423661708441715, parameters k is 10.30665015762916 and b is -42.10343618304759\n",
      "Iteration 6804, the loss is 4.442366155069785, parameters k is 10.306649768301098 and b is -42.10343223047842\n",
      "Iteration 6805, the loss is 4.442366139295407, parameters k is 10.306649378973034 and b is -42.103428277909245\n",
      "Iteration 6806, the loss is 4.442366123521029, parameters k is 10.306648989644971 and b is -42.10342432534007\n",
      "Iteration 6807, the loss is 4.442366107746649, parameters k is 10.306648600316908 and b is -42.1034203727709\n",
      "Iteration 6808, the loss is 4.442366091972268, parameters k is 10.306648210988845 and b is -42.103416420201725\n",
      "Iteration 6809, the loss is 4.442366076197891, parameters k is 10.306647821660782 and b is -42.10341246763255\n",
      "Iteration 6810, the loss is 4.442366060423509, parameters k is 10.306647432332719 and b is -42.10340851506338\n",
      "Iteration 6811, the loss is 4.44236604464913, parameters k is 10.306647043004656 and b is -42.103404562494205\n",
      "Iteration 6812, the loss is 4.442366028874752, parameters k is 10.306646653676593 and b is -42.10340060992503\n",
      "Iteration 6813, the loss is 4.4423660131003695, parameters k is 10.30664626434853 and b is -42.10339665735586\n",
      "Iteration 6814, the loss is 4.442365997325991, parameters k is 10.306645875020466 and b is -42.103392704786685\n",
      "Iteration 6815, the loss is 4.4423659815516165, parameters k is 10.306645485692403 and b is -42.10338875221751\n",
      "Iteration 6816, the loss is 4.442365965777234, parameters k is 10.30664509636434 and b is -42.10338479964834\n",
      "Iteration 6817, the loss is 4.442365950002854, parameters k is 10.306644707036277 and b is -42.103380847079166\n",
      "Iteration 6818, the loss is 4.442365934228473, parameters k is 10.306644317708214 and b is -42.10337689450999\n",
      "Iteration 6819, the loss is 4.442365918454096, parameters k is 10.30664392838015 and b is -42.10337294194082\n",
      "Iteration 6820, the loss is 4.442365902679715, parameters k is 10.306643539052088 and b is -42.103368989371646\n",
      "Iteration 6821, the loss is 4.4423658869053355, parameters k is 10.306643149724025 and b is -42.10336503680247\n",
      "Iteration 6822, the loss is 4.442365871130959, parameters k is 10.306642760395961 and b is -42.1033610842333\n",
      "Iteration 6823, the loss is 4.44236585535658, parameters k is 10.306642371067898 and b is -42.103357131664126\n",
      "Iteration 6824, the loss is 4.442365839582199, parameters k is 10.306641981739835 and b is -42.10335317909495\n",
      "Iteration 6825, the loss is 4.442365823807822, parameters k is 10.306641592411772 and b is -42.10334922652578\n",
      "Iteration 6826, the loss is 4.442365808033442, parameters k is 10.306641203083709 and b is -42.103345273956606\n",
      "Iteration 6827, the loss is 4.442365792259058, parameters k is 10.306640813755646 and b is -42.10334132138743\n",
      "Iteration 6828, the loss is 4.4423657764846824, parameters k is 10.306640424427583 and b is -42.10333736881826\n",
      "Iteration 6829, the loss is 4.442365760710303, parameters k is 10.30664003509952 and b is -42.103333416249086\n",
      "Iteration 6830, the loss is 4.4423657449359215, parameters k is 10.306639645771456 and b is -42.10332946367991\n",
      "Iteration 6831, the loss is 4.4423657291615415, parameters k is 10.306639256443393 and b is -42.10332551111074\n",
      "Iteration 6832, the loss is 4.442365713387164, parameters k is 10.30663886711533 and b is -42.103321558541566\n",
      "Iteration 6833, the loss is 4.442365697612782, parameters k is 10.306638477787267 and b is -42.10331760597239\n",
      "Iteration 6834, the loss is 4.442365681838406, parameters k is 10.306638088459204 and b is -42.10331365340322\n",
      "Iteration 6835, the loss is 4.442365666064027, parameters k is 10.30663769913114 and b is -42.103309700834046\n",
      "Iteration 6836, the loss is 4.4423656502896485, parameters k is 10.306637309803078 and b is -42.10330574826487\n",
      "Iteration 6837, the loss is 4.442365634515267, parameters k is 10.306636920475015 and b is -42.1033017956957\n",
      "Iteration 6838, the loss is 4.442365618740889, parameters k is 10.306636531146951 and b is -42.103297843126526\n",
      "Iteration 6839, the loss is 4.44236560296651, parameters k is 10.306636141818888 and b is -42.10329389055735\n",
      "Iteration 6840, the loss is 4.442365587192128, parameters k is 10.306635752490825 and b is -42.10328993798818\n",
      "Iteration 6841, the loss is 4.442365571417748, parameters k is 10.306635363162762 and b is -42.10328598541901\n",
      "Iteration 6842, the loss is 4.442365555643368, parameters k is 10.306634973834699 and b is -42.10328203284983\n",
      "Iteration 6843, the loss is 4.442365539868989, parameters k is 10.306634584506636 and b is -42.10327808028066\n",
      "Iteration 6844, the loss is 4.442365524094609, parameters k is 10.306634195178573 and b is -42.10327412771149\n",
      "Iteration 6845, the loss is 4.442365508320233, parameters k is 10.30663380585051 and b is -42.10327017514231\n",
      "Iteration 6846, the loss is 4.442365492545851, parameters k is 10.306633416522446 and b is -42.10326622257314\n",
      "Iteration 6847, the loss is 4.442365476771471, parameters k is 10.306633027194383 and b is -42.10326227000397\n",
      "Iteration 6848, the loss is 4.4423654609970935, parameters k is 10.30663263786632 and b is -42.10325831743479\n",
      "Iteration 6849, the loss is 4.4423654452227135, parameters k is 10.306632248538257 and b is -42.10325436486562\n",
      "Iteration 6850, the loss is 4.442365429448334, parameters k is 10.306631859210194 and b is -42.10325041229645\n",
      "Iteration 6851, the loss is 4.442365413673955, parameters k is 10.30663146988213 and b is -42.10324645972727\n",
      "Iteration 6852, the loss is 4.442365397899575, parameters k is 10.306631080554068 and b is -42.1032425071581\n",
      "Iteration 6853, the loss is 4.442365382125197, parameters k is 10.306630691226005 and b is -42.10323855458893\n",
      "Iteration 6854, the loss is 4.442365366350816, parameters k is 10.306630301897941 and b is -42.103234602019754\n",
      "Iteration 6855, the loss is 4.4423653505764396, parameters k is 10.306629912569878 and b is -42.10323064945058\n",
      "Iteration 6856, the loss is 4.4423653348020595, parameters k is 10.306629523241815 and b is -42.10322669688141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6857, the loss is 4.442365319027677, parameters k is 10.306629133913752 and b is -42.103222744312234\n",
      "Iteration 6858, the loss is 4.442365303253299, parameters k is 10.306628744585689 and b is -42.10321879174306\n",
      "Iteration 6859, the loss is 4.44236528747892, parameters k is 10.306628355257626 and b is -42.10321483917389\n",
      "Iteration 6860, the loss is 4.442365271704541, parameters k is 10.306627965929563 and b is -42.103210886604714\n",
      "Iteration 6861, the loss is 4.442365260342735, parameters k is 10.3066275766015 and b is -42.10320693403554\n",
      "Iteration 6862, the loss is 4.442365245072833, parameters k is 10.30659968924972 and b is -42.10320693403554\n",
      "Iteration 6863, the loss is 4.442365229298452, parameters k is 10.306599299921658 and b is -42.10320298146637\n",
      "Iteration 6864, the loss is 4.442365213524075, parameters k is 10.306598910593594 and b is -42.103199028897194\n",
      "Iteration 6865, the loss is 4.442365197749694, parameters k is 10.306598521265531 and b is -42.10319507632802\n",
      "Iteration 6866, the loss is 4.4423651819753145, parameters k is 10.306598131937468 and b is -42.10319112375885\n",
      "Iteration 6867, the loss is 4.4423651662009345, parameters k is 10.306597742609405 and b is -42.103187171189674\n",
      "Iteration 6868, the loss is 4.442365150426556, parameters k is 10.306597353281342 and b is -42.1031832186205\n",
      "Iteration 6869, the loss is 4.442365134652175, parameters k is 10.306596963953279 and b is -42.10317926605133\n",
      "Iteration 6870, the loss is 4.442365118877795, parameters k is 10.306596574625216 and b is -42.103175313482154\n",
      "Iteration 6871, the loss is 4.442365103103418, parameters k is 10.306596185297153 and b is -42.10317136091298\n",
      "Iteration 6872, the loss is 4.442365087329038, parameters k is 10.30659579596909 and b is -42.10316740834381\n",
      "Iteration 6873, the loss is 4.44236507155466, parameters k is 10.306595406641026 and b is -42.103163455774634\n",
      "Iteration 6874, the loss is 4.4423650557802805, parameters k is 10.306595017312963 and b is -42.10315950320546\n",
      "Iteration 6875, the loss is 4.442365040005899, parameters k is 10.3065946279849 and b is -42.10315555063629\n",
      "Iteration 6876, the loss is 4.44236502423152, parameters k is 10.306594238656837 and b is -42.103151598067114\n",
      "Iteration 6877, the loss is 4.44236500845714, parameters k is 10.306593849328774 and b is -42.10314764549794\n",
      "Iteration 6878, the loss is 4.442364992682763, parameters k is 10.30659346000071 and b is -42.10314369292877\n",
      "Iteration 6879, the loss is 4.442364976908381, parameters k is 10.306593070672648 and b is -42.103139740359595\n",
      "Iteration 6880, the loss is 4.442364961134005, parameters k is 10.306592681344585 and b is -42.10313578779042\n",
      "Iteration 6881, the loss is 4.442364945359624, parameters k is 10.306592292016521 and b is -42.10313183522125\n",
      "Iteration 6882, the loss is 4.442364929585245, parameters k is 10.306591902688458 and b is -42.103127882652075\n",
      "Iteration 6883, the loss is 4.442364913810865, parameters k is 10.306591513360395 and b is -42.1031239300829\n",
      "Iteration 6884, the loss is 4.442364898036485, parameters k is 10.306591124032332 and b is -42.10311997751373\n",
      "Iteration 6885, the loss is 4.442364882262104, parameters k is 10.306590734704269 and b is -42.103116024944555\n",
      "Iteration 6886, the loss is 4.4423648664877255, parameters k is 10.306590345376206 and b is -42.10311207237538\n",
      "Iteration 6887, the loss is 4.442364850713347, parameters k is 10.306589956048143 and b is -42.10310811980621\n",
      "Iteration 6888, the loss is 4.442364834938968, parameters k is 10.30658956672008 and b is -42.103104167237035\n",
      "Iteration 6889, the loss is 4.442364819164588, parameters k is 10.306589177392016 and b is -42.10310021466786\n",
      "Iteration 6890, the loss is 4.442364803390209, parameters k is 10.306588788063953 and b is -42.10309626209869\n",
      "Iteration 6891, the loss is 4.442364787615831, parameters k is 10.30658839873589 and b is -42.103092309529515\n",
      "Iteration 6892, the loss is 4.442364771841449, parameters k is 10.306588009407827 and b is -42.10308835696034\n",
      "Iteration 6893, the loss is 4.442364756067071, parameters k is 10.306587620079764 and b is -42.10308440439117\n",
      "Iteration 6894, the loss is 4.442364740292693, parameters k is 10.3065872307517 and b is -42.103080451821995\n",
      "Iteration 6895, the loss is 4.442364724518311, parameters k is 10.306586841423638 and b is -42.10307649925282\n",
      "Iteration 6896, the loss is 4.442364708743932, parameters k is 10.306586452095575 and b is -42.10307254668365\n",
      "Iteration 6897, the loss is 4.442364692969554, parameters k is 10.306586062767511 and b is -42.103068594114475\n",
      "Iteration 6898, the loss is 4.442364677195174, parameters k is 10.306585673439448 and b is -42.1030646415453\n",
      "Iteration 6899, the loss is 4.442364661420793, parameters k is 10.306585284111385 and b is -42.10306068897613\n",
      "Iteration 6900, the loss is 4.442364645646415, parameters k is 10.306584894783322 and b is -42.103056736406955\n",
      "Iteration 6901, the loss is 4.442364629872037, parameters k is 10.306584505455259 and b is -42.10305278383778\n",
      "Iteration 6902, the loss is 4.442364614097656, parameters k is 10.306584116127196 and b is -42.10304883126861\n",
      "Iteration 6903, the loss is 4.442364598323279, parameters k is 10.306583726799133 and b is -42.103044878699436\n",
      "Iteration 6904, the loss is 4.442364582548897, parameters k is 10.30658333747107 and b is -42.10304092613026\n",
      "Iteration 6905, the loss is 4.442364566774518, parameters k is 10.306582948143006 and b is -42.10303697356109\n",
      "Iteration 6906, the loss is 4.442364551000138, parameters k is 10.306582558814943 and b is -42.103033020991916\n",
      "Iteration 6907, the loss is 4.4423645352257575, parameters k is 10.30658216948688 and b is -42.10302906842274\n",
      "Iteration 6908, the loss is 4.442364519451379, parameters k is 10.306581780158817 and b is -42.10302511585357\n",
      "Iteration 6909, the loss is 4.442364503677001, parameters k is 10.306581390830754 and b is -42.103021163284396\n",
      "Iteration 6910, the loss is 4.44236448790262, parameters k is 10.30658100150269 and b is -42.10301721071522\n",
      "Iteration 6911, the loss is 4.442364472128243, parameters k is 10.306580612174628 and b is -42.10301325814605\n",
      "Iteration 6912, the loss is 4.442364456353864, parameters k is 10.306580222846565 and b is -42.103009305576876\n",
      "Iteration 6913, the loss is 4.442364440579484, parameters k is 10.306579833518501 and b is -42.1030053530077\n",
      "Iteration 6914, the loss is 4.442364424805103, parameters k is 10.306579444190438 and b is -42.10300140043853\n",
      "Iteration 6915, the loss is 4.4423644090307235, parameters k is 10.306579054862375 and b is -42.102997447869356\n",
      "Iteration 6916, the loss is 4.442364393256345, parameters k is 10.306578665534312 and b is -42.10299349530018\n",
      "Iteration 6917, the loss is 4.4423643774819634, parameters k is 10.306578276206249 and b is -42.10298954273101\n",
      "Iteration 6918, the loss is 4.442364361707587, parameters k is 10.306577886878186 and b is -42.102985590161836\n",
      "Iteration 6919, the loss is 4.442364345933206, parameters k is 10.306577497550123 and b is -42.10298163759266\n",
      "Iteration 6920, the loss is 4.442364330158828, parameters k is 10.30657710822206 and b is -42.10297768502349\n",
      "Iteration 6921, the loss is 4.4423643143844505, parameters k is 10.306576718893997 and b is -42.102973732454316\n",
      "Iteration 6922, the loss is 4.4423642986100695, parameters k is 10.306576329565933 and b is -42.10296977988514\n",
      "Iteration 6923, the loss is 4.44236428283569, parameters k is 10.30657594023787 and b is -42.10296582731597\n",
      "Iteration 6924, the loss is 4.442364267061311, parameters k is 10.306575550909807 and b is -42.102961874746796\n",
      "Iteration 6925, the loss is 4.442364251286931, parameters k is 10.306575161581744 and b is -42.10295792217762\n",
      "Iteration 6926, the loss is 4.442364235512553, parameters k is 10.306574772253681 and b is -42.10295396960845\n",
      "Iteration 6927, the loss is 4.442364219738171, parameters k is 10.306574382925618 and b is -42.10295001703928\n",
      "Iteration 6928, the loss is 4.442364203963794, parameters k is 10.306573993597555 and b is -42.1029460644701\n",
      "Iteration 6929, the loss is 4.442364188189413, parameters k is 10.306573604269492 and b is -42.10294211190093\n",
      "Iteration 6930, the loss is 4.442364172415031, parameters k is 10.306573214941428 and b is -42.10293815933176\n",
      "Iteration 6931, the loss is 4.442364156640655, parameters k is 10.306572825613365 and b is -42.10293420676258\n",
      "Iteration 6932, the loss is 4.442364140866274, parameters k is 10.306572436285302 and b is -42.10293025419341\n",
      "Iteration 6933, the loss is 4.442364125091894, parameters k is 10.306572046957239 and b is -42.10292630162424\n",
      "Iteration 6934, the loss is 4.442364109317514, parameters k is 10.306571657629176 and b is -42.10292234905506\n",
      "Iteration 6935, the loss is 4.442364093543136, parameters k is 10.306571268301113 and b is -42.10291839648589\n",
      "Iteration 6936, the loss is 4.442364077768755, parameters k is 10.30657087897305 and b is -42.10291444391672\n",
      "Iteration 6937, the loss is 4.44236406199438, parameters k is 10.306570489644987 and b is -42.102910491347544\n",
      "Iteration 6938, the loss is 4.44236404622, parameters k is 10.306570100316923 and b is -42.10290653877837\n",
      "Iteration 6939, the loss is 4.442364030445621, parameters k is 10.30656971098886 and b is -42.1029025862092\n",
      "Iteration 6940, the loss is 4.44236401467124, parameters k is 10.306569321660797 and b is -42.102898633640024\n",
      "Iteration 6941, the loss is 4.442363998896859, parameters k is 10.306568932332734 and b is -42.10289468107085\n",
      "Iteration 6942, the loss is 4.4423639831224815, parameters k is 10.306568543004671 and b is -42.10289072850168\n",
      "Iteration 6943, the loss is 4.4423639673481, parameters k is 10.306568153676608 and b is -42.102886775932504\n",
      "Iteration 6944, the loss is 4.442363951573722, parameters k is 10.306567764348545 and b is -42.10288282336333\n",
      "Iteration 6945, the loss is 4.442363935799344, parameters k is 10.306567375020482 and b is -42.10287887079416\n",
      "Iteration 6946, the loss is 4.442363920024963, parameters k is 10.306566985692418 and b is -42.102874918224984\n",
      "Iteration 6947, the loss is 4.442363904250583, parameters k is 10.306566596364355 and b is -42.10287096565581\n",
      "Iteration 6948, the loss is 4.442363888476205, parameters k is 10.306566207036292 and b is -42.10286701308664\n",
      "Iteration 6949, the loss is 4.442363872701826, parameters k is 10.306565817708229 and b is -42.102863060517464\n",
      "Iteration 6950, the loss is 4.4423638569274475, parameters k is 10.306565428380166 and b is -42.10285910794829\n",
      "Iteration 6951, the loss is 4.4423638411530675, parameters k is 10.306565039052103 and b is -42.10285515537912\n",
      "Iteration 6952, the loss is 4.442363825378686, parameters k is 10.30656464972404 and b is -42.102851202809944\n",
      "Iteration 6953, the loss is 4.4423638096043065, parameters k is 10.306564260395977 and b is -42.10284725024077\n",
      "Iteration 6954, the loss is 4.442363793829927, parameters k is 10.306563871067913 and b is -42.1028432976716\n",
      "Iteration 6955, the loss is 4.442363778055547, parameters k is 10.30656348173985 and b is -42.102839345102424\n",
      "Iteration 6956, the loss is 4.442363762281167, parameters k is 10.306563092411787 and b is -42.10283539253325\n",
      "Iteration 6957, the loss is 4.44236374650679, parameters k is 10.306562703083724 and b is -42.10283143996408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6958, the loss is 4.442363730732413, parameters k is 10.306562313755661 and b is -42.102827487394904\n",
      "Iteration 6959, the loss is 4.4423637149580335, parameters k is 10.306561924427598 and b is -42.10282353482573\n",
      "Iteration 6960, the loss is 4.442363699183653, parameters k is 10.306561535099535 and b is -42.10281958225656\n",
      "Iteration 6961, the loss is 4.442363683409273, parameters k is 10.306561145771472 and b is -42.102815629687385\n",
      "Iteration 6962, the loss is 4.442363667634892, parameters k is 10.306560756443409 and b is -42.10281167711821\n",
      "Iteration 6963, the loss is 4.442363651860513, parameters k is 10.306560367115345 and b is -42.10280772454904\n",
      "Iteration 6964, the loss is 4.442363636086133, parameters k is 10.306559977787282 and b is -42.102803771979865\n",
      "Iteration 6965, the loss is 4.442363620311754, parameters k is 10.30655958845922 and b is -42.10279981941069\n",
      "Iteration 6966, the loss is 4.442363604537376, parameters k is 10.306559199131156 and b is -42.10279586684152\n",
      "Iteration 6967, the loss is 4.442363588762994, parameters k is 10.306558809803093 and b is -42.102791914272345\n",
      "Iteration 6968, the loss is 4.442363572988615, parameters k is 10.30655842047503 and b is -42.10278796170317\n",
      "Iteration 6969, the loss is 4.442363557214239, parameters k is 10.306558031146967 and b is -42.102784009134\n",
      "Iteration 6970, the loss is 4.442363541439859, parameters k is 10.306557641818904 and b is -42.102780056564825\n",
      "Iteration 6971, the loss is 4.442363525665479, parameters k is 10.30655725249084 and b is -42.10277610399565\n",
      "Iteration 6972, the loss is 4.442363509891101, parameters k is 10.306556863162777 and b is -42.10277215142648\n",
      "Iteration 6973, the loss is 4.4423634941167185, parameters k is 10.306556473834714 and b is -42.102768198857305\n",
      "Iteration 6974, the loss is 4.442363478342338, parameters k is 10.306556084506651 and b is -42.10276424628813\n",
      "Iteration 6975, the loss is 4.442363462567959, parameters k is 10.306555695178588 and b is -42.10276029371896\n",
      "Iteration 6976, the loss is 4.442363446793581, parameters k is 10.306555305850525 and b is -42.102756341149785\n",
      "Iteration 6977, the loss is 4.442363431019203, parameters k is 10.306554916522462 and b is -42.10275238858061\n",
      "Iteration 6978, the loss is 4.442363415244823, parameters k is 10.306554527194399 and b is -42.10274843601144\n",
      "Iteration 6979, the loss is 4.442363399470444, parameters k is 10.306554137866335 and b is -42.102744483442265\n",
      "Iteration 6980, the loss is 4.442363383696065, parameters k is 10.306553748538272 and b is -42.10274053087309\n",
      "Iteration 6981, the loss is 4.442363367921683, parameters k is 10.30655335921021 and b is -42.10273657830392\n",
      "Iteration 6982, the loss is 4.442363352147306, parameters k is 10.306552969882146 and b is -42.102732625734745\n",
      "Iteration 6983, the loss is 4.442363336372927, parameters k is 10.306552580554083 and b is -42.10272867316557\n",
      "Iteration 6984, the loss is 4.442363320598545, parameters k is 10.30655219122602 and b is -42.1027247205964\n",
      "Iteration 6985, the loss is 4.442363304824165, parameters k is 10.306551801897957 and b is -42.102720768027226\n",
      "Iteration 6986, the loss is 4.442363289049787, parameters k is 10.306551412569894 and b is -42.10271681545805\n",
      "Iteration 6987, the loss is 4.442363273275409, parameters k is 10.30655102324183 and b is -42.10271286288888\n",
      "Iteration 6988, the loss is 4.442363257501028, parameters k is 10.306550633913767 and b is -42.102708910319706\n",
      "Iteration 6989, the loss is 4.44236324172665, parameters k is 10.306550244585704 and b is -42.10270495775053\n",
      "Iteration 6990, the loss is 4.442363225952269, parameters k is 10.306549855257641 and b is -42.10270100518136\n",
      "Iteration 6991, the loss is 4.4423632101778905, parameters k is 10.306549465929578 and b is -42.102697052612186\n",
      "Iteration 6992, the loss is 4.442363194403512, parameters k is 10.306549076601515 and b is -42.10269310004301\n",
      "Iteration 6993, the loss is 4.442363178629131, parameters k is 10.306548687273452 and b is -42.10268914747384\n",
      "Iteration 6994, the loss is 4.442363162854753, parameters k is 10.306548297945389 and b is -42.102685194904666\n",
      "Iteration 6995, the loss is 4.442363147080372, parameters k is 10.306547908617326 and b is -42.10268124233549\n",
      "Iteration 6996, the loss is 4.442363131305996, parameters k is 10.306547519289262 and b is -42.10267728976632\n",
      "Iteration 6997, the loss is 4.442363115531617, parameters k is 10.3065471299612 and b is -42.102673337197146\n",
      "Iteration 6998, the loss is 4.442363099757235, parameters k is 10.306546740633136 and b is -42.10266938462797\n",
      "Iteration 6999, the loss is 4.442363083982855, parameters k is 10.306546351305073 and b is -42.1026654320588\n",
      "Iteration 7000, the loss is 4.4423630682084765, parameters k is 10.30654596197701 and b is -42.102661479489626\n",
      "Iteration 7001, the loss is 4.442363052434099, parameters k is 10.306545572648947 and b is -42.10265752692045\n",
      "Iteration 7002, the loss is 4.442363036659716, parameters k is 10.306545183320884 and b is -42.10265357435128\n",
      "Iteration 7003, the loss is 4.442363020885336, parameters k is 10.30654479399282 and b is -42.102649621782106\n",
      "Iteration 7004, the loss is 4.442363005110956, parameters k is 10.306544404664757 and b is -42.10264566921293\n",
      "Iteration 7005, the loss is 4.442362989336576, parameters k is 10.306544015336694 and b is -42.10264171664376\n",
      "Iteration 7006, the loss is 4.442362973562198, parameters k is 10.306543626008631 and b is -42.102637764074586\n",
      "Iteration 7007, the loss is 4.44236295778782, parameters k is 10.306543236680568 and b is -42.10263381150541\n",
      "Iteration 7008, the loss is 4.442362942013441, parameters k is 10.306542847352505 and b is -42.10262985893624\n",
      "Iteration 7009, the loss is 4.4423629262390625, parameters k is 10.306542458024442 and b is -42.10262590636707\n",
      "Iteration 7010, the loss is 4.442362910464682, parameters k is 10.306542068696379 and b is -42.10262195379789\n",
      "Iteration 7011, the loss is 4.442362894690305, parameters k is 10.306541679368316 and b is -42.10261800122872\n",
      "Iteration 7012, the loss is 4.442362878915923, parameters k is 10.306541290040252 and b is -42.10261404865955\n",
      "Iteration 7013, the loss is 4.442362863141542, parameters k is 10.30654090071219 and b is -42.10261009609037\n",
      "Iteration 7014, the loss is 4.442362847367165, parameters k is 10.306540511384126 and b is -42.1026061435212\n",
      "Iteration 7015, the loss is 4.442362831592786, parameters k is 10.306540122056063 and b is -42.10260219095203\n",
      "Iteration 7016, the loss is 4.442362815818407, parameters k is 10.306539732728 and b is -42.10259823838285\n",
      "Iteration 7017, the loss is 4.4423628000440285, parameters k is 10.306539343399937 and b is -42.10259428581368\n",
      "Iteration 7018, the loss is 4.442362788895076, parameters k is 10.306538954071874 and b is -42.10259033324451\n",
      "Iteration 7019, the loss is 4.442362773412318, parameters k is 10.306511066720095 and b is -42.10259033324451\n",
      "Iteration 7020, the loss is 4.442362757637942, parameters k is 10.306510677392032 and b is -42.10258638067533\n",
      "Iteration 7021, the loss is 4.44236274186356, parameters k is 10.306510288063969 and b is -42.10258242810616\n",
      "Iteration 7022, the loss is 4.442362726089179, parameters k is 10.306509898735905 and b is -42.10257847553699\n",
      "Iteration 7023, the loss is 4.442362710314801, parameters k is 10.306509509407842 and b is -42.102574522967814\n",
      "Iteration 7024, the loss is 4.442362694540421, parameters k is 10.30650912007978 and b is -42.10257057039864\n",
      "Iteration 7025, the loss is 4.442362678766043, parameters k is 10.306508730751716 and b is -42.10256661782947\n",
      "Iteration 7026, the loss is 4.442362662991662, parameters k is 10.306508341423653 and b is -42.102562665260294\n",
      "Iteration 7027, the loss is 4.442362647217282, parameters k is 10.30650795209559 and b is -42.10255871269112\n",
      "Iteration 7028, the loss is 4.442362631442902, parameters k is 10.306507562767527 and b is -42.10255476012195\n",
      "Iteration 7029, the loss is 4.442362615668524, parameters k is 10.306507173439464 and b is -42.102550807552774\n",
      "Iteration 7030, the loss is 4.442362599894144, parameters k is 10.3065067841114 and b is -42.1025468549836\n",
      "Iteration 7031, the loss is 4.442362584119765, parameters k is 10.306506394783337 and b is -42.10254290241443\n",
      "Iteration 7032, the loss is 4.442362568345383, parameters k is 10.306506005455274 and b is -42.102538949845254\n",
      "Iteration 7033, the loss is 4.442362552571007, parameters k is 10.306505616127211 and b is -42.10253499727608\n",
      "Iteration 7034, the loss is 4.442362536796626, parameters k is 10.306505226799148 and b is -42.10253104470691\n",
      "Iteration 7035, the loss is 4.442362521022248, parameters k is 10.306504837471085 and b is -42.102527092137734\n",
      "Iteration 7036, the loss is 4.442362505247867, parameters k is 10.306504448143022 and b is -42.10252313956856\n",
      "Iteration 7037, the loss is 4.442362489473487, parameters k is 10.306504058814959 and b is -42.10251918699939\n",
      "Iteration 7038, the loss is 4.4423624736991085, parameters k is 10.306503669486895 and b is -42.102515234430214\n",
      "Iteration 7039, the loss is 4.442362457924732, parameters k is 10.306503280158832 and b is -42.10251128186104\n",
      "Iteration 7040, the loss is 4.44236244215035, parameters k is 10.30650289083077 and b is -42.10250732929187\n",
      "Iteration 7041, the loss is 4.442362426375971, parameters k is 10.306502501502706 and b is -42.102503376722694\n",
      "Iteration 7042, the loss is 4.442362410601592, parameters k is 10.306502112174643 and b is -42.10249942415352\n",
      "Iteration 7043, the loss is 4.442362394827212, parameters k is 10.30650172284658 and b is -42.10249547158435\n",
      "Iteration 7044, the loss is 4.442362379052832, parameters k is 10.306501333518517 and b is -42.102491519015175\n",
      "Iteration 7045, the loss is 4.442362363278453, parameters k is 10.306500944190454 and b is -42.102487566446\n",
      "Iteration 7046, the loss is 4.4423623475040745, parameters k is 10.30650055486239 and b is -42.10248361387683\n",
      "Iteration 7047, the loss is 4.4423623317296945, parameters k is 10.306500165534327 and b is -42.102479661307655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7048, the loss is 4.442362315955314, parameters k is 10.306499776206264 and b is -42.10247570873848\n",
      "Iteration 7049, the loss is 4.442362300180935, parameters k is 10.306499386878201 and b is -42.10247175616931\n",
      "Iteration 7050, the loss is 4.442362284406557, parameters k is 10.306498997550138 and b is -42.102467803600135\n",
      "Iteration 7051, the loss is 4.442362268632178, parameters k is 10.306498608222075 and b is -42.10246385103096\n",
      "Iteration 7052, the loss is 4.4423622528578, parameters k is 10.306498218894012 and b is -42.10245989846179\n",
      "Iteration 7053, the loss is 4.442362237083417, parameters k is 10.306497829565949 and b is -42.102455945892615\n",
      "Iteration 7054, the loss is 4.442362221309038, parameters k is 10.306497440237885 and b is -42.10245199332344\n",
      "Iteration 7055, the loss is 4.442362205534659, parameters k is 10.306497050909822 and b is -42.10244804075427\n",
      "Iteration 7056, the loss is 4.442362189760279, parameters k is 10.30649666158176 and b is -42.102444088185095\n",
      "Iteration 7057, the loss is 4.4423621739859, parameters k is 10.306496272253696 and b is -42.10244013561592\n",
      "Iteration 7058, the loss is 4.442362158211523, parameters k is 10.306495882925633 and b is -42.10243618304675\n",
      "Iteration 7059, the loss is 4.442362142437142, parameters k is 10.30649549359757 and b is -42.102432230477575\n",
      "Iteration 7060, the loss is 4.442362126662762, parameters k is 10.306495104269507 and b is -42.1024282779084\n",
      "Iteration 7061, the loss is 4.442362110888384, parameters k is 10.306494714941444 and b is -42.10242432533923\n",
      "Iteration 7062, the loss is 4.442362095114001, parameters k is 10.30649432561338 and b is -42.102420372770055\n",
      "Iteration 7063, the loss is 4.442362079339625, parameters k is 10.306493936285317 and b is -42.10241642020088\n",
      "Iteration 7064, the loss is 4.442362063565248, parameters k is 10.306493546957254 and b is -42.10241246763171\n",
      "Iteration 7065, the loss is 4.442362047790866, parameters k is 10.306493157629191 and b is -42.102408515062535\n",
      "Iteration 7066, the loss is 4.4423620320164865, parameters k is 10.306492768301128 and b is -42.10240456249336\n",
      "Iteration 7067, the loss is 4.442362016242107, parameters k is 10.306492378973065 and b is -42.10240060992419\n",
      "Iteration 7068, the loss is 4.442362000467726, parameters k is 10.306491989645002 and b is -42.102396657355015\n",
      "Iteration 7069, the loss is 4.442361984693351, parameters k is 10.306491600316939 and b is -42.10239270478584\n",
      "Iteration 7070, the loss is 4.44236196891897, parameters k is 10.306491210988876 and b is -42.10238875221667\n",
      "Iteration 7071, the loss is 4.442361953144587, parameters k is 10.306490821660812 and b is -42.102384799647496\n",
      "Iteration 7072, the loss is 4.44236193737021, parameters k is 10.30649043233275 and b is -42.10238084707832\n",
      "Iteration 7073, the loss is 4.442361921595829, parameters k is 10.306490043004686 and b is -42.10237689450915\n",
      "Iteration 7074, the loss is 4.442361905821451, parameters k is 10.306489653676623 and b is -42.102372941939976\n",
      "Iteration 7075, the loss is 4.4423618900470725, parameters k is 10.30648926434856 and b is -42.1023689893708\n",
      "Iteration 7076, the loss is 4.442361874272691, parameters k is 10.306488875020497 and b is -42.10236503680163\n",
      "Iteration 7077, the loss is 4.442361858498313, parameters k is 10.306488485692434 and b is -42.102361084232456\n",
      "Iteration 7078, the loss is 4.442361842723934, parameters k is 10.30648809636437 and b is -42.10235713166328\n",
      "Iteration 7079, the loss is 4.442361826949553, parameters k is 10.306487707036307 and b is -42.10235317909411\n",
      "Iteration 7080, the loss is 4.442361811175176, parameters k is 10.306487317708244 and b is -42.102349226524936\n",
      "Iteration 7081, the loss is 4.442361795400794, parameters k is 10.306486928380181 and b is -42.10234527395576\n",
      "Iteration 7082, the loss is 4.442361779626416, parameters k is 10.306486539052118 and b is -42.10234132138659\n",
      "Iteration 7083, the loss is 4.442361763852037, parameters k is 10.306486149724055 and b is -42.102337368817416\n",
      "Iteration 7084, the loss is 4.442361748077655, parameters k is 10.306485760395992 and b is -42.10233341624824\n",
      "Iteration 7085, the loss is 4.4423617323032785, parameters k is 10.306485371067929 and b is -42.10232946367907\n",
      "Iteration 7086, the loss is 4.4423617165289, parameters k is 10.306484981739866 and b is -42.102325511109896\n",
      "Iteration 7087, the loss is 4.442361700754519, parameters k is 10.306484592411802 and b is -42.10232155854072\n",
      "Iteration 7088, the loss is 4.442361684980139, parameters k is 10.30648420308374 and b is -42.10231760597155\n",
      "Iteration 7089, the loss is 4.442361669205761, parameters k is 10.306483813755676 and b is -42.102313653402376\n",
      "Iteration 7090, the loss is 4.442361653431382, parameters k is 10.306483424427613 and b is -42.1023097008332\n",
      "Iteration 7091, the loss is 4.442361637657002, parameters k is 10.30648303509955 and b is -42.10230574826403\n",
      "Iteration 7092, the loss is 4.442361621882622, parameters k is 10.306482645771487 and b is -42.102301795694856\n",
      "Iteration 7093, the loss is 4.442361606108241, parameters k is 10.306482256443424 and b is -42.10229784312568\n",
      "Iteration 7094, the loss is 4.442361590333863, parameters k is 10.30648186711536 and b is -42.10229389055651\n",
      "Iteration 7095, the loss is 4.442361574559485, parameters k is 10.306481477787298 and b is -42.10228993798734\n",
      "Iteration 7096, the loss is 4.442361558785105, parameters k is 10.306481088459234 and b is -42.10228598541816\n",
      "Iteration 7097, the loss is 4.442361543010725, parameters k is 10.306480699131171 and b is -42.10228203284899\n",
      "Iteration 7098, the loss is 4.442361527236344, parameters k is 10.306480309803108 and b is -42.10227808027982\n",
      "Iteration 7099, the loss is 4.442361511461967, parameters k is 10.306479920475045 and b is -42.10227412771064\n",
      "Iteration 7100, the loss is 4.442361495687584, parameters k is 10.306479531146982 and b is -42.10227017514147\n",
      "Iteration 7101, the loss is 4.442361479913208, parameters k is 10.306479141818919 and b is -42.1022662225723\n",
      "Iteration 7102, the loss is 4.442361464138829, parameters k is 10.306478752490856 and b is -42.10226227000312\n",
      "Iteration 7103, the loss is 4.4423614483644505, parameters k is 10.306478363162793 and b is -42.10225831743395\n",
      "Iteration 7104, the loss is 4.442361432590068, parameters k is 10.30647797383473 and b is -42.10225436486478\n",
      "Iteration 7105, the loss is 4.4423614168156895, parameters k is 10.306477584506666 and b is -42.102250412295604\n",
      "Iteration 7106, the loss is 4.442361401041308, parameters k is 10.306477195178603 and b is -42.10224645972643\n",
      "Iteration 7107, the loss is 4.442361385266931, parameters k is 10.30647680585054 and b is -42.10224250715726\n",
      "Iteration 7108, the loss is 4.442361369492552, parameters k is 10.306476416522477 and b is -42.102238554588084\n",
      "Iteration 7109, the loss is 4.442361353718173, parameters k is 10.306476027194414 and b is -42.10223460201891\n",
      "Iteration 7110, the loss is 4.442361337943794, parameters k is 10.30647563786635 and b is -42.10223064944974\n",
      "Iteration 7111, the loss is 4.442361322169413, parameters k is 10.306475248538288 and b is -42.102226696880564\n",
      "Iteration 7112, the loss is 4.442361306395035, parameters k is 10.306474859210224 and b is -42.10222274431139\n",
      "Iteration 7113, the loss is 4.442361290620656, parameters k is 10.306474469882161 and b is -42.10221879174222\n",
      "Iteration 7114, the loss is 4.442361274846274, parameters k is 10.306474080554098 and b is -42.102214839173044\n",
      "Iteration 7115, the loss is 4.442361259071897, parameters k is 10.306473691226035 and b is -42.10221088660387\n",
      "Iteration 7116, the loss is 4.442361243297516, parameters k is 10.306473301897972 and b is -42.1022069340347\n",
      "Iteration 7117, the loss is 4.442361227523134, parameters k is 10.306472912569909 and b is -42.102202981465524\n",
      "Iteration 7118, the loss is 4.442361211748758, parameters k is 10.306472523241846 and b is -42.10219902889635\n",
      "Iteration 7119, the loss is 4.442361195974381, parameters k is 10.306472133913783 and b is -42.10219507632718\n",
      "Iteration 7120, the loss is 4.442361180199999, parameters k is 10.30647174458572 and b is -42.102191123758004\n",
      "Iteration 7121, the loss is 4.442361164425619, parameters k is 10.306471355257656 and b is -42.10218717118883\n",
      "Iteration 7122, the loss is 4.442361148651241, parameters k is 10.306470965929593 and b is -42.10218321861966\n",
      "Iteration 7123, the loss is 4.442361132876859, parameters k is 10.30647057660153 and b is -42.102179266050484\n",
      "Iteration 7124, the loss is 4.442361117102479, parameters k is 10.306470187273467 and b is -42.10217531348131\n",
      "Iteration 7125, the loss is 4.442361101328102, parameters k is 10.306469797945404 and b is -42.10217136091214\n",
      "Iteration 7126, the loss is 4.44236108555372, parameters k is 10.30646940861734 and b is -42.102167408342964\n",
      "Iteration 7127, the loss is 4.442361069779343, parameters k is 10.306469019289278 and b is -42.10216345577379\n",
      "Iteration 7128, the loss is 4.442361054004962, parameters k is 10.306468629961214 and b is -42.10215950320462\n",
      "Iteration 7129, the loss is 4.442361038230582, parameters k is 10.306468240633151 and b is -42.102155550635445\n",
      "Iteration 7130, the loss is 4.442361022456206, parameters k is 10.306467851305088 and b is -42.10215159806627\n",
      "Iteration 7131, the loss is 4.442361006681826, parameters k is 10.306467461977025 and b is -42.1021476454971\n",
      "Iteration 7132, the loss is 4.4423609909074475, parameters k is 10.306467072648962 and b is -42.102143692927925\n",
      "Iteration 7133, the loss is 4.442360975133068, parameters k is 10.306466683320899 and b is -42.10213974035875\n",
      "Iteration 7134, the loss is 4.4423609593586875, parameters k is 10.306466293992836 and b is -42.10213578778958\n",
      "Iteration 7135, the loss is 4.442360943584307, parameters k is 10.306465904664773 and b is -42.102131835220405\n",
      "Iteration 7136, the loss is 4.442360927809929, parameters k is 10.30646551533671 and b is -42.10212788265123\n",
      "Iteration 7137, the loss is 4.44236091203555, parameters k is 10.306465126008646 and b is -42.10212393008206\n",
      "Iteration 7138, the loss is 4.442360896261172, parameters k is 10.306464736680583 and b is -42.102119977512885\n",
      "Iteration 7139, the loss is 4.44236088048679, parameters k is 10.30646434735252 and b is -42.10211602494371\n",
      "Iteration 7140, the loss is 4.442360864712412, parameters k is 10.306463958024457 and b is -42.10211207237454\n",
      "Iteration 7141, the loss is 4.442360848938035, parameters k is 10.306463568696394 and b is -42.102108119805365\n",
      "Iteration 7142, the loss is 4.442360833163652, parameters k is 10.30646317936833 and b is -42.10210416723619\n",
      "Iteration 7143, the loss is 4.442360817389272, parameters k is 10.306462790040268 and b is -42.10210021466702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7144, the loss is 4.442360801614893, parameters k is 10.306462400712205 and b is -42.102096262097845\n",
      "Iteration 7145, the loss is 4.442360785840516, parameters k is 10.306462011384141 and b is -42.10209230952867\n",
      "Iteration 7146, the loss is 4.442360770066134, parameters k is 10.306461622056078 and b is -42.1020883569595\n",
      "Iteration 7147, the loss is 4.442360754291753, parameters k is 10.306461232728015 and b is -42.102084404390325\n",
      "Iteration 7148, the loss is 4.442360738517375, parameters k is 10.306460843399952 and b is -42.10208045182115\n",
      "Iteration 7149, the loss is 4.442360722742995, parameters k is 10.306460454071889 and b is -42.10207649925198\n",
      "Iteration 7150, the loss is 4.442360706968616, parameters k is 10.306460064743826 and b is -42.102072546682805\n",
      "Iteration 7151, the loss is 4.442360691194238, parameters k is 10.306459675415763 and b is -42.10206859411363\n",
      "Iteration 7152, the loss is 4.4423606754198595, parameters k is 10.3064592860877 and b is -42.10206464154446\n",
      "Iteration 7153, the loss is 4.4423606596454785, parameters k is 10.306458896759636 and b is -42.102060688975286\n",
      "Iteration 7154, the loss is 4.4423606438711, parameters k is 10.306458507431573 and b is -42.10205673640611\n",
      "Iteration 7155, the loss is 4.44236062809672, parameters k is 10.30645811810351 and b is -42.10205278383694\n",
      "Iteration 7156, the loss is 4.442360612322339, parameters k is 10.306457728775447 and b is -42.102048831267766\n",
      "Iteration 7157, the loss is 4.442360596547961, parameters k is 10.306457339447384 and b is -42.10204487869859\n",
      "Iteration 7158, the loss is 4.442360580773584, parameters k is 10.30645695011932 and b is -42.10204092612942\n",
      "Iteration 7159, the loss is 4.442360564999204, parameters k is 10.306456560791258 and b is -42.102036973560246\n",
      "Iteration 7160, the loss is 4.442360549224824, parameters k is 10.306456171463195 and b is -42.10203302099107\n",
      "Iteration 7161, the loss is 4.4423605334504455, parameters k is 10.306455782135131 and b is -42.1020290684219\n",
      "Iteration 7162, the loss is 4.442360517676063, parameters k is 10.306455392807068 and b is -42.102025115852726\n",
      "Iteration 7163, the loss is 4.4423605019016845, parameters k is 10.306455003479005 and b is -42.10202116328355\n",
      "Iteration 7164, the loss is 4.442360486127304, parameters k is 10.306454614150942 and b is -42.10201721071438\n",
      "Iteration 7165, the loss is 4.442360470352927, parameters k is 10.306454224822879 and b is -42.102013258145206\n",
      "Iteration 7166, the loss is 4.442360454578547, parameters k is 10.306453835494816 and b is -42.10200930557603\n",
      "Iteration 7167, the loss is 4.442360438804166, parameters k is 10.306453446166753 and b is -42.10200535300686\n",
      "Iteration 7168, the loss is 4.442360423029787, parameters k is 10.30645305683869 and b is -42.102001400437686\n",
      "Iteration 7169, the loss is 4.44236040725541, parameters k is 10.306452667510626 and b is -42.10199744786851\n",
      "Iteration 7170, the loss is 4.442360391481029, parameters k is 10.306452278182563 and b is -42.10199349529934\n",
      "Iteration 7171, the loss is 4.4423603757066505, parameters k is 10.3064518888545 and b is -42.101989542730166\n",
      "Iteration 7172, the loss is 4.442360359932272, parameters k is 10.306451499526437 and b is -42.10198559016099\n",
      "Iteration 7173, the loss is 4.442360344157891, parameters k is 10.306451110198374 and b is -42.10198163759182\n",
      "Iteration 7174, the loss is 4.442360328383511, parameters k is 10.306450720870311 and b is -42.101977685022646\n",
      "Iteration 7175, the loss is 4.442360317447414, parameters k is 10.306450331542248 and b is -42.10197373245347\n",
      "Iteration 7176, the loss is 4.4423603017518, parameters k is 10.306422444190469 and b is -42.10197373245347\n",
      "Iteration 7177, the loss is 4.442360285977424, parameters k is 10.306422054862406 and b is -42.1019697798843\n",
      "Iteration 7178, the loss is 4.442360270203045, parameters k is 10.306421665534343 and b is -42.10196582731513\n",
      "Iteration 7179, the loss is 4.442360254428666, parameters k is 10.30642127620628 and b is -42.10196187474595\n",
      "Iteration 7180, the loss is 4.442360238654286, parameters k is 10.306420886878216 and b is -42.10195792217678\n",
      "Iteration 7181, the loss is 4.442360222879906, parameters k is 10.306420497550153 and b is -42.10195396960761\n",
      "Iteration 7182, the loss is 4.442360207105526, parameters k is 10.30642010822209 and b is -42.10195001703843\n",
      "Iteration 7183, the loss is 4.442360191331147, parameters k is 10.306419718894027 and b is -42.10194606446926\n",
      "Iteration 7184, the loss is 4.442360175556768, parameters k is 10.306419329565964 and b is -42.10194211190009\n",
      "Iteration 7185, the loss is 4.44236015978239, parameters k is 10.3064189402379 and b is -42.10193815933091\n",
      "Iteration 7186, the loss is 4.442360144008008, parameters k is 10.306418550909838 and b is -42.10193420676174\n",
      "Iteration 7187, the loss is 4.442360128233631, parameters k is 10.306418161581774 and b is -42.10193025419257\n",
      "Iteration 7188, the loss is 4.4423601124592516, parameters k is 10.306417772253711 and b is -42.101926301623394\n",
      "Iteration 7189, the loss is 4.442360096684874, parameters k is 10.306417382925648 and b is -42.10192234905422\n",
      "Iteration 7190, the loss is 4.442360080910492, parameters k is 10.306416993597585 and b is -42.10191839648505\n",
      "Iteration 7191, the loss is 4.44236006513611, parameters k is 10.306416604269522 and b is -42.101914443915874\n",
      "Iteration 7192, the loss is 4.442360049361732, parameters k is 10.306416214941459 and b is -42.1019104913467\n",
      "Iteration 7193, the loss is 4.442360033587352, parameters k is 10.306415825613396 and b is -42.10190653877753\n",
      "Iteration 7194, the loss is 4.442360017812976, parameters k is 10.306415436285333 and b is -42.101902586208354\n",
      "Iteration 7195, the loss is 4.442360002038595, parameters k is 10.30641504695727 and b is -42.10189863363918\n",
      "Iteration 7196, the loss is 4.442359986264216, parameters k is 10.306414657629206 and b is -42.10189468107001\n",
      "Iteration 7197, the loss is 4.442359970489835, parameters k is 10.306414268301143 and b is -42.101890728500834\n",
      "Iteration 7198, the loss is 4.442359954715456, parameters k is 10.30641387897308 and b is -42.10188677593166\n",
      "Iteration 7199, the loss is 4.4423599389410775, parameters k is 10.306413489645017 and b is -42.10188282336249\n",
      "Iteration 7200, the loss is 4.442359923166699, parameters k is 10.306413100316954 and b is -42.101878870793314\n",
      "Iteration 7201, the loss is 4.442359907392317, parameters k is 10.30641271098889 and b is -42.10187491822414\n",
      "Iteration 7202, the loss is 4.442359891617939, parameters k is 10.306412321660828 and b is -42.10187096565497\n",
      "Iteration 7203, the loss is 4.442359875843557, parameters k is 10.306411932332765 and b is -42.101867013085794\n",
      "Iteration 7204, the loss is 4.44235986006918, parameters k is 10.306411543004701 and b is -42.10186306051662\n",
      "Iteration 7205, the loss is 4.4423598442948, parameters k is 10.306411153676638 and b is -42.10185910794745\n",
      "Iteration 7206, the loss is 4.442359828520422, parameters k is 10.306410764348575 and b is -42.101855155378274\n",
      "Iteration 7207, the loss is 4.442359812746043, parameters k is 10.306410375020512 and b is -42.1018512028091\n",
      "Iteration 7208, the loss is 4.442359796971663, parameters k is 10.306409985692449 and b is -42.10184725023993\n",
      "Iteration 7209, the loss is 4.442359781197284, parameters k is 10.306409596364386 and b is -42.101843297670754\n",
      "Iteration 7210, the loss is 4.442359765422904, parameters k is 10.306409207036323 and b is -42.10183934510158\n",
      "Iteration 7211, the loss is 4.4423597496485225, parameters k is 10.30640881770826 and b is -42.10183539253241\n",
      "Iteration 7212, the loss is 4.442359733874144, parameters k is 10.306408428380196 and b is -42.101831439963235\n",
      "Iteration 7213, the loss is 4.442359718099765, parameters k is 10.306408039052133 and b is -42.10182748739406\n",
      "Iteration 7214, the loss is 4.442359702325384, parameters k is 10.30640764972407 and b is -42.10182353482489\n",
      "Iteration 7215, the loss is 4.442359686551008, parameters k is 10.306407260396007 and b is -42.101819582255715\n",
      "Iteration 7216, the loss is 4.442359670776631, parameters k is 10.306406871067944 and b is -42.10181562968654\n",
      "Iteration 7217, the loss is 4.442359655002247, parameters k is 10.30640648173988 and b is -42.10181167711737\n",
      "Iteration 7218, the loss is 4.442359639227868, parameters k is 10.306406092411818 and b is -42.101807724548195\n",
      "Iteration 7219, the loss is 4.442359623453489, parameters k is 10.306405703083755 and b is -42.10180377197902\n",
      "Iteration 7220, the loss is 4.44235960767911, parameters k is 10.306405313755691 and b is -42.10179981940985\n",
      "Iteration 7221, the loss is 4.442359591904729, parameters k is 10.306404924427628 and b is -42.101795866840675\n",
      "Iteration 7222, the loss is 4.442359576130351, parameters k is 10.306404535099565 and b is -42.1017919142715\n",
      "Iteration 7223, the loss is 4.44235956035597, parameters k is 10.306404145771502 and b is -42.10178796170233\n",
      "Iteration 7224, the loss is 4.442359544581592, parameters k is 10.306403756443439 and b is -42.101784009133155\n",
      "Iteration 7225, the loss is 4.44235952880721, parameters k is 10.306403367115376 and b is -42.10178005656398\n",
      "Iteration 7226, the loss is 4.442359513032835, parameters k is 10.306402977787313 and b is -42.10177610399481\n",
      "Iteration 7227, the loss is 4.442359497258453, parameters k is 10.30640258845925 and b is -42.101772151425635\n",
      "Iteration 7228, the loss is 4.442359481484072, parameters k is 10.306402199131186 and b is -42.10176819885646\n",
      "Iteration 7229, the loss is 4.442359465709695, parameters k is 10.306401809803123 and b is -42.10176424628729\n",
      "Iteration 7230, the loss is 4.442359449935315, parameters k is 10.30640142047506 and b is -42.101760293718115\n",
      "Iteration 7231, the loss is 4.442359434160936, parameters k is 10.306401031146997 and b is -42.10175634114894\n",
      "Iteration 7232, the loss is 4.442359418386558, parameters k is 10.306400641818934 and b is -42.10175238857977\n",
      "Iteration 7233, the loss is 4.442359402612178, parameters k is 10.30640025249087 and b is -42.101748436010595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7234, the loss is 4.4423593868378, parameters k is 10.306399863162808 and b is -42.10174448344142\n",
      "Iteration 7235, the loss is 4.442359371063421, parameters k is 10.306399473834745 and b is -42.10174053087225\n",
      "Iteration 7236, the loss is 4.4423593552890415, parameters k is 10.306399084506682 and b is -42.101736578303075\n",
      "Iteration 7237, the loss is 4.442359339514658, parameters k is 10.306398695178618 and b is -42.1017326257339\n",
      "Iteration 7238, the loss is 4.44235932374028, parameters k is 10.306398305850555 and b is -42.10172867316473\n",
      "Iteration 7239, the loss is 4.4423593079659, parameters k is 10.306397916522492 and b is -42.101724720595556\n",
      "Iteration 7240, the loss is 4.4423592921915205, parameters k is 10.306397527194429 and b is -42.10172076802638\n",
      "Iteration 7241, the loss is 4.442359276417142, parameters k is 10.306397137866366 and b is -42.10171681545721\n",
      "Iteration 7242, the loss is 4.442359260642765, parameters k is 10.306396748538303 and b is -42.101712862888036\n",
      "Iteration 7243, the loss is 4.442359244868385, parameters k is 10.30639635921024 and b is -42.10170891031886\n",
      "Iteration 7244, the loss is 4.442359229094005, parameters k is 10.306395969882177 and b is -42.10170495774969\n",
      "Iteration 7245, the loss is 4.442359213319626, parameters k is 10.306395580554113 and b is -42.101701005180516\n",
      "Iteration 7246, the loss is 4.4423591975452466, parameters k is 10.30639519122605 and b is -42.10169705261134\n",
      "Iteration 7247, the loss is 4.442359181770866, parameters k is 10.306394801897987 and b is -42.10169310004217\n",
      "Iteration 7248, the loss is 4.442359165996488, parameters k is 10.306394412569924 and b is -42.101689147472996\n",
      "Iteration 7249, the loss is 4.442359150222108, parameters k is 10.306394023241861 and b is -42.10168519490382\n",
      "Iteration 7250, the loss is 4.442359134447727, parameters k is 10.306393633913798 and b is -42.10168124233465\n",
      "Iteration 7251, the loss is 4.442359118673351, parameters k is 10.306393244585735 and b is -42.101677289765476\n",
      "Iteration 7252, the loss is 4.442359102898969, parameters k is 10.306392855257672 and b is -42.1016733371963\n",
      "Iteration 7253, the loss is 4.442359087124588, parameters k is 10.306392465929608 and b is -42.10166938462713\n",
      "Iteration 7254, the loss is 4.44235907135021, parameters k is 10.306392076601545 and b is -42.101665432057956\n",
      "Iteration 7255, the loss is 4.442359055575831, parameters k is 10.306391687273482 and b is -42.10166147948878\n",
      "Iteration 7256, the loss is 4.442359039801452, parameters k is 10.306391297945419 and b is -42.10165752691961\n",
      "Iteration 7257, the loss is 4.442359024027072, parameters k is 10.306390908617356 and b is -42.101653574350436\n",
      "Iteration 7258, the loss is 4.4423590082526925, parameters k is 10.306390519289293 and b is -42.10164962178126\n",
      "Iteration 7259, the loss is 4.4423589924783125, parameters k is 10.30639012996123 and b is -42.10164566921209\n",
      "Iteration 7260, the loss is 4.442358976703935, parameters k is 10.306389740633167 and b is -42.101641716642916\n",
      "Iteration 7261, the loss is 4.442358960929554, parameters k is 10.306389351305103 and b is -42.10163776407374\n",
      "Iteration 7262, the loss is 4.442358945155176, parameters k is 10.30638896197704 and b is -42.10163381150457\n",
      "Iteration 7263, the loss is 4.442358929380796, parameters k is 10.306388572648977 and b is -42.1016298589354\n",
      "Iteration 7264, the loss is 4.442358913606415, parameters k is 10.306388183320914 and b is -42.10162590636622\n",
      "Iteration 7265, the loss is 4.442358897832035, parameters k is 10.306387793992851 and b is -42.10162195379705\n",
      "Iteration 7266, the loss is 4.442358882057658, parameters k is 10.306387404664788 and b is -42.10161800122788\n",
      "Iteration 7267, the loss is 4.442358866283277, parameters k is 10.306387015336725 and b is -42.1016140486587\n",
      "Iteration 7268, the loss is 4.4423588505088984, parameters k is 10.306386626008662 and b is -42.10161009608953\n",
      "Iteration 7269, the loss is 4.4423588347345175, parameters k is 10.306386236680599 and b is -42.10160614352036\n",
      "Iteration 7270, the loss is 4.442358818960139, parameters k is 10.306385847352535 and b is -42.10160219095118\n",
      "Iteration 7271, the loss is 4.44235880318576, parameters k is 10.306385458024472 and b is -42.10159823838201\n",
      "Iteration 7272, the loss is 4.442358787411382, parameters k is 10.30638506869641 and b is -42.10159428581284\n",
      "Iteration 7273, the loss is 4.442358771637002, parameters k is 10.306384679368346 and b is -42.101590333243664\n",
      "Iteration 7274, the loss is 4.442358755862623, parameters k is 10.306384290040283 and b is -42.10158638067449\n",
      "Iteration 7275, the loss is 4.4423587400882445, parameters k is 10.30638390071222 and b is -42.10158242810532\n",
      "Iteration 7276, the loss is 4.442358724313864, parameters k is 10.306383511384157 and b is -42.101578475536144\n",
      "Iteration 7277, the loss is 4.442358708539485, parameters k is 10.306383122056094 and b is -42.10157452296697\n",
      "Iteration 7278, the loss is 4.442358692765105, parameters k is 10.30638273272803 and b is -42.1015705703978\n",
      "Iteration 7279, the loss is 4.442358676990724, parameters k is 10.306382343399967 and b is -42.101566617828624\n",
      "Iteration 7280, the loss is 4.442358661216346, parameters k is 10.306381954071904 and b is -42.10156266525945\n",
      "Iteration 7281, the loss is 4.442358645441969, parameters k is 10.306381564743841 and b is -42.10155871269028\n",
      "Iteration 7282, the loss is 4.442358629667585, parameters k is 10.306381175415778 and b is -42.101554760121104\n",
      "Iteration 7283, the loss is 4.4423586138932105, parameters k is 10.306380786087715 and b is -42.10155080755193\n",
      "Iteration 7284, the loss is 4.442358598118826, parameters k is 10.306380396759652 and b is -42.10154685498276\n",
      "Iteration 7285, the loss is 4.442358582344449, parameters k is 10.306380007431589 and b is -42.101542902413584\n",
      "Iteration 7286, the loss is 4.44235856657007, parameters k is 10.306379618103525 and b is -42.10153894984441\n",
      "Iteration 7287, the loss is 4.44235855079569, parameters k is 10.306379228775462 and b is -42.10153499727524\n",
      "Iteration 7288, the loss is 4.442358535021312, parameters k is 10.3063788394474 and b is -42.101531044706064\n",
      "Iteration 7289, the loss is 4.442358519246931, parameters k is 10.306378450119336 and b is -42.10152709213689\n",
      "Iteration 7290, the loss is 4.442358503472551, parameters k is 10.306378060791273 and b is -42.10152313956772\n",
      "Iteration 7291, the loss is 4.442358487698173, parameters k is 10.30637767146321 and b is -42.101519186998544\n",
      "Iteration 7292, the loss is 4.442358471923794, parameters k is 10.306377282135147 and b is -42.10151523442937\n",
      "Iteration 7293, the loss is 4.442358456149415, parameters k is 10.306376892807084 and b is -42.1015112818602\n",
      "Iteration 7294, the loss is 4.442358440375034, parameters k is 10.30637650347902 and b is -42.101507329291024\n",
      "Iteration 7295, the loss is 4.442358424600653, parameters k is 10.306376114150957 and b is -42.10150337672185\n",
      "Iteration 7296, the loss is 4.442358408826275, parameters k is 10.306375724822894 and b is -42.10149942415268\n",
      "Iteration 7297, the loss is 4.4423583930518955, parameters k is 10.306375335494831 and b is -42.101495471583505\n",
      "Iteration 7298, the loss is 4.442358377277518, parameters k is 10.306374946166768 and b is -42.10149151901433\n",
      "Iteration 7299, the loss is 4.442358361503139, parameters k is 10.306374556838705 and b is -42.10148756644516\n",
      "Iteration 7300, the loss is 4.442358345728758, parameters k is 10.306374167510642 and b is -42.101483613875985\n",
      "Iteration 7301, the loss is 4.44235832995438, parameters k is 10.306373778182579 and b is -42.10147966130681\n",
      "Iteration 7302, the loss is 4.442358314179999, parameters k is 10.306373388854515 and b is -42.10147570873764\n",
      "Iteration 7303, the loss is 4.44235829840562, parameters k is 10.306372999526452 and b is -42.101471756168465\n",
      "Iteration 7304, the loss is 4.442358282631241, parameters k is 10.30637261019839 and b is -42.10146780359929\n",
      "Iteration 7305, the loss is 4.44235826685686, parameters k is 10.306372220870326 and b is -42.10146385103012\n",
      "Iteration 7306, the loss is 4.442358251082485, parameters k is 10.306371831542263 and b is -42.101459898460945\n",
      "Iteration 7307, the loss is 4.4423582353081015, parameters k is 10.3063714422142 and b is -42.10145594589177\n",
      "Iteration 7308, the loss is 4.44235821953372, parameters k is 10.306371052886137 and b is -42.1014519933226\n",
      "Iteration 7309, the loss is 4.442358203759344, parameters k is 10.306370663558074 and b is -42.101448040753425\n",
      "Iteration 7310, the loss is 4.442358187984962, parameters k is 10.30637027423001 and b is -42.10144408818425\n",
      "Iteration 7311, the loss is 4.442358172210585, parameters k is 10.306369884901947 and b is -42.10144013561508\n",
      "Iteration 7312, the loss is 4.442358156436207, parameters k is 10.306369495573884 and b is -42.101436183045905\n",
      "Iteration 7313, the loss is 4.442358140661828, parameters k is 10.306369106245821 and b is -42.10143223047673\n",
      "Iteration 7314, the loss is 4.442358124887444, parameters k is 10.306368716917758 and b is -42.10142827790756\n",
      "Iteration 7315, the loss is 4.4423581091130675, parameters k is 10.306368327589695 and b is -42.101424325338385\n",
      "Iteration 7316, the loss is 4.442358093338686, parameters k is 10.306367938261632 and b is -42.10142037276921\n",
      "Iteration 7317, the loss is 4.442358077564308, parameters k is 10.306367548933569 and b is -42.10141642020004\n",
      "Iteration 7318, the loss is 4.44235806178993, parameters k is 10.306367159605506 and b is -42.101412467630865\n",
      "Iteration 7319, the loss is 4.44235804601555, parameters k is 10.306366770277442 and b is -42.10140851506169\n",
      "Iteration 7320, the loss is 4.442358030241171, parameters k is 10.30636638094938 and b is -42.10140456249252\n",
      "Iteration 7321, the loss is 4.442358014466793, parameters k is 10.306365991621316 and b is -42.101400609923346\n",
      "Iteration 7322, the loss is 4.4423579986924135, parameters k is 10.306365602293253 and b is -42.10139665735417\n",
      "Iteration 7323, the loss is 4.442357982918032, parameters k is 10.30636521296519 and b is -42.101392704785\n",
      "Iteration 7324, the loss is 4.442357967143653, parameters k is 10.306364823637127 and b is -42.101388752215826\n",
      "Iteration 7325, the loss is 4.4423579513692735, parameters k is 10.306364434309064 and b is -42.10138479964665\n",
      "Iteration 7326, the loss is 4.442357935594894, parameters k is 10.306364044981 and b is -42.10138084707748\n",
      "Iteration 7327, the loss is 4.442357919820515, parameters k is 10.306363655652937 and b is -42.101376894508306\n",
      "Iteration 7328, the loss is 4.442357904046134, parameters k is 10.306363266324874 and b is -42.10137294193913\n",
      "Iteration 7329, the loss is 4.442357888271755, parameters k is 10.306362876996811 and b is -42.10136898936996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7330, the loss is 4.442357872497374, parameters k is 10.306362487668748 and b is -42.101365036800786\n",
      "Iteration 7331, the loss is 4.442357856857085, parameters k is 10.306362098340685 and b is -42.10136108423161\n",
      "Iteration 7332, the loss is 4.442357845865668, parameters k is 10.306334210988906 and b is -42.10136108423161\n",
      "Iteration 7333, the loss is 4.442357830091289, parameters k is 10.306333821660843 and b is -42.10135713166244\n",
      "Iteration 7334, the loss is 4.442357814316906, parameters k is 10.30633343233278 and b is -42.101353179093266\n",
      "Iteration 7335, the loss is 4.44235779854253, parameters k is 10.306333043004717 and b is -42.10134922652409\n",
      "Iteration 7336, the loss is 4.442357782768152, parameters k is 10.306332653676654 and b is -42.10134527395492\n",
      "Iteration 7337, the loss is 4.442357766993769, parameters k is 10.30633226434859 and b is -42.101341321385746\n",
      "Iteration 7338, the loss is 4.44235775121939, parameters k is 10.306331875020527 and b is -42.10133736881657\n",
      "Iteration 7339, the loss is 4.442357735445012, parameters k is 10.306331485692464 and b is -42.1013334162474\n",
      "Iteration 7340, the loss is 4.442357719670631, parameters k is 10.306331096364401 and b is -42.101329463678226\n",
      "Iteration 7341, the loss is 4.442357703896255, parameters k is 10.306330707036338 and b is -42.10132551110905\n",
      "Iteration 7342, the loss is 4.442357688121875, parameters k is 10.306330317708275 and b is -42.10132155853988\n",
      "Iteration 7343, the loss is 4.442357672347496, parameters k is 10.306329928380212 and b is -42.101317605970706\n",
      "Iteration 7344, the loss is 4.442357656573114, parameters k is 10.306329539052149 and b is -42.10131365340153\n",
      "Iteration 7345, the loss is 4.4423576407987335, parameters k is 10.306329149724085 and b is -42.10130970083236\n",
      "Iteration 7346, the loss is 4.442357625024357, parameters k is 10.306328760396022 and b is -42.10130574826319\n",
      "Iteration 7347, the loss is 4.442357609249976, parameters k is 10.30632837106796 and b is -42.10130179569401\n",
      "Iteration 7348, the loss is 4.442357593475595, parameters k is 10.306327981739896 and b is -42.10129784312484\n",
      "Iteration 7349, the loss is 4.442357577701219, parameters k is 10.306327592411833 and b is -42.10129389055567\n",
      "Iteration 7350, the loss is 4.442357561926839, parameters k is 10.30632720308377 and b is -42.10128993798649\n",
      "Iteration 7351, the loss is 4.442357546152459, parameters k is 10.306326813755707 and b is -42.10128598541732\n",
      "Iteration 7352, the loss is 4.442357530378081, parameters k is 10.306326424427644 and b is -42.10128203284815\n",
      "Iteration 7353, the loss is 4.4423575146036995, parameters k is 10.30632603509958 and b is -42.10127808027897\n",
      "Iteration 7354, the loss is 4.4423574988293195, parameters k is 10.306325645771517 and b is -42.1012741277098\n",
      "Iteration 7355, the loss is 4.442357483054943, parameters k is 10.306325256443454 and b is -42.10127017514063\n",
      "Iteration 7356, the loss is 4.442357467280564, parameters k is 10.306324867115391 and b is -42.101266222571454\n",
      "Iteration 7357, the loss is 4.442357451506182, parameters k is 10.306324477787328 and b is -42.10126227000228\n",
      "Iteration 7358, the loss is 4.442357435731804, parameters k is 10.306324088459265 and b is -42.10125831743311\n",
      "Iteration 7359, the loss is 4.442357419957426, parameters k is 10.306323699131202 and b is -42.101254364863934\n",
      "Iteration 7360, the loss is 4.442357404183045, parameters k is 10.306323309803139 and b is -42.10125041229476\n",
      "Iteration 7361, the loss is 4.442357388408667, parameters k is 10.306322920475075 and b is -42.10124645972559\n",
      "Iteration 7362, the loss is 4.4423573726342855, parameters k is 10.306322531147012 and b is -42.101242507156414\n",
      "Iteration 7363, the loss is 4.442357356859907, parameters k is 10.30632214181895 and b is -42.10123855458724\n",
      "Iteration 7364, the loss is 4.442357341085526, parameters k is 10.306321752490886 and b is -42.10123460201807\n",
      "Iteration 7365, the loss is 4.442357325311146, parameters k is 10.306321363162823 and b is -42.101230649448894\n",
      "Iteration 7366, the loss is 4.442357309536771, parameters k is 10.30632097383476 and b is -42.10122669687972\n",
      "Iteration 7367, the loss is 4.442357293762389, parameters k is 10.306320584506697 and b is -42.10122274431055\n",
      "Iteration 7368, the loss is 4.4423572779880125, parameters k is 10.306320195178634 and b is -42.101218791741374\n",
      "Iteration 7369, the loss is 4.442357262213628, parameters k is 10.30631980585057 and b is -42.1012148391722\n",
      "Iteration 7370, the loss is 4.442357246439249, parameters k is 10.306319416522507 and b is -42.10121088660303\n",
      "Iteration 7371, the loss is 4.4423572306648715, parameters k is 10.306319027194444 and b is -42.101206934033854\n",
      "Iteration 7372, the loss is 4.4423572148904915, parameters k is 10.306318637866381 and b is -42.10120298146468\n",
      "Iteration 7373, the loss is 4.442357199116114, parameters k is 10.306318248538318 and b is -42.10119902889551\n",
      "Iteration 7374, the loss is 4.442357183341732, parameters k is 10.306317859210255 and b is -42.101195076326334\n",
      "Iteration 7375, the loss is 4.442357167567358, parameters k is 10.306317469882192 and b is -42.10119112375716\n",
      "Iteration 7376, the loss is 4.442357151792975, parameters k is 10.306317080554129 and b is -42.10118717118799\n",
      "Iteration 7377, the loss is 4.442357136018595, parameters k is 10.306316691226066 and b is -42.101183218618814\n",
      "Iteration 7378, the loss is 4.442357120244217, parameters k is 10.306316301898002 and b is -42.10117926604964\n",
      "Iteration 7379, the loss is 4.442357104469836, parameters k is 10.30631591256994 and b is -42.10117531348047\n",
      "Iteration 7380, the loss is 4.4423570886954575, parameters k is 10.306315523241876 and b is -42.101171360911295\n",
      "Iteration 7381, the loss is 4.442357072921078, parameters k is 10.306315133913813 and b is -42.10116740834212\n",
      "Iteration 7382, the loss is 4.442357057146698, parameters k is 10.30631474458575 and b is -42.10116345577295\n",
      "Iteration 7383, the loss is 4.442357041372319, parameters k is 10.306314355257687 and b is -42.101159503203775\n",
      "Iteration 7384, the loss is 4.442357025597937, parameters k is 10.306313965929624 and b is -42.1011555506346\n",
      "Iteration 7385, the loss is 4.44235700982356, parameters k is 10.30631357660156 and b is -42.10115159806543\n",
      "Iteration 7386, the loss is 4.44235699404918, parameters k is 10.306313187273497 and b is -42.101147645496255\n",
      "Iteration 7387, the loss is 4.442356978274802, parameters k is 10.306312797945434 and b is -42.10114369292708\n",
      "Iteration 7388, the loss is 4.442356962500423, parameters k is 10.306312408617371 and b is -42.10113974035791\n",
      "Iteration 7389, the loss is 4.442356946726043, parameters k is 10.306312019289308 and b is -42.101135787788735\n",
      "Iteration 7390, the loss is 4.442356930951663, parameters k is 10.306311629961245 and b is -42.10113183521956\n",
      "Iteration 7391, the loss is 4.442356915177286, parameters k is 10.306311240633182 and b is -42.10112788265039\n",
      "Iteration 7392, the loss is 4.442356899402905, parameters k is 10.306310851305119 and b is -42.101123930081215\n",
      "Iteration 7393, the loss is 4.442356883628525, parameters k is 10.306310461977056 and b is -42.10111997751204\n",
      "Iteration 7394, the loss is 4.442356867854146, parameters k is 10.306310072648992 and b is -42.10111602494287\n",
      "Iteration 7395, the loss is 4.442356852079766, parameters k is 10.30630968332093 and b is -42.101112072373695\n",
      "Iteration 7396, the loss is 4.442356836305387, parameters k is 10.306309293992866 and b is -42.10110811980452\n",
      "Iteration 7397, the loss is 4.442356820531006, parameters k is 10.306308904664803 and b is -42.10110416723535\n",
      "Iteration 7398, the loss is 4.442356804756629, parameters k is 10.30630851533674 and b is -42.101100214666175\n",
      "Iteration 7399, the loss is 4.442356788982245, parameters k is 10.306308126008677 and b is -42.101096262097\n",
      "Iteration 7400, the loss is 4.4423567732078695, parameters k is 10.306307736680614 and b is -42.10109230952783\n",
      "Iteration 7401, the loss is 4.4423567574334895, parameters k is 10.30630734735255 and b is -42.101088356958655\n",
      "Iteration 7402, the loss is 4.442356741659111, parameters k is 10.306306958024487 and b is -42.10108440438948\n",
      "Iteration 7403, the loss is 4.44235672588473, parameters k is 10.306306568696424 and b is -42.10108045182031\n",
      "Iteration 7404, the loss is 4.44235671011035, parameters k is 10.306306179368361 and b is -42.101076499251135\n",
      "Iteration 7405, the loss is 4.442356694335973, parameters k is 10.306305790040298 and b is -42.10107254668196\n",
      "Iteration 7406, the loss is 4.442356678561593, parameters k is 10.306305400712235 and b is -42.10106859411279\n",
      "Iteration 7407, the loss is 4.442356662787215, parameters k is 10.306305011384172 and b is -42.101064641543616\n",
      "Iteration 7408, the loss is 4.442356647012834, parameters k is 10.306304622056109 and b is -42.10106068897444\n",
      "Iteration 7409, the loss is 4.442356631238452, parameters k is 10.306304232728046 and b is -42.10105673640527\n",
      "Iteration 7410, the loss is 4.442356615464077, parameters k is 10.306303843399983 and b is -42.101052783836096\n",
      "Iteration 7411, the loss is 4.4423565996896945, parameters k is 10.30630345407192 and b is -42.10104883126692\n",
      "Iteration 7412, the loss is 4.442356583915316, parameters k is 10.306303064743856 and b is -42.10104487869775\n",
      "Iteration 7413, the loss is 4.442356568140936, parameters k is 10.306302675415793 and b is -42.101040926128576\n",
      "Iteration 7414, the loss is 4.442356552366557, parameters k is 10.30630228608773 and b is -42.1010369735594\n",
      "Iteration 7415, the loss is 4.442356536592177, parameters k is 10.306301896759667 and b is -42.10103302099023\n",
      "Iteration 7416, the loss is 4.442356520817798, parameters k is 10.306301507431604 and b is -42.101029068421056\n",
      "Iteration 7417, the loss is 4.442356505043418, parameters k is 10.30630111810354 and b is -42.10102511585188\n",
      "Iteration 7418, the loss is 4.44235648926904, parameters k is 10.306300728775478 and b is -42.10102116328271\n",
      "Iteration 7419, the loss is 4.442356473494659, parameters k is 10.306300339447414 and b is -42.101017210713536\n",
      "Iteration 7420, the loss is 4.442356457720282, parameters k is 10.306299950119351 and b is -42.10101325814436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7421, the loss is 4.442356441945904, parameters k is 10.306299560791288 and b is -42.10100930557519\n",
      "Iteration 7422, the loss is 4.442356426171523, parameters k is 10.306299171463225 and b is -42.101005353006016\n",
      "Iteration 7423, the loss is 4.442356410397143, parameters k is 10.306298782135162 and b is -42.10100140043684\n",
      "Iteration 7424, the loss is 4.442356394622765, parameters k is 10.306298392807099 and b is -42.10099744786767\n",
      "Iteration 7425, the loss is 4.442356378848382, parameters k is 10.306298003479036 and b is -42.100993495298496\n",
      "Iteration 7426, the loss is 4.442356363074004, parameters k is 10.306297614150973 and b is -42.10098954272932\n",
      "Iteration 7427, the loss is 4.442356347299625, parameters k is 10.30629722482291 and b is -42.10098559016015\n",
      "Iteration 7428, the loss is 4.442356331525246, parameters k is 10.306296835494846 and b is -42.10098163759098\n",
      "Iteration 7429, the loss is 4.4423563157508665, parameters k is 10.306296446166783 and b is -42.1009776850218\n",
      "Iteration 7430, the loss is 4.442356299976486, parameters k is 10.30629605683872 and b is -42.10097373245263\n",
      "Iteration 7431, the loss is 4.4423562842021065, parameters k is 10.306295667510657 and b is -42.10096977988346\n",
      "Iteration 7432, the loss is 4.442356268427727, parameters k is 10.306295278182594 and b is -42.10096582731428\n",
      "Iteration 7433, the loss is 4.44235625265335, parameters k is 10.30629488885453 and b is -42.10096187474511\n",
      "Iteration 7434, the loss is 4.442356236878972, parameters k is 10.306294499526468 and b is -42.10095792217594\n",
      "Iteration 7435, the loss is 4.442356221104592, parameters k is 10.306294110198404 and b is -42.10095396960676\n",
      "Iteration 7436, the loss is 4.442356205330211, parameters k is 10.306293720870341 and b is -42.10095001703759\n",
      "Iteration 7437, the loss is 4.442356189555833, parameters k is 10.306293331542278 and b is -42.10094606446842\n",
      "Iteration 7438, the loss is 4.44235617378145, parameters k is 10.306292942214215 and b is -42.10094211189924\n",
      "Iteration 7439, the loss is 4.442356158007071, parameters k is 10.306292552886152 and b is -42.10093815933007\n",
      "Iteration 7440, the loss is 4.442356142232693, parameters k is 10.306292163558089 and b is -42.1009342067609\n",
      "Iteration 7441, the loss is 4.4423561264583125, parameters k is 10.306291774230026 and b is -42.100930254191724\n",
      "Iteration 7442, the loss is 4.442356110683936, parameters k is 10.306291384901963 and b is -42.10092630162255\n",
      "Iteration 7443, the loss is 4.442356094909554, parameters k is 10.3062909955739 and b is -42.10092234905338\n",
      "Iteration 7444, the loss is 4.442356079135175, parameters k is 10.306290606245836 and b is -42.100918396484204\n",
      "Iteration 7445, the loss is 4.442356063360795, parameters k is 10.306290216917773 and b is -42.10091444391503\n",
      "Iteration 7446, the loss is 4.442356047586414, parameters k is 10.30628982758971 and b is -42.10091049134586\n",
      "Iteration 7447, the loss is 4.442356031812038, parameters k is 10.306289438261647 and b is -42.100906538776684\n",
      "Iteration 7448, the loss is 4.4423560160376585, parameters k is 10.306289048933584 and b is -42.10090258620751\n",
      "Iteration 7449, the loss is 4.442356000263276, parameters k is 10.30628865960552 and b is -42.10089863363834\n",
      "Iteration 7450, the loss is 4.4423559844889, parameters k is 10.306288270277458 and b is -42.100894681069164\n",
      "Iteration 7451, the loss is 4.442355968714518, parameters k is 10.306287880949395 and b is -42.10089072849999\n",
      "Iteration 7452, the loss is 4.44235595294014, parameters k is 10.306287491621331 and b is -42.10088677593082\n",
      "Iteration 7453, the loss is 4.4423559371657575, parameters k is 10.306287102293268 and b is -42.100882823361644\n",
      "Iteration 7454, the loss is 4.442355921391383, parameters k is 10.306286712965205 and b is -42.10087887079247\n",
      "Iteration 7455, the loss is 4.442355905616998, parameters k is 10.306286323637142 and b is -42.1008749182233\n",
      "Iteration 7456, the loss is 4.442355889842621, parameters k is 10.306285934309079 and b is -42.100870965654124\n",
      "Iteration 7457, the loss is 4.442355874068245, parameters k is 10.306285544981016 and b is -42.10086701308495\n",
      "Iteration 7458, the loss is 4.442355858293862, parameters k is 10.306285155652953 and b is -42.10086306051578\n",
      "Iteration 7459, the loss is 4.442355842519485, parameters k is 10.30628476632489 and b is -42.100859107946604\n",
      "Iteration 7460, the loss is 4.4423558267451035, parameters k is 10.306284376996826 and b is -42.10085515537743\n",
      "Iteration 7461, the loss is 4.442355810970727, parameters k is 10.306283987668763 and b is -42.10085120280826\n",
      "Iteration 7462, the loss is 4.442355795196347, parameters k is 10.3062835983407 and b is -42.100847250239084\n",
      "Iteration 7463, the loss is 4.442355779421967, parameters k is 10.306283209012637 and b is -42.10084329766991\n",
      "Iteration 7464, the loss is 4.442355763647588, parameters k is 10.306282819684574 and b is -42.10083934510074\n",
      "Iteration 7465, the loss is 4.44235574787321, parameters k is 10.30628243035651 and b is -42.100835392531565\n",
      "Iteration 7466, the loss is 4.442355732098828, parameters k is 10.306282041028448 and b is -42.10083143996239\n",
      "Iteration 7467, the loss is 4.4423557163244505, parameters k is 10.306281651700385 and b is -42.10082748739322\n",
      "Iteration 7468, the loss is 4.4423557005500705, parameters k is 10.306281262372321 and b is -42.100823534824045\n",
      "Iteration 7469, the loss is 4.442355684775693, parameters k is 10.306280873044258 and b is -42.10081958225487\n",
      "Iteration 7470, the loss is 4.442355669001312, parameters k is 10.306280483716195 and b is -42.1008156296857\n",
      "Iteration 7471, the loss is 4.442355653226932, parameters k is 10.306280094388132 and b is -42.100811677116525\n",
      "Iteration 7472, the loss is 4.442355637452554, parameters k is 10.306279705060069 and b is -42.10080772454735\n",
      "Iteration 7473, the loss is 4.442355621678174, parameters k is 10.306279315732006 and b is -42.10080377197818\n",
      "Iteration 7474, the loss is 4.442355605903792, parameters k is 10.306278926403943 and b is -42.100799819409005\n",
      "Iteration 7475, the loss is 4.442355590129414, parameters k is 10.30627853707588 and b is -42.10079586683983\n",
      "Iteration 7476, the loss is 4.442355574355035, parameters k is 10.306278147747816 and b is -42.10079191427066\n",
      "Iteration 7477, the loss is 4.442355558580653, parameters k is 10.306277758419753 and b is -42.100787961701485\n",
      "Iteration 7478, the loss is 4.4423555428062755, parameters k is 10.30627736909169 and b is -42.10078400913231\n",
      "Iteration 7479, the loss is 4.442355527031897, parameters k is 10.306276979763627 and b is -42.10078005656314\n",
      "Iteration 7480, the loss is 4.442355511257517, parameters k is 10.306276590435564 and b is -42.100776103993965\n",
      "Iteration 7481, the loss is 4.4423554954831355, parameters k is 10.3062762011075 and b is -42.10077215142479\n",
      "Iteration 7482, the loss is 4.442355479708759, parameters k is 10.306275811779438 and b is -42.10076819885562\n",
      "Iteration 7483, the loss is 4.442355463934379, parameters k is 10.306275422451375 and b is -42.100764246286445\n",
      "Iteration 7484, the loss is 4.442355448160001, parameters k is 10.306275033123312 and b is -42.10076029371727\n",
      "Iteration 7485, the loss is 4.442355432385622, parameters k is 10.306274643795248 and b is -42.1007563411481\n",
      "Iteration 7486, the loss is 4.442355416611242, parameters k is 10.306274254467185 and b is -42.100752388578925\n",
      "Iteration 7487, the loss is 4.4423554008368615, parameters k is 10.306273865139122 and b is -42.10074843600975\n",
      "Iteration 7488, the loss is 4.442355385409426, parameters k is 10.306273475811059 and b is -42.10074448344058\n",
      "Iteration 7489, the loss is 4.442355374205154, parameters k is 10.30624558845928 and b is -42.10074448344058\n",
      "Iteration 7490, the loss is 4.442355358430774, parameters k is 10.306245199131217 and b is -42.100740530871406\n",
      "Iteration 7491, the loss is 4.442355342656393, parameters k is 10.306244809803154 and b is -42.10073657830223\n",
      "Iteration 7492, the loss is 4.442355326882016, parameters k is 10.30624442047509 and b is -42.10073262573306\n",
      "Iteration 7493, the loss is 4.442355311107637, parameters k is 10.306244031147028 and b is -42.100728673163886\n",
      "Iteration 7494, the loss is 4.4423552953332575, parameters k is 10.306243641818964 and b is -42.10072472059471\n",
      "Iteration 7495, the loss is 4.4423552795588765, parameters k is 10.306243252490901 and b is -42.10072076802554\n",
      "Iteration 7496, the loss is 4.442355263784499, parameters k is 10.306242863162838 and b is -42.100716815456366\n",
      "Iteration 7497, the loss is 4.442355248010118, parameters k is 10.306242473834775 and b is -42.10071286288719\n",
      "Iteration 7498, the loss is 4.442355232235739, parameters k is 10.306242084506712 and b is -42.10070891031802\n",
      "Iteration 7499, the loss is 4.44235521646136, parameters k is 10.306241695178649 and b is -42.100704957748846\n",
      "Iteration 7500, the loss is 4.44235520068698, parameters k is 10.306241305850586 and b is -42.10070100517967\n",
      "Iteration 7501, the loss is 4.442355184912598, parameters k is 10.306240916522523 and b is -42.1006970526105\n",
      "Iteration 7502, the loss is 4.442355169138221, parameters k is 10.30624052719446 and b is -42.100693100041326\n",
      "Iteration 7503, the loss is 4.442355153363843, parameters k is 10.306240137866396 and b is -42.10068914747215\n",
      "Iteration 7504, the loss is 4.442355137589462, parameters k is 10.306239748538333 and b is -42.10068519490298\n",
      "Iteration 7505, the loss is 4.4423551218150825, parameters k is 10.30623935921027 and b is -42.100681242333806\n",
      "Iteration 7506, the loss is 4.4423551060407025, parameters k is 10.306238969882207 and b is -42.10067728976463\n",
      "Iteration 7507, the loss is 4.442355090266325, parameters k is 10.306238580554144 and b is -42.10067333719546\n",
      "Iteration 7508, the loss is 4.442355074491945, parameters k is 10.30623819122608 and b is -42.100669384626286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7509, the loss is 4.442355058717563, parameters k is 10.306237801898018 and b is -42.10066543205711\n",
      "Iteration 7510, the loss is 4.442355042943185, parameters k is 10.306237412569955 and b is -42.10066147948794\n",
      "Iteration 7511, the loss is 4.442355027168808, parameters k is 10.306237023241891 and b is -42.100657526918766\n",
      "Iteration 7512, the loss is 4.442355011394428, parameters k is 10.306236633913828 and b is -42.10065357434959\n",
      "Iteration 7513, the loss is 4.442354995620045, parameters k is 10.306236244585765 and b is -42.10064962178042\n",
      "Iteration 7514, the loss is 4.4423549798456685, parameters k is 10.306235855257702 and b is -42.10064566921125\n",
      "Iteration 7515, the loss is 4.4423549640712885, parameters k is 10.306235465929639 and b is -42.10064171664207\n",
      "Iteration 7516, the loss is 4.442354948296909, parameters k is 10.306235076601576 and b is -42.1006377640729\n",
      "Iteration 7517, the loss is 4.442354932522531, parameters k is 10.306234687273513 and b is -42.10063381150373\n",
      "Iteration 7518, the loss is 4.442354916748149, parameters k is 10.30623429794545 and b is -42.10062985893455\n",
      "Iteration 7519, the loss is 4.442354900973772, parameters k is 10.306233908617386 and b is -42.10062590636538\n",
      "Iteration 7520, the loss is 4.442354885199395, parameters k is 10.306233519289323 and b is -42.10062195379621\n",
      "Iteration 7521, the loss is 4.442354869425014, parameters k is 10.30623312996126 and b is -42.10061800122703\n",
      "Iteration 7522, the loss is 4.442354853650633, parameters k is 10.306232740633197 and b is -42.10061404865786\n",
      "Iteration 7523, the loss is 4.4423548378762545, parameters k is 10.306232351305134 and b is -42.10061009608869\n",
      "Iteration 7524, the loss is 4.4423548221018745, parameters k is 10.30623196197707 and b is -42.100606143519514\n",
      "Iteration 7525, the loss is 4.4423548063274945, parameters k is 10.306231572649008 and b is -42.10060219095034\n",
      "Iteration 7526, the loss is 4.4423547905531136, parameters k is 10.306231183320945 and b is -42.10059823838117\n",
      "Iteration 7527, the loss is 4.442354774778736, parameters k is 10.306230793992881 and b is -42.100594285811994\n",
      "Iteration 7528, the loss is 4.442354759004356, parameters k is 10.306230404664818 and b is -42.10059033324282\n",
      "Iteration 7529, the loss is 4.442354743229981, parameters k is 10.306230015336755 and b is -42.10058638067365\n",
      "Iteration 7530, the loss is 4.442354727455597, parameters k is 10.306229626008692 and b is -42.100582428104474\n",
      "Iteration 7531, the loss is 4.442354711681218, parameters k is 10.306229236680629 and b is -42.1005784755353\n",
      "Iteration 7532, the loss is 4.4423546959068405, parameters k is 10.306228847352566 and b is -42.10057452296613\n",
      "Iteration 7533, the loss is 4.442354680132461, parameters k is 10.306228458024503 and b is -42.100570570396954\n",
      "Iteration 7534, the loss is 4.442354664358083, parameters k is 10.30622806869644 and b is -42.10056661782778\n",
      "Iteration 7535, the loss is 4.4423546485836996, parameters k is 10.306227679368376 and b is -42.10056266525861\n",
      "Iteration 7536, the loss is 4.442354632809322, parameters k is 10.306227290040313 and b is -42.100558712689434\n",
      "Iteration 7537, the loss is 4.442354617034944, parameters k is 10.30622690071225 and b is -42.10055476012026\n",
      "Iteration 7538, the loss is 4.442354601260563, parameters k is 10.306226511384187 and b is -42.10055080755109\n",
      "Iteration 7539, the loss is 4.442354585486184, parameters k is 10.306226122056124 and b is -42.100546854981914\n",
      "Iteration 7540, the loss is 4.4423545697118065, parameters k is 10.30622573272806 and b is -42.10054290241274\n",
      "Iteration 7541, the loss is 4.442354553937424, parameters k is 10.306225343399998 and b is -42.10053894984357\n",
      "Iteration 7542, the loss is 4.442354538163046, parameters k is 10.306224954071935 and b is -42.100534997274394\n",
      "Iteration 7543, the loss is 4.442354522388666, parameters k is 10.306224564743871 and b is -42.10053104470522\n",
      "Iteration 7544, the loss is 4.442354506614285, parameters k is 10.306224175415808 and b is -42.10052709213605\n",
      "Iteration 7545, the loss is 4.442354490839906, parameters k is 10.306223786087745 and b is -42.100523139566874\n",
      "Iteration 7546, the loss is 4.442354475065526, parameters k is 10.306223396759682 and b is -42.1005191869977\n",
      "Iteration 7547, the loss is 4.442354459291148, parameters k is 10.306223007431619 and b is -42.10051523442853\n",
      "Iteration 7548, the loss is 4.442354443516767, parameters k is 10.306222618103556 and b is -42.100511281859355\n",
      "Iteration 7549, the loss is 4.44235442774239, parameters k is 10.306222228775493 and b is -42.10050732929018\n",
      "Iteration 7550, the loss is 4.442354411968009, parameters k is 10.30622183944743 and b is -42.10050337672101\n",
      "Iteration 7551, the loss is 4.4423543961936325, parameters k is 10.306221450119367 and b is -42.100499424151835\n",
      "Iteration 7552, the loss is 4.442354380419251, parameters k is 10.306221060791303 and b is -42.10049547158266\n",
      "Iteration 7553, the loss is 4.442354364644871, parameters k is 10.30622067146324 and b is -42.10049151901349\n",
      "Iteration 7554, the loss is 4.442354348870493, parameters k is 10.306220282135177 and b is -42.100487566444315\n",
      "Iteration 7555, the loss is 4.44235433309611, parameters k is 10.306219892807114 and b is -42.10048361387514\n",
      "Iteration 7556, the loss is 4.4423543173217315, parameters k is 10.306219503479051 and b is -42.10047966130597\n",
      "Iteration 7557, the loss is 4.442354301547356, parameters k is 10.306219114150988 and b is -42.100475708736795\n",
      "Iteration 7558, the loss is 4.442354285772976, parameters k is 10.306218724822925 and b is -42.10047175616762\n",
      "Iteration 7559, the loss is 4.442354269998595, parameters k is 10.306218335494862 and b is -42.10046780359845\n",
      "Iteration 7560, the loss is 4.442354254224215, parameters k is 10.306217946166798 and b is -42.100463851029275\n",
      "Iteration 7561, the loss is 4.442354238449833, parameters k is 10.306217556838735 and b is -42.1004598984601\n",
      "Iteration 7562, the loss is 4.4423542226754575, parameters k is 10.306217167510672 and b is -42.10045594589093\n",
      "Iteration 7563, the loss is 4.442354206901079, parameters k is 10.306216778182609 and b is -42.100451993321755\n",
      "Iteration 7564, the loss is 4.442354191126698, parameters k is 10.306216388854546 and b is -42.10044804075258\n",
      "Iteration 7565, the loss is 4.44235417535232, parameters k is 10.306215999526483 and b is -42.10044408818341\n",
      "Iteration 7566, the loss is 4.442354159577942, parameters k is 10.30621561019842 and b is -42.100440135614235\n",
      "Iteration 7567, the loss is 4.442354143803558, parameters k is 10.306215220870357 and b is -42.10043618304506\n",
      "Iteration 7568, the loss is 4.44235412802918, parameters k is 10.306214831542293 and b is -42.10043223047589\n",
      "Iteration 7569, the loss is 4.442354112254801, parameters k is 10.30621444221423 and b is -42.100428277906715\n",
      "Iteration 7570, the loss is 4.442354096480421, parameters k is 10.306214052886167 and b is -42.10042432533754\n",
      "Iteration 7571, the loss is 4.442354080706044, parameters k is 10.306213663558104 and b is -42.10042037276837\n",
      "Iteration 7572, the loss is 4.442354064931664, parameters k is 10.306213274230041 and b is -42.100416420199195\n",
      "Iteration 7573, the loss is 4.442354049157285, parameters k is 10.306212884901978 and b is -42.10041246763002\n",
      "Iteration 7574, the loss is 4.442354033382903, parameters k is 10.306212495573915 and b is -42.10040851506085\n",
      "Iteration 7575, the loss is 4.442354017608526, parameters k is 10.306212106245852 and b is -42.100404562491676\n",
      "Iteration 7576, the loss is 4.442354001834147, parameters k is 10.306211716917788 and b is -42.1004006099225\n",
      "Iteration 7577, the loss is 4.442353986059766, parameters k is 10.306211327589725 and b is -42.10039665735333\n",
      "Iteration 7578, the loss is 4.44235397028539, parameters k is 10.306210938261662 and b is -42.100392704784156\n",
      "Iteration 7579, the loss is 4.442353954511008, parameters k is 10.3062105489336 and b is -42.10038875221498\n",
      "Iteration 7580, the loss is 4.442353938736629, parameters k is 10.306210159605536 and b is -42.10038479964581\n",
      "Iteration 7581, the loss is 4.442353922962248, parameters k is 10.306209770277473 and b is -42.100380847076636\n",
      "Iteration 7582, the loss is 4.442353907187869, parameters k is 10.30620938094941 and b is -42.10037689450746\n",
      "Iteration 7583, the loss is 4.442353891413492, parameters k is 10.306208991621347 and b is -42.10037294193829\n",
      "Iteration 7584, the loss is 4.442353875639113, parameters k is 10.306208602293284 and b is -42.100368989369116\n",
      "Iteration 7585, the loss is 4.442353859864729, parameters k is 10.30620821296522 and b is -42.10036503679994\n",
      "Iteration 7586, the loss is 4.442353844090349, parameters k is 10.306207823637157 and b is -42.10036108423077\n",
      "Iteration 7587, the loss is 4.442353828315973, parameters k is 10.306207434309094 and b is -42.100357131661596\n",
      "Iteration 7588, the loss is 4.442353812541592, parameters k is 10.306207044981031 and b is -42.10035317909242\n",
      "Iteration 7589, the loss is 4.442353796767214, parameters k is 10.306206655652968 and b is -42.10034922652325\n",
      "Iteration 7590, the loss is 4.442353780992835, parameters k is 10.306206266324905 and b is -42.100345273954076\n",
      "Iteration 7591, the loss is 4.442353765218455, parameters k is 10.306205876996842 and b is -42.1003413213849\n",
      "Iteration 7592, the loss is 4.442353749444075, parameters k is 10.306205487668779 and b is -42.10033736881573\n",
      "Iteration 7593, the loss is 4.442353733669694, parameters k is 10.306205098340715 and b is -42.100333416246556\n",
      "Iteration 7594, the loss is 4.442353717895313, parameters k is 10.306204709012652 and b is -42.10032946367738\n",
      "Iteration 7595, the loss is 4.442353702120937, parameters k is 10.30620431968459 and b is -42.10032551110821\n",
      "Iteration 7596, the loss is 4.442353686346556, parameters k is 10.306203930356526 and b is -42.10032155853904\n",
      "Iteration 7597, the loss is 4.442353670572182, parameters k is 10.306203541028463 and b is -42.10031760596986\n",
      "Iteration 7598, the loss is 4.442353654797798, parameters k is 10.3062031517004 and b is -42.10031365340069\n",
      "Iteration 7599, the loss is 4.442353639023419, parameters k is 10.306202762372337 and b is -42.10030970083152\n",
      "Iteration 7600, the loss is 4.44235362324904, parameters k is 10.306202373044274 and b is -42.10030574826234\n",
      "Iteration 7601, the loss is 4.442353607474661, parameters k is 10.30620198371621 and b is -42.10030179569317\n",
      "Iteration 7602, the loss is 4.442353591700279, parameters k is 10.306201594388147 and b is -42.100297843124\n",
      "Iteration 7603, the loss is 4.442353575925902, parameters k is 10.306201205060084 and b is -42.10029389055482\n",
      "Iteration 7604, the loss is 4.442353560151524, parameters k is 10.306200815732021 and b is -42.10028993798565\n",
      "Iteration 7605, the loss is 4.442353544377142, parameters k is 10.306200426403958 and b is -42.10028598541648\n",
      "Iteration 7606, the loss is 4.442353528602765, parameters k is 10.306200037075895 and b is -42.1002820328473\n",
      "Iteration 7607, the loss is 4.442353512828385, parameters k is 10.306199647747832 and b is -42.10027808027813\n",
      "Iteration 7608, the loss is 4.442353497054007, parameters k is 10.306199258419769 and b is -42.10027412770896\n",
      "Iteration 7609, the loss is 4.4423534812796275, parameters k is 10.306198869091705 and b is -42.100270175139784\n",
      "Iteration 7610, the loss is 4.4423534655052475, parameters k is 10.306198479763642 and b is -42.10026622257061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7611, the loss is 4.4423534497308665, parameters k is 10.30619809043558 and b is -42.10026227000144\n",
      "Iteration 7612, the loss is 4.442353433956487, parameters k is 10.306197701107516 and b is -42.100258317432264\n",
      "Iteration 7613, the loss is 4.442353418182108, parameters k is 10.306197311779453 and b is -42.10025436486309\n",
      "Iteration 7614, the loss is 4.442353402407728, parameters k is 10.30619692245139 and b is -42.10025041229392\n",
      "Iteration 7615, the loss is 4.442353386633349, parameters k is 10.306196533123327 and b is -42.100246459724744\n",
      "Iteration 7616, the loss is 4.442353370858969, parameters k is 10.306196143795264 and b is -42.10024250715557\n",
      "Iteration 7617, the loss is 4.442353355084591, parameters k is 10.3061957544672 and b is -42.1002385545864\n",
      "Iteration 7618, the loss is 4.442353339310212, parameters k is 10.306195365139137 and b is -42.100234602017224\n",
      "Iteration 7619, the loss is 4.44235332353583, parameters k is 10.306194975811074 and b is -42.10023064944805\n",
      "Iteration 7620, the loss is 4.442353307761453, parameters k is 10.306194586483011 and b is -42.10022669687888\n",
      "Iteration 7621, the loss is 4.44235329198707, parameters k is 10.306194197154948 and b is -42.100222744309704\n",
      "Iteration 7622, the loss is 4.442353276212694, parameters k is 10.306193807826885 and b is -42.10021879174053\n",
      "Iteration 7623, the loss is 4.442353260438316, parameters k is 10.306193418498822 and b is -42.10021483917136\n",
      "Iteration 7624, the loss is 4.442353244663933, parameters k is 10.306193029170759 and b is -42.100210886602184\n",
      "Iteration 7625, the loss is 4.442353228889555, parameters k is 10.306192639842696 and b is -42.10020693403301\n",
      "Iteration 7626, the loss is 4.442353213115175, parameters k is 10.306192250514632 and b is -42.10020298146384\n",
      "Iteration 7627, the loss is 4.442353197340797, parameters k is 10.30619186118657 and b is -42.100199028894664\n",
      "Iteration 7628, the loss is 4.442353181566418, parameters k is 10.306191471858506 and b is -42.10019507632549\n",
      "Iteration 7629, the loss is 4.442353165792038, parameters k is 10.306191082530443 and b is -42.10019112375632\n",
      "Iteration 7630, the loss is 4.442353150017656, parameters k is 10.30619069320238 and b is -42.100187171187144\n",
      "Iteration 7631, the loss is 4.4423531342432785, parameters k is 10.306190303874317 and b is -42.10018321861797\n",
      "Iteration 7632, the loss is 4.4423531184689, parameters k is 10.306189914546254 and b is -42.1001792660488\n",
      "Iteration 7633, the loss is 4.44235310269452, parameters k is 10.30618952521819 and b is -42.100175313479625\n",
      "Iteration 7634, the loss is 4.442353086920141, parameters k is 10.306189135890127 and b is -42.10017136091045\n",
      "Iteration 7635, the loss is 4.442353071145759, parameters k is 10.306188746562064 and b is -42.10016740834128\n",
      "Iteration 7636, the loss is 4.442353055371383, parameters k is 10.306188357234001 and b is -42.100163455772105\n",
      "Iteration 7637, the loss is 4.442353039597002, parameters k is 10.306187967905938 and b is -42.10015950320293\n",
      "Iteration 7638, the loss is 4.442353023822623, parameters k is 10.306187578577875 and b is -42.10015555063376\n",
      "Iteration 7639, the loss is 4.442353008048243, parameters k is 10.306187189249812 and b is -42.100151598064585\n",
      "Iteration 7640, the loss is 4.4423529922738645, parameters k is 10.306186799921749 and b is -42.10014764549541\n",
      "Iteration 7641, the loss is 4.442352976499485, parameters k is 10.306186410593686 and b is -42.10014369292624\n",
      "Iteration 7642, the loss is 4.442352960725107, parameters k is 10.306186021265622 and b is -42.100139740357065\n",
      "Iteration 7643, the loss is 4.442352944950728, parameters k is 10.30618563193756 and b is -42.10013578778789\n",
      "Iteration 7644, the loss is 4.442352929176346, parameters k is 10.306185242609496 and b is -42.10013183521872\n",
      "Iteration 7645, the loss is 4.442352913961768, parameters k is 10.306184853281433 and b is -42.100127882649545\n",
      "Iteration 7646, the loss is 4.4423529025446395, parameters k is 10.306156965929654 and b is -42.100127882649545\n",
      "Iteration 7647, the loss is 4.44235288677026, parameters k is 10.306156576601591 and b is -42.10012393008037\n",
      "Iteration 7648, the loss is 4.442352870995881, parameters k is 10.306156187273528 and b is -42.1001199775112\n",
      "Iteration 7649, the loss is 4.442352855221498, parameters k is 10.306155797945465 and b is -42.100116024942025\n",
      "Iteration 7650, the loss is 4.442352839447121, parameters k is 10.306155408617402 and b is -42.10011207237285\n",
      "Iteration 7651, the loss is 4.442352823672744, parameters k is 10.306155019289339 and b is -42.10010811980368\n",
      "Iteration 7652, the loss is 4.442352807898366, parameters k is 10.306154629961275 and b is -42.100104167234505\n",
      "Iteration 7653, the loss is 4.442352792123982, parameters k is 10.306154240633212 and b is -42.10010021466533\n",
      "Iteration 7654, the loss is 4.442352776349604, parameters k is 10.30615385130515 and b is -42.10009626209616\n",
      "Iteration 7655, the loss is 4.442352760575222, parameters k is 10.306153461977086 and b is -42.100092309526985\n",
      "Iteration 7656, the loss is 4.442352744800843, parameters k is 10.306153072649023 and b is -42.10008835695781\n",
      "Iteration 7657, the loss is 4.442352729026468, parameters k is 10.30615268332096 and b is -42.10008440438864\n",
      "Iteration 7658, the loss is 4.442352713252086, parameters k is 10.306152293992897 and b is -42.100080451819466\n",
      "Iteration 7659, the loss is 4.442352697477707, parameters k is 10.306151904664834 and b is -42.10007649925029\n",
      "Iteration 7660, the loss is 4.442352681703329, parameters k is 10.30615151533677 and b is -42.10007254668112\n",
      "Iteration 7661, the loss is 4.442352665928948, parameters k is 10.306151126008707 and b is -42.100068594111946\n",
      "Iteration 7662, the loss is 4.442352650154568, parameters k is 10.306150736680644 and b is -42.10006464154277\n",
      "Iteration 7663, the loss is 4.442352634380187, parameters k is 10.306150347352581 and b is -42.1000606889736\n",
      "Iteration 7664, the loss is 4.442352618605811, parameters k is 10.306149958024518 and b is -42.100056736404426\n",
      "Iteration 7665, the loss is 4.442352602831432, parameters k is 10.306149568696455 and b is -42.10005278383525\n",
      "Iteration 7666, the loss is 4.44235258705705, parameters k is 10.306149179368392 and b is -42.10004883126608\n",
      "Iteration 7667, the loss is 4.4423525712826715, parameters k is 10.306148790040329 and b is -42.100044878696906\n",
      "Iteration 7668, the loss is 4.442352555508293, parameters k is 10.306148400712265 and b is -42.10004092612773\n",
      "Iteration 7669, the loss is 4.442352539733912, parameters k is 10.306148011384202 and b is -42.10003697355856\n",
      "Iteration 7670, the loss is 4.442352523959535, parameters k is 10.30614762205614 and b is -42.100033020989386\n",
      "Iteration 7671, the loss is 4.442352508185153, parameters k is 10.306147232728076 and b is -42.10002906842021\n",
      "Iteration 7672, the loss is 4.442352492410775, parameters k is 10.306146843400013 and b is -42.10002511585104\n",
      "Iteration 7673, the loss is 4.442352476636395, parameters k is 10.30614645407195 and b is -42.100021163281866\n",
      "Iteration 7674, the loss is 4.442352460862012, parameters k is 10.306146064743887 and b is -42.10001721071269\n",
      "Iteration 7675, the loss is 4.4423524450876375, parameters k is 10.306145675415824 and b is -42.10001325814352\n",
      "Iteration 7676, the loss is 4.442352429313255, parameters k is 10.30614528608776 and b is -42.100009305574346\n",
      "Iteration 7677, the loss is 4.442352413538878, parameters k is 10.306144896759697 and b is -42.10000535300517\n",
      "Iteration 7678, the loss is 4.442352397764498, parameters k is 10.306144507431634 and b is -42.100001400436\n",
      "Iteration 7679, the loss is 4.442352381990118, parameters k is 10.306144118103571 and b is -42.099997447866826\n",
      "Iteration 7680, the loss is 4.442352366215741, parameters k is 10.306143728775508 and b is -42.09999349529765\n",
      "Iteration 7681, the loss is 4.442352350441358, parameters k is 10.306143339447445 and b is -42.09998954272848\n",
      "Iteration 7682, the loss is 4.442352334666982, parameters k is 10.306142950119382 and b is -42.09998559015931\n",
      "Iteration 7683, the loss is 4.442352318892599, parameters k is 10.306142560791319 and b is -42.09998163759013\n",
      "Iteration 7684, the loss is 4.442352303118225, parameters k is 10.306142171463256 and b is -42.09997768502096\n",
      "Iteration 7685, the loss is 4.442352287343843, parameters k is 10.306141782135192 and b is -42.09997373245179\n",
      "Iteration 7686, the loss is 4.4423522715694626, parameters k is 10.30614139280713 and b is -42.09996977988261\n",
      "Iteration 7687, the loss is 4.4423522557950825, parameters k is 10.306141003479066 and b is -42.09996582731344\n",
      "Iteration 7688, the loss is 4.442352240020703, parameters k is 10.306140614151003 and b is -42.09996187474427\n",
      "Iteration 7689, the loss is 4.442352224246325, parameters k is 10.30614022482294 and b is -42.09995792217509\n",
      "Iteration 7690, the loss is 4.442352208471947, parameters k is 10.306139835494877 and b is -42.09995396960592\n",
      "Iteration 7691, the loss is 4.442352192697568, parameters k is 10.306139446166814 and b is -42.09995001703675\n",
      "Iteration 7692, the loss is 4.442352176923184, parameters k is 10.30613905683875 and b is -42.099946064467574\n",
      "Iteration 7693, the loss is 4.442352161148806, parameters k is 10.306138667510687 and b is -42.0999421118984\n",
      "Iteration 7694, the loss is 4.442352145374428, parameters k is 10.306138278182624 and b is -42.09993815932923\n",
      "Iteration 7695, the loss is 4.44235212960005, parameters k is 10.306137888854561 and b is -42.099934206760054\n",
      "Iteration 7696, the loss is 4.442352113825668, parameters k is 10.306137499526498 and b is -42.09993025419088\n",
      "Iteration 7697, the loss is 4.442352098051288, parameters k is 10.306137110198435 and b is -42.09992630162171\n",
      "Iteration 7698, the loss is 4.442352082276913, parameters k is 10.306136720870372 and b is -42.099922349052534\n",
      "Iteration 7699, the loss is 4.44235206650253, parameters k is 10.306136331542309 and b is -42.09991839648336\n",
      "Iteration 7700, the loss is 4.442352050728152, parameters k is 10.306135942214246 and b is -42.09991444391419\n",
      "Iteration 7701, the loss is 4.442352034953772, parameters k is 10.306135552886182 and b is -42.099910491345014\n",
      "Iteration 7702, the loss is 4.442352019179394, parameters k is 10.30613516355812 and b is -42.09990653877584\n",
      "Iteration 7703, the loss is 4.442352003405015, parameters k is 10.306134774230056 and b is -42.09990258620667\n",
      "Iteration 7704, the loss is 4.442351987630636, parameters k is 10.306134384901993 and b is -42.099898633637494\n",
      "Iteration 7705, the loss is 4.4423519718562545, parameters k is 10.30613399557393 and b is -42.09989468106832\n",
      "Iteration 7706, the loss is 4.442351956081874, parameters k is 10.306133606245867 and b is -42.09989072849915\n",
      "Iteration 7707, the loss is 4.442351940307496, parameters k is 10.306133216917804 and b is -42.099886775929974\n",
      "Iteration 7708, the loss is 4.442351924533116, parameters k is 10.30613282758974 and b is -42.0998828233608\n",
      "Iteration 7709, the loss is 4.442351908758735, parameters k is 10.306132438261677 and b is -42.09987887079163\n",
      "Iteration 7710, the loss is 4.442351892984357, parameters k is 10.306132048933614 and b is -42.099874918222454\n",
      "Iteration 7711, the loss is 4.442351877209979, parameters k is 10.306131659605551 and b is -42.09987096565328\n",
      "Iteration 7712, the loss is 4.4423518614356, parameters k is 10.306131270277488 and b is -42.09986701308411\n",
      "Iteration 7713, the loss is 4.44235184566122, parameters k is 10.306130880949425 and b is -42.099863060514934\n",
      "Iteration 7714, the loss is 4.442351829886839, parameters k is 10.306130491621362 and b is -42.09985910794576\n",
      "Iteration 7715, the loss is 4.442351814112459, parameters k is 10.306130102293299 and b is -42.09985515537659\n",
      "Iteration 7716, the loss is 4.442351798338079, parameters k is 10.306129712965236 and b is -42.099851202807415\n",
      "Iteration 7717, the loss is 4.4423517825637004, parameters k is 10.306129323637172 and b is -42.09984725023824\n",
      "Iteration 7718, the loss is 4.442351766789322, parameters k is 10.30612893430911 and b is -42.09984329766907\n",
      "Iteration 7719, the loss is 4.442351751014943, parameters k is 10.306128544981046 and b is -42.099839345099895\n",
      "Iteration 7720, the loss is 4.442351735240564, parameters k is 10.306128155652983 and b is -42.09983539253072\n",
      "Iteration 7721, the loss is 4.442351719466186, parameters k is 10.30612776632492 and b is -42.09983143996155\n",
      "Iteration 7722, the loss is 4.442351703691806, parameters k is 10.306127376996857 and b is -42.099827487392375\n",
      "Iteration 7723, the loss is 4.442351687917426, parameters k is 10.306126987668794 and b is -42.0998235348232\n",
      "Iteration 7724, the loss is 4.4423516721430465, parameters k is 10.30612659834073 and b is -42.09981958225403\n",
      "Iteration 7725, the loss is 4.442351656368665, parameters k is 10.306126209012668 and b is -42.099815629684855\n",
      "Iteration 7726, the loss is 4.442351640594287, parameters k is 10.306125819684604 and b is -42.09981167711568\n",
      "Iteration 7727, the loss is 4.442351624819909, parameters k is 10.306125430356541 and b is -42.09980772454651\n",
      "Iteration 7728, the loss is 4.442351609045533, parameters k is 10.306125041028478 and b is -42.099803771977335\n",
      "Iteration 7729, the loss is 4.442351593271148, parameters k is 10.306124651700415 and b is -42.09979981940816\n",
      "Iteration 7730, the loss is 4.44235157749677, parameters k is 10.306124262372352 and b is -42.09979586683899\n",
      "Iteration 7731, the loss is 4.442351561722391, parameters k is 10.306123873044289 and b is -42.099791914269815\n",
      "Iteration 7732, the loss is 4.442351545948012, parameters k is 10.306123483716226 and b is -42.09978796170064\n",
      "Iteration 7733, the loss is 4.4423515301736325, parameters k is 10.306123094388163 and b is -42.09978400913147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7734, the loss is 4.4423515143992525, parameters k is 10.3061227050601 and b is -42.099780056562295\n",
      "Iteration 7735, the loss is 4.442351498624872, parameters k is 10.306122315732036 and b is -42.09977610399312\n",
      "Iteration 7736, the loss is 4.442351482850493, parameters k is 10.306121926403973 and b is -42.09977215142395\n",
      "Iteration 7737, the loss is 4.442351467076113, parameters k is 10.30612153707591 and b is -42.099768198854775\n",
      "Iteration 7738, the loss is 4.442351451301734, parameters k is 10.306121147747847 and b is -42.0997642462856\n",
      "Iteration 7739, the loss is 4.442351435527354, parameters k is 10.306120758419784 and b is -42.09976029371643\n",
      "Iteration 7740, the loss is 4.4423514197529785, parameters k is 10.30612036909172 and b is -42.099756341147256\n",
      "Iteration 7741, the loss is 4.442351403978596, parameters k is 10.306119979763658 and b is -42.09975238857808\n",
      "Iteration 7742, the loss is 4.442351388204217, parameters k is 10.306119590435594 and b is -42.09974843600891\n",
      "Iteration 7743, the loss is 4.442351372429836, parameters k is 10.306119201107531 and b is -42.099744483439736\n",
      "Iteration 7744, the loss is 4.442351356655457, parameters k is 10.306118811779468 and b is -42.09974053087056\n",
      "Iteration 7745, the loss is 4.442351340881078, parameters k is 10.306118422451405 and b is -42.09973657830139\n",
      "Iteration 7746, the loss is 4.442351325106698, parameters k is 10.306118033123342 and b is -42.099732625732216\n",
      "Iteration 7747, the loss is 4.4423513093323175, parameters k is 10.306117643795279 and b is -42.09972867316304\n",
      "Iteration 7748, the loss is 4.44235129355794, parameters k is 10.306117254467216 and b is -42.09972472059387\n",
      "Iteration 7749, the loss is 4.442351277783559, parameters k is 10.306116865139153 and b is -42.099720768024696\n",
      "Iteration 7750, the loss is 4.442351262009181, parameters k is 10.30611647581109 and b is -42.09971681545552\n",
      "Iteration 7751, the loss is 4.442351246234802, parameters k is 10.306116086483026 and b is -42.09971286288635\n",
      "Iteration 7752, the loss is 4.442351230460423, parameters k is 10.306115697154963 and b is -42.099708910317176\n",
      "Iteration 7753, the loss is 4.442351214686043, parameters k is 10.3061153078269 and b is -42.099704957748\n",
      "Iteration 7754, the loss is 4.442351198911661, parameters k is 10.306114918498837 and b is -42.09970100517883\n",
      "Iteration 7755, the loss is 4.442351183137284, parameters k is 10.306114529170774 and b is -42.099697052609656\n",
      "Iteration 7756, the loss is 4.442351167362906, parameters k is 10.30611413984271 and b is -42.09969310004048\n",
      "Iteration 7757, the loss is 4.442351151588527, parameters k is 10.306113750514648 and b is -42.09968914747131\n",
      "Iteration 7758, the loss is 4.442351135814145, parameters k is 10.306113361186584 and b is -42.099685194902136\n",
      "Iteration 7759, the loss is 4.442351120039767, parameters k is 10.306112971858521 and b is -42.09968124233296\n",
      "Iteration 7760, the loss is 4.44235110426539, parameters k is 10.306112582530458 and b is -42.09967728976379\n",
      "Iteration 7761, the loss is 4.44235108849101, parameters k is 10.306112193202395 and b is -42.099673337194616\n",
      "Iteration 7762, the loss is 4.442351072716627, parameters k is 10.306111803874332 and b is -42.09966938462544\n",
      "Iteration 7763, the loss is 4.44235105694225, parameters k is 10.306111414546269 and b is -42.09966543205627\n",
      "Iteration 7764, the loss is 4.442351041167869, parameters k is 10.306111025218206 and b is -42.0996614794871\n",
      "Iteration 7765, the loss is 4.4423510253934895, parameters k is 10.306110635890143 and b is -42.09965752691792\n",
      "Iteration 7766, the loss is 4.442351009619113, parameters k is 10.30611024656208 and b is -42.09965357434875\n",
      "Iteration 7767, the loss is 4.442350993844729, parameters k is 10.306109857234016 and b is -42.09964962177958\n",
      "Iteration 7768, the loss is 4.442350978070352, parameters k is 10.306109467905953 and b is -42.0996456692104\n",
      "Iteration 7769, the loss is 4.442350962295975, parameters k is 10.30610907857789 and b is -42.09964171664123\n",
      "Iteration 7770, the loss is 4.442350946521595, parameters k is 10.306108689249827 and b is -42.09963776407206\n",
      "Iteration 7771, the loss is 4.442350930747214, parameters k is 10.306108299921764 and b is -42.09963381150288\n",
      "Iteration 7772, the loss is 4.442350914972836, parameters k is 10.3061079105937 and b is -42.09962985893371\n",
      "Iteration 7773, the loss is 4.4423508991984555, parameters k is 10.306107521265638 and b is -42.09962590636454\n",
      "Iteration 7774, the loss is 4.4423508834240755, parameters k is 10.306107131937575 and b is -42.09962195379536\n",
      "Iteration 7775, the loss is 4.4423508676496954, parameters k is 10.306106742609511 and b is -42.09961800122619\n",
      "Iteration 7776, the loss is 4.442350851875315, parameters k is 10.306106353281448 and b is -42.09961404865702\n",
      "Iteration 7777, the loss is 4.442350836100938, parameters k is 10.306105963953385 and b is -42.099610096087844\n",
      "Iteration 7778, the loss is 4.442350820326558, parameters k is 10.306105574625322 and b is -42.09960614351867\n",
      "Iteration 7779, the loss is 4.442350804552179, parameters k is 10.306105185297259 and b is -42.0996021909495\n",
      "Iteration 7780, the loss is 4.442350788777801, parameters k is 10.306104795969196 and b is -42.099598238380324\n",
      "Iteration 7781, the loss is 4.442350773003421, parameters k is 10.306104406641133 and b is -42.09959428581115\n",
      "Iteration 7782, the loss is 4.44235075722904, parameters k is 10.30610401731307 and b is -42.09959033324198\n",
      "Iteration 7783, the loss is 4.44235074145466, parameters k is 10.306103627985006 and b is -42.099586380672804\n",
      "Iteration 7784, the loss is 4.4423507256802806, parameters k is 10.306103238656943 and b is -42.09958242810363\n",
      "Iteration 7785, the loss is 4.442350709905901, parameters k is 10.30610284932888 and b is -42.09957847553446\n",
      "Iteration 7786, the loss is 4.442350694131523, parameters k is 10.306102460000817 and b is -42.099574522965284\n",
      "Iteration 7787, the loss is 4.442350678357142, parameters k is 10.306102070672754 and b is -42.09957057039611\n",
      "Iteration 7788, the loss is 4.442350662582763, parameters k is 10.30610168134469 and b is -42.09956661782694\n",
      "Iteration 7789, the loss is 4.442350646808385, parameters k is 10.306101292016628 and b is -42.099562665257764\n",
      "Iteration 7790, the loss is 4.442350631034003, parameters k is 10.306100902688565 and b is -42.09955871268859\n",
      "Iteration 7791, the loss is 4.442350615259622, parameters k is 10.306100513360501 and b is -42.09955476011942\n",
      "Iteration 7792, the loss is 4.4423505994852475, parameters k is 10.306100124032438 and b is -42.099550807550244\n",
      "Iteration 7793, the loss is 4.442350583710866, parameters k is 10.306099734704375 and b is -42.09954685498107\n",
      "Iteration 7794, the loss is 4.442350567936488, parameters k is 10.306099345376312 and b is -42.0995429024119\n",
      "Iteration 7795, the loss is 4.442350552162107, parameters k is 10.306098956048249 and b is -42.099538949842724\n",
      "Iteration 7796, the loss is 4.442350536387727, parameters k is 10.306098566720186 and b is -42.09953499727355\n",
      "Iteration 7797, the loss is 4.442350520613353, parameters k is 10.306098177392123 and b is -42.09953104470438\n",
      "Iteration 7798, the loss is 4.44235050483897, parameters k is 10.30609778806406 and b is -42.099527092135204\n",
      "Iteration 7799, the loss is 4.4423504890645935, parameters k is 10.306097398735997 and b is -42.09952313956603\n",
      "Iteration 7800, the loss is 4.442350473290212, parameters k is 10.306097009407933 and b is -42.09951918699686\n",
      "Iteration 7801, the loss is 4.442350457515831, parameters k is 10.30609662007987 and b is -42.099515234427685\n",
      "Iteration 7802, the loss is 4.442350442514106, parameters k is 10.306096230751807 and b is -42.09951128185851\n",
      "Iteration 7803, the loss is 4.442350430884124, parameters k is 10.306068343400028 and b is -42.09951128185851\n",
      "Iteration 7804, the loss is 4.442350415109745, parameters k is 10.306067954071965 and b is -42.09950732928934\n",
      "Iteration 7805, the loss is 4.442350399335365, parameters k is 10.306067564743902 and b is -42.099503376720165\n",
      "Iteration 7806, the loss is 4.442350383560987, parameters k is 10.306067175415839 and b is -42.09949942415099\n",
      "Iteration 7807, the loss is 4.442350367786606, parameters k is 10.306066786087776 and b is -42.09949547158182\n",
      "Iteration 7808, the loss is 4.442350352012228, parameters k is 10.306066396759713 and b is -42.099491519012645\n",
      "Iteration 7809, the loss is 4.442350336237846, parameters k is 10.30606600743165 and b is -42.09948756644347\n",
      "Iteration 7810, the loss is 4.442350320463467, parameters k is 10.306065618103586 and b is -42.0994836138743\n",
      "Iteration 7811, the loss is 4.44235030468909, parameters k is 10.306065228775523 and b is -42.099479661305125\n",
      "Iteration 7812, the loss is 4.442350288914709, parameters k is 10.30606483944746 and b is -42.09947570873595\n",
      "Iteration 7813, the loss is 4.442350273140331, parameters k is 10.306064450119397 and b is -42.09947175616678\n",
      "Iteration 7814, the loss is 4.442350257365951, parameters k is 10.306064060791334 and b is -42.099467803597605\n",
      "Iteration 7815, the loss is 4.442350241591571, parameters k is 10.30606367146327 and b is -42.09946385102843\n",
      "Iteration 7816, the loss is 4.44235022581719, parameters k is 10.306063282135208 and b is -42.09945989845926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7817, the loss is 4.442350210042812, parameters k is 10.306062892807144 and b is -42.099455945890085\n",
      "Iteration 7818, the loss is 4.442350194268434, parameters k is 10.306062503479081 and b is -42.09945199332091\n",
      "Iteration 7819, the loss is 4.442350178494051, parameters k is 10.306062114151018 and b is -42.09944804075174\n",
      "Iteration 7820, the loss is 4.4423501627196735, parameters k is 10.306061724822955 and b is -42.099444088182565\n",
      "Iteration 7821, the loss is 4.442350146945297, parameters k is 10.306061335494892 and b is -42.09944013561339\n",
      "Iteration 7822, the loss is 4.442350131170911, parameters k is 10.306060946166829 and b is -42.09943618304422\n",
      "Iteration 7823, the loss is 4.442350115396535, parameters k is 10.306060556838766 and b is -42.099432230475045\n",
      "Iteration 7824, the loss is 4.442350099622156, parameters k is 10.306060167510703 and b is -42.09942827790587\n",
      "Iteration 7825, the loss is 4.44235008384778, parameters k is 10.30605977818264 and b is -42.0994243253367\n",
      "Iteration 7826, the loss is 4.442350068073397, parameters k is 10.306059388854576 and b is -42.099420372767526\n",
      "Iteration 7827, the loss is 4.442350052299017, parameters k is 10.306058999526513 and b is -42.09941642019835\n",
      "Iteration 7828, the loss is 4.442350036524637, parameters k is 10.30605861019845 and b is -42.09941246762918\n",
      "Iteration 7829, the loss is 4.4423500207502595, parameters k is 10.306058220870387 and b is -42.099408515060006\n",
      "Iteration 7830, the loss is 4.442350004975881, parameters k is 10.306057831542324 and b is -42.09940456249083\n",
      "Iteration 7831, the loss is 4.442349989201503, parameters k is 10.30605744221426 and b is -42.09940060992166\n",
      "Iteration 7832, the loss is 4.442349973427122, parameters k is 10.306057052886198 and b is -42.099396657352486\n",
      "Iteration 7833, the loss is 4.442349957652742, parameters k is 10.306056663558135 and b is -42.09939270478331\n",
      "Iteration 7834, the loss is 4.442349941878362, parameters k is 10.306056274230071 and b is -42.09938875221414\n",
      "Iteration 7835, the loss is 4.442349926103985, parameters k is 10.306055884902008 and b is -42.099384799644966\n",
      "Iteration 7836, the loss is 4.442349910329605, parameters k is 10.306055495573945 and b is -42.09938084707579\n",
      "Iteration 7837, the loss is 4.442349894555222, parameters k is 10.306055106245882 and b is -42.09937689450662\n",
      "Iteration 7838, the loss is 4.442349878780844, parameters k is 10.306054716917819 and b is -42.099372941937446\n",
      "Iteration 7839, the loss is 4.4423498630064655, parameters k is 10.306054327589756 and b is -42.09936898936827\n",
      "Iteration 7840, the loss is 4.442349847232086, parameters k is 10.306053938261693 and b is -42.0993650367991\n",
      "Iteration 7841, the loss is 4.442349831457706, parameters k is 10.30605354893363 and b is -42.099361084229926\n",
      "Iteration 7842, the loss is 4.442349815683326, parameters k is 10.306053159605566 and b is -42.09935713166075\n",
      "Iteration 7843, the loss is 4.442349799908949, parameters k is 10.306052770277503 and b is -42.09935317909158\n",
      "Iteration 7844, the loss is 4.442349784134569, parameters k is 10.30605238094944 and b is -42.099349226522406\n",
      "Iteration 7845, the loss is 4.442349768360189, parameters k is 10.306051991621377 and b is -42.09934527395323\n",
      "Iteration 7846, the loss is 4.442349752585811, parameters k is 10.306051602293314 and b is -42.09934132138406\n",
      "Iteration 7847, the loss is 4.44234973681143, parameters k is 10.30605121296525 and b is -42.099337368814886\n",
      "Iteration 7848, the loss is 4.442349721037051, parameters k is 10.306050823637188 and b is -42.09933341624571\n",
      "Iteration 7849, the loss is 4.442349705262671, parameters k is 10.306050434309125 and b is -42.09932946367654\n",
      "Iteration 7850, the loss is 4.442349689488294, parameters k is 10.306050044981061 and b is -42.09932551110737\n",
      "Iteration 7851, the loss is 4.442349673713913, parameters k is 10.306049655652998 and b is -42.09932155853819\n",
      "Iteration 7852, the loss is 4.442349657939533, parameters k is 10.306049266324935 and b is -42.09931760596902\n",
      "Iteration 7853, the loss is 4.442349642165155, parameters k is 10.306048876996872 and b is -42.09931365339985\n",
      "Iteration 7854, the loss is 4.442349626390776, parameters k is 10.306048487668809 and b is -42.09930970083067\n",
      "Iteration 7855, the loss is 4.442349610616397, parameters k is 10.306048098340746 and b is -42.0993057482615\n",
      "Iteration 7856, the loss is 4.442349594842019, parameters k is 10.306047709012683 and b is -42.09930179569233\n",
      "Iteration 7857, the loss is 4.442349579067636, parameters k is 10.30604731968462 and b is -42.09929784312315\n",
      "Iteration 7858, the loss is 4.442349563293256, parameters k is 10.306046930356557 and b is -42.09929389055398\n",
      "Iteration 7859, the loss is 4.442349547518878, parameters k is 10.306046541028493 and b is -42.09928993798481\n",
      "Iteration 7860, the loss is 4.442349531744499, parameters k is 10.30604615170043 and b is -42.099285985415634\n",
      "Iteration 7861, the loss is 4.44234951597012, parameters k is 10.306045762372367 and b is -42.09928203284646\n",
      "Iteration 7862, the loss is 4.442349500195738, parameters k is 10.306045373044304 and b is -42.09927808027729\n",
      "Iteration 7863, the loss is 4.442349484421362, parameters k is 10.306044983716241 and b is -42.099274127708114\n",
      "Iteration 7864, the loss is 4.442349468646983, parameters k is 10.306044594388178 and b is -42.09927017513894\n",
      "Iteration 7865, the loss is 4.442349452872596, parameters k is 10.306044205060115 and b is -42.09926622256977\n",
      "Iteration 7866, the loss is 4.442349437098221, parameters k is 10.306043815732052 and b is -42.099262270000594\n",
      "Iteration 7867, the loss is 4.442349421323843, parameters k is 10.306043426403988 and b is -42.09925831743142\n",
      "Iteration 7868, the loss is 4.4423494055494634, parameters k is 10.306043037075925 and b is -42.09925436486225\n",
      "Iteration 7869, the loss is 4.442349389775087, parameters k is 10.306042647747862 and b is -42.099250412293074\n",
      "Iteration 7870, the loss is 4.442349374000705, parameters k is 10.306042258419799 and b is -42.0992464597239\n",
      "Iteration 7871, the loss is 4.442349358226323, parameters k is 10.306041869091736 and b is -42.09924250715473\n",
      "Iteration 7872, the loss is 4.442349342451945, parameters k is 10.306041479763673 and b is -42.099238554585554\n",
      "Iteration 7873, the loss is 4.442349326677566, parameters k is 10.30604109043561 and b is -42.09923460201638\n",
      "Iteration 7874, the loss is 4.442349310903185, parameters k is 10.306040701107547 and b is -42.09923064944721\n",
      "Iteration 7875, the loss is 4.4423492951288095, parameters k is 10.306040311779483 and b is -42.099226696878034\n",
      "Iteration 7876, the loss is 4.4423492793544295, parameters k is 10.30603992245142 and b is -42.09922274430886\n",
      "Iteration 7877, the loss is 4.4423492635800494, parameters k is 10.306039533123357 and b is -42.09921879173969\n",
      "Iteration 7878, the loss is 4.4423492478056685, parameters k is 10.306039143795294 and b is -42.099214839170514\n",
      "Iteration 7879, the loss is 4.442349232031292, parameters k is 10.306038754467231 and b is -42.09921088660134\n",
      "Iteration 7880, the loss is 4.442349216256912, parameters k is 10.306038365139168 and b is -42.09920693403217\n",
      "Iteration 7881, the loss is 4.44234920048253, parameters k is 10.306037975811105 and b is -42.099202981462994\n",
      "Iteration 7882, the loss is 4.442349184708151, parameters k is 10.306037586483042 and b is -42.09919902889382\n",
      "Iteration 7883, the loss is 4.442349168933772, parameters k is 10.306037197154978 and b is -42.09919507632465\n",
      "Iteration 7884, the loss is 4.442349153159392, parameters k is 10.306036807826915 and b is -42.099191123755475\n",
      "Iteration 7885, the loss is 4.442349137385012, parameters k is 10.306036418498852 and b is -42.0991871711863\n",
      "Iteration 7886, the loss is 4.442349121610633, parameters k is 10.306036029170789 and b is -42.09918321861713\n",
      "Iteration 7887, the loss is 4.4423491058362545, parameters k is 10.306035639842726 and b is -42.099179266047955\n",
      "Iteration 7888, the loss is 4.442349090061876, parameters k is 10.306035250514663 and b is -42.09917531347878\n",
      "Iteration 7889, the loss is 4.442349074287498, parameters k is 10.3060348611866 and b is -42.09917136090961\n",
      "Iteration 7890, the loss is 4.442349058513115, parameters k is 10.306034471858537 and b is -42.099167408340435\n",
      "Iteration 7891, the loss is 4.442349042738736, parameters k is 10.306034082530473 and b is -42.09916345577126\n",
      "Iteration 7892, the loss is 4.442349026964357, parameters k is 10.30603369320241 and b is -42.09915950320209\n",
      "Iteration 7893, the loss is 4.44234901118998, parameters k is 10.306033303874347 and b is -42.099155550632915\n",
      "Iteration 7894, the loss is 4.4423489954156, parameters k is 10.306032914546284 and b is -42.09915159806374\n",
      "Iteration 7895, the loss is 4.4423489796412206, parameters k is 10.306032525218221 and b is -42.09914764549457\n",
      "Iteration 7896, the loss is 4.4423489638668405, parameters k is 10.306032135890158 and b is -42.099143692925395\n",
      "Iteration 7897, the loss is 4.442348948092462, parameters k is 10.306031746562095 and b is -42.09913974035622\n",
      "Iteration 7898, the loss is 4.442348932318081, parameters k is 10.306031357234032 and b is -42.09913578778705\n",
      "Iteration 7899, the loss is 4.442348916543703, parameters k is 10.306030967905969 and b is -42.099131835217875\n",
      "Iteration 7900, the loss is 4.442348900769323, parameters k is 10.306030578577905 and b is -42.0991278826487\n",
      "Iteration 7901, the loss is 4.442348884994946, parameters k is 10.306030189249842 and b is -42.09912393007953\n",
      "Iteration 7902, the loss is 4.442348869220564, parameters k is 10.30602979992178 and b is -42.099119977510355\n",
      "Iteration 7903, the loss is 4.442348853446186, parameters k is 10.306029410593716 and b is -42.09911602494118\n",
      "Iteration 7904, the loss is 4.442348837671804, parameters k is 10.306029021265653 and b is -42.09911207237201\n",
      "Iteration 7905, the loss is 4.442348821897425, parameters k is 10.30602863193759 and b is -42.099108119802835\n",
      "Iteration 7906, the loss is 4.442348806123046, parameters k is 10.306028242609527 and b is -42.09910416723366\n",
      "Iteration 7907, the loss is 4.442348790348667, parameters k is 10.306027853281464 and b is -42.09910021466449\n",
      "Iteration 7908, the loss is 4.442348774574289, parameters k is 10.3060274639534 and b is -42.099096262095316\n",
      "Iteration 7909, the loss is 4.442348758799908, parameters k is 10.306027074625337 and b is -42.09909230952614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7910, the loss is 4.442348743025528, parameters k is 10.306026685297274 and b is -42.09908835695697\n",
      "Iteration 7911, the loss is 4.442348727251149, parameters k is 10.306026295969211 and b is -42.099084404387796\n",
      "Iteration 7912, the loss is 4.442348711476771, parameters k is 10.306025906641148 and b is -42.09908045181862\n",
      "Iteration 7913, the loss is 4.4423486957023925, parameters k is 10.306025517313085 and b is -42.09907649924945\n",
      "Iteration 7914, the loss is 4.4423486799280125, parameters k is 10.306025127985022 and b is -42.099072546680276\n",
      "Iteration 7915, the loss is 4.442348664153633, parameters k is 10.306024738656959 and b is -42.0990685941111\n",
      "Iteration 7916, the loss is 4.4423486483792525, parameters k is 10.306024349328895 and b is -42.09906464154193\n",
      "Iteration 7917, the loss is 4.4423486326048724, parameters k is 10.306023960000832 and b is -42.099060688972756\n",
      "Iteration 7918, the loss is 4.442348616830492, parameters k is 10.30602357067277 and b is -42.09905673640358\n",
      "Iteration 7919, the loss is 4.442348601056118, parameters k is 10.306023181344706 and b is -42.09905278383441\n",
      "Iteration 7920, the loss is 4.442348585281735, parameters k is 10.306022792016643 and b is -42.099048831265236\n",
      "Iteration 7921, the loss is 4.442348569507355, parameters k is 10.30602240268858 and b is -42.09904487869606\n",
      "Iteration 7922, the loss is 4.442348553732976, parameters k is 10.306022013360517 and b is -42.09904092612689\n",
      "Iteration 7923, the loss is 4.442348537958596, parameters k is 10.306021624032454 and b is -42.099036973557716\n",
      "Iteration 7924, the loss is 4.442348522184218, parameters k is 10.30602123470439 and b is -42.09903302098854\n",
      "Iteration 7925, the loss is 4.442348506409839, parameters k is 10.306020845376327 and b is -42.09902906841937\n",
      "Iteration 7926, the loss is 4.4423484906354584, parameters k is 10.306020456048264 and b is -42.099025115850196\n",
      "Iteration 7927, the loss is 4.44234847486108, parameters k is 10.306020066720201 and b is -42.09902116328102\n",
      "Iteration 7928, the loss is 4.442348459086698, parameters k is 10.306019677392138 and b is -42.09901721071185\n",
      "Iteration 7929, the loss is 4.442348443312319, parameters k is 10.306019288064075 and b is -42.099013258142676\n",
      "Iteration 7930, the loss is 4.442348427537939, parameters k is 10.306018898736012 and b is -42.0990093055735\n",
      "Iteration 7931, the loss is 4.44234841176356, parameters k is 10.306018509407949 and b is -42.09900535300433\n",
      "Iteration 7932, the loss is 4.442348395989184, parameters k is 10.306018120079885 and b is -42.09900140043516\n",
      "Iteration 7933, the loss is 4.442348380214803, parameters k is 10.306017730751822 and b is -42.09899744786598\n",
      "Iteration 7934, the loss is 4.4423483644404245, parameters k is 10.30601734142376 and b is -42.09899349529681\n",
      "Iteration 7935, the loss is 4.4423483486660444, parameters k is 10.306016952095696 and b is -42.09898954272764\n",
      "Iteration 7936, the loss is 4.442348332891664, parameters k is 10.306016562767633 and b is -42.09898559015846\n",
      "Iteration 7937, the loss is 4.4423483171172835, parameters k is 10.30601617343957 and b is -42.09898163758929\n",
      "Iteration 7938, the loss is 4.442348301342907, parameters k is 10.306015784111507 and b is -42.09897768502012\n",
      "Iteration 7939, the loss is 4.442348285568526, parameters k is 10.306015394783444 and b is -42.09897373245094\n",
      "Iteration 7940, the loss is 4.442348269794146, parameters k is 10.30601500545538 and b is -42.09896977988177\n",
      "Iteration 7941, the loss is 4.442348254019769, parameters k is 10.306014616127317 and b is -42.0989658273126\n",
      "Iteration 7942, the loss is 4.442348238245389, parameters k is 10.306014226799254 and b is -42.09896187474342\n",
      "Iteration 7943, the loss is 4.442348222471009, parameters k is 10.306013837471191 and b is -42.09895792217425\n",
      "Iteration 7944, the loss is 4.442348206696631, parameters k is 10.306013448143128 and b is -42.09895396960508\n",
      "Iteration 7945, the loss is 4.4423481909222495, parameters k is 10.306013058815065 and b is -42.098950017035904\n",
      "Iteration 7946, the loss is 4.44234817514787, parameters k is 10.306012669487002 and b is -42.09894606446673\n",
      "Iteration 7947, the loss is 4.442348159373495, parameters k is 10.306012280158939 and b is -42.09894211189756\n",
      "Iteration 7948, the loss is 4.442348143599112, parameters k is 10.306011890830876 and b is -42.098938159328384\n",
      "Iteration 7949, the loss is 4.442348127824731, parameters k is 10.306011501502812 and b is -42.09893420675921\n",
      "Iteration 7950, the loss is 4.442348112050352, parameters k is 10.30601111217475 and b is -42.09893025419004\n",
      "Iteration 7951, the loss is 4.442348096275973, parameters k is 10.306010722846686 and b is -42.098926301620864\n",
      "Iteration 7952, the loss is 4.4423480805015965, parameters k is 10.306010333518623 and b is -42.09892234905169\n",
      "Iteration 7953, the loss is 4.442348064727216, parameters k is 10.30600994419056 and b is -42.09891839648252\n",
      "Iteration 7954, the loss is 4.442348048952837, parameters k is 10.306009554862497 and b is -42.098914443913344\n",
      "Iteration 7955, the loss is 4.442348033178456, parameters k is 10.306009165534434 and b is -42.09891049134417\n",
      "Iteration 7956, the loss is 4.442348017404073, parameters k is 10.30600877620637 and b is -42.098906538775\n",
      "Iteration 7957, the loss is 4.442348001629696, parameters k is 10.306008386878307 and b is -42.098902586205824\n",
      "Iteration 7958, the loss is 4.442347985855318, parameters k is 10.306007997550244 and b is -42.09889863363665\n",
      "Iteration 7959, the loss is 4.442347971066448, parameters k is 10.306007608222181 and b is -42.09889468106748\n",
      "Iteration 7960, the loss is 4.442347959223609, parameters k is 10.305979720870402 and b is -42.09889468106748\n",
      "Iteration 7961, the loss is 4.44234794344923, parameters k is 10.30597933154234 and b is -42.098890728498304\n",
      "Iteration 7962, the loss is 4.442347927674851, parameters k is 10.305978942214276 and b is -42.09888677592913\n",
      "Iteration 7963, the loss is 4.4423479119004705, parameters k is 10.305978552886213 and b is -42.09888282335996\n",
      "Iteration 7964, the loss is 4.442347896126092, parameters k is 10.30597816355815 and b is -42.098878870790784\n",
      "Iteration 7965, the loss is 4.442347880351714, parameters k is 10.305977774230087 and b is -42.09887491822161\n",
      "Iteration 7966, the loss is 4.442347864577332, parameters k is 10.305977384902024 and b is -42.09887096565244\n",
      "Iteration 7967, the loss is 4.442347848802955, parameters k is 10.30597699557396 and b is -42.098867013083265\n",
      "Iteration 7968, the loss is 4.442347833028573, parameters k is 10.305976606245897 and b is -42.09886306051409\n",
      "Iteration 7969, the loss is 4.442347817254194, parameters k is 10.305976216917834 and b is -42.09885910794492\n",
      "Iteration 7970, the loss is 4.442347801479814, parameters k is 10.305975827589771 and b is -42.098855155375745\n",
      "Iteration 7971, the loss is 4.442347785705436, parameters k is 10.305975438261708 and b is -42.09885120280657\n",
      "Iteration 7972, the loss is 4.442347769931057, parameters k is 10.305975048933645 and b is -42.0988472502374\n",
      "Iteration 7973, the loss is 4.442347754156677, parameters k is 10.305974659605582 and b is -42.098843297668225\n",
      "Iteration 7974, the loss is 4.442347738382299, parameters k is 10.305974270277519 and b is -42.09883934509905\n",
      "Iteration 7975, the loss is 4.442347722607918, parameters k is 10.305973880949455 and b is -42.09883539252988\n",
      "Iteration 7976, the loss is 4.442347706833538, parameters k is 10.305973491621392 and b is -42.098831439960705\n",
      "Iteration 7977, the loss is 4.442347691059159, parameters k is 10.30597310229333 and b is -42.09882748739153\n",
      "Iteration 7978, the loss is 4.442347675284781, parameters k is 10.305972712965266 and b is -42.09882353482236\n",
      "Iteration 7979, the loss is 4.442347659510401, parameters k is 10.305972323637203 and b is -42.098819582253185\n",
      "Iteration 7980, the loss is 4.4423476437360225, parameters k is 10.30597193430914 and b is -42.09881562968401\n",
      "Iteration 7981, the loss is 4.442347627961643, parameters k is 10.305971544981077 and b is -42.09881167711484\n",
      "Iteration 7982, the loss is 4.4423476121872625, parameters k is 10.305971155653014 and b is -42.098807724545665\n",
      "Iteration 7983, the loss is 4.4423475964128825, parameters k is 10.30597076632495 and b is -42.09880377197649\n",
      "Iteration 7984, the loss is 4.442347580638503, parameters k is 10.305970376996887 and b is -42.09879981940732\n",
      "Iteration 7985, the loss is 4.4423475648641215, parameters k is 10.305969987668824 and b is -42.098795866838145\n",
      "Iteration 7986, the loss is 4.442347549089745, parameters k is 10.305969598340761 and b is -42.09879191426897\n",
      "Iteration 7987, the loss is 4.442347533315366, parameters k is 10.305969209012698 and b is -42.0987879616998\n",
      "Iteration 7988, the loss is 4.442347517540986, parameters k is 10.305968819684635 and b is -42.098784009130625\n",
      "Iteration 7989, the loss is 4.442347501766606, parameters k is 10.305968430356572 and b is -42.09878005656145\n",
      "Iteration 7990, the loss is 4.442347485992228, parameters k is 10.305968041028509 and b is -42.09877610399228\n",
      "Iteration 7991, the loss is 4.442347470217847, parameters k is 10.305967651700445 and b is -42.098772151423105\n",
      "Iteration 7992, the loss is 4.442347454443468, parameters k is 10.305967262372382 and b is -42.09876819885393\n",
      "Iteration 7993, the loss is 4.44234743866909, parameters k is 10.30596687304432 and b is -42.09876424628476\n",
      "Iteration 7994, the loss is 4.442347422894709, parameters k is 10.305966483716256 and b is -42.098760293715586\n",
      "Iteration 7995, the loss is 4.44234740712033, parameters k is 10.305966094388193 and b is -42.09875634114641\n",
      "Iteration 7996, the loss is 4.442347391345954, parameters k is 10.30596570506013 and b is -42.09875238857724\n",
      "Iteration 7997, the loss is 4.442347375571571, parameters k is 10.305965315732067 and b is -42.098748436008066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7998, the loss is 4.442347359797191, parameters k is 10.305964926404004 and b is -42.09874448343889\n",
      "Iteration 7999, the loss is 4.442347344022814, parameters k is 10.30596453707594 and b is -42.09874053086972\n"
     ]
    }
   ],
   "source": [
    "#initialized parameters\n",
    "\n",
    "k = random.random() * 200 - 100  # -100 100\n",
    "b = random.random() * 200 - 100  # -100 100\n",
    "\n",
    "learning_rate = 1e-3\n",
    "\n",
    "iteration_num = 8000\n",
    "losses = []\n",
    "for i in range(iteration_num):\n",
    "    \n",
    "    price_use_current_parameters = [price(r, k, b) for r in X_rm]  # \\hat{y}\n",
    "    \n",
    "    current_loss = loss(y, price_use_current_parameters)\n",
    "    losses.append(current_loss)\n",
    "    print(\"Iteration {}, the loss is {}, parameters k is {} and b is {}\".format(i,current_loss,k,b))\n",
    "    \n",
    "    k_gradient = partial_derivative_k(X_rm, y, price_use_current_parameters)\n",
    "    b_gradient = partial_derivative_b(y, price_use_current_parameters)\n",
    "    \n",
    "    k = k + (-1 * k_gradient) * learning_rate\n",
    "    b = b + (-1 * b_gradient) * learning_rate\n",
    "best_k = k\n",
    "best_b = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xe468048>]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(iteration_num)),losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0xe3f4f60>"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_use_best_parameters = [price(r, best_k, best_b) for r in X_rm]\n",
    "\n",
    "plt.scatter(X_rm,y)\n",
    "plt.scatter(X_rm,price_use_current_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "绝对值loss函数 VS 平方loss函数\n",
    "\n",
    "迭代次数上：  平方loss，迭代200次； 大概50次左右收敛；\n",
    "          绝对值loss，迭代了8000次，大概在2000次左右收敛；\n",
    "          \n",
    "损失曲线上可以看出， 平方loss 是按指数级下降； 绝对值loss是线性下降\n",
    "\n",
    "性能上：平方loss函数的下降收敛速度更快\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
