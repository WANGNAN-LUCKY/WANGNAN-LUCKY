{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征：节点与节点前后的迭代关系（后一层的输入是前一层的输出）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:                         #创建一个 Node的 类\n",
    "    def __init__(self, inputs=[]):  # self 实例，inputs是实例属性\n",
    "        self.inputs = inputs        # inputs为要输入的列表； self对象等于inputs\n",
    "        self.outputs = []           # self.outputs 默认为空列表\n",
    "        for n in self.inputs:       \n",
    "            n.outputs.append(self)  # 实现上一个节点的输出是下个节点的输入\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "        self.value = None          # 节点值\n",
    "        self.gradients = {}        # 节点梯度\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "        raise NotImplemented\n",
    "    \n",
    "    def backward(self):\n",
    "        raise NotImplemented\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征：输入层的节点(只能向前传播，不接收)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.   作为输入节点，所以不需要传输节点 instatiator ？？\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None): \n",
    "        '''  向前传播\n",
    "        Only input node is the node where the value may be passed    只有输入节点是可以传递值的节点作为forward（）的参数。\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the   所有其他节点实现都应该获得来自self.inbound_节点的上一个节点\n",
    "        previous node from self.inbound_nodes        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.  第一层输入，初始值应该是它本身\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        # 输入子类只保存一个值，如数据特征或模型参数（权重/偏差）\n",
    "    def backward(self):\n",
    "        self.gradients = {self:0} # initialization   初始化self梯度\n",
    "        for n in self.outputs:     #遍历 实例的 输出\n",
    "            grad_cost = n.gradients[self]   \n",
    "            self.gradients[self] = grad_cost * 1\n",
    "            \n",
    "        \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征： 节点的线性计算y = wx+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):   #实例的属性值包括（节点（上一层的输出结果），权重w，偏差b）\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value         #输入的是inputs列表中第一个元素的值 \n",
    "        weights = self.inputs[1].value        #权重是 inputs列表中第二个元素的值\n",
    "        bias = self.inputs[2].value           #bias 是 inputs列表中第三个元素的值 \n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias  #矩阵乘法 inputs × weights （1×n乘 n×1 等于1个数值） + bias\n",
    "        \n",
    "    def backward(self):\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T) #反向传播组合\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost) #反向传播组合\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False) #反向传播组合\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征： 节点的sigmoid激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value   # [0] input is a list\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征：loss function MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征： 向前，向后传播函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forward_and_backward(outputnode, graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "    #return outputnode.value\n",
    "\n",
    "###   v -->  a -->  C\n",
    "##    b --> C\n",
    "##    b --> v -- a --> C\n",
    "##    v --> v ---> a -- > C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "表征：拓扑排序\n",
    "\n",
    "用Kahn算法对一般节点进行拓扑排序。feed_dict`：一个字典，其中键是一个“Input”节点，值是该节点的相应值feed。返回已排序节点的列表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "\n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "沿着梯度方向，学习率 1e-2，更新参数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n",
      "Epoch: 1, Loss: 217.667\n",
      "Epoch: 101, Loss: 7.928\n",
      "Epoch: 201, Loss: 5.697\n",
      "Epoch: 301, Loss: 5.325\n",
      "Epoch: 401, Loss: 4.277\n",
      "Epoch: 501, Loss: 4.422\n",
      "Epoch: 601, Loss: 4.841\n",
      "Epoch: 701, Loss: 4.334\n",
      "Epoch: 801, Loss: 4.773\n",
      "Epoch: 901, Loss: 3.992\n",
      "Epoch: 1001, Loss: 3.874\n",
      "Epoch: 1101, Loss: 4.101\n",
      "Epoch: 1201, Loss: 3.866\n",
      "Epoch: 1301, Loss: 3.697\n",
      "Epoch: 1401, Loss: 3.910\n",
      "Epoch: 1501, Loss: 3.303\n",
      "Epoch: 1601, Loss: 3.662\n",
      "Epoch: 1701, Loss: 3.741\n",
      "Epoch: 1801, Loss: 3.798\n",
      "Epoch: 1901, Loss: 3.706\n",
      "Epoch: 2001, Loss: 3.666\n",
      "Epoch: 2101, Loss: 4.041\n",
      "Epoch: 2201, Loss: 3.722\n",
      "Epoch: 2301, Loss: 3.737\n",
      "Epoch: 2401, Loss: 3.909\n",
      "Epoch: 2501, Loss: 3.771\n",
      "Epoch: 2601, Loss: 3.659\n",
      "Epoch: 2701, Loss: 3.813\n",
      "Epoch: 2801, Loss: 2.905\n",
      "Epoch: 2901, Loss: 3.421\n",
      "Epoch: 3001, Loss: 3.399\n",
      "Epoch: 3101, Loss: 3.921\n",
      "Epoch: 3201, Loss: 3.510\n",
      "Epoch: 3301, Loss: 3.754\n",
      "Epoch: 3401, Loss: 3.191\n",
      "Epoch: 3501, Loss: 3.462\n",
      "Epoch: 3601, Loss: 3.963\n",
      "Epoch: 3701, Loss: 3.157\n",
      "Epoch: 3801, Loss: 3.571\n",
      "Epoch: 3901, Loss: 3.591\n",
      "Epoch: 4001, Loss: 3.463\n",
      "Epoch: 4101, Loss: 3.133\n",
      "Epoch: 4201, Loss: 3.628\n",
      "Epoch: 4301, Loss: 3.476\n",
      "Epoch: 4401, Loss: 3.314\n",
      "Epoch: 4501, Loss: 3.266\n",
      "Epoch: 4601, Loss: 3.675\n",
      "Epoch: 4701, Loss: 3.185\n",
      "Epoch: 4801, Loss: 3.050\n",
      "Epoch: 4901, Loss: 3.800\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Check out the new network architecture and dataset!\n",
    "Notice that the weights and biases are\n",
    "generated randomly.\n",
    "No need to change anything, but feel free to tweak\n",
    "to test your network, play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data  #标准化\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000   #迭代5000次\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(outputNode,graph):\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "    return outputNode.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20.93267421],\n",
       "       [49.35036771],\n",
       "       [33.29664394],\n",
       "       [15.20626827],\n",
       "       [30.18593599],\n",
       "       [13.07325767],\n",
       "       [17.02880881],\n",
       "       [20.63705905],\n",
       "       [18.68481838],\n",
       "       [31.00998823],\n",
       "       [23.93937779],\n",
       "       [10.45296923],\n",
       "       [23.54223323],\n",
       "       [17.41337829],\n",
       "       [32.71856478],\n",
       "       [24.98264937]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward(l2,graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11e9ad68>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.16470261],\n",
       "       [ 4.39189181],\n",
       "       [ 8.94895531],\n",
       "       [11.56667321],\n",
       "       [-4.64983392],\n",
       "       [11.18344666],\n",
       "       [11.64152758],\n",
       "       [ 9.02670822],\n",
       "       [ 6.07092023],\n",
       "       [-3.68203322]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
